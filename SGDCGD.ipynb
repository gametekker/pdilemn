{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1 Beliefs: {'CC': tensor(1.7346), 'CB': tensor(-2.9444), 'BC': tensor(-2.9444), 'BB': tensor(-2.9444)}\n",
      "Player 2 Beliefs: {'CC': tensor(1.7346), 'CB': tensor(-2.9444), 'BC': tensor(-2.9444), 'BB': tensor(-2.9444)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from modules.utility import generate_player_beliefs, doplots\n",
    "\n",
    "# Example usage - make the starting probas\n",
    "import torch\n",
    "probabilities1 = torch.tensor([0.85, 0.05, 0.05, 0.05])\n",
    "probabilities2 = torch.tensor([0.85, 0.05, 0.05, 0.05])\n",
    "logits1 = torch.log(probabilities1 / (1 - probabilities1))\n",
    "logits2 = torch.log(probabilities2 / (1 - probabilities2))\n",
    "states = ['CC','CB','BC','BB']\n",
    "P1_beliefs, P2_beliefs = dict(zip(states,logits1)), dict(zip(states,logits2))\n",
    "\n",
    "# Define the rewards and payoffs\n",
    "r1, r2 = 3, 3  # Reward for mutual cooperation\n",
    "t1, t2 = 5, 5  # Temptation payoff\n",
    "p1, p2 = 0, 0  # Punishment payoff\n",
    "s1, s2 = 1, 1  # Sucker's payoff\n",
    "gamma = 0.9    # Discount rate\n",
    "\n",
    "# Define the rewards matrix\n",
    "rewards_matrix = np.array([\n",
    "    [r1, r2],  # Payoffs for when both cooperate\n",
    "    [t1, p2],  # Payoffs for when one defects and the other cooperates\n",
    "    [p1, t2],  # Payoffs for when one defects and the other cooperates\n",
    "    [s1, s2]   # Payoffs for when both defect\n",
    "])\n",
    "\n",
    "print(\"Player 1 Beliefs:\", P1_beliefs)\n",
    "print(\"Player 2 Beliefs:\", P2_beliefs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 0, 1]\n",
      "[3, 0, 5, 1]\n",
      "tensor([0.8500, 0.0500, 0.0500, 0.0500], grad_fn=<SigmoidBackward0>)\n",
      "grim trigger - expected cumulative rewards with cooperate,cooperate start\n",
      "player 1: 17.7195987701416\n",
      "player 2: 17.7195987701416\n",
      "grim trigger - expected cumulative rewards with cooperate,betray start\n",
      "player 1: 15.424144744873047\n",
      "player 2: 10.424144744873047\n",
      "grim trigger - expected cumulative rewards with betray,cooperate start\n",
      "player 1: 10.424144744873047\n",
      "player 2: 15.424144744873047\n",
      "grim trigger - expected cumulative rewards with betray,betray start\n",
      "player 1: 11.42414379119873\n",
      "player 2: 11.42414379119873\n",
      "tensor([[17.7196, 17.7196],\n",
      "        [15.4241, 10.4241],\n",
      "        [10.4241, 15.4241],\n",
      "        [11.4241, 11.4241]], grad_fn=<MmBackward0>)\n",
      "done testing\n",
      "player 1 reward: tensor([[17.7196, 17.7196],\n",
      "        [15.4241, 10.4241],\n",
      "        [10.4241, 15.4241],\n",
      "        [11.4241, 11.4241]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8500, 0.0500, 0.0500, 0.0500], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.7361, 17.7168],\n",
      "        [15.4457, 10.4198],\n",
      "        [10.4453, 15.4199],\n",
      "        [11.4478, 11.4194]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8501, 0.0501, 0.0500, 0.0507], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.7333, 17.7333],\n",
      "        [15.4414, 10.4414],\n",
      "        [10.4411, 15.4411],\n",
      "        [11.4430, 11.4430]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8501, 0.0501, 0.0500, 0.0507], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.7502, 17.7305],\n",
      "        [15.4634, 10.4370],\n",
      "        [10.4628, 15.4368],\n",
      "        [11.4672, 11.4382]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8501, 0.0502, 0.0501, 0.0514], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.7474, 17.7474],\n",
      "        [15.4590, 10.4590],\n",
      "        [10.4585, 15.4585],\n",
      "        [11.4624, 11.4624]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8501, 0.0502, 0.0501, 0.0514], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.7646, 17.7445],\n",
      "        [15.4815, 10.4545],\n",
      "        [10.4807, 15.4540],\n",
      "        [11.4872, 11.4575]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8502, 0.0504, 0.0501, 0.0521], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.7617, 17.7617],\n",
      "        [15.4770, 10.4770],\n",
      "        [10.4762, 15.4762],\n",
      "        [11.4822, 11.4822]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8502, 0.0504, 0.0501, 0.0521], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.7794, 17.7588],\n",
      "        [15.5001, 10.4724],\n",
      "        [10.4990, 15.4717],\n",
      "        [11.5076, 11.4772]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8503, 0.0505, 0.0501, 0.0529], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.7764, 17.7765],\n",
      "        [15.4955, 10.4955],\n",
      "        [10.4944, 15.4944],\n",
      "        [11.5025, 11.5025]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8503, 0.0505, 0.0501, 0.0529], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.7945, 17.7734],\n",
      "        [15.5191, 10.4907],\n",
      "        [10.5177, 15.4898],\n",
      "        [11.5285, 11.4973]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8503, 0.0506, 0.0502, 0.0536], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.7915, 17.7915],\n",
      "        [15.5144, 10.5144],\n",
      "        [10.5131, 15.5131],\n",
      "        [11.5233, 11.5233]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8503, 0.0506, 0.0502, 0.0536], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.8100, 17.7884],\n",
      "        [15.5385, 10.5095],\n",
      "        [10.5370, 15.5083],\n",
      "        [11.5500, 11.5180]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8504, 0.0507, 0.0502, 0.0544], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.8069, 17.8069],\n",
      "        [15.5337, 10.5337],\n",
      "        [10.5322, 15.5322],\n",
      "        [11.5446, 11.5446]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8504, 0.0507, 0.0502, 0.0544], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.8259, 17.8038],\n",
      "        [15.5585, 10.5288],\n",
      "        [10.5566, 15.5273],\n",
      "        [11.5719, 11.5392]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8505, 0.0509, 0.0503, 0.0552], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.8227, 17.8228],\n",
      "        [15.5536, 10.5535],\n",
      "        [10.5518, 15.5517],\n",
      "        [11.5665, 11.5665]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8505, 0.0509, 0.0503, 0.0552], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.8421, 17.8195],\n",
      "        [15.5789, 10.5485],\n",
      "        [10.5768, 15.5468],\n",
      "        [11.5944, 11.5609]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8506, 0.0510, 0.0503, 0.0560], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.8389, 17.8389],\n",
      "        [15.5739, 10.5739],\n",
      "        [10.5718, 15.5718],\n",
      "        [11.5889, 11.5888]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8506, 0.0510, 0.0503, 0.0560], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.8588, 17.8356],\n",
      "        [15.5999, 10.5687],\n",
      "        [10.5975, 15.5667],\n",
      "        [11.6175, 11.5831]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8506, 0.0511, 0.0503, 0.0569], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.8555, 17.8555],\n",
      "        [15.5947, 10.5947],\n",
      "        [10.5924, 15.5923],\n",
      "        [11.6118, 11.6118]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8506, 0.0511, 0.0503, 0.0569], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.8759, 17.8521],\n",
      "        [15.6214, 10.5894],\n",
      "        [10.6187, 15.5871],\n",
      "        [11.6412, 11.6059]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8507, 0.0513, 0.0504, 0.0577], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.8725, 17.8725],\n",
      "        [15.6161, 10.6160],\n",
      "        [10.6135, 15.6134],\n",
      "        [11.6354, 11.6353]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8507, 0.0513, 0.0504, 0.0577], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.8934, 17.8690],\n",
      "        [15.6434, 10.6106],\n",
      "        [10.6405, 15.6081],\n",
      "        [11.6655, 11.6293]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8508, 0.0514, 0.0504, 0.0586], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.8899, 17.8900],\n",
      "        [15.6380, 10.6379],\n",
      "        [10.6351, 15.6350],\n",
      "        [11.6595, 11.6594]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8508, 0.0514, 0.0504, 0.0586], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.9114, 17.8864],\n",
      "        [15.6660, 10.6323],\n",
      "        [10.6629, 15.6296],\n",
      "        [11.6905, 11.6533]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8509, 0.0515, 0.0505, 0.0595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.9078, 17.9078],\n",
      "        [15.6604, 10.6604],\n",
      "        [10.6573, 15.6572],\n",
      "        [11.6843, 11.6842]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8509, 0.0515, 0.0505, 0.0595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.9298, 17.9042],\n",
      "        [15.6892, 10.6547],\n",
      "        [10.6858, 15.6516],\n",
      "        [11.7161, 11.6779]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8510, 0.0517, 0.0505, 0.0605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.9261, 17.9262],\n",
      "        [15.6835, 10.6834],\n",
      "        [10.6801, 15.6800],\n",
      "        [11.7097, 11.7096]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8510, 0.0517, 0.0505, 0.0605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.9487, 17.9224],\n",
      "        [15.7130, 10.6775],\n",
      "        [10.7093, 15.6742],\n",
      "        [11.7423, 11.7031]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8510, 0.0518, 0.0506, 0.0614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.9449, 17.9450],\n",
      "        [15.7071, 10.7070],\n",
      "        [10.7035, 15.7033],\n",
      "        [11.7358, 11.7356]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8510, 0.0518, 0.0506, 0.0614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.9681, 17.9411],\n",
      "        [15.7374, 10.7010],\n",
      "        [10.7335, 15.6974],\n",
      "        [11.7693, 11.7290]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8511, 0.0519, 0.0506, 0.0624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.9642, 17.9643],\n",
      "        [15.7314, 10.7312],\n",
      "        [10.7275, 15.7273],\n",
      "        [11.7627, 11.7624]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8511, 0.0519, 0.0506, 0.0624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[17.9881, 17.9603],\n",
      "        [15.7625, 10.7251],\n",
      "        [10.7583, 15.7212],\n",
      "        [11.7970, 11.7556]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8512, 0.0521, 0.0506, 0.0634], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[17.9841, 17.9841],\n",
      "        [15.7563, 10.7561],\n",
      "        [10.7522, 15.7519],\n",
      "        [11.7902, 11.7899]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8512, 0.0521, 0.0506, 0.0634], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.0085, 17.9800],\n",
      "        [15.7882, 10.7498],\n",
      "        [10.7837, 15.7457],\n",
      "        [11.8254, 11.7829]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8513, 0.0522, 0.0507, 0.0645], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.0044, 18.0044],\n",
      "        [15.7819, 10.7816],\n",
      "        [10.7775, 15.7772],\n",
      "        [11.8185, 11.8181]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8513, 0.0522, 0.0507, 0.0645], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.0295, 18.0002],\n",
      "        [15.8147, 10.7752],\n",
      "        [10.8099, 15.7708],\n",
      "        [11.8547, 11.8110]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8514, 0.0523, 0.0507, 0.0656], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.0253, 18.0253],\n",
      "        [15.8082, 10.8079],\n",
      "        [10.8035, 15.8031],\n",
      "        [11.8475, 11.8471]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8514, 0.0523, 0.0507, 0.0656], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.0511, 18.0210],\n",
      "        [15.8418, 10.8012],\n",
      "        [10.8368, 15.7966],\n",
      "        [11.8847, 11.8398]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8515, 0.0525, 0.0508, 0.0667], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.0468, 18.0468],\n",
      "        [15.8352, 10.8348],\n",
      "        [10.8302, 15.8298],\n",
      "        [11.8773, 11.8769]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8515, 0.0525, 0.0508, 0.0667], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.0733, 18.0424],\n",
      "        [15.8697, 10.8280],\n",
      "        [10.8644, 15.8231],\n",
      "        [11.9156, 11.8694]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8516, 0.0526, 0.0508, 0.0678], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.0688, 18.0688],\n",
      "        [15.8629, 10.8625],\n",
      "        [10.8577, 15.8572],\n",
      "        [11.9080, 11.9075]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8516, 0.0526, 0.0508, 0.0678], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.0961, 18.0643],\n",
      "        [15.8984, 10.8555],\n",
      "        [10.8929, 15.8503],\n",
      "        [11.9474, 11.8998]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8517, 0.0528, 0.0509, 0.0690], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.0915, 18.0914],\n",
      "        [15.8914, 10.8909],\n",
      "        [10.8859, 15.8854],\n",
      "        [11.9396, 11.9390]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8517, 0.0528, 0.0509, 0.0690], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.1195, 18.0868],\n",
      "        [15.9279, 10.8837],\n",
      "        [10.9221, 15.8783],\n",
      "        [11.9800, 11.9311]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8518, 0.0529, 0.0509, 0.0702], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.1148, 18.1147],\n",
      "        [15.9207, 10.9202],\n",
      "        [10.9149, 15.9144],\n",
      "        [11.9720, 11.9714]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8518, 0.0529, 0.0509, 0.0702], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.1436, 18.1099],\n",
      "        [15.9582, 10.9128],\n",
      "        [10.9521, 15.9070],\n",
      "        [12.0136, 11.9632]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8519, 0.0531, 0.0510, 0.0715], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.1388, 18.1386],\n",
      "        [15.9508, 10.9502],\n",
      "        [10.9448, 15.9441],\n",
      "        [12.0054, 12.0047]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8519, 0.0531, 0.0510, 0.0715], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.1683, 18.1337],\n",
      "        [15.9894, 10.9426],\n",
      "        [10.9831, 15.9366],\n",
      "        [12.0482, 11.9963]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8520, 0.0532, 0.0510, 0.0728], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.1634, 18.1632],\n",
      "        [15.9818, 10.9811],\n",
      "        [10.9755, 15.9748],\n",
      "        [12.0397, 12.0389]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8520, 0.0532, 0.0510, 0.0728], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.1938, 18.1582],\n",
      "        [16.0215, 10.9733],\n",
      "        [11.0149, 15.9671],\n",
      "        [12.0837, 12.0303]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8522, 0.0533, 0.0511, 0.0741], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.1887, 18.1885],\n",
      "        [16.0137, 11.0129],\n",
      "        [11.0071, 16.0063],\n",
      "        [12.0751, 12.0741]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8522, 0.0533, 0.0511, 0.0741], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.2200, 18.1833],\n",
      "        [16.0545, 11.0049],\n",
      "        [11.0476, 15.9984],\n",
      "        [12.1203, 12.0653]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8523, 0.0535, 0.0511, 0.0755], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.2148, 18.2146],\n",
      "        [16.0465, 11.0456],\n",
      "        [11.0396, 16.0387],\n",
      "        [12.1114, 12.1104]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8523, 0.0535, 0.0511, 0.0755], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.2470, 18.2092],\n",
      "        [16.0885, 11.0374],\n",
      "        [11.0813, 16.0306],\n",
      "        [12.1580, 12.1013]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8524, 0.0537, 0.0512, 0.0769], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.2416, 18.2413],\n",
      "        [16.0803, 11.0793],\n",
      "        [11.0731, 16.0721],\n",
      "        [12.1489, 12.1477]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8524, 0.0537, 0.0512, 0.0769], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.2748, 18.2359],\n",
      "        [16.1235, 11.0708],\n",
      "        [11.1161, 16.0637],\n",
      "        [12.1969, 12.1383]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8525, 0.0538, 0.0512, 0.0784], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.2693, 18.2689],\n",
      "        [16.1150, 11.1139],\n",
      "        [11.1076, 16.1065],\n",
      "        [12.1874, 12.1862]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8525, 0.0538, 0.0512, 0.0784], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.3034, 18.2633],\n",
      "        [16.1595, 11.1052],\n",
      "        [11.1518, 16.0979],\n",
      "        [12.2369, 12.1765]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8527, 0.0540, 0.0513, 0.0799], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.2977, 18.2973],\n",
      "        [16.1508, 11.1496],\n",
      "        [11.1431, 16.1419],\n",
      "        [12.2272, 12.2257]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8527, 0.0540, 0.0513, 0.0799], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.3328, 18.2915],\n",
      "        [16.1966, 11.1407],\n",
      "        [11.1886, 16.1330],\n",
      "        [12.2780, 12.2158]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8528, 0.0541, 0.0513, 0.0814], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.3270, 18.3265],\n",
      "        [16.1876, 11.1863],\n",
      "        [11.1797, 16.1783],\n",
      "        [12.2681, 12.2665]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8528, 0.0541, 0.0513, 0.0814], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.3631, 18.3205],\n",
      "        [16.2349, 11.1771],\n",
      "        [11.2266, 16.1692],\n",
      "        [12.3205, 12.2563]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8529, 0.0543, 0.0514, 0.0831], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.3571, 18.3566],\n",
      "        [16.2256, 11.2242],\n",
      "        [11.2174, 16.2159],\n",
      "        [12.3102, 12.3085]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8529, 0.0543, 0.0514, 0.0831], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.3944, 18.3505],\n",
      "        [16.2743, 11.2147],\n",
      "        [11.2657, 16.2065],\n",
      "        [12.3643, 12.2980]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8531, 0.0544, 0.0514, 0.0847], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.3882, 18.3876],\n",
      "        [16.2647, 11.2631],\n",
      "        [11.2563, 16.2546],\n",
      "        [12.3537, 12.3518]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8531, 0.0544, 0.0514, 0.0847], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.4266, 18.3813],\n",
      "        [16.3149, 11.2534],\n",
      "        [11.3061, 16.2449],\n",
      "        [12.4094, 12.3410]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8532, 0.0546, 0.0515, 0.0864], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.4203, 18.4196],\n",
      "        [16.3051, 11.3033],\n",
      "        [11.2963, 16.2944],\n",
      "        [12.3985, 12.3964]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8532, 0.0546, 0.0515, 0.0864], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.4598, 18.4131],\n",
      "        [16.3567, 11.2932],\n",
      "        [11.3476, 16.2845],\n",
      "        [12.4559, 12.3853]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8534, 0.0548, 0.0516, 0.0882], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.4533, 18.4525],\n",
      "        [16.3466, 11.3447],\n",
      "        [11.3376, 16.3356],\n",
      "        [12.4447, 12.4424]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8534, 0.0548, 0.0516, 0.0882], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.4941, 18.4458],\n",
      "        [16.3999, 11.3343],\n",
      "        [11.3905, 16.3253],\n",
      "        [12.5039, 12.4309]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8535, 0.0549, 0.0516, 0.0901], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.4873, 18.4864],\n",
      "        [16.3895, 11.3873],\n",
      "        [11.3802, 16.3779],\n",
      "        [12.4924, 12.4898]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8535, 0.0549, 0.0516, 0.0901], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.5293, 18.4795],\n",
      "        [16.4444, 11.3767],\n",
      "        [11.4347, 16.3674],\n",
      "        [12.5534, 12.4780]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8537, 0.0551, 0.0517, 0.0920], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.5224, 18.5214],\n",
      "        [16.4337, 11.4313],\n",
      "        [11.4241, 16.4216],\n",
      "        [12.5415, 12.5387]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8537, 0.0551, 0.0517, 0.0920], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.5658, 18.5143],\n",
      "        [16.4903, 11.4204],\n",
      "        [11.4804, 16.4108],\n",
      "        [12.6045, 12.5266]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8539, 0.0553, 0.0517, 0.0939], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.5586, 18.5575],\n",
      "        [16.4792, 11.4767],\n",
      "        [11.4694, 16.4667],\n",
      "        [12.5922, 12.5892]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8539, 0.0553, 0.0517, 0.0939], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.6033, 18.5502],\n",
      "        [16.5376, 11.4654],\n",
      "        [11.5275, 16.4555],\n",
      "        [12.6572, 12.5767]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8541, 0.0554, 0.0518, 0.0960], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.5960, 18.5947],\n",
      "        [16.5263, 11.5235],\n",
      "        [11.5162, 16.5133],\n",
      "        [12.6446, 12.6413]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8541, 0.0554, 0.0518, 0.0960], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.6421, 18.5872],\n",
      "        [16.5865, 11.5118],\n",
      "        [11.5761, 16.5017],\n",
      "        [12.7116, 12.6284]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8542, 0.0556, 0.0519, 0.0981], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.6345, 18.6331],\n",
      "        [16.5748, 11.5717],\n",
      "        [11.5644, 16.5612],\n",
      "        [12.6986, 12.6950]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8542, 0.0556, 0.0519, 0.0981], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.6821, 18.6254],\n",
      "        [16.6369, 11.5598],\n",
      "        [11.6262, 16.5494],\n",
      "        [12.7677, 12.6817]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8544, 0.0558, 0.0519, 0.1003], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.6743, 18.6727],\n",
      "        [16.6248, 11.6215],\n",
      "        [11.6142, 16.6108],\n",
      "        [12.7543, 12.7504]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8544, 0.0558, 0.0519, 0.1003], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.7233, 18.6647],\n",
      "        [16.6889, 11.6092],\n",
      "        [11.6780, 16.5985],\n",
      "        [12.8257, 12.7367]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8546, 0.0559, 0.0520, 0.1026], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.7153, 18.7136],\n",
      "        [16.6765, 11.6729],\n",
      "        [11.6656, 16.6619],\n",
      "        [12.8119, 12.8077]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8546, 0.0559, 0.0520, 0.1026], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.7659, 18.7054],\n",
      "        [16.7427, 11.6602],\n",
      "        [11.7314, 16.6493],\n",
      "        [12.8856, 12.7936]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8548, 0.0561, 0.0521, 0.1049], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.7577, 18.7558],\n",
      "        [16.7298, 11.7259],\n",
      "        [11.7187, 16.7146],\n",
      "        [12.8713, 12.8667]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8548, 0.0561, 0.0521, 0.1049], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.8099, 18.7473],\n",
      "        [16.7981, 11.7128],\n",
      "        [11.7866, 16.7016],\n",
      "        [12.9474, 12.8522]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8550, 0.0563, 0.0521, 0.1074], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.8014, 18.7993],\n",
      "        [16.7849, 11.7807],\n",
      "        [11.7735, 16.7691],\n",
      "        [12.9327, 12.9277]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8550, 0.0563, 0.0521, 0.1074], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.8553, 18.7906],\n",
      "        [16.8554, 11.7672],\n",
      "        [11.8436, 16.7557],\n",
      "        [13.0112, 12.9128]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8552, 0.0565, 0.0522, 0.1099], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.8466, 18.8443],\n",
      "        [16.8418, 11.8372],\n",
      "        [11.8301, 16.8254],\n",
      "        [12.9961, 12.9908]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8552, 0.0565, 0.0522, 0.1099], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.9022, 18.8353],\n",
      "        [16.9145, 11.8233],\n",
      "        [11.9025, 16.8115],\n",
      "        [13.0772, 12.9753]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8555, 0.0567, 0.0523, 0.1125], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.8932, 18.8907],\n",
      "        [16.9005, 11.8955],\n",
      "        [11.8886, 16.8834],\n",
      "        [13.0616, 13.0558]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8555, 0.0567, 0.0523, 0.1125], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[18.9506, 18.8815],\n",
      "        [16.9756, 11.8812],\n",
      "        [11.9633, 16.8692],\n",
      "        [13.1453, 13.0399]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8557, 0.0568, 0.0523, 0.1152], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.9413, 18.9386],\n",
      "        [16.9611, 11.9557],\n",
      "        [11.9490, 16.9434],\n",
      "        [13.1292, 13.1230]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8557, 0.0568, 0.0523, 0.1152], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.0007, 18.9291],\n",
      "        [17.0386, 11.9410],\n",
      "        [12.0261, 16.9287],\n",
      "        [13.2157, 13.1066]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8559, 0.0570, 0.0524, 0.1181], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[18.9910, 18.9881],\n",
      "        [17.0237, 12.0179],\n",
      "        [12.0113, 17.0053],\n",
      "        [13.1991, 13.1924]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8559, 0.0570, 0.0524, 0.1181], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.0523, 18.9783],\n",
      "        [17.1038, 12.0027],\n",
      "        [12.0910, 16.9902],\n",
      "        [13.2884, 13.1754]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8562, 0.0572, 0.0525, 0.1210], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.0424, 19.0392],\n",
      "        [17.0884, 12.0822],\n",
      "        [12.0758, 17.0693],\n",
      "        [13.2713, 13.2640]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8562, 0.0572, 0.0525, 0.1210], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.1056, 19.0291],\n",
      "        [17.1710, 12.0665],\n",
      "        [12.1580, 17.0537],\n",
      "        [13.3634, 13.2466]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8565, 0.0574, 0.0525, 0.1240], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.0955, 19.0920],\n",
      "        [17.1552, 12.1485],\n",
      "        [12.1423, 17.1354],\n",
      "        [13.3458, 13.3381]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8565, 0.0574, 0.0525, 0.1240], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.1607, 19.0816],\n",
      "        [17.2405, 12.1324],\n",
      "        [12.2273, 17.1193],\n",
      "        [13.4410, 13.3201]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8567, 0.0576, 0.0526, 0.1272], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.1503, 19.1465],\n",
      "        [17.2242, 12.2170],\n",
      "        [12.2111, 17.2036],\n",
      "        [13.4229, 13.4145]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8567, 0.0576, 0.0526, 0.1272], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.2176, 19.1358],\n",
      "        [17.3123, 12.2003],\n",
      "        [12.2988, 17.1871],\n",
      "        [13.5212, 13.3960]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8570, 0.0578, 0.0527, 0.1305], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.2068, 19.2028],\n",
      "        [17.2954, 12.2877],\n",
      "        [12.2821, 17.2740],\n",
      "        [13.5025, 13.4935]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8570, 0.0578, 0.0527, 0.1305], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.2764, 19.1918],\n",
      "        [17.3863, 12.2706],\n",
      "        [12.3726, 17.2570],\n",
      "        [13.6039, 13.4744]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8573, 0.0580, 0.0528, 0.1339], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.2653, 19.2609],\n",
      "        [17.3690, 12.3607],\n",
      "        [12.3554, 17.3468],\n",
      "        [13.5847, 13.5750]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8573, 0.0580, 0.0528, 0.1339], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.3371, 19.2496],\n",
      "        [17.4628, 12.3431],\n",
      "        [12.4489, 17.3293],\n",
      "        [13.6894, 13.5554]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8576, 0.0582, 0.0529, 0.1374], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.3256, 19.3209],\n",
      "        [17.4450, 12.4361],\n",
      "        [12.4311, 17.4219],\n",
      "        [13.6696, 13.6593]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8576, 0.0582, 0.0529, 0.1374], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.3997, 19.3093],\n",
      "        [17.5418, 12.4179],\n",
      "        [12.5276, 17.4039],\n",
      "        [13.7777, 13.6390]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8579, 0.0584, 0.0529, 0.1411], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.3879, 19.3828],\n",
      "        [17.5234, 12.5139],\n",
      "        [12.5094, 17.4995],\n",
      "        [13.7573, 13.7462]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8579, 0.0584, 0.0529, 0.1411], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.4644, 19.3709],\n",
      "        [17.6233, 12.4952],\n",
      "        [12.6089, 17.4809],\n",
      "        [13.8688, 13.7254]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8583, 0.0586, 0.0530, 0.1449], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.4523, 19.4468],\n",
      "        [17.6044, 12.5942],\n",
      "        [12.5901, 17.5796],\n",
      "        [13.8478, 13.8360]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8583, 0.0586, 0.0530, 0.1449], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.5311, 19.4345],\n",
      "        [17.7074, 12.5750],\n",
      "        [12.6928, 17.5605],\n",
      "        [13.9629, 13.8146]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8586, 0.0588, 0.0531, 0.1488], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.5187, 19.5128],\n",
      "        [17.6880, 12.6770],\n",
      "        [12.6735, 17.6622],\n",
      "        [13.9412, 13.9286]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8586, 0.0588, 0.0531, 0.1488], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.6000, 19.5002],\n",
      "        [17.7942, 12.6573],\n",
      "        [12.7794, 17.6425],\n",
      "        [14.0600, 13.9066]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8590, 0.0590, 0.0532, 0.1529], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.5872, 19.5809],\n",
      "        [17.7742, 12.7625],\n",
      "        [12.7595, 17.7475],\n",
      "        [14.0377, 14.0243]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8590, 0.0590, 0.0532, 0.1529], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.6710, 19.5680],\n",
      "        [17.8837, 12.7422],\n",
      "        [12.8687, 17.7273],\n",
      "        [14.1601, 14.0016]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8593, 0.0593, 0.0533, 0.1572], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.6579, 19.6512],\n",
      "        [17.8631, 12.8507],\n",
      "        [12.8482, 17.8354],\n",
      "        [14.1372, 14.1229]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8593, 0.0593, 0.0533, 0.1572], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.7443, 19.6379],\n",
      "        [17.9760, 12.8298],\n",
      "        [12.9607, 17.8147],\n",
      "        [14.2634, 14.0996]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8597, 0.0595, 0.0534, 0.1616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.7308, 19.7236],\n",
      "        [17.9549, 12.9416],\n",
      "        [12.9397, 17.9261],\n",
      "        [14.2399, 14.2246]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8597, 0.0595, 0.0534, 0.1616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.8198, 19.7100],\n",
      "        [18.0711, 12.9202],\n",
      "        [13.0556, 17.9048],\n",
      "        [14.3698, 14.2007]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8601, 0.0597, 0.0534, 0.1662], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.8059, 19.7983],\n",
      "        [18.0494, 13.0353],\n",
      "        [13.0341, 18.0196],\n",
      "        [14.3457, 14.3295]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8601, 0.0597, 0.0534, 0.1662], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.8975, 19.7843],\n",
      "        [18.1690, 13.0133],\n",
      "        [13.1534, 17.9977],\n",
      "        [14.4795, 14.3049]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8605, 0.0599, 0.0535, 0.1710], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.8834, 19.8752],\n",
      "        [18.1468, 13.1318],\n",
      "        [13.1313, 18.1159],\n",
      "        [14.4547, 14.4375]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8605, 0.0599, 0.0535, 0.1710], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[19.9777, 19.8609],\n",
      "        [18.2699, 13.1093],\n",
      "        [13.2541, 18.0935],\n",
      "        [14.5925, 14.4124]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8610, 0.0601, 0.0536, 0.1760], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[19.9631, 19.9545],\n",
      "        [18.2471, 13.2312],\n",
      "        [13.2314, 18.2151],\n",
      "        [14.5670, 14.5488]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8610, 0.0601, 0.0536, 0.1760], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[20.0601, 19.9399],\n",
      "        [18.3737, 13.2081],\n",
      "        [13.3577, 18.1921],\n",
      "        [14.7088, 14.5230]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8614, 0.0604, 0.0537, 0.1811], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[20.0452, 20.0361],\n",
      "        [18.3503, 13.3335],\n",
      "        [13.3345, 18.3173],\n",
      "        [14.6827, 14.6634]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8614, 0.0604, 0.0537, 0.1811], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[20.1449, 20.0212],\n",
      "        [18.4805, 13.3099],\n",
      "        [13.4643, 18.2937],\n",
      "        [14.8284, 14.6370]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8619, 0.0606, 0.0538, 0.1864], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[20.1297, 20.1201],\n",
      "        [18.4565, 13.4388],\n",
      "        [13.4405, 18.4223],\n",
      "        [14.8016, 14.7812]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8619, 0.0606, 0.0538, 0.1864], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[20.2321, 20.1048],\n",
      "        [18.5902, 13.4146],\n",
      "        [13.5739, 18.3982],\n",
      "        [14.9513, 14.7542]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8624, 0.0608, 0.0539, 0.1919], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[20.2166, 20.2064],\n",
      "        [18.5657, 13.5469],\n",
      "        [13.5495, 18.5303],\n",
      "        [14.9239, 14.9024]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8624, 0.0608, 0.0539, 0.1919], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[20.3217, 20.1908],\n",
      "        [18.7029, 13.5222],\n",
      "        [13.6864, 18.5057],\n",
      "        [15.0776, 14.8748]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8629, 0.0611, 0.0540, 0.1976], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[20.3059, 20.2951],\n",
      "        [18.6778, 13.6580],\n",
      "        [13.6614, 18.6412],\n",
      "        [15.0496, 15.0269]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8629, 0.0611, 0.0540, 0.1976], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[20.4137, 20.2792],\n",
      "        [18.8185, 13.6328],\n",
      "        [13.8019, 18.6161],\n",
      "        [15.2071, 14.9988]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8634, 0.0613, 0.0541, 0.2035], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[20.3975, 20.3862],\n",
      "        [18.7929, 13.7721],\n",
      "        [13.7764, 18.7551],\n",
      "        [15.1786, 15.1547]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8634, 0.0613, 0.0541, 0.2035], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[20.5080, 20.3700],\n",
      "        [18.9370, 13.7463],\n",
      "        [13.9203, 18.7295],\n",
      "        [15.3400, 15.1260]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8640, 0.0615, 0.0542, 0.2096], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[20.4915, 20.4797],\n",
      "        [18.9109, 13.8890],\n",
      "        [13.8943, 18.8719],\n",
      "        [15.3109, 15.2858]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8640, 0.0615, 0.0542, 0.2096], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[20.6046, 20.4632],\n",
      "        [19.0584, 13.8628],\n",
      "        [14.0416, 18.8458],\n",
      "        [15.4762, 15.2566]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8646, 0.0618, 0.0543, 0.2159], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[20.5879, 20.5755],\n",
      "        [19.0318, 14.0089],\n",
      "        [14.0151, 18.9916],\n",
      "        [15.4465, 15.4202]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8646, 0.0618, 0.0543, 0.2159], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[20.7035, 20.5588],\n",
      "        [19.1826, 13.9822],\n",
      "        [14.1657, 18.9651],\n",
      "        [15.6155, 15.3905]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8652, 0.0620, 0.0544, 0.2225], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[20.6865, 20.6736],\n",
      "        [19.1555, 14.1316],\n",
      "        [14.1387, 19.1142],\n",
      "        [15.5853, 15.5578]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8652, 0.0620, 0.0544, 0.2225], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[20.8047, 20.6567],\n",
      "        [19.3096, 14.1045],\n",
      "        [14.2925, 19.0872],\n",
      "        [15.7579, 15.5276]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8658, 0.0623, 0.0545, 0.2292], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[20.7874, 20.7740],\n",
      "        [19.2821, 14.2570],\n",
      "        [14.2651, 19.2395],\n",
      "        [15.7272, 15.6985]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8658, 0.0623, 0.0545, 0.2292], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[20.9080, 20.7569],\n",
      "        [19.4392, 14.2295],\n",
      "        [14.4221, 19.2121],\n",
      "        [15.9034, 15.6678]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8664, 0.0625, 0.0546, 0.2361], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[20.8906, 20.8766],\n",
      "        [19.4113, 14.3852],\n",
      "        [14.3943, 19.3676],\n",
      "        [15.8722, 15.8423]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8664, 0.0625, 0.0546, 0.2361], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[21.0135, 20.8593],\n",
      "        [19.5714, 14.3574],\n",
      "        [14.5542, 19.3398],\n",
      "        [16.0517, 15.8112]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8671, 0.0628, 0.0547, 0.2433], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[20.9958, 20.9814],\n",
      "        [19.5431, 14.5160],\n",
      "        [14.5260, 19.4983],\n",
      "        [16.0202, 15.9890]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8671, 0.0628, 0.0547, 0.2433], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[21.1209, 20.9639],\n",
      "        [19.7061, 14.4878],\n",
      "        [14.6888, 19.4702],\n",
      "        [16.2029, 15.9576]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8678, 0.0630, 0.0548, 0.2506], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[21.1031, 21.0882],\n",
      "        [19.6775, 14.6493],\n",
      "        [14.6603, 19.6315],\n",
      "        [16.1709, 16.1386]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8678, 0.0630, 0.0548, 0.2506], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[21.2303, 21.0706],\n",
      "        [19.8431, 14.6208],\n",
      "        [14.8257, 19.6031],\n",
      "        [16.3566, 16.1069]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8685, 0.0633, 0.0549, 0.2582], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[21.2124, 21.1970],\n",
      "        [19.8141, 14.7850],\n",
      "        [14.7969, 19.7671],\n",
      "        [16.3244, 16.2909]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8685, 0.0633, 0.0549, 0.2582], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[21.3415, 21.1793],\n",
      "        [19.9822, 14.7563],\n",
      "        [14.9648, 19.7385],\n",
      "        [16.5128, 16.2589]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8693, 0.0636, 0.0550, 0.2660], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[21.3235, 21.3077],\n",
      "        [19.9530, 14.9229],\n",
      "        [14.9358, 19.9049],\n",
      "        [16.4803, 16.4457]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8693, 0.0636, 0.0550, 0.2660], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[21.4544, 21.2900],\n",
      "        [20.1233, 14.8940],\n",
      "        [15.1059, 19.8762],\n",
      "        [16.6713, 16.4135]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8700, 0.0638, 0.0551, 0.2739], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[21.4363, 21.4201],\n",
      "        [20.0940, 15.0629],\n",
      "        [15.0767, 20.0448],\n",
      "        [16.6386, 16.6029]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8700, 0.0638, 0.0551, 0.2739], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[21.5688, 21.4024],\n",
      "        [20.2663, 15.0339],\n",
      "        [15.2488, 20.0160],\n",
      "        [16.8318, 16.5706]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8708, 0.0641, 0.0553, 0.2820], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[21.5507, 21.5341],\n",
      "        [20.2368, 15.2048],\n",
      "        [15.2195, 20.1867],\n",
      "        [16.7989, 16.7622]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8708, 0.0641, 0.0553, 0.2820], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[21.6846, 21.5164],\n",
      "        [20.4108, 15.1757],\n",
      "        [15.3934, 20.1578],\n",
      "        [16.9942, 16.7298]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8717, 0.0644, 0.0554, 0.2904], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[21.6665, 21.6497],\n",
      "        [20.3813, 15.3484],\n",
      "        [15.3639, 20.3303],\n",
      "        [16.9612, 16.9235]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8717, 0.0644, 0.0554, 0.2904], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[21.8017, 21.6320],\n",
      "        [20.5568, 15.3194],\n",
      "        [15.5393, 20.3014],\n",
      "        [17.1582, 16.8911]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8725, 0.0646, 0.0555, 0.2989], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[21.7836, 21.7665],\n",
      "        [20.5272, 15.4936],\n",
      "        [15.5099, 20.4755],\n",
      "        [17.1252, 17.0866]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8725, 0.0646, 0.0555, 0.2989], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[21.9198, 21.7490],\n",
      "        [20.7040, 15.4646],\n",
      "        [15.6865, 20.4466],\n",
      "        [17.3235, 17.0543]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8734, 0.0649, 0.0556, 0.3075], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[21.9018, 21.8846],\n",
      "        [20.6744, 15.6401],\n",
      "        [15.6571, 20.6220],\n",
      "        [17.2906, 17.2512]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8734, 0.0649, 0.0556, 0.3075], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[22.0389, 21.8671],\n",
      "        [20.8521, 15.6112],\n",
      "        [15.8347, 20.5932],\n",
      "        [17.4900, 17.2190]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8743, 0.0652, 0.0557, 0.3163], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[22.0210, 22.0036],\n",
      "        [20.8227, 15.7877],\n",
      "        [15.8054, 20.7696],\n",
      "        [17.4572, 17.4170]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8743, 0.0652, 0.0557, 0.3163], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[22.1587, 21.9863],\n",
      "        [21.0010, 15.7590],\n",
      "        [15.9836, 20.7410],\n",
      "        [17.6573, 17.3850]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8752, 0.0654, 0.0558, 0.3253], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[22.1409, 22.1234],\n",
      "        [20.9717, 15.9362],\n",
      "        [15.9544, 20.9181],\n",
      "        [17.6246, 17.5839]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8752, 0.0654, 0.0558, 0.3253], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[22.2790, 22.1064],\n",
      "        [21.1504, 15.9077],\n",
      "        [16.1331, 20.8897],\n",
      "        [17.8252, 17.5521]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8762, 0.0657, 0.0559, 0.3343], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[22.2614, 22.2439],\n",
      "        [21.1213, 16.0853],\n",
      "        [16.1041, 21.0672],\n",
      "        [17.7928, 17.7515]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8762, 0.0657, 0.0559, 0.3343], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[22.3996, 22.2271],\n",
      "        [21.3001, 16.0571],\n",
      "        [16.2828, 21.0391],\n",
      "        [17.9934, 17.7200]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8771, 0.0660, 0.0560, 0.3435], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[22.3823, 22.3649],\n",
      "        [21.2712, 16.2349],\n",
      "        [16.2541, 21.2168],\n",
      "        [17.9613, 17.9195]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8771, 0.0660, 0.0560, 0.3435], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[22.5205, 22.3484],\n",
      "        [21.4497, 16.2070],\n",
      "        [16.4325, 21.1890],\n",
      "        [18.1617, 17.8885]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8782, 0.0663, 0.0562, 0.3528], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[22.5034, 22.4862],\n",
      "        [21.4212, 16.3846],\n",
      "        [16.4041, 21.3665],\n",
      "        [18.1300, 18.0878]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8782, 0.0663, 0.0562, 0.3528], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[22.6413, 22.4699],\n",
      "        [21.5992, 16.3571],\n",
      "        [16.5820, 21.3392],\n",
      "        [18.3297, 18.0572]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8792, 0.0665, 0.0563, 0.3622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[22.6245, 22.6075],\n",
      "        [21.5710, 16.5342],\n",
      "        [16.5540, 21.5162],\n",
      "        [18.2984, 18.2561]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8792, 0.0665, 0.0563, 0.3622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[22.7620, 22.5916],\n",
      "        [21.7482, 16.5071],\n",
      "        [16.7311, 21.4893],\n",
      "        [18.4973, 18.2260]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8802, 0.0668, 0.0564, 0.3716], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[22.7455, 22.7287],\n",
      "        [21.7205, 16.6836],\n",
      "        [16.7036, 21.6656],\n",
      "        [18.4665, 18.4240]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8802, 0.0668, 0.0564, 0.3716], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[22.8823, 22.7132],\n",
      "        [21.8965, 16.6570],\n",
      "        [16.8795, 21.6392],\n",
      "        [18.6641, 18.3944]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8813, 0.0671, 0.0565, 0.3811], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[22.8662, 22.8497],\n",
      "        [21.8693, 16.8324],\n",
      "        [16.8524, 21.8145],\n",
      "        [18.6338, 18.5913]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8813, 0.0671, 0.0565, 0.3811], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[23.0020, 22.8346],\n",
      "        [22.0440, 16.8063],\n",
      "        [17.0271, 21.7886],\n",
      "        [18.8299, 18.5623]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8824, 0.0674, 0.0566, 0.3907], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[22.9863, 22.9702],\n",
      "        [22.0172, 16.9804],\n",
      "        [17.0005, 21.9626],\n",
      "        [18.8002, 18.7578]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8824, 0.0674, 0.0566, 0.3907], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[23.1211, 22.9555],\n",
      "        [22.1903, 16.9549],\n",
      "        [17.1735, 21.9373],\n",
      "        [18.9945, 18.7295]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8835, 0.0677, 0.0567, 0.4002], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[23.1057, 23.0901],\n",
      "        [22.1641, 17.1275],\n",
      "        [17.1475, 22.1097],\n",
      "        [18.9654, 18.9232]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8835, 0.0677, 0.0567, 0.4002], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[23.2393, 23.0758],\n",
      "        [22.3353, 17.1026],\n",
      "        [17.3186, 22.0850],\n",
      "        [19.1576, 18.8956]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8846, 0.0679, 0.0568, 0.4098], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[23.2243, 23.2092],\n",
      "        [22.3097, 17.2734],\n",
      "        [17.2932, 22.2557],\n",
      "        [19.1293, 19.0873]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8846, 0.0679, 0.0568, 0.4098], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[23.3565, 23.1954],\n",
      "        [22.4788, 17.2491],\n",
      "        [17.4623, 22.2316],\n",
      "        [19.3191, 19.0604]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8858, 0.0682, 0.0570, 0.4193], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[23.3420, 23.3274],\n",
      "        [22.4539, 17.4179],\n",
      "        [17.4375, 22.4003],\n",
      "        [19.2914, 19.2499]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8858, 0.0682, 0.0570, 0.4193], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[23.4725, 23.3140],\n",
      "        [22.6207, 17.3943],\n",
      "        [17.6043, 22.3769],\n",
      "        [19.4788, 19.2237]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8869, 0.0685, 0.0571, 0.4288], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[23.4584, 23.4445],\n",
      "        [22.5964, 17.5608],\n",
      "        [17.5801, 22.5434],\n",
      "        [19.4518, 19.4107]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8869, 0.0685, 0.0571, 0.4288], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[23.5873, 23.4315],\n",
      "        [22.7608, 17.5379],\n",
      "        [17.7444, 22.5206],\n",
      "        [19.6364, 19.3853]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8881, 0.0688, 0.0572, 0.4383], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[23.5737, 23.5603],\n",
      "        [22.7371, 17.7021],\n",
      "        [17.7210, 22.6847],\n",
      "        [19.6102, 19.5696]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8881, 0.0688, 0.0572, 0.4383], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[23.7007, 23.5479],\n",
      "        [22.8989, 17.6798],\n",
      "        [17.8826, 22.6626],\n",
      "        [19.7918, 19.5450]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8893, 0.0691, 0.0573, 0.4477], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[23.6875, 23.6749],\n",
      "        [22.8759, 17.8414],\n",
      "        [17.8599, 22.8242],\n",
      "        [19.7663, 19.7264]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8893, 0.0691, 0.0573, 0.4477], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[23.8126, 23.6629],\n",
      "        [23.0349, 17.8199],\n",
      "        [18.0188, 22.8028],\n",
      "        [19.9448, 19.7026]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8905, 0.0693, 0.0574, 0.4571], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[23.7999, 23.7880],\n",
      "        [23.0126, 17.9788],\n",
      "        [17.9967, 22.9617],\n",
      "        [19.9202, 19.8810]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8905, 0.0693, 0.0574, 0.4571], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[23.9229, 23.7764],\n",
      "        [23.1687, 17.9579],\n",
      "        [18.1527, 22.9410],\n",
      "        [20.0954, 19.8580]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8917, 0.0696, 0.0575, 0.4663], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[23.9107, 23.8995],\n",
      "        [23.1471, 18.1140],\n",
      "        [18.1314, 23.0970],\n",
      "        [20.0716, 20.0332]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8917, 0.0696, 0.0575, 0.4663], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[24.0316, 23.8884],\n",
      "        [23.3002, 18.0939],\n",
      "        [18.2844, 23.0771],\n",
      "        [20.2435, 20.0110]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8929, 0.0699, 0.0576, 0.4755], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[24.0198, 24.0094],\n",
      "        [23.2794, 18.2470],\n",
      "        [18.2638, 23.2301],\n",
      "        [20.2205, 20.1829]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8929, 0.0699, 0.0576, 0.4755], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[24.1385, 23.9988],\n",
      "        [23.4294, 18.2276],\n",
      "        [18.4137, 23.2109],\n",
      "        [20.3889, 20.1615]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8941, 0.0702, 0.0577, 0.4846], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[24.1272, 24.1176],\n",
      "        [23.4093, 18.3777],\n",
      "        [18.3938, 23.3609],\n",
      "        [20.3667, 20.3300]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8941, 0.0702, 0.0577, 0.4846], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[24.2436, 24.1074],\n",
      "        [23.5561, 18.3589],\n",
      "        [18.5406, 23.3424],\n",
      "        [20.5316, 20.3094]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8954, 0.0705, 0.0578, 0.4935], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[24.2328, 24.2239],\n",
      "        [23.5367, 18.5059],\n",
      "        [18.5214, 23.4893],\n",
      "        [20.5102, 20.4744]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8954, 0.0705, 0.0578, 0.4935], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[24.3470, 24.2143],\n",
      "        [23.6803, 18.4879],\n",
      "        [18.6650, 23.4715],\n",
      "        [20.6714, 20.4546]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8966, 0.0708, 0.0579, 0.5024], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[24.3366, 24.3285],\n",
      "        [23.6616, 18.6317],\n",
      "        [18.6465, 23.6153],\n",
      "        [20.6508, 20.6160]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8966, 0.0708, 0.0579, 0.5024], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[24.4484, 24.3192],\n",
      "        [23.8020, 18.6144],\n",
      "        [18.7868, 23.5981],\n",
      "        [20.8084, 20.5970]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8978, 0.0710, 0.0580, 0.5111], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[24.4385, 24.4312],\n",
      "        [23.7840, 18.7550],\n",
      "        [18.7690, 23.7387],\n",
      "        [20.7886, 20.7548]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8978, 0.0710, 0.0580, 0.5111], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[24.5479, 24.4223],\n",
      "        [23.9212, 18.7383],\n",
      "        [18.9061, 23.7222],\n",
      "        [20.9426, 20.7365]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.8991, 0.0713, 0.0582, 0.5196], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[24.5384, 24.5319],\n",
      "        [23.9038, 18.8757],\n",
      "        [18.8890, 23.8595],\n",
      "        [20.9236, 20.8908]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.8991, 0.0713, 0.0582, 0.5196], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[24.6455, 24.5235],\n",
      "        [24.0377, 18.8597],\n",
      "        [19.0228, 23.8438],\n",
      "        [21.0739, 20.8732]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9003, 0.0716, 0.0583, 0.5280], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[24.6365, 24.6307],\n",
      "        [24.0210, 18.9939],\n",
      "        [19.0064, 23.9778],\n",
      "        [21.0556, 21.0238]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9003, 0.0716, 0.0583, 0.5280], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[24.7412, 24.6227],\n",
      "        [24.1517, 18.9785],\n",
      "        [19.1369, 23.9627],\n",
      "        [21.2022, 21.0070]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9015, 0.0719, 0.0584, 0.5363], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[24.7325, 24.7276],\n",
      "        [24.1357, 19.1095],\n",
      "        [19.1212, 24.0935],\n",
      "        [21.1847, 21.1540]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9015, 0.0719, 0.0584, 0.5363], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[24.8349, 24.7199],\n",
      "        [24.2631, 19.0947],\n",
      "        [19.2485, 24.0790],\n",
      "        [21.3277, 21.1379]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9028, 0.0721, 0.0585, 0.5444], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[24.8267, 24.8225],\n",
      "        [24.2477, 19.2224],\n",
      "        [19.2334, 24.2067],\n",
      "        [21.3109, 21.2812]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9028, 0.0721, 0.0585, 0.5444], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[24.9267, 24.8152],\n",
      "        [24.3719, 19.2083],\n",
      "        [19.3574, 24.1928],\n",
      "        [21.4503, 21.2658]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9040, 0.0724, 0.0586, 0.5524], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[24.9188, 24.9154],\n",
      "        [24.3572, 19.3328],\n",
      "        [19.3430, 24.3172],\n",
      "        [21.4342, 21.4056]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9040, 0.0724, 0.0586, 0.5524], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[25.0165, 24.9084],\n",
      "        [24.4782, 19.3193],\n",
      "        [19.4639, 24.3039],\n",
      "        [21.5700, 21.3908]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9052, 0.0727, 0.0587, 0.5602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[25.0090, 25.0063],\n",
      "        [24.4640, 19.4406],\n",
      "        [19.4500, 24.4251],\n",
      "        [21.5546, 21.5270]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9052, 0.0727, 0.0587, 0.5602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[25.1044, 24.9997],\n",
      "        [24.5819, 19.4277],\n",
      "        [19.5678, 24.4124],\n",
      "        [21.6868, 21.5129]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9064, 0.0730, 0.0588, 0.5678], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[25.0973, 25.0952],\n",
      "        [24.5684, 19.5459],\n",
      "        [19.5545, 24.5305],\n",
      "        [21.6721, 21.6456]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9064, 0.0730, 0.0588, 0.5678], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[25.1904, 25.0890],\n",
      "        [24.6832, 19.5335],\n",
      "        [19.6691, 24.5183],\n",
      "        [21.8009, 21.6321]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9076, 0.0732, 0.0589, 0.5753], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[25.1836, 25.1822],\n",
      "        [24.6702, 19.6486],\n",
      "        [19.6564, 24.6334],\n",
      "        [21.7868, 21.7613]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9076, 0.0732, 0.0589, 0.5753], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[25.2745, 25.1763],\n",
      "        [24.7819, 19.6367],\n",
      "        [19.7681, 24.6217],\n",
      "        [21.9122, 21.7484]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9088, 0.0735, 0.0589, 0.5826], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[25.2680, 25.2673],\n",
      "        [24.7695, 19.7488],\n",
      "        [19.7559, 24.7337],\n",
      "        [21.8987, 21.8742]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9088, 0.0735, 0.0589, 0.5826], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[25.3567, 25.2617],\n",
      "        [24.8783, 19.7374],\n",
      "        [19.8646, 24.7226],\n",
      "        [22.0207, 21.8618]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9100, 0.0738, 0.0590, 0.5897], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[25.3505, 25.3505],\n",
      "        [24.8663, 19.8466],\n",
      "        [19.8529, 24.8316],\n",
      "        [22.0078, 21.9843]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9100, 0.0738, 0.0590, 0.5897], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[25.4370, 25.3451],\n",
      "        [24.9722, 19.8356],\n",
      "        [19.9587, 24.8210],\n",
      "        [22.1266, 21.9725]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9112, 0.0741, 0.0591, 0.5967], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[25.4312, 25.4317],\n",
      "        [24.9608, 19.9419],\n",
      "        [19.9475, 24.9271],\n",
      "        [22.1143, 22.0917]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9112, 0.0741, 0.0591, 0.5967], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[25.5156, 25.4266],\n",
      "        [25.0639, 19.9314],\n",
      "        [20.0504, 24.9169],\n",
      "        [22.2298, 22.0805]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9124, 0.0743, 0.0592, 0.6035], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[25.5100, 25.5111],\n",
      "        [25.0529, 20.0348],\n",
      "        [20.0398, 25.0202],\n",
      "        [22.2180, 22.1964]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9124, 0.0743, 0.0592, 0.6035], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[25.5923, 25.5063],\n",
      "        [25.1532, 20.0248],\n",
      "        [20.1399, 25.0104],\n",
      "        [22.3305, 22.1857]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9136, 0.0746, 0.0593, 0.6102], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[25.5870, 25.5887],\n",
      "        [25.1427, 20.1255],\n",
      "        [20.1297, 25.1109],\n",
      "        [22.3192, 22.2986]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9136, 0.0746, 0.0593, 0.6102], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[25.6673, 25.5841],\n",
      "        [25.2403, 20.1159],\n",
      "        [20.2271, 25.1016],\n",
      "        [22.4287, 22.2883]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9147, 0.0749, 0.0594, 0.6167], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[25.6623, 25.6645],\n",
      "        [25.2302, 20.2138],\n",
      "        [20.2174, 25.1994],\n",
      "        [22.4179, 22.3981]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9147, 0.0749, 0.0594, 0.6167], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[25.7406, 25.6601],\n",
      "        [25.3252, 20.2046],\n",
      "        [20.3122, 25.1905],\n",
      "        [22.5243, 22.3883]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9158, 0.0752, 0.0595, 0.6230], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[25.7358, 25.7385],\n",
      "        [25.3155, 20.2999],\n",
      "        [20.3028, 25.2856],\n",
      "        [22.5140, 22.4951]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9158, 0.0752, 0.0595, 0.6230], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[25.8122, 25.7343],\n",
      "        [25.4080, 20.2911],\n",
      "        [20.3951, 25.2771],\n",
      "        [22.6176, 22.4857]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9170, 0.0754, 0.0596, 0.6292], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[25.8076, 25.8108],\n",
      "        [25.3987, 20.3838],\n",
      "        [20.3861, 25.3696],\n",
      "        [22.6077, 22.5897]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9170, 0.0754, 0.0596, 0.6292], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[25.8821, 25.8068],\n",
      "        [25.4886, 20.3754],\n",
      "        [20.4759, 25.3615],\n",
      "        [22.7085, 22.5807]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9181, 0.0757, 0.0597, 0.6352], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[25.8777, 25.8813],\n",
      "        [25.4798, 20.4656],\n",
      "        [20.4673, 25.4515],\n",
      "        [22.6991, 22.6819]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9181, 0.0757, 0.0597, 0.6352], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[25.9504, 25.8776],\n",
      "        [25.5673, 20.4575],\n",
      "        [20.5547, 25.4438],\n",
      "        [22.7972, 22.6733]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9192, 0.0760, 0.0598, 0.6411], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[25.9462, 25.9503],\n",
      "        [25.5588, 20.5453],\n",
      "        [20.5465, 25.5314],\n",
      "        [22.7882, 22.7717]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9192, 0.0760, 0.0598, 0.6411], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.0171, 25.9467],\n",
      "        [25.6439, 20.5375],\n",
      "        [20.6315, 25.5239],\n",
      "        [22.8836, 22.7635]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9203, 0.0762, 0.0598, 0.6468], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.0132, 26.0176],\n",
      "        [25.6358, 20.6229],\n",
      "        [20.6236, 25.6092],\n",
      "        [22.8749, 22.8592]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9203, 0.0762, 0.0598, 0.6468], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.0823, 26.0142],\n",
      "        [25.7186, 20.6155],\n",
      "        [20.7063, 25.6021],\n",
      "        [22.9678, 22.8514]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9213, 0.0765, 0.0599, 0.6524], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.0785, 26.0833],\n",
      "        [25.7108, 20.6987],\n",
      "        [20.6988, 25.6850],\n",
      "        [22.9596, 22.9446]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9213, 0.0765, 0.0599, 0.6524], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.1460, 26.0801],\n",
      "        [25.7915, 20.6915],\n",
      "        [20.7793, 25.6782],\n",
      "        [23.0499, 22.9371]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9224, 0.0768, 0.0600, 0.6578], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.1424, 26.1475],\n",
      "        [25.7840, 20.7724],\n",
      "        [20.7721, 25.7589],\n",
      "        [23.0420, 23.0278]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9224, 0.0768, 0.0600, 0.6578], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.2082, 26.1444],\n",
      "        [25.8625, 20.7656],\n",
      "        [20.8504, 25.7524],\n",
      "        [23.1300, 23.0206]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9234, 0.0770, 0.0601, 0.6632], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.2047, 26.2102],\n",
      "        [25.8553, 20.8443],\n",
      "        [20.8435, 25.8309],\n",
      "        [23.1224, 23.1088]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9234, 0.0770, 0.0601, 0.6632], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.2689, 26.2072],\n",
      "        [25.9318, 20.8378],\n",
      "        [20.9198, 25.8247],\n",
      "        [23.2081, 23.1020]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9245, 0.0773, 0.0602, 0.6683], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.2656, 26.2714],\n",
      "        [25.9248, 20.9145],\n",
      "        [20.9132, 25.9012],\n",
      "        [23.2008, 23.1879]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9245, 0.0773, 0.0602, 0.6683], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.3283, 26.2686],\n",
      "        [25.9993, 20.9081],\n",
      "        [20.9875, 25.8952],\n",
      "        [23.2842, 23.1813]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9255, 0.0776, 0.0603, 0.6734], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.3251, 26.3311],\n",
      "        [25.9926, 20.9828],\n",
      "        [20.9811, 25.9696],\n",
      "        [23.2772, 23.2649]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9255, 0.0776, 0.0603, 0.6734], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.3862, 26.3285],\n",
      "        [26.0651, 20.9767],\n",
      "        [21.0534, 25.9639],\n",
      "        [23.3584, 23.2587]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9265, 0.0778, 0.0603, 0.6783], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.3832, 26.3895],\n",
      "        [26.0587, 21.0494],\n",
      "        [21.0473, 26.0364],\n",
      "        [23.3518, 23.3400]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9265, 0.0778, 0.0603, 0.6783], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.4429, 26.3870],\n",
      "        [26.1293, 21.0436],\n",
      "        [21.1178, 26.0309],\n",
      "        [23.4308, 23.3340]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9275, 0.0781, 0.0604, 0.6831], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.4400, 26.4465],\n",
      "        [26.1232, 21.1144],\n",
      "        [21.1119, 26.1014],\n",
      "        [23.4244, 23.4133]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9275, 0.0781, 0.0604, 0.6831], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.4982, 26.4441],\n",
      "        [26.1919, 21.1088],\n",
      "        [21.1805, 26.0961],\n",
      "        [23.5014, 23.4075]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9284, 0.0783, 0.0605, 0.6877], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.4955, 26.5022],\n",
      "        [26.1860, 21.1777],\n",
      "        [21.1749, 26.1649],\n",
      "        [23.4953, 23.4847]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9284, 0.0783, 0.0605, 0.6877], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.5523, 26.4999],\n",
      "        [26.2531, 21.1723],\n",
      "        [21.2417, 26.1598],\n",
      "        [23.5703, 23.4792]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9294, 0.0786, 0.0606, 0.6923], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.5497, 26.5566],\n",
      "        [26.2473, 21.2395],\n",
      "        [21.2363, 26.2268],\n",
      "        [23.5645, 23.5544]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9294, 0.0786, 0.0606, 0.6923], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.6052, 26.5544],\n",
      "        [26.3126, 21.2343],\n",
      "        [21.3014, 26.2219],\n",
      "        [23.6375, 23.5491]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9303, 0.0789, 0.0606, 0.6967], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.6027, 26.6097],\n",
      "        [26.3071, 21.2997],\n",
      "        [21.2963, 26.2871],\n",
      "        [23.6319, 23.6223]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9303, 0.0789, 0.0606, 0.6967], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.6568, 26.6076],\n",
      "        [26.3708, 21.2947],\n",
      "        [21.3597, 26.2825],\n",
      "        [23.7031, 23.6172]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9312, 0.0791, 0.0607, 0.7010], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.6544, 26.6616],\n",
      "        [26.3655, 21.3585],\n",
      "        [21.3547, 26.3460],\n",
      "        [23.6977, 23.6886]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9312, 0.0791, 0.0607, 0.7010], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.7073, 26.6596],\n",
      "        [26.4276, 21.3537],\n",
      "        [21.4166, 26.3415],\n",
      "        [23.7671, 23.6837]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9322, 0.0794, 0.0608, 0.7052], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.7050, 26.7124],\n",
      "        [26.4224, 21.4158],\n",
      "        [21.4118, 26.4035],\n",
      "        [23.7620, 23.7532]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9322, 0.0794, 0.0608, 0.7052], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.7566, 26.7104],\n",
      "        [26.4829, 21.4112],\n",
      "        [21.4721, 26.3991],\n",
      "        [23.8296, 23.7486]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9330, 0.0797, 0.0609, 0.7093], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.7544, 26.7619],\n",
      "        [26.4780, 21.4718],\n",
      "        [21.4675, 26.4595],\n",
      "        [23.8246, 23.8163]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9330, 0.0797, 0.0609, 0.7093], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.8049, 26.7601],\n",
      "        [26.5370, 21.4673],\n",
      "        [21.5262, 26.4554],\n",
      "        [23.8906, 23.8119]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9339, 0.0799, 0.0609, 0.7133], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.8027, 26.8104],\n",
      "        [26.5322, 21.5264],\n",
      "        [21.5218, 26.5142],\n",
      "        [23.8858, 23.8779]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9339, 0.0799, 0.0609, 0.7133], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.8520, 26.8086],\n",
      "        [26.5898, 21.5221],\n",
      "        [21.5791, 26.5102],\n",
      "        [23.9501, 23.8736]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9348, 0.0802, 0.0610, 0.7172], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.8500, 26.8577],\n",
      "        [26.5852, 21.5797],\n",
      "        [21.5749, 26.5676],\n",
      "        [23.9455, 23.9380]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9348, 0.0802, 0.0610, 0.7172], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.8981, 26.8560],\n",
      "        [26.6413, 21.5755],\n",
      "        [21.6307, 26.5637],\n",
      "        [24.0082, 23.9339]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9356, 0.0804, 0.0611, 0.7210], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.8962, 26.9040],\n",
      "        [26.6369, 21.6317],\n",
      "        [21.6267, 26.6197],\n",
      "        [24.0038, 23.9967]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9356, 0.0804, 0.0611, 0.7210], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.9432, 26.9023],\n",
      "        [26.6916, 21.6276],\n",
      "        [21.6812, 26.6160],\n",
      "        [24.0650, 23.9927]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9365, 0.0807, 0.0612, 0.7247], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.9413, 26.9492],\n",
      "        [26.6874, 21.6825],\n",
      "        [21.6772, 26.6706],\n",
      "        [24.0608, 24.0540]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9365, 0.0807, 0.0612, 0.7247], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[26.9873, 26.9476],\n",
      "        [26.7408, 21.6786],\n",
      "        [21.7304, 26.6670],\n",
      "        [24.1204, 24.0501]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9373, 0.0810, 0.0612, 0.7284], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[26.9855, 26.9934],\n",
      "        [26.7366, 21.7321],\n",
      "        [21.7267, 26.7203],\n",
      "        [24.1164, 24.1099]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9373, 0.0810, 0.0612, 0.7284], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.0304, 26.9919],\n",
      "        [26.7888, 21.7283],\n",
      "        [21.7785, 26.7168],\n",
      "        [24.1746, 24.1062]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9381, 0.0812, 0.0613, 0.7319], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.0287, 27.0366],\n",
      "        [26.7848, 21.7805],\n",
      "        [21.7749, 26.7688],\n",
      "        [24.1707, 24.1645]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9381, 0.0812, 0.0613, 0.7319], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.0725, 27.0352],\n",
      "        [26.8357, 21.7768],\n",
      "        [21.8256, 26.7655],\n",
      "        [24.2275, 24.1610]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9389, 0.0815, 0.0614, 0.7353], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.0709, 27.0789],\n",
      "        [26.8318, 21.8278],\n",
      "        [21.8220, 26.8162],\n",
      "        [24.2237, 24.2179]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9389, 0.0815, 0.0614, 0.7353], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.1138, 27.0775],\n",
      "        [26.8815, 21.8242],\n",
      "        [21.8715, 26.8130],\n",
      "        [24.2792, 24.2145]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9397, 0.0817, 0.0614, 0.7387], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.1122, 27.1203],\n",
      "        [26.8778, 21.8740],\n",
      "        [21.8681, 26.8625],\n",
      "        [24.2756, 24.2700]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9397, 0.0817, 0.0614, 0.7387], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.1541, 27.1189],\n",
      "        [26.9263, 21.8705],\n",
      "        [21.9164, 26.8594],\n",
      "        [24.3297, 24.2667]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9404, 0.0820, 0.0615, 0.7420], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.1526, 27.1607],\n",
      "        [26.9227, 21.9191],\n",
      "        [21.9131, 26.9077],\n",
      "        [24.3262, 24.3209]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9404, 0.0820, 0.0615, 0.7420], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.1936, 27.1594],\n",
      "        [26.9701, 21.9158],\n",
      "        [21.9602, 26.9047],\n",
      "        [24.3791, 24.3178]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9412, 0.0822, 0.0616, 0.7452], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.1921, 27.2002],\n",
      "        [26.9665, 21.9632],\n",
      "        [21.9570, 26.9519],\n",
      "        [24.3757, 24.3707]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9412, 0.0822, 0.0616, 0.7452], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.2322, 27.1990],\n",
      "        [27.0129, 21.9600],\n",
      "        [22.0031, 26.9490],\n",
      "        [24.4274, 24.3676]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9419, 0.0825, 0.0616, 0.7483], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.2308, 27.2389],\n",
      "        [27.0094, 22.0064],\n",
      "        [22.0000, 26.9951],\n",
      "        [24.4241, 24.4193]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9419, 0.0825, 0.0616, 0.7483], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.2701, 27.2377],\n",
      "        [27.0547, 22.0032],\n",
      "        [22.0450, 26.9923],\n",
      "        [24.4746, 24.4164]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9426, 0.0828, 0.0617, 0.7513], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.2687, 27.2768],\n",
      "        [27.0514, 22.0485],\n",
      "        [22.0421, 27.0373],\n",
      "        [24.4715, 24.4669]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9426, 0.0828, 0.0617, 0.7513], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.3071, 27.2756],\n",
      "        [27.0956, 22.0454],\n",
      "        [22.0860, 27.0346],\n",
      "        [24.5208, 24.4640]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9434, 0.0830, 0.0618, 0.7543], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.3057, 27.3138],\n",
      "        [27.0924, 22.0897],\n",
      "        [22.0832, 27.0786],\n",
      "        [24.5177, 24.5134]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9434, 0.0830, 0.0618, 0.7543], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.3433, 27.3127],\n",
      "        [27.1356, 22.0867],\n",
      "        [22.1261, 27.0760],\n",
      "        [24.5659, 24.5106]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9441, 0.0833, 0.0618, 0.7572], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.3420, 27.3501],\n",
      "        [27.1325, 22.1300],\n",
      "        [22.1234, 27.1190],\n",
      "        [24.5630, 24.5588]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9441, 0.0833, 0.0618, 0.7572], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.3787, 27.3490],\n",
      "        [27.1748, 22.1271],\n",
      "        [22.1653, 27.1164],\n",
      "        [24.6101, 24.5561]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9447, 0.0835, 0.0619, 0.7601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.3775, 27.3855],\n",
      "        [27.1717, 22.1694],\n",
      "        [22.1626, 27.1584],\n",
      "        [24.6072, 24.6033]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9447, 0.0835, 0.0619, 0.7601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.4135, 27.3845],\n",
      "        [27.2130, 22.1665],\n",
      "        [22.2037, 27.1560],\n",
      "        [24.6533, 24.6007]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9454, 0.0838, 0.0619, 0.7629], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.4123, 27.4203],\n",
      "        [27.2101, 22.2079],\n",
      "        [22.2011, 27.1971],\n",
      "        [24.6505, 24.6468]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9454, 0.0838, 0.0619, 0.7629], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.4474, 27.4193],\n",
      "        [27.2505, 22.2051],\n",
      "        [22.2412, 27.1947],\n",
      "        [24.6955, 24.6442]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9461, 0.0840, 0.0620, 0.7656], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.4463, 27.4543],\n",
      "        [27.2476, 22.2456],\n",
      "        [22.2387, 27.2348],\n",
      "        [24.6929, 24.6893]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9461, 0.0840, 0.0620, 0.7656], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.4807, 27.4533],\n",
      "        [27.2871, 22.2429],\n",
      "        [22.2780, 27.2325],\n",
      "        [24.7369, 24.6869]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9467, 0.0843, 0.0621, 0.7682], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.4796, 27.4876],\n",
      "        [27.2843, 22.2824],\n",
      "        [22.2755, 27.2718],\n",
      "        [24.7343, 24.7309]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9467, 0.0843, 0.0621, 0.7682], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.5133, 27.4866],\n",
      "        [27.3230, 22.2798],\n",
      "        [22.3139, 27.2695],\n",
      "        [24.7774, 24.7285]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9474, 0.0846, 0.0621, 0.7708], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.5123, 27.5202],\n",
      "        [27.3202, 22.3185],\n",
      "        [22.3116, 27.3079],\n",
      "        [24.7749, 24.7716]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9474, 0.0846, 0.0621, 0.7708], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.5453, 27.5193],\n",
      "        [27.3581, 22.3160],\n",
      "        [22.3491, 27.3058],\n",
      "        [24.8170, 24.7694]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9480, 0.0848, 0.0622, 0.7734], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.5442, 27.5521],\n",
      "        [27.3554, 22.3538],\n",
      "        [22.3468, 27.3433],\n",
      "        [24.8146, 24.8115]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9480, 0.0848, 0.0622, 0.7734], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.5765, 27.5512],\n",
      "        [27.3925, 22.3513],\n",
      "        [22.3836, 27.3412],\n",
      "        [24.8558, 24.8093]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9486, 0.0851, 0.0622, 0.7759], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.5755, 27.5834],\n",
      "        [27.3899, 22.3884],\n",
      "        [22.3813, 27.3780],\n",
      "        [24.8534, 24.8505]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9486, 0.0851, 0.0622, 0.7759], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.6072, 27.5825],\n",
      "        [27.4262, 22.3860],\n",
      "        [22.4173, 27.3759],\n",
      "        [24.8938, 24.8483]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9492, 0.0853, 0.0623, 0.7783], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.6062, 27.6140],\n",
      "        [27.4236, 22.4222],\n",
      "        [22.4151, 27.4119],\n",
      "        [24.8915, 24.8887]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9492, 0.0853, 0.0623, 0.7783], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.6372, 27.6132],\n",
      "        [27.4591, 22.4198],\n",
      "        [22.4503, 27.4099],\n",
      "        [24.9310, 24.8866]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9498, 0.0856, 0.0624, 0.7807], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.6363, 27.6440],\n",
      "        [27.4566, 22.4554],\n",
      "        [22.4482, 27.4451],\n",
      "        [24.9288, 24.9260]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9498, 0.0856, 0.0624, 0.7807], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.6667, 27.6432],\n",
      "        [27.4914, 22.4530],\n",
      "        [22.4827, 27.4431],\n",
      "        [24.9674, 24.9240]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9504, 0.0859, 0.0624, 0.7830], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.6657, 27.6734],\n",
      "        [27.4889, 22.4878],\n",
      "        [22.4806, 27.4776],\n",
      "        [24.9653, 24.9627]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9504, 0.0859, 0.0624, 0.7830], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.6955, 27.6726],\n",
      "        [27.5230, 22.4855],\n",
      "        [22.5144, 27.4757],\n",
      "        [25.0031, 24.9607]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9510, 0.0861, 0.0625, 0.7853], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.6946, 27.7022],\n",
      "        [27.5206, 22.5196],\n",
      "        [22.5124, 27.5094],\n",
      "        [25.0010, 24.9985]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9510, 0.0861, 0.0625, 0.7853], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.7238, 27.7015],\n",
      "        [27.5540, 22.5174],\n",
      "        [22.5454, 27.5076],\n",
      "        [25.0381, 24.9967]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9515, 0.0864, 0.0625, 0.7875], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.7229, 27.7304],\n",
      "        [27.5516, 22.5507],\n",
      "        [22.5435, 27.5406],\n",
      "        [25.0360, 25.0337]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9515, 0.0864, 0.0625, 0.7875], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.7515, 27.7297],\n",
      "        [27.5843, 22.5485],\n",
      "        [22.5759, 27.5388],\n",
      "        [25.0723, 25.0318]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9521, 0.0866, 0.0626, 0.7897], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.7506, 27.7581],\n",
      "        [27.5820, 22.5812],\n",
      "        [22.5740, 27.5712],\n",
      "        [25.0703, 25.0681]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9521, 0.0866, 0.0626, 0.7897], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.7786, 27.7574],\n",
      "        [27.6141, 22.5791],\n",
      "        [22.6057, 27.5694],\n",
      "        [25.1059, 25.0663]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9526, 0.0869, 0.0626, 0.7918], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.7778, 27.7852],\n",
      "        [27.6118, 22.6111],\n",
      "        [22.6038, 27.6011],\n",
      "        [25.1040, 25.1018]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9526, 0.0869, 0.0626, 0.7918], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.8053, 27.7845],\n",
      "        [27.6432, 22.6090],\n",
      "        [22.6349, 27.5994],\n",
      "        [25.1388, 25.1001]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9532, 0.0871, 0.0627, 0.7939], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.8045, 27.8118],\n",
      "        [27.6410, 22.6403],\n",
      "        [22.6331, 27.6304],\n",
      "        [25.1369, 25.1349]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9532, 0.0871, 0.0627, 0.7939], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.8314, 27.8111],\n",
      "        [27.6718, 22.6383],\n",
      "        [22.6635, 27.6288],\n",
      "        [25.1710, 25.1332]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9537, 0.0874, 0.0628, 0.7960], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.8306, 27.8379],\n",
      "        [27.6696, 22.6690],\n",
      "        [22.6618, 27.6592],\n",
      "        [25.1692, 25.1672]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9537, 0.0874, 0.0628, 0.7960], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.8570, 27.8372],\n",
      "        [27.6998, 22.6670],\n",
      "        [22.6916, 27.6576],\n",
      "        [25.2027, 25.1656]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9542, 0.0877, 0.0628, 0.7980], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.8562, 27.8635],\n",
      "        [27.6977, 22.6972],\n",
      "        [22.6899, 27.6874],\n",
      "        [25.2009, 25.1990]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9542, 0.0877, 0.0628, 0.7980], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.8821, 27.8628],\n",
      "        [27.7272, 22.6952],\n",
      "        [22.7191, 27.6858],\n",
      "        [25.2337, 25.1974]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9547, 0.0879, 0.0629, 0.7999], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.8814, 27.8885],\n",
      "        [27.7252, 22.7247],\n",
      "        [22.7175, 27.7150],\n",
      "        [25.2320, 25.2301]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9547, 0.0879, 0.0629, 0.7999], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.9067, 27.8879],\n",
      "        [27.7542, 22.7228],\n",
      "        [22.7461, 27.7135],\n",
      "        [25.2641, 25.2286]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9552, 0.0882, 0.0629, 0.8019], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.9060, 27.9131],\n",
      "        [27.7521, 22.7518],\n",
      "        [22.7445, 27.7421],\n",
      "        [25.2624, 25.2606]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9552, 0.0882, 0.0629, 0.8019], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.9309, 27.9125],\n",
      "        [27.7806, 22.7498],\n",
      "        [22.7726, 27.7406],\n",
      "        [25.2939, 25.2591]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9557, 0.0884, 0.0630, 0.8038], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.9302, 27.9372],\n",
      "        [27.7786, 22.7783],\n",
      "        [22.7710, 27.7687],\n",
      "        [25.2923, 25.2906]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9557, 0.0884, 0.0630, 0.8038], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.9546, 27.9366],\n",
      "        [27.8065, 22.7764],\n",
      "        [22.7986, 27.7672],\n",
      "        [25.3231, 25.2891]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9562, 0.0887, 0.0630, 0.8056], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.9539, 27.9609],\n",
      "        [27.8045, 22.8043],\n",
      "        [22.7970, 27.7947],\n",
      "        [25.3216, 25.3199]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9562, 0.0887, 0.0630, 0.8056], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[27.9779, 27.9603],\n",
      "        [27.8319, 22.8024],\n",
      "        [22.8240, 27.7933],\n",
      "        [25.3518, 25.3185]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9567, 0.0890, 0.0631, 0.8074], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[27.9772, 27.9841],\n",
      "        [27.8299, 22.8298],\n",
      "        [22.8225, 27.8203],\n",
      "        [25.3503, 25.3487]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9567, 0.0890, 0.0631, 0.8074], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.0007, 27.9835],\n",
      "        [27.8568, 22.8279],\n",
      "        [22.8490, 27.8189],\n",
      "        [25.3800, 25.3473]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9571, 0.0892, 0.0631, 0.8092], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.0000, 28.0069],\n",
      "        [27.8549, 22.8548],\n",
      "        [22.8475, 27.8454],\n",
      "        [25.3785, 25.3770]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9571, 0.0892, 0.0631, 0.8092], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.0231, 28.0063],\n",
      "        [27.8813, 22.8530],\n",
      "        [22.8735, 27.8440],\n",
      "        [25.4076, 25.3756]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9576, 0.0895, 0.0632, 0.8110], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.0225, 28.0292],\n",
      "        [27.8794, 22.8793],\n",
      "        [22.8721, 27.8700],\n",
      "        [25.4061, 25.4047]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9576, 0.0895, 0.0632, 0.8110], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.0451, 28.0287],\n",
      "        [27.9053, 22.8776],\n",
      "        [22.8976, 27.8686],\n",
      "        [25.4347, 25.4033]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9580, 0.0898, 0.0632, 0.8127], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.0445, 28.0512],\n",
      "        [27.9034, 22.9034],\n",
      "        [22.8962, 27.8941],\n",
      "        [25.4333, 25.4319]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9580, 0.0898, 0.0632, 0.8127], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.0667, 28.0506],\n",
      "        [27.9289, 22.9017],\n",
      "        [22.9212, 27.8928],\n",
      "        [25.4613, 25.4306]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9585, 0.0900, 0.0633, 0.8144], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.0661, 28.0727],\n",
      "        [27.9270, 22.9270],\n",
      "        [22.9198, 27.9178],\n",
      "        [25.4599, 25.4586]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9585, 0.0900, 0.0633, 0.8144], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.0879, 28.0721],\n",
      "        [27.9520, 22.9253],\n",
      "        [22.9444, 27.9165],\n",
      "        [25.4874, 25.4573]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9589, 0.0903, 0.0633, 0.8160], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.0873, 28.0938],\n",
      "        [27.9502, 22.9502],\n",
      "        [22.9431, 27.9411],\n",
      "        [25.4861, 25.4848]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9589, 0.0903, 0.0633, 0.8160], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.1087, 28.0933],\n",
      "        [27.9747, 22.9485],\n",
      "        [22.9672, 27.9398],\n",
      "        [25.5131, 25.4835]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9593, 0.0905, 0.0634, 0.8176], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.1081, 28.1146],\n",
      "        [27.9729, 22.9730],\n",
      "        [22.9658, 27.9639],\n",
      "        [25.5117, 25.5105]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9593, 0.0905, 0.0634, 0.8176], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.1291, 28.1141],\n",
      "        [27.9970, 22.9714],\n",
      "        [22.9895, 27.9627],\n",
      "        [25.5383, 25.5093]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9597, 0.0908, 0.0634, 0.8192], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.1285, 28.1349],\n",
      "        [27.9952, 22.9954],\n",
      "        [22.9882, 27.9863],\n",
      "        [25.5369, 25.5357]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9597, 0.0908, 0.0634, 0.8192], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.1492, 28.1344],\n",
      "        [28.0189, 22.9937],\n",
      "        [23.0115, 27.9851],\n",
      "        [25.5630, 25.5345]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9602, 0.0911, 0.0635, 0.8208], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.1486, 28.1549],\n",
      "        [28.0172, 23.0173],\n",
      "        [23.0102, 28.0083],\n",
      "        [25.5617, 25.5605]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9602, 0.0911, 0.0635, 0.8208], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.1689, 28.1544],\n",
      "        [28.0404, 23.0157],\n",
      "        [23.0330, 28.0071],\n",
      "        [25.5872, 25.5593]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9606, 0.0913, 0.0635, 0.8223], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.1683, 28.1746],\n",
      "        [28.0387, 23.0389],\n",
      "        [23.0318, 28.0299],\n",
      "        [25.5860, 25.5849]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9606, 0.0913, 0.0635, 0.8223], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.1882, 28.1741],\n",
      "        [28.0615, 23.0373],\n",
      "        [23.0542, 28.0287],\n",
      "        [25.6111, 25.5837]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9610, 0.0916, 0.0636, 0.8238], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.1877, 28.1939],\n",
      "        [28.0598, 23.0601],\n",
      "        [23.0530, 28.0511],\n",
      "        [25.6099, 25.6088]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9610, 0.0916, 0.0636, 0.8238], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.2073, 28.1934],\n",
      "        [28.0822, 23.0585],\n",
      "        [23.0750, 28.0500],\n",
      "        [25.6345, 25.6077]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9613, 0.0919, 0.0636, 0.8253], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.2067, 28.2128],\n",
      "        [28.0806, 23.0809],\n",
      "        [23.0738, 28.0720],\n",
      "        [25.6333, 25.6323]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9613, 0.0919, 0.0636, 0.8253], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.2259, 28.2124],\n",
      "        [28.1026, 23.0793],\n",
      "        [23.0954, 28.0709],\n",
      "        [25.6575, 25.6312]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9617, 0.0921, 0.0637, 0.8268], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.2254, 28.2314],\n",
      "        [28.1010, 23.1013],\n",
      "        [23.0942, 28.0924],\n",
      "        [25.6564, 25.6553]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9617, 0.0921, 0.0637, 0.8268], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.2443, 28.2310],\n",
      "        [28.1226, 23.0997],\n",
      "        [23.1155, 28.0913],\n",
      "        [25.6801, 25.6542]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9621, 0.0924, 0.0637, 0.8282], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.2438, 28.2497],\n",
      "        [28.1210, 23.1214],\n",
      "        [23.1143, 28.1126],\n",
      "        [25.6790, 25.6780]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9621, 0.0924, 0.0637, 0.8282], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.2623, 28.2493],\n",
      "        [28.1423, 23.1198],\n",
      "        [23.1352, 28.1115],\n",
      "        [25.7024, 25.6769]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9625, 0.0927, 0.0638, 0.8296], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.2618, 28.2677],\n",
      "        [28.1407, 23.1411],\n",
      "        [23.1341, 28.1323],\n",
      "        [25.7012, 25.7003]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9625, 0.0927, 0.0638, 0.8296], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.2801, 28.2673],\n",
      "        [28.1617, 23.1396],\n",
      "        [23.1546, 28.1313],\n",
      "        [25.7242, 25.6992]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9628, 0.0929, 0.0638, 0.8310], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.2796, 28.2854],\n",
      "        [28.1601, 23.1605],\n",
      "        [23.1535, 28.1518],\n",
      "        [25.7231, 25.7222]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9628, 0.0929, 0.0638, 0.8310], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.2975, 28.2849],\n",
      "        [28.1806, 23.1590],\n",
      "        [23.1736, 28.1507],\n",
      "        [25.7457, 25.7211]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9632, 0.0932, 0.0639, 0.8323], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.2970, 28.3027],\n",
      "        [28.1791, 23.1795],\n",
      "        [23.1725, 28.1708],\n",
      "        [25.7446, 25.7437]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9632, 0.0932, 0.0639, 0.8323], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.3146, 28.3023],\n",
      "        [28.1993, 23.1780],\n",
      "        [23.1924, 28.1698],\n",
      "        [25.7668, 25.7427]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9636, 0.0935, 0.0639, 0.8337], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.3141, 28.3198],\n",
      "        [28.1978, 23.1982],\n",
      "        [23.1913, 28.1896],\n",
      "        [25.7657, 25.7648]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9636, 0.0935, 0.0639, 0.8337], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.3314, 28.3194],\n",
      "        [28.2177, 23.1967],\n",
      "        [23.2108, 28.1886],\n",
      "        [25.7875, 25.7638]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9639, 0.0937, 0.0640, 0.8350], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.3309, 28.3366],\n",
      "        [28.2162, 23.2166],\n",
      "        [23.2097, 28.2080],\n",
      "        [25.7865, 25.7856]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9639, 0.0937, 0.0640, 0.8350], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.3479, 28.3361],\n",
      "        [28.2357, 23.2152],\n",
      "        [23.2289, 28.2071],\n",
      "        [25.8079, 25.7846]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9643, 0.0940, 0.0640, 0.8363], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.3475, 28.3530],\n",
      "        [28.2342, 23.2347],\n",
      "        [23.2278, 28.2262],\n",
      "        [25.8069, 25.8060]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9643, 0.0940, 0.0640, 0.8363], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.3642, 28.3526],\n",
      "        [28.2535, 23.2333],\n",
      "        [23.2467, 28.2252],\n",
      "        [25.8280, 25.8051]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9646, 0.0943, 0.0640, 0.8375], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.3638, 28.3692],\n",
      "        [28.2520, 23.2525],\n",
      "        [23.2456, 28.2440],\n",
      "        [25.8270, 25.8261]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9646, 0.0943, 0.0640, 0.8375], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.3802, 28.3688],\n",
      "        [28.2710, 23.2511],\n",
      "        [23.2642, 28.2430],\n",
      "        [25.8477, 25.8252]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9649, 0.0945, 0.0641, 0.8388], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.3798, 28.3852],\n",
      "        [28.2695, 23.2700],\n",
      "        [23.2632, 28.2615],\n",
      "        [25.8467, 25.8459]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9649, 0.0945, 0.0641, 0.8388], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.3959, 28.3848],\n",
      "        [28.2881, 23.2686],\n",
      "        [23.2814, 28.2606],\n",
      "        [25.8671, 25.8450]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9652, 0.0948, 0.0641, 0.8400], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.3955, 28.4009],\n",
      "        [28.2867, 23.2872],\n",
      "        [23.2804, 28.2788],\n",
      "        [25.8661, 25.8653]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9652, 0.0948, 0.0641, 0.8400], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.4114, 28.4005],\n",
      "        [28.3050, 23.2858],\n",
      "        [23.2983, 28.2779],\n",
      "        [25.8861, 25.8644]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9656, 0.0951, 0.0642, 0.8412], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.4110, 28.4163],\n",
      "        [28.3036, 23.3041],\n",
      "        [23.2973, 28.2957],\n",
      "        [25.8852, 25.8844]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9656, 0.0951, 0.0642, 0.8412], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.4266, 28.4159],\n",
      "        [28.3216, 23.3027],\n",
      "        [23.3150, 28.2948],\n",
      "        [25.9049, 25.8835]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9659, 0.0954, 0.0642, 0.8424], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.4262, 28.4314],\n",
      "        [28.3202, 23.3208],\n",
      "        [23.3140, 28.3124],\n",
      "        [25.9040, 25.9032]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9659, 0.0954, 0.0642, 0.8424], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.4416, 28.4310],\n",
      "        [28.3380, 23.3194],\n",
      "        [23.3314, 28.3115],\n",
      "        [25.9234, 25.9024]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9662, 0.0956, 0.0643, 0.8436], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.4412, 28.4463],\n",
      "        [28.3365, 23.3371],\n",
      "        [23.3304, 28.3288],\n",
      "        [25.9225, 25.9217]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9662, 0.0956, 0.0643, 0.8436], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.4563, 28.4459],\n",
      "        [28.3540, 23.3358],\n",
      "        [23.3475, 28.3279],\n",
      "        [25.9415, 25.9209]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9665, 0.0959, 0.0643, 0.8447], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.4559, 28.4610],\n",
      "        [28.3526, 23.3533],\n",
      "        [23.3465, 28.3450],\n",
      "        [25.9407, 25.9399]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9665, 0.0959, 0.0643, 0.8447], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.4708, 28.4606],\n",
      "        [28.3699, 23.3519],\n",
      "        [23.3633, 28.3441],\n",
      "        [25.9594, 25.9391]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9668, 0.0962, 0.0644, 0.8459], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.4704, 28.4754],\n",
      "        [28.3685, 23.3691],\n",
      "        [23.3624, 28.3609],\n",
      "        [25.9585, 25.9578]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9668, 0.0962, 0.0644, 0.8459], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.4850, 28.4750],\n",
      "        [28.3855, 23.3677],\n",
      "        [23.3789, 28.3600],\n",
      "        [25.9770, 25.9570]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9671, 0.0965, 0.0644, 0.8470], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.4846, 28.4896],\n",
      "        [28.3840, 23.3847],\n",
      "        [23.3780, 28.3765],\n",
      "        [25.9761, 25.9754]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9671, 0.0965, 0.0644, 0.8470], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.4991, 28.4892],\n",
      "        [28.4008, 23.3834],\n",
      "        [23.3943, 28.3756],\n",
      "        [25.9943, 25.9746]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9674, 0.0967, 0.0644, 0.8481], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.4986, 28.5036],\n",
      "        [28.3994, 23.4000],\n",
      "        [23.3934, 28.3919],\n",
      "        [25.9935, 25.9928]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9674, 0.0967, 0.0644, 0.8481], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.5129, 28.5032],\n",
      "        [28.4159, 23.3987],\n",
      "        [23.4094, 28.3910],\n",
      "        [26.0114, 25.9920]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9677, 0.0970, 0.0645, 0.8492], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.5125, 28.5173],\n",
      "        [28.4145, 23.4152],\n",
      "        [23.4086, 28.4070],\n",
      "        [26.0105, 26.0098]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9677, 0.0970, 0.0645, 0.8492], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.5264, 28.5170],\n",
      "        [28.4307, 23.4138],\n",
      "        [23.4243, 28.4062],\n",
      "        [26.0282, 26.0091]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9680, 0.0973, 0.0645, 0.8502], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.5260, 28.5308],\n",
      "        [28.4294, 23.4300],\n",
      "        [23.4235, 28.4219],\n",
      "        [26.0273, 26.0266]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9680, 0.0973, 0.0645, 0.8502], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.5398, 28.5305],\n",
      "        [28.4453, 23.4287],\n",
      "        [23.4390, 28.4211],\n",
      "        [26.0447, 26.0259]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9682, 0.0976, 0.0646, 0.8513], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.5394, 28.5442],\n",
      "        [28.4440, 23.4447],\n",
      "        [23.4381, 28.4366],\n",
      "        [26.0439, 26.0432]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9682, 0.0976, 0.0646, 0.8513], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.5530, 28.5438],\n",
      "        [28.4597, 23.4434],\n",
      "        [23.4534, 28.4358],\n",
      "        [26.0609, 26.0424]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9685, 0.0978, 0.0646, 0.8523], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.5526, 28.5573],\n",
      "        [28.4584, 23.4591],\n",
      "        [23.4526, 28.4510],\n",
      "        [26.0601, 26.0595]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9685, 0.0978, 0.0646, 0.8523], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.5659, 28.5569],\n",
      "        [28.4739, 23.4578],\n",
      "        [23.4676, 28.4502],\n",
      "        [26.0769, 26.0587]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9688, 0.0981, 0.0647, 0.8533], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.5655, 28.5702],\n",
      "        [28.4726, 23.4733],\n",
      "        [23.4668, 28.4653],\n",
      "        [26.0762, 26.0755]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9688, 0.0981, 0.0647, 0.8533], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.5787, 28.5698],\n",
      "        [28.4879, 23.4720],\n",
      "        [23.4816, 28.4645],\n",
      "        [26.0927, 26.0748]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9691, 0.0984, 0.0647, 0.8543], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.5783, 28.5829],\n",
      "        [28.4866, 23.4873],\n",
      "        [23.4808, 28.4793],\n",
      "        [26.0919, 26.0913]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9691, 0.0984, 0.0647, 0.8543], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.5912, 28.5825],\n",
      "        [28.5016, 23.4860],\n",
      "        [23.4954, 28.4785],\n",
      "        [26.1082, 26.0906]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9693, 0.0987, 0.0647, 0.8553], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.5908, 28.5954],\n",
      "        [28.5003, 23.5010],\n",
      "        [23.4946, 28.4931],\n",
      "        [26.1075, 26.1068]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9693, 0.0987, 0.0647, 0.8553], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.6036, 28.5950],\n",
      "        [28.5152, 23.4997],\n",
      "        [23.5089, 28.4923],\n",
      "        [26.1235, 26.1061]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9696, 0.0990, 0.0648, 0.8563], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.6032, 28.6077],\n",
      "        [28.5138, 23.5146],\n",
      "        [23.5082, 28.5067],\n",
      "        [26.1228, 26.1221]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9696, 0.0990, 0.0648, 0.8563], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.6158, 28.6074],\n",
      "        [28.5285, 23.5133],\n",
      "        [23.5223, 28.5059],\n",
      "        [26.1386, 26.1215]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9698, 0.0993, 0.0648, 0.8572], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.6154, 28.6198],\n",
      "        [28.5272, 23.5279],\n",
      "        [23.5215, 28.5200],\n",
      "        [26.1379, 26.1372]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9698, 0.0993, 0.0648, 0.8572], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.6277, 28.6195],\n",
      "        [28.5416, 23.5267],\n",
      "        [23.5355, 28.5193],\n",
      "        [26.1534, 26.1365]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9701, 0.0995, 0.0649, 0.8582], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.6274, 28.6318],\n",
      "        [28.5403, 23.5411],\n",
      "        [23.5347, 28.5332],\n",
      "        [26.1527, 26.1521]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9701, 0.0995, 0.0649, 0.8582], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.6395, 28.6314],\n",
      "        [28.5546, 23.5398],\n",
      "        [23.5485, 28.5325],\n",
      "        [26.1681, 26.1514]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9703, 0.0998, 0.0649, 0.8591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.6392, 28.6435],\n",
      "        [28.5533, 23.5541],\n",
      "        [23.5477, 28.5462],\n",
      "        [26.1674, 26.1667]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9703, 0.0998, 0.0649, 0.8591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.6512, 28.6432],\n",
      "        [28.5674, 23.5528],\n",
      "        [23.5613, 28.5455],\n",
      "        [26.1825, 26.1661]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9706, 0.1001, 0.0649, 0.8600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.6508, 28.6551],\n",
      "        [28.5661, 23.5669],\n",
      "        [23.5605, 28.5590],\n",
      "        [26.1818, 26.1812]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9706, 0.1001, 0.0649, 0.8600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.6626, 28.6548],\n",
      "        [28.5799, 23.5656],\n",
      "        [23.5739, 28.5583],\n",
      "        [26.1967, 26.1805]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9708, 0.1004, 0.0650, 0.8609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.6623, 28.6665],\n",
      "        [28.5786, 23.5794],\n",
      "        [23.5731, 28.5716],\n",
      "        [26.1960, 26.1954]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9708, 0.1004, 0.0650, 0.8609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.6739, 28.6662],\n",
      "        [28.5923, 23.5782],\n",
      "        [23.5863, 28.5709],\n",
      "        [26.2107, 26.1947]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9711, 0.1007, 0.0650, 0.8618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.6736, 28.6777],\n",
      "        [28.5910, 23.5918],\n",
      "        [23.5855, 28.5840],\n",
      "        [26.2100, 26.2094]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9711, 0.1007, 0.0650, 0.8618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.6850, 28.6774],\n",
      "        [28.6045, 23.5906],\n",
      "        [23.5985, 28.5833],\n",
      "        [26.2245, 26.2087]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9713, 0.1010, 0.0651, 0.8627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.6847, 28.6888],\n",
      "        [28.6033, 23.6041],\n",
      "        [23.5978, 28.5963],\n",
      "        [26.2238, 26.2232]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9713, 0.1010, 0.0651, 0.8627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.6960, 28.6885],\n",
      "        [28.6166, 23.6028],\n",
      "        [23.6106, 28.5956],\n",
      "        [26.2381, 26.2226]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9715, 0.1013, 0.0651, 0.8636], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.6957, 28.6997],\n",
      "        [28.6153, 23.6161],\n",
      "        [23.6099, 28.6084],\n",
      "        [26.2374, 26.2368]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9715, 0.1013, 0.0651, 0.8636], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.7068, 28.6994],\n",
      "        [28.6284, 23.6149],\n",
      "        [23.6225, 28.6077],\n",
      "        [26.2515, 26.2362]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9717, 0.1015, 0.0651, 0.8644], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.7065, 28.7105],\n",
      "        [28.6272, 23.6280],\n",
      "        [23.6217, 28.6202],\n",
      "        [26.2508, 26.2502]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9717, 0.1015, 0.0651, 0.8644], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.7174, 28.7102],\n",
      "        [28.6401, 23.6268],\n",
      "        [23.6342, 28.6196],\n",
      "        [26.2647, 26.2496]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9720, 0.1018, 0.0652, 0.8653], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.7171, 28.7211],\n",
      "        [28.6389, 23.6397],\n",
      "        [23.6335, 28.6320],\n",
      "        [26.2640, 26.2634]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9720, 0.1018, 0.0652, 0.8653], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.7279, 28.7208],\n",
      "        [28.6517, 23.6385],\n",
      "        [23.6457, 28.6313],\n",
      "        [26.2777, 26.2628]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9722, 0.1021, 0.0652, 0.8661], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.7276, 28.7315],\n",
      "        [28.6504, 23.6512],\n",
      "        [23.6450, 28.6435],\n",
      "        [26.2771, 26.2765]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9722, 0.1021, 0.0652, 0.8661], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.7383, 28.7312],\n",
      "        [28.6630, 23.6500],\n",
      "        [23.6571, 28.6429],\n",
      "        [26.2905, 26.2759]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9724, 0.1024, 0.0653, 0.8669], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.7380, 28.7418],\n",
      "        [28.6618, 23.6626],\n",
      "        [23.6564, 28.6549],\n",
      "        [26.2899, 26.2893]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9724, 0.1024, 0.0653, 0.8669], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.7485, 28.7415],\n",
      "        [28.6742, 23.6614],\n",
      "        [23.6684, 28.6543],\n",
      "        [26.3032, 26.2887]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9726, 0.1027, 0.0653, 0.8678], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.7481, 28.7520],\n",
      "        [28.6730, 23.6738],\n",
      "        [23.6677, 28.6662],\n",
      "        [26.3026, 26.3020]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9726, 0.1027, 0.0653, 0.8678], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.7585, 28.7517],\n",
      "        [28.6853, 23.6726],\n",
      "        [23.6794, 28.6655],\n",
      "        [26.3157, 26.3014]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9728, 0.1030, 0.0653, 0.8686], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.7582, 28.7620],\n",
      "        [28.6840, 23.6849],\n",
      "        [23.6787, 28.6773],\n",
      "        [26.3151, 26.3145]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9728, 0.1030, 0.0653, 0.8686], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.7684, 28.7617],\n",
      "        [28.6962, 23.6837],\n",
      "        [23.6903, 28.6766],\n",
      "        [26.3280, 26.3139]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9730, 0.1033, 0.0654, 0.8694], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.7681, 28.7718],\n",
      "        [28.6949, 23.6958],\n",
      "        [23.6897, 28.6882],\n",
      "        [26.3274, 26.3268]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9730, 0.1033, 0.0654, 0.8694], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.7782, 28.7716],\n",
      "        [28.7070, 23.6946],\n",
      "        [23.7011, 28.6876],\n",
      "        [26.3402, 26.3262]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9733, 0.1036, 0.0654, 0.8701], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.7779, 28.7816],\n",
      "        [28.7057, 23.7066],\n",
      "        [23.7005, 28.6990],\n",
      "        [26.3395, 26.3390]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9733, 0.1036, 0.0654, 0.8701], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.7878, 28.7813],\n",
      "        [28.7176, 23.7054],\n",
      "        [23.7118, 28.6983],\n",
      "        [26.3521, 26.3384]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9735, 0.1039, 0.0655, 0.8709], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.7875, 28.7911],\n",
      "        [28.7163, 23.7172],\n",
      "        [23.7111, 28.7096],\n",
      "        [26.3515, 26.3510]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9735, 0.1039, 0.0655, 0.8709], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.7973, 28.7909],\n",
      "        [28.7280, 23.7160],\n",
      "        [23.7222, 28.7090],\n",
      "        [26.3639, 26.3504]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9737, 0.1042, 0.0655, 0.8717], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.7970, 28.8006],\n",
      "        [28.7268, 23.7277],\n",
      "        [23.7216, 28.7201],\n",
      "        [26.3633, 26.3628]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9737, 0.1042, 0.0655, 0.8717], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.8067, 28.8003],\n",
      "        [28.7383, 23.7265],\n",
      "        [23.7326, 28.7195],\n",
      "        [26.3756, 26.3622]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9739, 0.1045, 0.0655, 0.8724], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.8064, 28.8099],\n",
      "        [28.7371, 23.7380],\n",
      "        [23.7319, 28.7304],\n",
      "        [26.3750, 26.3745]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9739, 0.1045, 0.0655, 0.8724], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.8159, 28.8097],\n",
      "        [28.7485, 23.7368],\n",
      "        [23.7428, 28.7298],\n",
      "        [26.3871, 26.3739]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9741, 0.1048, 0.0656, 0.8732], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.8156, 28.8191],\n",
      "        [28.7473, 23.7482],\n",
      "        [23.7421, 28.7406],\n",
      "        [26.3865, 26.3860]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9741, 0.1048, 0.0656, 0.8732], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.8250, 28.8188],\n",
      "        [28.7586, 23.7470],\n",
      "        [23.7528, 28.7400],\n",
      "        [26.3984, 26.3854]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9742, 0.1051, 0.0656, 0.8739], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.8247, 28.8282],\n",
      "        [28.7574, 23.7583],\n",
      "        [23.7522, 28.7507],\n",
      "        [26.3979, 26.3973]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9742, 0.1051, 0.0656, 0.8739], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.8340, 28.8279],\n",
      "        [28.7685, 23.7571],\n",
      "        [23.7628, 28.7501],\n",
      "        [26.4097, 26.3968]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9744, 0.1054, 0.0656, 0.8746], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.8337, 28.8371],\n",
      "        [28.7673, 23.7682],\n",
      "        [23.7621, 28.7607],\n",
      "        [26.4091, 26.4085]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9744, 0.1054, 0.0656, 0.8746], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.8428, 28.8369],\n",
      "        [28.7783, 23.7670],\n",
      "        [23.7726, 28.7600],\n",
      "        [26.4207, 26.4080]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9746, 0.1057, 0.0657, 0.8753], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.8426, 28.8460],\n",
      "        [28.7771, 23.7780],\n",
      "        [23.7719, 28.7705],\n",
      "        [26.4201, 26.4196]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9746, 0.1057, 0.0657, 0.8753], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.8516, 28.8457],\n",
      "        [28.7879, 23.7768],\n",
      "        [23.7822, 28.7698],\n",
      "        [26.4316, 26.4190]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9748, 0.1060, 0.0657, 0.8760], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.8513, 28.8547],\n",
      "        [28.7867, 23.7877],\n",
      "        [23.7816, 28.7801],\n",
      "        [26.4310, 26.4305]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9748, 0.1060, 0.0657, 0.8760], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.8602, 28.8544],\n",
      "        [28.7975, 23.7865],\n",
      "        [23.7918, 28.7795],\n",
      "        [26.4424, 26.4300]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9750, 0.1063, 0.0658, 0.8767], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.8599, 28.8632],\n",
      "        [28.7963, 23.7972],\n",
      "        [23.7912, 28.7897],\n",
      "        [26.4418, 26.4413]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9750, 0.1063, 0.0658, 0.8767], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.8687, 28.8630],\n",
      "        [28.8069, 23.7960],\n",
      "        [23.8012, 28.7891],\n",
      "        [26.4530, 26.4407]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9752, 0.1066, 0.0658, 0.8774], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.8684, 28.8717],\n",
      "        [28.8057, 23.8066],\n",
      "        [23.8006, 28.7991],\n",
      "        [26.4524, 26.4519]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9752, 0.1066, 0.0658, 0.8774], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.8771, 28.8715],\n",
      "        [28.8162, 23.8054],\n",
      "        [23.8105, 28.7985],\n",
      "        [26.4635, 26.4514]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9753, 0.1069, 0.0658, 0.8781], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.8768, 28.8801],\n",
      "        [28.8150, 23.8159],\n",
      "        [23.8099, 28.8084],\n",
      "        [26.4629, 26.4624]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9753, 0.1069, 0.0658, 0.8781], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.8854, 28.8798],\n",
      "        [28.8253, 23.8147],\n",
      "        [23.8197, 28.8078],\n",
      "        [26.4738, 26.4619]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9755, 0.1072, 0.0659, 0.8788], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.8851, 28.8883],\n",
      "        [28.8242, 23.8251],\n",
      "        [23.8191, 28.8176],\n",
      "        [26.4733, 26.4727]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9755, 0.1072, 0.0659, 0.8788], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.8936, 28.8881],\n",
      "        [28.8344, 23.8239],\n",
      "        [23.8288, 28.8170],\n",
      "        [26.4841, 26.4722]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9757, 0.1076, 0.0659, 0.8794], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.8933, 28.8965],\n",
      "        [28.8332, 23.8342],\n",
      "        [23.8282, 28.8267],\n",
      "        [26.4835, 26.4830]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9757, 0.1076, 0.0659, 0.8794], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9016, 28.8962],\n",
      "        [28.8433, 23.8330],\n",
      "        [23.8377, 28.8261],\n",
      "        [26.4941, 26.4824]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9759, 0.1079, 0.0659, 0.8801], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9014, 28.9045],\n",
      "        [28.8421, 23.8431],\n",
      "        [23.8371, 28.8356],\n",
      "        [26.4936, 26.4931]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9759, 0.1079, 0.0659, 0.8801], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9096, 28.9043],\n",
      "        [28.8522, 23.8419],\n",
      "        [23.8466, 28.8351],\n",
      "        [26.5041, 26.4926]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9760, 0.1082, 0.0660, 0.8807], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9093, 28.9124],\n",
      "        [28.8510, 23.8519],\n",
      "        [23.8460, 28.8445],\n",
      "        [26.5036, 26.5030]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9760, 0.1082, 0.0660, 0.8807], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9175, 28.9122],\n",
      "        [28.8609, 23.8507],\n",
      "        [23.8553, 28.8439],\n",
      "        [26.5139, 26.5025]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9762, 0.1085, 0.0660, 0.8814], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9172, 28.9202],\n",
      "        [28.8597, 23.8606],\n",
      "        [23.8547, 28.8532],\n",
      "        [26.5134, 26.5129]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9762, 0.1085, 0.0660, 0.8814], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9252, 28.9200],\n",
      "        [28.8695, 23.8595],\n",
      "        [23.8639, 28.8526],\n",
      "        [26.5237, 26.5124]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9764, 0.1088, 0.0660, 0.8820], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9249, 28.9280],\n",
      "        [28.8683, 23.8693],\n",
      "        [23.8633, 28.8618],\n",
      "        [26.5231, 26.5226]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9764, 0.1088, 0.0660, 0.8820], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9329, 28.9277],\n",
      "        [28.8780, 23.8681],\n",
      "        [23.8724, 28.8612],\n",
      "        [26.5332, 26.5221]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9765, 0.1091, 0.0661, 0.8826], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9326, 28.9356],\n",
      "        [28.8768, 23.8778],\n",
      "        [23.8718, 28.8703],\n",
      "        [26.5327, 26.5322]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9765, 0.1091, 0.0661, 0.8826], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9405, 28.9354],\n",
      "        [28.8864, 23.8766],\n",
      "        [23.8808, 28.8698],\n",
      "        [26.5427, 26.5317]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9767, 0.1094, 0.0661, 0.8833], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9402, 28.9431],\n",
      "        [28.8852, 23.8862],\n",
      "        [23.8802, 28.8787],\n",
      "        [26.5422, 26.5417]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9767, 0.1094, 0.0661, 0.8833], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9479, 28.9429],\n",
      "        [28.8947, 23.8850],\n",
      "        [23.8891, 28.8782],\n",
      "        [26.5521, 26.5412]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9768, 0.1098, 0.0662, 0.8839], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9476, 28.9506],\n",
      "        [28.8935, 23.8945],\n",
      "        [23.8885, 28.8870],\n",
      "        [26.5516, 26.5510]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9768, 0.1098, 0.0662, 0.8839], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9553, 28.9503],\n",
      "        [28.9029, 23.8933],\n",
      "        [23.8973, 28.8865],\n",
      "        [26.5613, 26.5506]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9770, 0.1101, 0.0662, 0.8845], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9550, 28.9579],\n",
      "        [28.9017, 23.9027],\n",
      "        [23.8967, 28.8952],\n",
      "        [26.5608, 26.5603]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9770, 0.1101, 0.0662, 0.8845], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9625, 28.9577],\n",
      "        [28.9110, 23.9015],\n",
      "        [23.9054, 28.8947],\n",
      "        [26.5704, 26.5598]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9772, 0.1104, 0.0662, 0.8851], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9623, 28.9652],\n",
      "        [28.9098, 23.9108],\n",
      "        [23.9048, 28.9033],\n",
      "        [26.5700, 26.5694]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9772, 0.1104, 0.0662, 0.8851], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9697, 28.9649],\n",
      "        [28.9190, 23.9096],\n",
      "        [23.9134, 28.9028],\n",
      "        [26.5795, 26.5689]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9773, 0.1107, 0.0663, 0.8857], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9695, 28.9723],\n",
      "        [28.9178, 23.9188],\n",
      "        [23.9128, 28.9113],\n",
      "        [26.5790, 26.5784]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9773, 0.1107, 0.0663, 0.8857], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9768, 28.9721],\n",
      "        [28.9269, 23.9176],\n",
      "        [23.9213, 28.9108],\n",
      "        [26.5884, 26.5780]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9775, 0.1111, 0.0663, 0.8862], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9766, 28.9794],\n",
      "        [28.9257, 23.9267],\n",
      "        [23.9207, 28.9192],\n",
      "        [26.5879, 26.5874]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9775, 0.1111, 0.0663, 0.8862], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9839, 28.9791],\n",
      "        [28.9347, 23.9255],\n",
      "        [23.9291, 28.9187],\n",
      "        [26.5972, 26.5869]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9776, 0.1114, 0.0663, 0.8868], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9836, 28.9864],\n",
      "        [28.9335, 23.9345],\n",
      "        [23.9286, 28.9270],\n",
      "        [26.5967, 26.5962]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9776, 0.1114, 0.0663, 0.8868], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9908, 28.9861],\n",
      "        [28.9424, 23.9333],\n",
      "        [23.9368, 28.9265],\n",
      "        [26.6059, 26.5957]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9778, 0.1117, 0.0664, 0.8874], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9905, 28.9933],\n",
      "        [28.9412, 23.9422],\n",
      "        [23.9363, 28.9348],\n",
      "        [26.6054, 26.6049]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9778, 0.1117, 0.0664, 0.8874], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[28.9976, 28.9930],\n",
      "        [28.9500, 23.9411],\n",
      "        [23.9445, 28.9342],\n",
      "        [26.6145, 26.6044]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9779, 0.1120, 0.0664, 0.8880], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[28.9974, 29.0001],\n",
      "        [28.9489, 23.9499],\n",
      "        [23.9439, 28.9424],\n",
      "        [26.6140, 26.6135]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9779, 0.1120, 0.0664, 0.8880], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0044, 28.9998],\n",
      "        [28.9576, 23.9487],\n",
      "        [23.9520, 28.9419],\n",
      "        [26.6230, 26.6130]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9780, 0.1124, 0.0664, 0.8885], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0041, 29.0068],\n",
      "        [28.9564, 23.9574],\n",
      "        [23.9514, 28.9499],\n",
      "        [26.6225, 26.6220]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9780, 0.1124, 0.0664, 0.8885], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0111, 29.0066],\n",
      "        [28.9650, 23.9562],\n",
      "        [23.9594, 28.9494],\n",
      "        [26.6314, 26.6215]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9782, 0.1127, 0.0665, 0.8891], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0108, 29.0134],\n",
      "        [28.9638, 23.9649],\n",
      "        [23.9589, 28.9574],\n",
      "        [26.6309, 26.6304]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9782, 0.1127, 0.0665, 0.8891], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0176, 29.0132],\n",
      "        [28.9724, 23.9637],\n",
      "        [23.9668, 28.9568],\n",
      "        [26.6397, 26.6299]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9783, 0.1130, 0.0665, 0.8896], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0174, 29.0200],\n",
      "        [28.9712, 23.9722],\n",
      "        [23.9662, 28.9647],\n",
      "        [26.6392, 26.6387]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9783, 0.1130, 0.0665, 0.8896], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0242, 29.0198],\n",
      "        [28.9797, 23.9711],\n",
      "        [23.9741, 28.9642],\n",
      "        [26.6479, 26.6382]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9785, 0.1134, 0.0665, 0.8902], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0239, 29.0265],\n",
      "        [28.9785, 23.9795],\n",
      "        [23.9735, 28.9720],\n",
      "        [26.6474, 26.6469]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9785, 0.1134, 0.0665, 0.8902], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0306, 29.0263],\n",
      "        [28.9869, 23.9783],\n",
      "        [23.9813, 28.9715],\n",
      "        [26.6560, 26.6464]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9786, 0.1137, 0.0666, 0.8907], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0303, 29.0329],\n",
      "        [28.9857, 23.9867],\n",
      "        [23.9807, 28.9792],\n",
      "        [26.6555, 26.6550]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9786, 0.1137, 0.0666, 0.8907], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0370, 29.0327],\n",
      "        [28.9940, 23.9855],\n",
      "        [23.9884, 28.9787],\n",
      "        [26.6640, 26.6546]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9787, 0.1140, 0.0666, 0.8912], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0367, 29.0392],\n",
      "        [28.9928, 23.9938],\n",
      "        [23.9878, 28.9863],\n",
      "        [26.6636, 26.6630]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9787, 0.1140, 0.0666, 0.8912], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0432, 29.0390],\n",
      "        [29.0010, 23.9926],\n",
      "        [23.9954, 28.9858],\n",
      "        [26.6719, 26.6626]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9789, 0.1144, 0.0666, 0.8918], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0430, 29.0455],\n",
      "        [28.9998, 24.0009],\n",
      "        [23.9949, 28.9933],\n",
      "        [26.6715, 26.6709]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9789, 0.1144, 0.0666, 0.8918], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0494, 29.0453],\n",
      "        [29.0080, 23.9997],\n",
      "        [24.0023, 28.9928],\n",
      "        [26.6798, 26.6705]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9790, 0.1147, 0.0667, 0.8923], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0492, 29.0517],\n",
      "        [29.0068, 24.0078],\n",
      "        [24.0018, 29.0003],\n",
      "        [26.6793, 26.6788]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9790, 0.1147, 0.0667, 0.8923], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0556, 29.0514],\n",
      "        [29.0148, 24.0066],\n",
      "        [24.0092, 28.9997],\n",
      "        [26.6875, 26.6783]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9791, 0.1151, 0.0667, 0.8928], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0553, 29.0578],\n",
      "        [29.0136, 24.0147],\n",
      "        [24.0087, 29.0071],\n",
      "        [26.6871, 26.6865]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9791, 0.1151, 0.0667, 0.8928], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0617, 29.0576],\n",
      "        [29.0217, 24.0135],\n",
      "        [24.0160, 29.0066],\n",
      "        [26.6952, 26.6861]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9793, 0.1154, 0.0667, 0.8933], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0614, 29.0638],\n",
      "        [29.0204, 24.0215],\n",
      "        [24.0155, 29.0139],\n",
      "        [26.6947, 26.6942]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9793, 0.1154, 0.0667, 0.8933], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0676, 29.0636],\n",
      "        [29.0284, 24.0203],\n",
      "        [24.0227, 29.0134],\n",
      "        [26.7027, 26.6938]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9794, 0.1157, 0.0668, 0.8938], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0674, 29.0698],\n",
      "        [29.0272, 24.0282],\n",
      "        [24.0222, 29.0206],\n",
      "        [26.7023, 26.7017]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9794, 0.1157, 0.0668, 0.8938], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0736, 29.0696],\n",
      "        [29.0350, 24.0270],\n",
      "        [24.0293, 29.0201],\n",
      "        [26.7102, 26.7013]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9795, 0.1161, 0.0668, 0.8943], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0733, 29.0757],\n",
      "        [29.0338, 24.0349],\n",
      "        [24.0288, 29.0273],\n",
      "        [26.7098, 26.7092]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9795, 0.1161, 0.0668, 0.8943], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0794, 29.0755],\n",
      "        [29.0416, 24.0337],\n",
      "        [24.0359, 29.0268],\n",
      "        [26.7176, 26.7088]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9796, 0.1164, 0.0668, 0.8948], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0792, 29.0815],\n",
      "        [29.0404, 24.0415],\n",
      "        [24.0354, 29.0338],\n",
      "        [26.7172, 26.7166]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9796, 0.1164, 0.0668, 0.8948], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0852, 29.0813],\n",
      "        [29.0481, 24.0403],\n",
      "        [24.0424, 29.0333],\n",
      "        [26.7249, 26.7162]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9798, 0.1168, 0.0669, 0.8953], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0849, 29.0873],\n",
      "        [29.0469, 24.0480],\n",
      "        [24.0419, 29.0403],\n",
      "        [26.7245, 26.7240]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9798, 0.1168, 0.0669, 0.8953], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0909, 29.0871],\n",
      "        [29.0545, 24.0468],\n",
      "        [24.0488, 29.0398],\n",
      "        [26.7322, 26.7235]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9799, 0.1171, 0.0669, 0.8958], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0907, 29.0930],\n",
      "        [29.0533, 24.0544],\n",
      "        [24.0483, 29.0468],\n",
      "        [26.7318, 26.7312]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9799, 0.1171, 0.0669, 0.8958], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.0966, 29.0928],\n",
      "        [29.0609, 24.0532],\n",
      "        [24.0552, 29.0463],\n",
      "        [26.7394, 26.7308]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9800, 0.1175, 0.0669, 0.8962], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.0963, 29.0986],\n",
      "        [29.0597, 24.0608],\n",
      "        [24.0546, 29.0531],\n",
      "        [26.7389, 26.7384]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9800, 0.1175, 0.0669, 0.8962], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1022, 29.0984],\n",
      "        [29.0672, 24.0596],\n",
      "        [24.0614, 29.0526],\n",
      "        [26.7464, 26.7379]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9801, 0.1178, 0.0670, 0.8967], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1019, 29.1042],\n",
      "        [29.0660, 24.0671],\n",
      "        [24.0609, 29.0594],\n",
      "        [26.7460, 26.7455]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9801, 0.1178, 0.0670, 0.8967], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1077, 29.1040],\n",
      "        [29.0734, 24.0659],\n",
      "        [24.0677, 29.0589],\n",
      "        [26.7534, 26.7451]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9803, 0.1182, 0.0670, 0.8972], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1075, 29.1097],\n",
      "        [29.0722, 24.0733],\n",
      "        [24.0672, 29.0656],\n",
      "        [26.7530, 26.7525]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9803, 0.1182, 0.0670, 0.8972], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1132, 29.1095],\n",
      "        [29.0796, 24.0721],\n",
      "        [24.0738, 29.0651],\n",
      "        [26.7604, 26.7521]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9804, 0.1185, 0.0670, 0.8976], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1129, 29.1151],\n",
      "        [29.0784, 24.0795],\n",
      "        [24.0733, 29.0717],\n",
      "        [26.7599, 26.7594]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9804, 0.1185, 0.0670, 0.8976], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1186, 29.1149],\n",
      "        [29.0857, 24.0783],\n",
      "        [24.0799, 29.0712],\n",
      "        [26.7672, 26.7590]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9805, 0.1189, 0.0671, 0.8981], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1183, 29.1205],\n",
      "        [29.0845, 24.0856],\n",
      "        [24.0794, 29.0778],\n",
      "        [26.7668, 26.7663]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9805, 0.1189, 0.0671, 0.8981], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1239, 29.1203],\n",
      "        [29.0917, 24.0844],\n",
      "        [24.0859, 29.0773],\n",
      "        [26.7740, 26.7659]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9806, 0.1193, 0.0671, 0.8986], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1237, 29.1258],\n",
      "        [29.0905, 24.0916],\n",
      "        [24.0854, 29.0838],\n",
      "        [26.7736, 26.7730]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9806, 0.1193, 0.0671, 0.8986], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1292, 29.1256],\n",
      "        [29.0977, 24.0904],\n",
      "        [24.0919, 29.0834],\n",
      "        [26.7807, 26.7727]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9807, 0.1196, 0.0671, 0.8990], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1290, 29.1311],\n",
      "        [29.0965, 24.0976],\n",
      "        [24.0913, 29.0898],\n",
      "        [26.7803, 26.7798]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9807, 0.1196, 0.0671, 0.8990], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1344, 29.1309],\n",
      "        [29.1036, 24.0964],\n",
      "        [24.0977, 29.0893],\n",
      "        [26.7874, 26.7794]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9808, 0.1200, 0.0672, 0.8995], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1342, 29.1363],\n",
      "        [29.1024, 24.1035],\n",
      "        [24.0972, 29.0957],\n",
      "        [26.7869, 26.7864]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9808, 0.1200, 0.0672, 0.8995], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1396, 29.1361],\n",
      "        [29.1095, 24.1023],\n",
      "        [24.1036, 29.0952],\n",
      "        [26.7939, 26.7860]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9809, 0.1204, 0.0672, 0.8999], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1394, 29.1415],\n",
      "        [29.1082, 24.1094],\n",
      "        [24.1031, 29.1015],\n",
      "        [26.7935, 26.7930]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9809, 0.1204, 0.0672, 0.8999], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1447, 29.1413],\n",
      "        [29.1153, 24.1081],\n",
      "        [24.1093, 29.1010],\n",
      "        [26.8004, 26.7926]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9810, 0.1207, 0.0672, 0.9003], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1445, 29.1466],\n",
      "        [29.1140, 24.1151],\n",
      "        [24.1088, 29.1073],\n",
      "        [26.8000, 26.7995]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9810, 0.1207, 0.0672, 0.9003], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1498, 29.1463],\n",
      "        [29.1210, 24.1139],\n",
      "        [24.1150, 29.1068],\n",
      "        [26.8069, 26.7991]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9812, 0.1211, 0.0673, 0.9008], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1495, 29.1516],\n",
      "        [29.1197, 24.1209],\n",
      "        [24.1145, 29.1130],\n",
      "        [26.8065, 26.8059]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9812, 0.1211, 0.0673, 0.9008], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1548, 29.1514],\n",
      "        [29.1266, 24.1197],\n",
      "        [24.1207, 29.1125],\n",
      "        [26.8132, 26.8055]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9813, 0.1215, 0.0673, 0.9012], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1546, 29.1566],\n",
      "        [29.1254, 24.1266],\n",
      "        [24.1202, 29.1186],\n",
      "        [26.8128, 26.8123]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9813, 0.1215, 0.0673, 0.9012], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1597, 29.1564],\n",
      "        [29.1322, 24.1253],\n",
      "        [24.1262, 29.1181],\n",
      "        [26.8195, 26.8119]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9814, 0.1218, 0.0673, 0.9016], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1595, 29.1615],\n",
      "        [29.1310, 24.1322],\n",
      "        [24.1258, 29.1242],\n",
      "        [26.8191, 26.8186]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9814, 0.1218, 0.0673, 0.9016], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1646, 29.1613],\n",
      "        [29.1378, 24.1309],\n",
      "        [24.1318, 29.1237],\n",
      "        [26.8258, 26.8182]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9815, 0.1222, 0.0674, 0.9020], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1644, 29.1664],\n",
      "        [29.1366, 24.1377],\n",
      "        [24.1313, 29.1297],\n",
      "        [26.8254, 26.8248]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9815, 0.1222, 0.0674, 0.9020], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1695, 29.1662],\n",
      "        [29.1433, 24.1365],\n",
      "        [24.1373, 29.1292],\n",
      "        [26.8319, 26.8244]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9816, 0.1226, 0.0674, 0.9025], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1693, 29.1712],\n",
      "        [29.1421, 24.1432],\n",
      "        [24.1368, 29.1352],\n",
      "        [26.8315, 26.8310]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9816, 0.1226, 0.0674, 0.9025], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1743, 29.1710],\n",
      "        [29.1488, 24.1420],\n",
      "        [24.1427, 29.1347],\n",
      "        [26.8381, 26.8306]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9817, 0.1230, 0.0674, 0.9029], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1740, 29.1760],\n",
      "        [29.1475, 24.1487],\n",
      "        [24.1422, 29.1406],\n",
      "        [26.8376, 26.8371]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9817, 0.1230, 0.0674, 0.9029], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1790, 29.1758],\n",
      "        [29.1541, 24.1474],\n",
      "        [24.1480, 29.1401],\n",
      "        [26.8441, 26.8367]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9818, 0.1233, 0.0675, 0.9033], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1788, 29.1807],\n",
      "        [29.1529, 24.1541],\n",
      "        [24.1476, 29.1460],\n",
      "        [26.8437, 26.8431]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9818, 0.1233, 0.0675, 0.9033], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1837, 29.1805],\n",
      "        [29.1595, 24.1528],\n",
      "        [24.1533, 29.1455],\n",
      "        [26.8501, 26.8428]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9819, 0.1237, 0.0675, 0.9037], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1835, 29.1854],\n",
      "        [29.1582, 24.1594],\n",
      "        [24.1529, 29.1513],\n",
      "        [26.8497, 26.8491]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9819, 0.1237, 0.0675, 0.9037], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1884, 29.1852],\n",
      "        [29.1648, 24.1582],\n",
      "        [24.1586, 29.1508],\n",
      "        [26.8560, 26.8488]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9820, 0.1241, 0.0675, 0.9041], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1881, 29.1900],\n",
      "        [29.1635, 24.1647],\n",
      "        [24.1581, 29.1565],\n",
      "        [26.8556, 26.8551]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9820, 0.1241, 0.0675, 0.9041], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1930, 29.1898],\n",
      "        [29.1700, 24.1635],\n",
      "        [24.1638, 29.1561],\n",
      "        [26.8619, 26.8547]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9821, 0.1245, 0.0676, 0.9045], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1927, 29.1946],\n",
      "        [29.1688, 24.1699],\n",
      "        [24.1633, 29.1617],\n",
      "        [26.8615, 26.8609]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9821, 0.1245, 0.0676, 0.9045], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.1975, 29.1944],\n",
      "        [29.1752, 24.1687],\n",
      "        [24.1689, 29.1613],\n",
      "        [26.8677, 26.8606]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9822, 0.1249, 0.0676, 0.9049], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.1973, 29.1991],\n",
      "        [29.1739, 24.1751],\n",
      "        [24.1685, 29.1669],\n",
      "        [26.8673, 26.8667]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9822, 0.1249, 0.0676, 0.9049], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2020, 29.1989],\n",
      "        [29.1803, 24.1739],\n",
      "        [24.1741, 29.1664],\n",
      "        [26.8734, 26.8664]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9823, 0.1253, 0.0676, 0.9053], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2018, 29.2036],\n",
      "        [29.1791, 24.1803],\n",
      "        [24.1736, 29.1720],\n",
      "        [26.8730, 26.8725]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9823, 0.1253, 0.0676, 0.9053], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2065, 29.2034],\n",
      "        [29.1854, 24.1790],\n",
      "        [24.1791, 29.1715],\n",
      "        [26.8791, 26.8721]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9824, 0.1256, 0.0677, 0.9057], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2062, 29.2080],\n",
      "        [29.1842, 24.1854],\n",
      "        [24.1786, 29.1770],\n",
      "        [26.8787, 26.8782]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9824, 0.1256, 0.0677, 0.9057], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2109, 29.2078],\n",
      "        [29.1905, 24.1841],\n",
      "        [24.1841, 29.1766],\n",
      "        [26.8848, 26.8778]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9825, 0.1260, 0.0677, 0.9060], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2107, 29.2125],\n",
      "        [29.1892, 24.1904],\n",
      "        [24.1836, 29.1820],\n",
      "        [26.8844, 26.8838]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9825, 0.1260, 0.0677, 0.9060], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2152, 29.2122],\n",
      "        [29.1954, 24.1891],\n",
      "        [24.1890, 29.1816],\n",
      "        [26.8903, 26.8834]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9826, 0.1264, 0.0677, 0.9064], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2150, 29.2168],\n",
      "        [29.1942, 24.1954],\n",
      "        [24.1886, 29.1870],\n",
      "        [26.8900, 26.8894]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9826, 0.1264, 0.0677, 0.9064], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2196, 29.2166],\n",
      "        [29.2004, 24.1941],\n",
      "        [24.1939, 29.1865],\n",
      "        [26.8959, 26.8890]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9826, 0.1268, 0.0678, 0.9068], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2193, 29.2211],\n",
      "        [29.1991, 24.2003],\n",
      "        [24.1935, 29.1919],\n",
      "        [26.8955, 26.8949]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9826, 0.1268, 0.0678, 0.9068], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2238, 29.2209],\n",
      "        [29.2053, 24.1991],\n",
      "        [24.1988, 29.1914],\n",
      "        [26.9013, 26.8946]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9827, 0.1272, 0.0678, 0.9072], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2236, 29.2254],\n",
      "        [29.2040, 24.2052],\n",
      "        [24.1983, 29.1967],\n",
      "        [26.9010, 26.9004]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9827, 0.1272, 0.0678, 0.9072], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2281, 29.2251],\n",
      "        [29.2102, 24.2040],\n",
      "        [24.2036, 29.1963],\n",
      "        [26.9068, 26.9001]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9828, 0.1276, 0.0678, 0.9075], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2278, 29.2296],\n",
      "        [29.2089, 24.2101],\n",
      "        [24.2032, 29.2015],\n",
      "        [26.9064, 26.9058]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9828, 0.1276, 0.0678, 0.9075], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2322, 29.2293],\n",
      "        [29.2149, 24.2088],\n",
      "        [24.2084, 29.2011],\n",
      "        [26.9121, 26.9055]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9829, 0.1280, 0.0679, 0.9079], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2320, 29.2337],\n",
      "        [29.2137, 24.2149],\n",
      "        [24.2079, 29.2063],\n",
      "        [26.9118, 26.9112]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9829, 0.1280, 0.0679, 0.9079], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2364, 29.2335],\n",
      "        [29.2197, 24.2136],\n",
      "        [24.2131, 29.2058],\n",
      "        [26.9175, 26.9108]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9830, 0.1284, 0.0679, 0.9083], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2362, 29.2379],\n",
      "        [29.2184, 24.2197],\n",
      "        [24.2126, 29.2110],\n",
      "        [26.9171, 26.9165]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9830, 0.1284, 0.0679, 0.9083], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2405, 29.2377],\n",
      "        [29.2244, 24.2184],\n",
      "        [24.2178, 29.2106],\n",
      "        [26.9227, 26.9162]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9831, 0.1288, 0.0679, 0.9086], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2403, 29.2420],\n",
      "        [29.2231, 24.2244],\n",
      "        [24.2173, 29.2157],\n",
      "        [26.9223, 26.9218]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9831, 0.1288, 0.0679, 0.9086], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2446, 29.2417],\n",
      "        [29.2291, 24.2231],\n",
      "        [24.2224, 29.2152],\n",
      "        [26.9279, 26.9214]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9832, 0.1292, 0.0679, 0.9090], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2444, 29.2460],\n",
      "        [29.2278, 24.2291],\n",
      "        [24.2219, 29.2203],\n",
      "        [26.9276, 26.9270]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9832, 0.1292, 0.0679, 0.9090], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2486, 29.2458],\n",
      "        [29.2337, 24.2277],\n",
      "        [24.2270, 29.2198],\n",
      "        [26.9331, 26.9266]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9833, 0.1296, 0.0680, 0.9093], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2484, 29.2500],\n",
      "        [29.2324, 24.2337],\n",
      "        [24.2265, 29.2249],\n",
      "        [26.9327, 26.9322]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9833, 0.1296, 0.0680, 0.9093], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2526, 29.2498],\n",
      "        [29.2383, 24.2324],\n",
      "        [24.2315, 29.2244],\n",
      "        [26.9382, 26.9318]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9834, 0.1301, 0.0680, 0.9097], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2524, 29.2540],\n",
      "        [29.2370, 24.2383],\n",
      "        [24.2310, 29.2294],\n",
      "        [26.9379, 26.9373]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9834, 0.1301, 0.0680, 0.9097], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2565, 29.2538],\n",
      "        [29.2429, 24.2370],\n",
      "        [24.2360, 29.2290],\n",
      "        [26.9433, 26.9370]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9834, 0.1305, 0.0680, 0.9101], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2563, 29.2579],\n",
      "        [29.2416, 24.2428],\n",
      "        [24.2355, 29.2339],\n",
      "        [26.9429, 26.9424]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9834, 0.1305, 0.0680, 0.9101], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2605, 29.2577],\n",
      "        [29.2474, 24.2415],\n",
      "        [24.2405, 29.2335],\n",
      "        [26.9483, 26.9420]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9835, 0.1309, 0.0681, 0.9104], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2602, 29.2618],\n",
      "        [29.2461, 24.2473],\n",
      "        [24.2400, 29.2384],\n",
      "        [26.9480, 26.9474]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9835, 0.1309, 0.0681, 0.9104], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2643, 29.2616],\n",
      "        [29.2519, 24.2460],\n",
      "        [24.2449, 29.2379],\n",
      "        [26.9533, 26.9470]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9836, 0.1313, 0.0681, 0.9107], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2641, 29.2657],\n",
      "        [29.2505, 24.2518],\n",
      "        [24.2444, 29.2428],\n",
      "        [26.9529, 26.9524]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9836, 0.1313, 0.0681, 0.9107], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2682, 29.2655],\n",
      "        [29.2563, 24.2505],\n",
      "        [24.2493, 29.2423],\n",
      "        [26.9583, 26.9520]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9837, 0.1317, 0.0681, 0.9111], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2679, 29.2695],\n",
      "        [29.2550, 24.2562],\n",
      "        [24.2488, 29.2472],\n",
      "        [26.9579, 26.9573]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9837, 0.1317, 0.0681, 0.9111], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2719, 29.2693],\n",
      "        [29.2607, 24.2549],\n",
      "        [24.2536, 29.2467],\n",
      "        [26.9631, 26.9569]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9838, 0.1321, 0.0682, 0.9114], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2717, 29.2733],\n",
      "        [29.2594, 24.2606],\n",
      "        [24.2531, 29.2515],\n",
      "        [26.9628, 26.9622]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9838, 0.1321, 0.0682, 0.9114], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2757, 29.2731],\n",
      "        [29.2651, 24.2593],\n",
      "        [24.2579, 29.2510],\n",
      "        [26.9680, 26.9618]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9839, 0.1326, 0.0682, 0.9118], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2755, 29.2770],\n",
      "        [29.2637, 24.2650],\n",
      "        [24.2574, 29.2558],\n",
      "        [26.9676, 26.9670]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9839, 0.1326, 0.0682, 0.9118], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2794, 29.2768],\n",
      "        [29.2694, 24.2637],\n",
      "        [24.2621, 29.2553],\n",
      "        [26.9728, 26.9667]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9839, 0.1330, 0.0682, 0.9121], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2792, 29.2807],\n",
      "        [29.2680, 24.2693],\n",
      "        [24.2617, 29.2600],\n",
      "        [26.9724, 26.9718]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9839, 0.1330, 0.0682, 0.9121], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2831, 29.2805],\n",
      "        [29.2736, 24.2680],\n",
      "        [24.2664, 29.2596],\n",
      "        [26.9775, 26.9715]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9840, 0.1334, 0.0683, 0.9124], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2829, 29.2844],\n",
      "        [29.2723, 24.2736],\n",
      "        [24.2659, 29.2643],\n",
      "        [26.9772, 26.9766]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9840, 0.1334, 0.0683, 0.9124], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2868, 29.2842],\n",
      "        [29.2779, 24.2722],\n",
      "        [24.2705, 29.2638],\n",
      "        [26.9822, 26.9762]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9841, 0.1339, 0.0683, 0.9127], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2866, 29.2881],\n",
      "        [29.2765, 24.2778],\n",
      "        [24.2701, 29.2684],\n",
      "        [26.9819, 26.9813]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9841, 0.1339, 0.0683, 0.9127], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2904, 29.2878],\n",
      "        [29.2821, 24.2765],\n",
      "        [24.2747, 29.2680],\n",
      "        [26.9869, 26.9809]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9842, 0.1343, 0.0683, 0.9131], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2902, 29.2916],\n",
      "        [29.2807, 24.2820],\n",
      "        [24.2742, 29.2726],\n",
      "        [26.9865, 26.9860]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9842, 0.1343, 0.0683, 0.9131], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2940, 29.2914],\n",
      "        [29.2863, 24.2807],\n",
      "        [24.2788, 29.2721],\n",
      "        [26.9915, 26.9856]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9842, 0.1347, 0.0684, 0.9134], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2938, 29.2952],\n",
      "        [29.2849, 24.2862],\n",
      "        [24.2783, 29.2767],\n",
      "        [26.9912, 26.9906]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9842, 0.1347, 0.0684, 0.9134], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.2975, 29.2950],\n",
      "        [29.2904, 24.2848],\n",
      "        [24.2828, 29.2762],\n",
      "        [26.9961, 26.9902]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9843, 0.1352, 0.0684, 0.9137], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.2973, 29.2988],\n",
      "        [29.2890, 24.2903],\n",
      "        [24.2824, 29.2807],\n",
      "        [26.9958, 26.9952]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9843, 0.1352, 0.0684, 0.9137], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3011, 29.2986],\n",
      "        [29.2945, 24.2890],\n",
      "        [24.2869, 29.2803],\n",
      "        [27.0007, 26.9948]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9844, 0.1356, 0.0684, 0.9140], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3008, 29.3023],\n",
      "        [29.2931, 24.2944],\n",
      "        [24.2864, 29.2847],\n",
      "        [27.0003, 26.9997]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9844, 0.1356, 0.0684, 0.9140], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3045, 29.3020],\n",
      "        [29.2986, 24.2931],\n",
      "        [24.2909, 29.2843],\n",
      "        [27.0052, 26.9994]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9845, 0.1361, 0.0685, 0.9143], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3043, 29.3057],\n",
      "        [29.2972, 24.2985],\n",
      "        [24.2904, 29.2887],\n",
      "        [27.0048, 27.0042]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9845, 0.1361, 0.0685, 0.9143], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3080, 29.3055],\n",
      "        [29.3026, 24.2971],\n",
      "        [24.2948, 29.2883],\n",
      "        [27.0096, 27.0039]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9845, 0.1365, 0.0685, 0.9146], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3078, 29.3092],\n",
      "        [29.3012, 24.3025],\n",
      "        [24.2944, 29.2927],\n",
      "        [27.0093, 27.0087]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9845, 0.1365, 0.0685, 0.9146], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3114, 29.3090],\n",
      "        [29.3066, 24.3012],\n",
      "        [24.2987, 29.2922],\n",
      "        [27.0141, 27.0083]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9846, 0.1369, 0.0685, 0.9149], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3112, 29.3126],\n",
      "        [29.3052, 24.3065],\n",
      "        [24.2983, 29.2966],\n",
      "        [27.0137, 27.0131]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9846, 0.1369, 0.0685, 0.9149], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3148, 29.3124],\n",
      "        [29.3106, 24.3052],\n",
      "        [24.3026, 29.2962],\n",
      "        [27.0184, 27.0128]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9847, 0.1374, 0.0685, 0.9153], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3146, 29.3160],\n",
      "        [29.3092, 24.3105],\n",
      "        [24.3022, 29.3005],\n",
      "        [27.0181, 27.0175]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9847, 0.1374, 0.0685, 0.9153], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3182, 29.3157],\n",
      "        [29.3145, 24.3091],\n",
      "        [24.3065, 29.3001],\n",
      "        [27.0228, 27.0171]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9848, 0.1378, 0.0686, 0.9156], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3180, 29.3193],\n",
      "        [29.3131, 24.3144],\n",
      "        [24.3060, 29.3044],\n",
      "        [27.0224, 27.0218]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9848, 0.1378, 0.0686, 0.9156], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3215, 29.3191],\n",
      "        [29.3184, 24.3130],\n",
      "        [24.3103, 29.3039],\n",
      "        [27.0271, 27.0215]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9848, 0.1383, 0.0686, 0.9159], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3213, 29.3226],\n",
      "        [29.3170, 24.3183],\n",
      "        [24.3099, 29.3082],\n",
      "        [27.0268, 27.0262]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9848, 0.1383, 0.0686, 0.9159], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3248, 29.3224],\n",
      "        [29.3223, 24.3169],\n",
      "        [24.3141, 29.3077],\n",
      "        [27.0314, 27.0258]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9849, 0.1388, 0.0686, 0.9162], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3246, 29.3259],\n",
      "        [29.3209, 24.3222],\n",
      "        [24.3137, 29.3120],\n",
      "        [27.0310, 27.0304]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9849, 0.1388, 0.0686, 0.9162], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3281, 29.3257],\n",
      "        [29.3261, 24.3208],\n",
      "        [24.3179, 29.3115],\n",
      "        [27.0356, 27.0301]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9850, 0.1392, 0.0687, 0.9165], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3279, 29.3292],\n",
      "        [29.3247, 24.3260],\n",
      "        [24.3174, 29.3157],\n",
      "        [27.0353, 27.0347]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9850, 0.1392, 0.0687, 0.9165], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3313, 29.3290],\n",
      "        [29.3299, 24.3246],\n",
      "        [24.3216, 29.3153],\n",
      "        [27.0398, 27.0343]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9851, 0.1397, 0.0687, 0.9167], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3311, 29.3324],\n",
      "        [29.3285, 24.3298],\n",
      "        [24.3211, 29.3195],\n",
      "        [27.0395, 27.0389]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9851, 0.1397, 0.0687, 0.9167], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3345, 29.3322],\n",
      "        [29.3337, 24.3284],\n",
      "        [24.3253, 29.3190],\n",
      "        [27.0440, 27.0385]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9851, 0.1401, 0.0687, 0.9170], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3343, 29.3356],\n",
      "        [29.3323, 24.3336],\n",
      "        [24.3249, 29.3232],\n",
      "        [27.0436, 27.0430]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9851, 0.1401, 0.0687, 0.9170], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3377, 29.3354],\n",
      "        [29.3375, 24.3322],\n",
      "        [24.3290, 29.3227],\n",
      "        [27.0481, 27.0427]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9852, 0.1406, 0.0688, 0.9173], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3375, 29.3388],\n",
      "        [29.3360, 24.3374],\n",
      "        [24.3285, 29.3268],\n",
      "        [27.0478, 27.0472]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9852, 0.1406, 0.0688, 0.9173], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3409, 29.3386],\n",
      "        [29.3412, 24.3360],\n",
      "        [24.3326, 29.3264],\n",
      "        [27.0522, 27.0468]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9853, 0.1411, 0.0688, 0.9176], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3407, 29.3419],\n",
      "        [29.3398, 24.3411],\n",
      "        [24.3321, 29.3304],\n",
      "        [27.0519, 27.0513]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9853, 0.1411, 0.0688, 0.9176], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3440, 29.3417],\n",
      "        [29.3449, 24.3397],\n",
      "        [24.3362, 29.3300],\n",
      "        [27.0563, 27.0509]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9853, 0.1416, 0.0688, 0.9179], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3438, 29.3450],\n",
      "        [29.3434, 24.3448],\n",
      "        [24.3357, 29.3340],\n",
      "        [27.0559, 27.0553]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9853, 0.1416, 0.0688, 0.9179], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3471, 29.3448],\n",
      "        [29.3486, 24.3434],\n",
      "        [24.3398, 29.3336],\n",
      "        [27.0603, 27.0550]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9854, 0.1420, 0.0689, 0.9182], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3469, 29.3481],\n",
      "        [29.3471, 24.3485],\n",
      "        [24.3393, 29.3376],\n",
      "        [27.0599, 27.0593]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9854, 0.1420, 0.0689, 0.9182], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3502, 29.3479],\n",
      "        [29.3522, 24.3470],\n",
      "        [24.3433, 29.3372],\n",
      "        [27.0643, 27.0590]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9855, 0.1425, 0.0689, 0.9185], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3500, 29.3512],\n",
      "        [29.3507, 24.3521],\n",
      "        [24.3429, 29.3411],\n",
      "        [27.0639, 27.0633]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9855, 0.1425, 0.0689, 0.9185], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3532, 29.3510],\n",
      "        [29.3558, 24.3506],\n",
      "        [24.3468, 29.3407],\n",
      "        [27.0682, 27.0630]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9855, 0.1430, 0.0689, 0.9187], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3530, 29.3542],\n",
      "        [29.3543, 24.3557],\n",
      "        [24.3464, 29.3447],\n",
      "        [27.0679, 27.0673]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9855, 0.1430, 0.0689, 0.9187], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3563, 29.3540],\n",
      "        [29.3594, 24.3543],\n",
      "        [24.3503, 29.3442],\n",
      "        [27.0722, 27.0670]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9856, 0.1435, 0.0689, 0.9190], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3560, 29.3572],\n",
      "        [29.3579, 24.3593],\n",
      "        [24.3499, 29.3481],\n",
      "        [27.0718, 27.0712]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9856, 0.1435, 0.0689, 0.9190], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3592, 29.3570],\n",
      "        [29.3629, 24.3578],\n",
      "        [24.3538, 29.3477],\n",
      "        [27.0761, 27.0709]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9857, 0.1440, 0.0690, 0.9193], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3590, 29.3602],\n",
      "        [29.3615, 24.3628],\n",
      "        [24.3533, 29.3516],\n",
      "        [27.0757, 27.0751]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9857, 0.1440, 0.0690, 0.9193], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3622, 29.3600],\n",
      "        [29.3665, 24.3614],\n",
      "        [24.3572, 29.3511],\n",
      "        [27.0799, 27.0748]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9857, 0.1445, 0.0690, 0.9196], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3620, 29.3632],\n",
      "        [29.3650, 24.3664],\n",
      "        [24.3567, 29.3550],\n",
      "        [27.0796, 27.0790]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9857, 0.1445, 0.0690, 0.9196], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3652, 29.3630],\n",
      "        [29.3700, 24.3649],\n",
      "        [24.3606, 29.3546],\n",
      "        [27.0838, 27.0786]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9858, 0.1450, 0.0690, 0.9198], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3649, 29.3661],\n",
      "        [29.3685, 24.3699],\n",
      "        [24.3601, 29.3584],\n",
      "        [27.0834, 27.0828]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9858, 0.1450, 0.0690, 0.9198], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3681, 29.3659],\n",
      "        [29.3735, 24.3684],\n",
      "        [24.3640, 29.3580],\n",
      "        [27.0876, 27.0825]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9858, 0.1454, 0.0691, 0.9201], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3678, 29.3690],\n",
      "        [29.3720, 24.3733],\n",
      "        [24.3635, 29.3618],\n",
      "        [27.0872, 27.0866]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9858, 0.1454, 0.0691, 0.9201], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3710, 29.3688],\n",
      "        [29.3769, 24.3719],\n",
      "        [24.3673, 29.3613],\n",
      "        [27.0913, 27.0863]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9859, 0.1459, 0.0691, 0.9204], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3708, 29.3719],\n",
      "        [29.3754, 24.3768],\n",
      "        [24.3669, 29.3651],\n",
      "        [27.0910, 27.0904]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9859, 0.1459, 0.0691, 0.9204], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3738, 29.3717],\n",
      "        [29.3803, 24.3753],\n",
      "        [24.3706, 29.3647],\n",
      "        [27.0951, 27.0900]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9860, 0.1464, 0.0691, 0.9206], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3736, 29.3747],\n",
      "        [29.3789, 24.3802],\n",
      "        [24.3702, 29.3684],\n",
      "        [27.0947, 27.0941]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9860, 0.1464, 0.0691, 0.9206], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3767, 29.3745],\n",
      "        [29.3838, 24.3787],\n",
      "        [24.3739, 29.3680],\n",
      "        [27.0988, 27.0938]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9860, 0.1469, 0.0692, 0.9209], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3765, 29.3776],\n",
      "        [29.3823, 24.3836],\n",
      "        [24.3735, 29.3717],\n",
      "        [27.0984, 27.0978]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9860, 0.1469, 0.0692, 0.9209], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3795, 29.3774],\n",
      "        [29.3872, 24.3821],\n",
      "        [24.3772, 29.3713],\n",
      "        [27.1025, 27.0975]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9861, 0.1475, 0.0692, 0.9212], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3793, 29.3804],\n",
      "        [29.3856, 24.3870],\n",
      "        [24.3767, 29.3750],\n",
      "        [27.1021, 27.1015]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9861, 0.1475, 0.0692, 0.9212], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3823, 29.3802],\n",
      "        [29.3905, 24.3855],\n",
      "        [24.3804, 29.3745],\n",
      "        [27.1061, 27.1012]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9862, 0.1480, 0.0692, 0.9214], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3821, 29.3832],\n",
      "        [29.3890, 24.3904],\n",
      "        [24.3800, 29.3782],\n",
      "        [27.1058, 27.1051]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9862, 0.1480, 0.0692, 0.9214], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3851, 29.3830],\n",
      "        [29.3939, 24.3889],\n",
      "        [24.3836, 29.3778],\n",
      "        [27.1097, 27.1048]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9862, 0.1485, 0.0693, 0.9217], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3848, 29.3859],\n",
      "        [29.3923, 24.3937],\n",
      "        [24.3832, 29.3814],\n",
      "        [27.1094, 27.1087]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9862, 0.1485, 0.0693, 0.9217], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3878, 29.3857],\n",
      "        [29.3972, 24.3922],\n",
      "        [24.3868, 29.3810],\n",
      "        [27.1133, 27.1084]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9863, 0.1490, 0.0693, 0.9219], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3876, 29.3887],\n",
      "        [29.3956, 24.3970],\n",
      "        [24.3864, 29.3846],\n",
      "        [27.1130, 27.1123]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9863, 0.1490, 0.0693, 0.9219], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3905, 29.3884],\n",
      "        [29.4004, 24.3955],\n",
      "        [24.3900, 29.3842],\n",
      "        [27.1169, 27.1120]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9863, 0.1495, 0.0693, 0.9222], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3903, 29.3914],\n",
      "        [29.3989, 24.4003],\n",
      "        [24.3895, 29.3878],\n",
      "        [27.1165, 27.1159]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9863, 0.1495, 0.0693, 0.9222], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3932, 29.3912],\n",
      "        [29.4037, 24.3987],\n",
      "        [24.3931, 29.3873],\n",
      "        [27.1204, 27.1156]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9864, 0.1500, 0.0693, 0.9224], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3930, 29.3941],\n",
      "        [29.4022, 24.4035],\n",
      "        [24.3927, 29.3909],\n",
      "        [27.1201, 27.1194]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9864, 0.1500, 0.0693, 0.9224], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3959, 29.3939],\n",
      "        [29.4070, 24.4020],\n",
      "        [24.3962, 29.3905],\n",
      "        [27.1239, 27.1191]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9864, 0.1506, 0.0694, 0.9227], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3957, 29.3967],\n",
      "        [29.4054, 24.4068],\n",
      "        [24.3958, 29.3940],\n",
      "        [27.1236, 27.1229]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9864, 0.1506, 0.0694, 0.9227], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.3986, 29.3965],\n",
      "        [29.4102, 24.4052],\n",
      "        [24.3993, 29.3936],\n",
      "        [27.1274, 27.1226]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9865, 0.1511, 0.0694, 0.9229], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.3984, 29.3994],\n",
      "        [29.4086, 24.4100],\n",
      "        [24.3989, 29.3971],\n",
      "        [27.1271, 27.1264]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9865, 0.1511, 0.0694, 0.9229], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4012, 29.3992],\n",
      "        [29.4134, 24.4084],\n",
      "        [24.4024, 29.3967],\n",
      "        [27.1309, 27.1261]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9866, 0.1516, 0.0694, 0.9232], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4010, 29.4020],\n",
      "        [29.4118, 24.4132],\n",
      "        [24.4019, 29.4002],\n",
      "        [27.1305, 27.1299]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9866, 0.1516, 0.0694, 0.9232], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4039, 29.4018],\n",
      "        [29.4166, 24.4116],\n",
      "        [24.4055, 29.3997],\n",
      "        [27.1343, 27.1295]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9866, 0.1522, 0.0695, 0.9234], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4036, 29.4046],\n",
      "        [29.4150, 24.4164],\n",
      "        [24.4050, 29.4032],\n",
      "        [27.1340, 27.1333]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9866, 0.1522, 0.0695, 0.9234], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4064, 29.4044],\n",
      "        [29.4197, 24.4148],\n",
      "        [24.4085, 29.4027],\n",
      "        [27.1377, 27.1329]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9867, 0.1527, 0.0695, 0.9237], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4062, 29.4072],\n",
      "        [29.4181, 24.4195],\n",
      "        [24.4080, 29.4062],\n",
      "        [27.1373, 27.1367]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9867, 0.1527, 0.0695, 0.9237], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4090, 29.4070],\n",
      "        [29.4229, 24.4180],\n",
      "        [24.4115, 29.4058],\n",
      "        [27.1411, 27.1364]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9867, 0.1532, 0.0695, 0.9239], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4088, 29.4097],\n",
      "        [29.4213, 24.4226],\n",
      "        [24.4110, 29.4092],\n",
      "        [27.1407, 27.1400]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9867, 0.1532, 0.0695, 0.9239], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4116, 29.4095],\n",
      "        [29.4260, 24.4211],\n",
      "        [24.4144, 29.4088],\n",
      "        [27.1444, 27.1397]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9868, 0.1538, 0.0696, 0.9241], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4113, 29.4123],\n",
      "        [29.4244, 24.4258],\n",
      "        [24.4140, 29.4122],\n",
      "        [27.1441, 27.1434]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9868, 0.1538, 0.0696, 0.9241], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4141, 29.4121],\n",
      "        [29.4291, 24.4242],\n",
      "        [24.4174, 29.4117],\n",
      "        [27.1477, 27.1431]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9868, 0.1543, 0.0696, 0.9244], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4139, 29.4148],\n",
      "        [29.4275, 24.4289],\n",
      "        [24.4169, 29.4151],\n",
      "        [27.1474, 27.1467]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9868, 0.1543, 0.0696, 0.9244], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4166, 29.4146],\n",
      "        [29.4322, 24.4273],\n",
      "        [24.4203, 29.4147],\n",
      "        [27.1510, 27.1464]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9869, 0.1549, 0.0696, 0.9246], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4164, 29.4173],\n",
      "        [29.4305, 24.4319],\n",
      "        [24.4199, 29.4180],\n",
      "        [27.1507, 27.1500]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9869, 0.1549, 0.0696, 0.9246], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4191, 29.4171],\n",
      "        [29.4352, 24.4303],\n",
      "        [24.4232, 29.4176],\n",
      "        [27.1543, 27.1497]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9869, 0.1554, 0.0697, 0.9249], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4189, 29.4198],\n",
      "        [29.4336, 24.4350],\n",
      "        [24.4228, 29.4209],\n",
      "        [27.1540, 27.1533]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9869, 0.1554, 0.0697, 0.9249], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4216, 29.4196],\n",
      "        [29.4383, 24.4334],\n",
      "        [24.4261, 29.4205],\n",
      "        [27.1576, 27.1530]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9870, 0.1560, 0.0697, 0.9251], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4214, 29.4223],\n",
      "        [29.4366, 24.4380],\n",
      "        [24.4256, 29.4238],\n",
      "        [27.1572, 27.1565]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9870, 0.1560, 0.0697, 0.9251], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4240, 29.4221],\n",
      "        [29.4413, 24.4364],\n",
      "        [24.4290, 29.4234],\n",
      "        [27.1608, 27.1562]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9871, 0.1566, 0.0697, 0.9253], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4238, 29.4247],\n",
      "        [29.4397, 24.4410],\n",
      "        [24.4285, 29.4267],\n",
      "        [27.1604, 27.1597]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9871, 0.1566, 0.0697, 0.9253], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4265, 29.4245],\n",
      "        [29.4443, 24.4394],\n",
      "        [24.4318, 29.4262],\n",
      "        [27.1640, 27.1594]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9871, 0.1571, 0.0697, 0.9255], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4263, 29.4271],\n",
      "        [29.4427, 24.4440],\n",
      "        [24.4314, 29.4295],\n",
      "        [27.1636, 27.1630]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9871, 0.1571, 0.0697, 0.9255], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4289, 29.4269],\n",
      "        [29.4473, 24.4424],\n",
      "        [24.4346, 29.4291],\n",
      "        [27.1671, 27.1626]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9872, 0.1577, 0.0698, 0.9258], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4287, 29.4295],\n",
      "        [29.4456, 24.4470],\n",
      "        [24.4342, 29.4323],\n",
      "        [27.1668, 27.1661]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9872, 0.1577, 0.0698, 0.9258], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4313, 29.4293],\n",
      "        [29.4503, 24.4454],\n",
      "        [24.4374, 29.4319],\n",
      "        [27.1703, 27.1658]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9872, 0.1583, 0.0698, 0.9260], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4311, 29.4319],\n",
      "        [29.4486, 24.4500],\n",
      "        [24.4370, 29.4351],\n",
      "        [27.1700, 27.1693]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9872, 0.1583, 0.0698, 0.9260], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4337, 29.4317],\n",
      "        [29.4532, 24.4483],\n",
      "        [24.4402, 29.4347],\n",
      "        [27.1734, 27.1689]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9873, 0.1588, 0.0698, 0.9262], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4334, 29.4343],\n",
      "        [29.4516, 24.4529],\n",
      "        [24.4398, 29.4379],\n",
      "        [27.1731, 27.1724]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9873, 0.1588, 0.0698, 0.9262], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4360, 29.4341],\n",
      "        [29.4562, 24.4513],\n",
      "        [24.4430, 29.4375],\n",
      "        [27.1765, 27.1721]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9873, 0.1594, 0.0699, 0.9264], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4358, 29.4366],\n",
      "        [29.4545, 24.4558],\n",
      "        [24.4425, 29.4407],\n",
      "        [27.1762, 27.1755]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9873, 0.1594, 0.0699, 0.9264], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4384, 29.4364],\n",
      "        [29.4591, 24.4542],\n",
      "        [24.4457, 29.4402],\n",
      "        [27.1796, 27.1752]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9874, 0.1600, 0.0699, 0.9267], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4381, 29.4390],\n",
      "        [29.4574, 24.4588],\n",
      "        [24.4453, 29.4434],\n",
      "        [27.1793, 27.1786]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9874, 0.1600, 0.0699, 0.9267], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4407, 29.4388],\n",
      "        [29.4620, 24.4571],\n",
      "        [24.4484, 29.4429],\n",
      "        [27.1827, 27.1782]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9874, 0.1606, 0.0699, 0.9269], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4405, 29.4413],\n",
      "        [29.4603, 24.4617],\n",
      "        [24.4480, 29.4461],\n",
      "        [27.1823, 27.1816]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9874, 0.1606, 0.0699, 0.9269], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4430, 29.4411],\n",
      "        [29.4649, 24.4600],\n",
      "        [24.4511, 29.4457],\n",
      "        [27.1857, 27.1813]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9875, 0.1612, 0.0700, 0.9271], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4428, 29.4436],\n",
      "        [29.4632, 24.4645],\n",
      "        [24.4507, 29.4488],\n",
      "        [27.1854, 27.1847]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9875, 0.1612, 0.0700, 0.9271], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4453, 29.4434],\n",
      "        [29.4678, 24.4628],\n",
      "        [24.4538, 29.4483],\n",
      "        [27.1887, 27.1843]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9875, 0.1618, 0.0700, 0.9273], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4451, 29.4459],\n",
      "        [29.4660, 24.4674],\n",
      "        [24.4534, 29.4515],\n",
      "        [27.1884, 27.1877]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9875, 0.1618, 0.0700, 0.9273], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4476, 29.4457],\n",
      "        [29.4706, 24.4657],\n",
      "        [24.4565, 29.4510],\n",
      "        [27.1917, 27.1874]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9876, 0.1624, 0.0700, 0.9275], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4473, 29.4481],\n",
      "        [29.4689, 24.4702],\n",
      "        [24.4560, 29.4542],\n",
      "        [27.1914, 27.1907]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9876, 0.1624, 0.0700, 0.9275], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4498, 29.4479],\n",
      "        [29.4734, 24.4685],\n",
      "        [24.4591, 29.4537],\n",
      "        [27.1947, 27.1903]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9876, 0.1630, 0.0701, 0.9278], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4496, 29.4504],\n",
      "        [29.4717, 24.4731],\n",
      "        [24.4587, 29.4568],\n",
      "        [27.1944, 27.1936]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9876, 0.1630, 0.0701, 0.9278], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4521, 29.4502],\n",
      "        [29.4763, 24.4713],\n",
      "        [24.4618, 29.4563],\n",
      "        [27.1977, 27.1933]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9877, 0.1636, 0.0701, 0.9280], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4518, 29.4526],\n",
      "        [29.4745, 24.4759],\n",
      "        [24.4613, 29.4594],\n",
      "        [27.1973, 27.1966]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9877, 0.1636, 0.0701, 0.9280], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4543, 29.4524],\n",
      "        [29.4791, 24.4741],\n",
      "        [24.4644, 29.4589],\n",
      "        [27.2006, 27.1963]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9877, 0.1642, 0.0701, 0.9282], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4541, 29.4548],\n",
      "        [29.4773, 24.4787],\n",
      "        [24.4639, 29.4620],\n",
      "        [27.2003, 27.1995]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9877, 0.1642, 0.0701, 0.9282], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4565, 29.4546],\n",
      "        [29.4819, 24.4769],\n",
      "        [24.4670, 29.4615],\n",
      "        [27.2035, 27.1992]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9878, 0.1648, 0.0702, 0.9284], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4563, 29.4570],\n",
      "        [29.4801, 24.4815],\n",
      "        [24.4665, 29.4646],\n",
      "        [27.2032, 27.2024]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9878, 0.1648, 0.0702, 0.9284], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4587, 29.4568],\n",
      "        [29.4847, 24.4797],\n",
      "        [24.4695, 29.4641],\n",
      "        [27.2064, 27.2021]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9878, 0.1654, 0.0702, 0.9286], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4585, 29.4592],\n",
      "        [29.4829, 24.4842],\n",
      "        [24.4691, 29.4672],\n",
      "        [27.2061, 27.2053]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9878, 0.1654, 0.0702, 0.9286], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4608, 29.4590],\n",
      "        [29.4874, 24.4825],\n",
      "        [24.4721, 29.4667],\n",
      "        [27.2093, 27.2050]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9878, 0.1660, 0.0702, 0.9288], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4606, 29.4614],\n",
      "        [29.4857, 24.4870],\n",
      "        [24.4716, 29.4697],\n",
      "        [27.2089, 27.2082]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9878, 0.1660, 0.0702, 0.9288], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4630, 29.4611],\n",
      "        [29.4902, 24.4852],\n",
      "        [24.4746, 29.4692],\n",
      "        [27.2121, 27.2078]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9879, 0.1667, 0.0702, 0.9290], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4628, 29.4635],\n",
      "        [29.4884, 24.4897],\n",
      "        [24.4742, 29.4722],\n",
      "        [27.2118, 27.2110]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9879, 0.1667, 0.0702, 0.9290], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4651, 29.4633],\n",
      "        [29.4929, 24.4879],\n",
      "        [24.4772, 29.4718],\n",
      "        [27.2150, 27.2107]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9879, 0.1673, 0.0703, 0.9292], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4649, 29.4656],\n",
      "        [29.4911, 24.4924],\n",
      "        [24.4767, 29.4747],\n",
      "        [27.2146, 27.2138]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9879, 0.1673, 0.0703, 0.9292], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4673, 29.4654],\n",
      "        [29.4957, 24.4906],\n",
      "        [24.4797, 29.4743],\n",
      "        [27.2178, 27.2135]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9880, 0.1679, 0.0703, 0.9294], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4671, 29.4677],\n",
      "        [29.4939, 24.4952],\n",
      "        [24.4792, 29.4772],\n",
      "        [27.2174, 27.2167]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9880, 0.1679, 0.0703, 0.9294], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4694, 29.4675],\n",
      "        [29.4984, 24.4934],\n",
      "        [24.4821, 29.4768],\n",
      "        [27.2206, 27.2163]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9880, 0.1686, 0.0703, 0.9296], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4692, 29.4698],\n",
      "        [29.4966, 24.4978],\n",
      "        [24.4817, 29.4797],\n",
      "        [27.2202, 27.2194]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9880, 0.1686, 0.0703, 0.9296], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4715, 29.4696],\n",
      "        [29.5011, 24.4960],\n",
      "        [24.4846, 29.4792],\n",
      "        [27.2233, 27.2191]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9881, 0.1692, 0.0704, 0.9298], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4713, 29.4719],\n",
      "        [29.4993, 24.5005],\n",
      "        [24.4841, 29.4822],\n",
      "        [27.2230, 27.2222]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9881, 0.1692, 0.0704, 0.9298], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4736, 29.4717],\n",
      "        [29.5038, 24.4987],\n",
      "        [24.4871, 29.4817],\n",
      "        [27.2261, 27.2219]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9881, 0.1699, 0.0704, 0.9300], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4733, 29.4740],\n",
      "        [29.5019, 24.5032],\n",
      "        [24.4866, 29.4846],\n",
      "        [27.2257, 27.2249]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9881, 0.1699, 0.0704, 0.9300], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4756, 29.4738],\n",
      "        [29.5065, 24.5014],\n",
      "        [24.4895, 29.4841],\n",
      "        [27.2288, 27.2246]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9882, 0.1705, 0.0704, 0.9302], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4754, 29.4760],\n",
      "        [29.5046, 24.5059],\n",
      "        [24.4890, 29.4871],\n",
      "        [27.2285, 27.2277]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9882, 0.1705, 0.0704, 0.9302], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4777, 29.4758],\n",
      "        [29.5091, 24.5040],\n",
      "        [24.4919, 29.4866],\n",
      "        [27.2315, 27.2273]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9882, 0.1712, 0.0705, 0.9304], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4774, 29.4781],\n",
      "        [29.5073, 24.5085],\n",
      "        [24.4914, 29.4895],\n",
      "        [27.2312, 27.2304]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9882, 0.1712, 0.0705, 0.9304], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4797, 29.4779],\n",
      "        [29.5118, 24.5067],\n",
      "        [24.4943, 29.4890],\n",
      "        [27.2342, 27.2301]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9883, 0.1718, 0.0705, 0.9306], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4795, 29.4801],\n",
      "        [29.5099, 24.5112],\n",
      "        [24.4938, 29.4919],\n",
      "        [27.2339, 27.2331]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9883, 0.1718, 0.0705, 0.9306], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4817, 29.4799],\n",
      "        [29.5144, 24.5093],\n",
      "        [24.4967, 29.4914],\n",
      "        [27.2369, 27.2327]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9883, 0.1725, 0.0705, 0.9308], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4815, 29.4821],\n",
      "        [29.5125, 24.5138],\n",
      "        [24.4962, 29.4942],\n",
      "        [27.2365, 27.2357]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9883, 0.1725, 0.0705, 0.9308], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4837, 29.4819],\n",
      "        [29.5171, 24.5119],\n",
      "        [24.4991, 29.4938],\n",
      "        [27.2396, 27.2354]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9883, 0.1732, 0.0706, 0.9310], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4835, 29.4841],\n",
      "        [29.5152, 24.5164],\n",
      "        [24.4986, 29.4966],\n",
      "        [27.2392, 27.2384]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9883, 0.1732, 0.0706, 0.9310], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4857, 29.4839],\n",
      "        [29.5197, 24.5145],\n",
      "        [24.5014, 29.4961],\n",
      "        [27.2422, 27.2381]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9884, 0.1738, 0.0706, 0.9312], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4855, 29.4861],\n",
      "        [29.5178, 24.5190],\n",
      "        [24.5010, 29.4989],\n",
      "        [27.2419, 27.2410]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9884, 0.1738, 0.0706, 0.9312], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4877, 29.4859],\n",
      "        [29.5223, 24.5171],\n",
      "        [24.5038, 29.4985],\n",
      "        [27.2448, 27.2407]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9884, 0.1745, 0.0706, 0.9314], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4875, 29.4881],\n",
      "        [29.5204, 24.5216],\n",
      "        [24.5033, 29.5013],\n",
      "        [27.2445, 27.2437]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9884, 0.1745, 0.0706, 0.9314], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4897, 29.4878],\n",
      "        [29.5249, 24.5197],\n",
      "        [24.5061, 29.5008],\n",
      "        [27.2474, 27.2433]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9885, 0.1752, 0.0707, 0.9316], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4895, 29.4900],\n",
      "        [29.5230, 24.5242],\n",
      "        [24.5056, 29.5036],\n",
      "        [27.2471, 27.2463]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9885, 0.1752, 0.0707, 0.9316], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4916, 29.4898],\n",
      "        [29.5275, 24.5222],\n",
      "        [24.5084, 29.5031],\n",
      "        [27.2500, 27.2459]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9885, 0.1759, 0.0707, 0.9318], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4914, 29.4920],\n",
      "        [29.5256, 24.5267],\n",
      "        [24.5079, 29.5059],\n",
      "        [27.2497, 27.2489]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9885, 0.1759, 0.0707, 0.9318], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4936, 29.4917],\n",
      "        [29.5301, 24.5248],\n",
      "        [24.5107, 29.5054],\n",
      "        [27.2526, 27.2485]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9886, 0.1766, 0.0707, 0.9319], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4933, 29.4939],\n",
      "        [29.5281, 24.5293],\n",
      "        [24.5102, 29.5082],\n",
      "        [27.2523, 27.2514]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9886, 0.1766, 0.0707, 0.9319], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4955, 29.4937],\n",
      "        [29.5326, 24.5273],\n",
      "        [24.5130, 29.5077],\n",
      "        [27.2552, 27.2511]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9886, 0.1773, 0.0707, 0.9321], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4952, 29.4958],\n",
      "        [29.5307, 24.5318],\n",
      "        [24.5125, 29.5104],\n",
      "        [27.2548, 27.2540]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9886, 0.1773, 0.0707, 0.9321], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4974, 29.4956],\n",
      "        [29.5352, 24.5299],\n",
      "        [24.5153, 29.5100],\n",
      "        [27.2577, 27.2536]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9886, 0.1780, 0.0708, 0.9323], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4972, 29.4977],\n",
      "        [29.5332, 24.5343],\n",
      "        [24.5148, 29.5127],\n",
      "        [27.2573, 27.2565]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9886, 0.1780, 0.0708, 0.9323], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.4993, 29.4975],\n",
      "        [29.5378, 24.5324],\n",
      "        [24.5175, 29.5122],\n",
      "        [27.2602, 27.2561]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9887, 0.1787, 0.0708, 0.9325], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.4991, 29.4996],\n",
      "        [29.5358, 24.5369],\n",
      "        [24.5170, 29.5150],\n",
      "        [27.2599, 27.2590]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9887, 0.1787, 0.0708, 0.9325], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5012, 29.4994],\n",
      "        [29.5403, 24.5349],\n",
      "        [24.5198, 29.5145],\n",
      "        [27.2627, 27.2587]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9887, 0.1794, 0.0708, 0.9327], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5009, 29.5014],\n",
      "        [29.5383, 24.5394],\n",
      "        [24.5193, 29.5172],\n",
      "        [27.2624, 27.2615]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9887, 0.1794, 0.0708, 0.9327], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5030, 29.5012],\n",
      "        [29.5428, 24.5374],\n",
      "        [24.5220, 29.5167],\n",
      "        [27.2652, 27.2612]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9888, 0.1801, 0.0709, 0.9329], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5028, 29.5033],\n",
      "        [29.5408, 24.5419],\n",
      "        [24.5215, 29.5194],\n",
      "        [27.2649, 27.2640]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9888, 0.1801, 0.0709, 0.9329], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5049, 29.5031],\n",
      "        [29.5454, 24.5399],\n",
      "        [24.5242, 29.5189],\n",
      "        [27.2677, 27.2636]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9888, 0.1808, 0.0709, 0.9330], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5047, 29.5052],\n",
      "        [29.5433, 24.5444],\n",
      "        [24.5237, 29.5216],\n",
      "        [27.2673, 27.2665]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9888, 0.1808, 0.0709, 0.9330], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5068, 29.5049],\n",
      "        [29.5479, 24.5424],\n",
      "        [24.5264, 29.5211],\n",
      "        [27.2702, 27.2661]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9888, 0.1816, 0.0709, 0.9332], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5065, 29.5070],\n",
      "        [29.5458, 24.5469],\n",
      "        [24.5259, 29.5238],\n",
      "        [27.2698, 27.2689]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9888, 0.1816, 0.0709, 0.9332], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5086, 29.5068],\n",
      "        [29.5504, 24.5449],\n",
      "        [24.5286, 29.5233],\n",
      "        [27.2726, 27.2686]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9889, 0.1823, 0.0710, 0.9334], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5084, 29.5088],\n",
      "        [29.5484, 24.5494],\n",
      "        [24.5281, 29.5260],\n",
      "        [27.2723, 27.2714]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9889, 0.1823, 0.0710, 0.9334], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5104, 29.5086],\n",
      "        [29.5529, 24.5473],\n",
      "        [24.5308, 29.5255],\n",
      "        [27.2750, 27.2710]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9889, 0.1830, 0.0710, 0.9336], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5102, 29.5106],\n",
      "        [29.5508, 24.5518],\n",
      "        [24.5302, 29.5281],\n",
      "        [27.2747, 27.2738]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9889, 0.1830, 0.0710, 0.9336], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5122, 29.5104],\n",
      "        [29.5554, 24.5498],\n",
      "        [24.5329, 29.5276],\n",
      "        [27.2775, 27.2734]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9890, 0.1838, 0.0710, 0.9338], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5120, 29.5124],\n",
      "        [29.5533, 24.5543],\n",
      "        [24.5324, 29.5303],\n",
      "        [27.2771, 27.2762]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9890, 0.1838, 0.0710, 0.9338], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5140, 29.5122],\n",
      "        [29.5579, 24.5522],\n",
      "        [24.5351, 29.5298],\n",
      "        [27.2799, 27.2758]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9890, 0.1845, 0.0711, 0.9339], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5138, 29.5142],\n",
      "        [29.5558, 24.5568],\n",
      "        [24.5345, 29.5324],\n",
      "        [27.2795, 27.2786]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9890, 0.1845, 0.0711, 0.9339], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5158, 29.5140],\n",
      "        [29.5604, 24.5547],\n",
      "        [24.5372, 29.5319],\n",
      "        [27.2822, 27.2782]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9890, 0.1853, 0.0711, 0.9341], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5156, 29.5160],\n",
      "        [29.5583, 24.5592],\n",
      "        [24.5367, 29.5345],\n",
      "        [27.2819, 27.2809]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9890, 0.1853, 0.0711, 0.9341], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5176, 29.5158],\n",
      "        [29.5628, 24.5571],\n",
      "        [24.5393, 29.5340],\n",
      "        [27.2846, 27.2806]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9891, 0.1861, 0.0711, 0.9343], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5173, 29.5178],\n",
      "        [29.5607, 24.5617],\n",
      "        [24.5388, 29.5366],\n",
      "        [27.2842, 27.2833]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9891, 0.1861, 0.0711, 0.9343], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5193, 29.5175],\n",
      "        [29.5653, 24.5595],\n",
      "        [24.5414, 29.5361],\n",
      "        [27.2870, 27.2829]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9891, 0.1868, 0.0712, 0.9344], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5191, 29.5195],\n",
      "        [29.5632, 24.5641],\n",
      "        [24.5409, 29.5387],\n",
      "        [27.2866, 27.2856]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9891, 0.1868, 0.0712, 0.9344], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5211, 29.5193],\n",
      "        [29.5678, 24.5620],\n",
      "        [24.5435, 29.5382],\n",
      "        [27.2893, 27.2853]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9891, 0.1876, 0.0712, 0.9346], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5209, 29.5213],\n",
      "        [29.5657, 24.5665],\n",
      "        [24.5430, 29.5408],\n",
      "        [27.2889, 27.2880]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9891, 0.1876, 0.0712, 0.9346], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5228, 29.5210],\n",
      "        [29.5702, 24.5644],\n",
      "        [24.5456, 29.5403],\n",
      "        [27.2916, 27.2876]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9892, 0.1884, 0.0712, 0.9348], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5226, 29.5230],\n",
      "        [29.5681, 24.5689],\n",
      "        [24.5451, 29.5429],\n",
      "        [27.2912, 27.2903]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9892, 0.1884, 0.0712, 0.9348], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5246, 29.5228],\n",
      "        [29.5727, 24.5668],\n",
      "        [24.5477, 29.5424],\n",
      "        [27.2939, 27.2899]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9892, 0.1891, 0.0713, 0.9350], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5243, 29.5247],\n",
      "        [29.5705, 24.5713],\n",
      "        [24.5471, 29.5449],\n",
      "        [27.2936, 27.2926]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9892, 0.1891, 0.0713, 0.9350], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5263, 29.5245],\n",
      "        [29.5751, 24.5692],\n",
      "        [24.5497, 29.5444],\n",
      "        [27.2962, 27.2922]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9893, 0.1899, 0.0713, 0.9351], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5261, 29.5264],\n",
      "        [29.5730, 24.5737],\n",
      "        [24.5492, 29.5470],\n",
      "        [27.2959, 27.2949]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9893, 0.1899, 0.0713, 0.9351], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5280, 29.5262],\n",
      "        [29.5776, 24.5716],\n",
      "        [24.5518, 29.5465],\n",
      "        [27.2985, 27.2945]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9893, 0.1907, 0.0713, 0.9353], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5278, 29.5281],\n",
      "        [29.5754, 24.5761],\n",
      "        [24.5512, 29.5490],\n",
      "        [27.2981, 27.2971]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9893, 0.1907, 0.0713, 0.9353], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5297, 29.5279],\n",
      "        [29.5800, 24.5740],\n",
      "        [24.5538, 29.5485],\n",
      "        [27.3008, 27.2968]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9893, 0.1915, 0.0714, 0.9355], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5295, 29.5298],\n",
      "        [29.5778, 24.5785],\n",
      "        [24.5533, 29.5510],\n",
      "        [27.3004, 27.2994]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9893, 0.1915, 0.0714, 0.9355], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5314, 29.5295],\n",
      "        [29.5825, 24.5763],\n",
      "        [24.5558, 29.5505],\n",
      "        [27.3030, 27.2990]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9894, 0.1923, 0.0714, 0.9356], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5311, 29.5314],\n",
      "        [29.5802, 24.5809],\n",
      "        [24.5553, 29.5530],\n",
      "        [27.3027, 27.3016]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9894, 0.1923, 0.0714, 0.9356], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5331, 29.5312],\n",
      "        [29.5849, 24.5787],\n",
      "        [24.5578, 29.5525],\n",
      "        [27.3053, 27.3013]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9894, 0.1931, 0.0714, 0.9358], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5328, 29.5331],\n",
      "        [29.5827, 24.5833],\n",
      "        [24.5573, 29.5550],\n",
      "        [27.3049, 27.3039]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9894, 0.1931, 0.0714, 0.9358], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5347, 29.5329],\n",
      "        [29.5873, 24.5811],\n",
      "        [24.5599, 29.5545],\n",
      "        [27.3075, 27.3035]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9894, 0.1940, 0.0714, 0.9359], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5345, 29.5348],\n",
      "        [29.5851, 24.5857],\n",
      "        [24.5593, 29.5570],\n",
      "        [27.3071, 27.3061]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9894, 0.1940, 0.0714, 0.9359], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5364, 29.5345],\n",
      "        [29.5897, 24.5834],\n",
      "        [24.5618, 29.5565],\n",
      "        [27.3097, 27.3057]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9895, 0.1948, 0.0715, 0.9361], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5361, 29.5364],\n",
      "        [29.5875, 24.5881],\n",
      "        [24.5613, 29.5590],\n",
      "        [27.3093, 27.3083]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9895, 0.1948, 0.0715, 0.9361], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5380, 29.5362],\n",
      "        [29.5922, 24.5858],\n",
      "        [24.5638, 29.5585],\n",
      "        [27.3119, 27.3079]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9895, 0.1956, 0.0715, 0.9363], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5378, 29.5380],\n",
      "        [29.5899, 24.5904],\n",
      "        [24.5633, 29.5610],\n",
      "        [27.3116, 27.3105]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9895, 0.1956, 0.0715, 0.9363], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5397, 29.5378],\n",
      "        [29.5946, 24.5882],\n",
      "        [24.5658, 29.5604],\n",
      "        [27.3141, 27.3101]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9895, 0.1964, 0.0715, 0.9364], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5394, 29.5397],\n",
      "        [29.5923, 24.5928],\n",
      "        [24.5652, 29.5629],\n",
      "        [27.3137, 27.3127]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9895, 0.1964, 0.0715, 0.9364], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5413, 29.5394],\n",
      "        [29.5970, 24.5905],\n",
      "        [24.5677, 29.5624],\n",
      "        [27.3163, 27.3123]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9896, 0.1973, 0.0716, 0.9366], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5410, 29.5413],\n",
      "        [29.5947, 24.5951],\n",
      "        [24.5672, 29.5648],\n",
      "        [27.3159, 27.3148]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9896, 0.1973, 0.0716, 0.9366], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5429, 29.5410],\n",
      "        [29.5994, 24.5929],\n",
      "        [24.5697, 29.5643],\n",
      "        [27.3185, 27.3145]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9896, 0.1981, 0.0716, 0.9367], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5426, 29.5429],\n",
      "        [29.5971, 24.5975],\n",
      "        [24.5691, 29.5668],\n",
      "        [27.3181, 27.3170]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9896, 0.1981, 0.0716, 0.9367], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5445, 29.5426],\n",
      "        [29.6018, 24.5952],\n",
      "        [24.5716, 29.5662],\n",
      "        [27.3206, 27.3166]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9896, 0.1990, 0.0716, 0.9369], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5443, 29.5445],\n",
      "        [29.5995, 24.5999],\n",
      "        [24.5711, 29.5687],\n",
      "        [27.3202, 27.3191]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9896, 0.1990, 0.0716, 0.9369], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5461, 29.5442],\n",
      "        [29.6042, 24.5975],\n",
      "        [24.5736, 29.5682],\n",
      "        [27.3228, 27.3188]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9897, 0.1998, 0.0717, 0.9371], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5458, 29.5460],\n",
      "        [29.6019, 24.6022],\n",
      "        [24.5730, 29.5706],\n",
      "        [27.3224, 27.3213]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9897, 0.1998, 0.0717, 0.9371], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5477, 29.5458],\n",
      "        [29.6066, 24.5999],\n",
      "        [24.5755, 29.5701],\n",
      "        [27.3249, 27.3209]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9897, 0.2007, 0.0717, 0.9372], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5474, 29.5476],\n",
      "        [29.6043, 24.6046],\n",
      "        [24.5749, 29.5725],\n",
      "        [27.3245, 27.3234]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9897, 0.2007, 0.0717, 0.9372], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5492, 29.5474],\n",
      "        [29.6090, 24.6022],\n",
      "        [24.5774, 29.5720],\n",
      "        [27.3270, 27.3230]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9897, 0.2016, 0.0717, 0.9374], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5490, 29.5492],\n",
      "        [29.6066, 24.6069],\n",
      "        [24.5768, 29.5744],\n",
      "        [27.3266, 27.3255]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9897, 0.2016, 0.0717, 0.9374], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5508, 29.5490],\n",
      "        [29.6114, 24.6045],\n",
      "        [24.5793, 29.5739],\n",
      "        [27.3291, 27.3251]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9898, 0.2025, 0.0718, 0.9375], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5506, 29.5507],\n",
      "        [29.6090, 24.6092],\n",
      "        [24.5787, 29.5763],\n",
      "        [27.3287, 27.3276]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9898, 0.2025, 0.0718, 0.9375], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5524, 29.5505],\n",
      "        [29.6138, 24.6069],\n",
      "        [24.5811, 29.5757],\n",
      "        [27.3312, 27.3272]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9898, 0.2033, 0.0718, 0.9377], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5521, 29.5523],\n",
      "        [29.6114, 24.6116],\n",
      "        [24.5806, 29.5781],\n",
      "        [27.3308, 27.3297]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9898, 0.2033, 0.0718, 0.9377], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5539, 29.5520],\n",
      "        [29.6162, 24.6092],\n",
      "        [24.5830, 29.5776],\n",
      "        [27.3333, 27.3293]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9898, 0.2042, 0.0718, 0.9378], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5537, 29.5538],\n",
      "        [29.6138, 24.6139],\n",
      "        [24.5825, 29.5800],\n",
      "        [27.3329, 27.3317]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9898, 0.2042, 0.0718, 0.9378], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5555, 29.5536],\n",
      "        [29.6186, 24.6115],\n",
      "        [24.5849, 29.5795],\n",
      "        [27.3354, 27.3314]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9899, 0.2051, 0.0719, 0.9380], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5552, 29.5553],\n",
      "        [29.6162, 24.6162],\n",
      "        [24.5843, 29.5818],\n",
      "        [27.3350, 27.3338]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9899, 0.2051, 0.0719, 0.9380], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5570, 29.5551],\n",
      "        [29.6210, 24.6138],\n",
      "        [24.5868, 29.5813],\n",
      "        [27.3374, 27.3334]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9899, 0.2060, 0.0719, 0.9381], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5567, 29.5568],\n",
      "        [29.6186, 24.6186],\n",
      "        [24.5862, 29.5837],\n",
      "        [27.3370, 27.3358]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9899, 0.2060, 0.0719, 0.9381], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5585, 29.5566],\n",
      "        [29.6234, 24.6162],\n",
      "        [24.5886, 29.5831],\n",
      "        [27.3395, 27.3354]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9899, 0.2070, 0.0719, 0.9383], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5583, 29.5583],\n",
      "        [29.6210, 24.6209],\n",
      "        [24.5880, 29.5855],\n",
      "        [27.3391, 27.3378]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9899, 0.2070, 0.0719, 0.9383], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5600, 29.5581],\n",
      "        [29.6258, 24.6185],\n",
      "        [24.5905, 29.5850],\n",
      "        [27.3415, 27.3375]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9900, 0.2079, 0.0720, 0.9384], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5598, 29.5599],\n",
      "        [29.6234, 24.6233],\n",
      "        [24.5899, 29.5873],\n",
      "        [27.3411, 27.3399]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9900, 0.2079, 0.0720, 0.9384], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5615, 29.5596],\n",
      "        [29.6282, 24.6208],\n",
      "        [24.5923, 29.5868],\n",
      "        [27.3435, 27.3395]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9900, 0.2088, 0.0720, 0.9386], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5613, 29.5614],\n",
      "        [29.6257, 24.6256],\n",
      "        [24.5917, 29.5891],\n",
      "        [27.3431, 27.3419]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9900, 0.2088, 0.0720, 0.9386], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5630, 29.5611],\n",
      "        [29.6306, 24.6231],\n",
      "        [24.5941, 29.5886],\n",
      "        [27.3455, 27.3415]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9900, 0.2097, 0.0720, 0.9387], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5628, 29.5628],\n",
      "        [29.6281, 24.6279],\n",
      "        [24.5935, 29.5909],\n",
      "        [27.3451, 27.3439]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9900, 0.2097, 0.0720, 0.9387], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5645, 29.5626],\n",
      "        [29.6331, 24.6254],\n",
      "        [24.5959, 29.5904],\n",
      "        [27.3475, 27.3435]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9901, 0.2107, 0.0721, 0.9389], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5643, 29.5643],\n",
      "        [29.6305, 24.6302],\n",
      "        [24.5954, 29.5927],\n",
      "        [27.3471, 27.3459]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9901, 0.2107, 0.0721, 0.9389], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5660, 29.5641],\n",
      "        [29.6355, 24.6277],\n",
      "        [24.5977, 29.5922],\n",
      "        [27.3495, 27.3455]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9901, 0.2116, 0.0721, 0.9390], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5657, 29.5658],\n",
      "        [29.6329, 24.6325],\n",
      "        [24.5971, 29.5945],\n",
      "        [27.3491, 27.3478]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9901, 0.2116, 0.0721, 0.9390], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5675, 29.5655],\n",
      "        [29.6379, 24.6300],\n",
      "        [24.5995, 29.5939],\n",
      "        [27.3515, 27.3475]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9901, 0.2126, 0.0721, 0.9391], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5672, 29.5672],\n",
      "        [29.6353, 24.6349],\n",
      "        [24.5989, 29.5963],\n",
      "        [27.3511, 27.3498]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9901, 0.2126, 0.0721, 0.9391], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5689, 29.5670],\n",
      "        [29.6403, 24.6323],\n",
      "        [24.6013, 29.5957],\n",
      "        [27.3535, 27.3494]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9902, 0.2136, 0.0722, 0.9393], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5687, 29.5687],\n",
      "        [29.6377, 24.6372],\n",
      "        [24.6007, 29.5980],\n",
      "        [27.3531, 27.3518]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9902, 0.2136, 0.0722, 0.9393], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5704, 29.5684],\n",
      "        [29.6427, 24.6346],\n",
      "        [24.6031, 29.5975],\n",
      "        [27.3555, 27.3514]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9902, 0.2145, 0.0722, 0.9394], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5701, 29.5701],\n",
      "        [29.6401, 24.6396],\n",
      "        [24.6025, 29.5998],\n",
      "        [27.3551, 27.3537]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9902, 0.2145, 0.0722, 0.9394], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5719, 29.5699],\n",
      "        [29.6451, 24.6370],\n",
      "        [24.6049, 29.5992],\n",
      "        [27.3574, 27.3533]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9902, 0.2155, 0.0722, 0.9396], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5716, 29.5715],\n",
      "        [29.6425, 24.6419],\n",
      "        [24.6043, 29.6015],\n",
      "        [27.3570, 27.3556]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9902, 0.2155, 0.0722, 0.9396], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5733, 29.5713],\n",
      "        [29.6475, 24.6393],\n",
      "        [24.6066, 29.6010],\n",
      "        [27.3593, 27.3552]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9903, 0.2165, 0.0723, 0.9397], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5730, 29.5730],\n",
      "        [29.6449, 24.6442],\n",
      "        [24.6060, 29.6033],\n",
      "        [27.3589, 27.3576]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9903, 0.2165, 0.0723, 0.9397], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5747, 29.5727],\n",
      "        [29.6500, 24.6416],\n",
      "        [24.6084, 29.6027],\n",
      "        [27.3613, 27.3572]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9903, 0.2175, 0.0723, 0.9399], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5744, 29.5744],\n",
      "        [29.6473, 24.6465],\n",
      "        [24.6078, 29.6050],\n",
      "        [27.3609, 27.3595]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9903, 0.2175, 0.0723, 0.9399], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5761, 29.5741],\n",
      "        [29.6524, 24.6439],\n",
      "        [24.6101, 29.6044],\n",
      "        [27.3632, 27.3591]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9903, 0.2185, 0.0723, 0.9400], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5759, 29.5758],\n",
      "        [29.6497, 24.6489],\n",
      "        [24.6095, 29.6067],\n",
      "        [27.3628, 27.3614]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9903, 0.2185, 0.0723, 0.9400], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5776, 29.5755],\n",
      "        [29.6548, 24.6462],\n",
      "        [24.6119, 29.6062],\n",
      "        [27.3651, 27.3610]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9903, 0.2195, 0.0724, 0.9401], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5773, 29.5772],\n",
      "        [29.6521, 24.6512],\n",
      "        [24.6113, 29.6084],\n",
      "        [27.3647, 27.3633]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9903, 0.2195, 0.0724, 0.9401], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5790, 29.5769],\n",
      "        [29.6573, 24.6485],\n",
      "        [24.6136, 29.6079],\n",
      "        [27.3670, 27.3629]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9904, 0.2205, 0.0724, 0.9403], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5787, 29.5786],\n",
      "        [29.6546, 24.6536],\n",
      "        [24.6130, 29.6101],\n",
      "        [27.3666, 27.3651]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9904, 0.2205, 0.0724, 0.9403], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5804, 29.5783],\n",
      "        [29.6597, 24.6508],\n",
      "        [24.6153, 29.6096],\n",
      "        [27.3689, 27.3647]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9904, 0.2216, 0.0725, 0.9404], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5801, 29.5800],\n",
      "        [29.6570, 24.6559],\n",
      "        [24.6147, 29.6118],\n",
      "        [27.3685, 27.3670]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9904, 0.2216, 0.0725, 0.9404], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5818, 29.5797],\n",
      "        [29.6622, 24.6532],\n",
      "        [24.6170, 29.6112],\n",
      "        [27.3708, 27.3666]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9904, 0.2226, 0.0725, 0.9405], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5815, 29.5813],\n",
      "        [29.6594, 24.6582],\n",
      "        [24.6164, 29.6135],\n",
      "        [27.3704, 27.3689]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9904, 0.2226, 0.0725, 0.9405], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5832, 29.5811],\n",
      "        [29.6646, 24.6555],\n",
      "        [24.6188, 29.6129],\n",
      "        [27.3727, 27.3685]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9905, 0.2237, 0.0725, 0.9407], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5829, 29.5827],\n",
      "        [29.6619, 24.6606],\n",
      "        [24.6181, 29.6152],\n",
      "        [27.3722, 27.3707]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9905, 0.2237, 0.0725, 0.9407], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5845, 29.5824],\n",
      "        [29.6671, 24.6578],\n",
      "        [24.6204, 29.6146],\n",
      "        [27.3745, 27.3703]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9905, 0.2247, 0.0726, 0.9408], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5843, 29.5841],\n",
      "        [29.6643, 24.6629],\n",
      "        [24.6198, 29.6169],\n",
      "        [27.3741, 27.3726]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9905, 0.2247, 0.0726, 0.9408], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5859, 29.5838],\n",
      "        [29.6696, 24.6602],\n",
      "        [24.6222, 29.6163],\n",
      "        [27.3764, 27.3722]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9905, 0.2258, 0.0726, 0.9409], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5856, 29.5854],\n",
      "        [29.6668, 24.6653],\n",
      "        [24.6215, 29.6185],\n",
      "        [27.3760, 27.3744]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9905, 0.2258, 0.0726, 0.9409], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5873, 29.5852],\n",
      "        [29.6720, 24.6625],\n",
      "        [24.6238, 29.6179],\n",
      "        [27.3782, 27.3740]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9906, 0.2268, 0.0726, 0.9411], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5870, 29.5868],\n",
      "        [29.6692, 24.6677],\n",
      "        [24.6232, 29.6202],\n",
      "        [27.3778, 27.3762]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9906, 0.2268, 0.0726, 0.9411], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5886, 29.5865],\n",
      "        [29.6745, 24.6648],\n",
      "        [24.6255, 29.6196],\n",
      "        [27.3801, 27.3758]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9906, 0.2279, 0.0727, 0.9412], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5884, 29.5881],\n",
      "        [29.6717, 24.6700],\n",
      "        [24.6249, 29.6219],\n",
      "        [27.3797, 27.3781]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9906, 0.2279, 0.0727, 0.9412], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5900, 29.5878],\n",
      "        [29.6770, 24.6672],\n",
      "        [24.6272, 29.6213],\n",
      "        [27.3819, 27.3777]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9906, 0.2290, 0.0727, 0.9413], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5897, 29.5894],\n",
      "        [29.6742, 24.6724],\n",
      "        [24.6266, 29.6235],\n",
      "        [27.3815, 27.3799]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9906, 0.2290, 0.0727, 0.9413], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5913, 29.5892],\n",
      "        [29.6795, 24.6695],\n",
      "        [24.6289, 29.6229],\n",
      "        [27.3837, 27.3794]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9906, 0.2301, 0.0727, 0.9415], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5910, 29.5908],\n",
      "        [29.6767, 24.6748],\n",
      "        [24.6282, 29.6251],\n",
      "        [27.3833, 27.3817]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9906, 0.2301, 0.0727, 0.9415], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5927, 29.5905],\n",
      "        [29.6820, 24.6719],\n",
      "        [24.6305, 29.6245],\n",
      "        [27.3855, 27.3813]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9907, 0.2312, 0.0728, 0.9416], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5924, 29.5921],\n",
      "        [29.6791, 24.6771],\n",
      "        [24.6299, 29.6268],\n",
      "        [27.3851, 27.3834]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9907, 0.2312, 0.0728, 0.9416], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5940, 29.5918],\n",
      "        [29.6846, 24.6742],\n",
      "        [24.6322, 29.6261],\n",
      "        [27.3873, 27.3830]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9907, 0.2323, 0.0728, 0.9417], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5937, 29.5934],\n",
      "        [29.6817, 24.6795],\n",
      "        [24.6316, 29.6284],\n",
      "        [27.3869, 27.3852]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9907, 0.2323, 0.0728, 0.9417], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5953, 29.5931],\n",
      "        [29.6871, 24.6766],\n",
      "        [24.6338, 29.6278],\n",
      "        [27.3891, 27.3848]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9907, 0.2335, 0.0728, 0.9419], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5950, 29.5947],\n",
      "        [29.6842, 24.6819],\n",
      "        [24.6332, 29.6300],\n",
      "        [27.3887, 27.3870]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9907, 0.2335, 0.0728, 0.9419], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5966, 29.5944],\n",
      "        [29.6897, 24.6790],\n",
      "        [24.6355, 29.6294],\n",
      "        [27.3909, 27.3866]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9907, 0.2346, 0.0729, 0.9420], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5964, 29.5960],\n",
      "        [29.6867, 24.6843],\n",
      "        [24.6349, 29.6316],\n",
      "        [27.3905, 27.3888]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9907, 0.2346, 0.0729, 0.9420], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5979, 29.5957],\n",
      "        [29.6922, 24.6814],\n",
      "        [24.6371, 29.6310],\n",
      "        [27.3927, 27.3883]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9908, 0.2357, 0.0729, 0.9421], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5977, 29.5973],\n",
      "        [29.6892, 24.6867],\n",
      "        [24.6365, 29.6332],\n",
      "        [27.3923, 27.3905]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9908, 0.2357, 0.0729, 0.9421], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.5993, 29.5970],\n",
      "        [29.6948, 24.6838],\n",
      "        [24.6388, 29.6326],\n",
      "        [27.3945, 27.3901]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9908, 0.2369, 0.0729, 0.9422], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.5990, 29.5986],\n",
      "        [29.6917, 24.6891],\n",
      "        [24.6381, 29.6348],\n",
      "        [27.3941, 27.3923]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9908, 0.2369, 0.0729, 0.9422], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6006, 29.5983],\n",
      "        [29.6973, 24.6861],\n",
      "        [24.6404, 29.6342],\n",
      "        [27.3963, 27.3919]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9908, 0.2381, 0.0730, 0.9424], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6003, 29.5998],\n",
      "        [29.6943, 24.6915],\n",
      "        [24.6397, 29.6364],\n",
      "        [27.3958, 27.3940]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9908, 0.2381, 0.0730, 0.9424], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6018, 29.5996],\n",
      "        [29.6999, 24.6885],\n",
      "        [24.6420, 29.6358],\n",
      "        [27.3980, 27.3936]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9909, 0.2392, 0.0730, 0.9425], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6016, 29.6011],\n",
      "        [29.6969, 24.6940],\n",
      "        [24.6414, 29.6380],\n",
      "        [27.3976, 27.3957]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9909, 0.2392, 0.0730, 0.9425], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6032, 29.6008],\n",
      "        [29.7025, 24.6910],\n",
      "        [24.6436, 29.6374],\n",
      "        [27.3998, 27.3953]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9909, 0.2404, 0.0730, 0.9426], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6029, 29.6024],\n",
      "        [29.6994, 24.6964],\n",
      "        [24.6430, 29.6396],\n",
      "        [27.3993, 27.3975]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9909, 0.2404, 0.0730, 0.9426], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6044, 29.6021],\n",
      "        [29.7051, 24.6934],\n",
      "        [24.6452, 29.6389],\n",
      "        [27.4015, 27.3970]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9909, 0.2416, 0.0731, 0.9427], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6041, 29.6036],\n",
      "        [29.7020, 24.6989],\n",
      "        [24.6446, 29.6411],\n",
      "        [27.4011, 27.3992]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9909, 0.2416, 0.0731, 0.9427], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6057, 29.6034],\n",
      "        [29.7077, 24.6958],\n",
      "        [24.6468, 29.6405],\n",
      "        [27.4032, 27.3987]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9909, 0.2428, 0.0731, 0.9429], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6054, 29.6049],\n",
      "        [29.7046, 24.7013],\n",
      "        [24.6462, 29.6427],\n",
      "        [27.4028, 27.4009]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9909, 0.2428, 0.0731, 0.9429], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6070, 29.6046],\n",
      "        [29.7104, 24.6982],\n",
      "        [24.6484, 29.6420],\n",
      "        [27.4050, 27.4004]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9910, 0.2440, 0.0732, 0.9430], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6067, 29.6061],\n",
      "        [29.7072, 24.7038],\n",
      "        [24.6478, 29.6442],\n",
      "        [27.4045, 27.4026]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9910, 0.2440, 0.0732, 0.9430], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6082, 29.6059],\n",
      "        [29.7130, 24.7007],\n",
      "        [24.6500, 29.6436],\n",
      "        [27.4067, 27.4021]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9910, 0.2452, 0.0732, 0.9431], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6079, 29.6074],\n",
      "        [29.7099, 24.7062],\n",
      "        [24.6494, 29.6458],\n",
      "        [27.4062, 27.4043]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9910, 0.2452, 0.0732, 0.9431], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6095, 29.6071],\n",
      "        [29.7157, 24.7031],\n",
      "        [24.6516, 29.6452],\n",
      "        [27.4084, 27.4038]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9910, 0.2465, 0.0732, 0.9432], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6092, 29.6086],\n",
      "        [29.7125, 24.7087],\n",
      "        [24.6510, 29.6474],\n",
      "        [27.4080, 27.4059]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9910, 0.2465, 0.0732, 0.9432], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6108, 29.6083],\n",
      "        [29.7184, 24.7056],\n",
      "        [24.6532, 29.6467],\n",
      "        [27.4101, 27.4055]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9910, 0.2477, 0.0733, 0.9433], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6105, 29.6099],\n",
      "        [29.7152, 24.7112],\n",
      "        [24.6526, 29.6489],\n",
      "        [27.4097, 27.4076]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9910, 0.2477, 0.0733, 0.9433], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6120, 29.6096],\n",
      "        [29.7211, 24.7080],\n",
      "        [24.6548, 29.6482],\n",
      "        [27.4118, 27.4072]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9911, 0.2490, 0.0733, 0.9435], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6117, 29.6111],\n",
      "        [29.7178, 24.7137],\n",
      "        [24.6541, 29.6504],\n",
      "        [27.4114, 27.4093]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9911, 0.2490, 0.0733, 0.9435], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6132, 29.6108],\n",
      "        [29.7238, 24.7105],\n",
      "        [24.6564, 29.6498],\n",
      "        [27.4135, 27.4088]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9911, 0.2502, 0.0733, 0.9436], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6130, 29.6123],\n",
      "        [29.7206, 24.7162],\n",
      "        [24.6557, 29.6520],\n",
      "        [27.4131, 27.4109]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9911, 0.2502, 0.0733, 0.9436], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6145, 29.6120],\n",
      "        [29.7265, 24.7130],\n",
      "        [24.6580, 29.6513],\n",
      "        [27.4152, 27.4105]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9911, 0.2515, 0.0734, 0.9437], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6142, 29.6135],\n",
      "        [29.7232, 24.7188],\n",
      "        [24.6573, 29.6535],\n",
      "        [27.4147, 27.4126]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9911, 0.2515, 0.0734, 0.9437], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6157, 29.6132],\n",
      "        [29.7293, 24.7155],\n",
      "        [24.6595, 29.6528],\n",
      "        [27.4169, 27.4122]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9911, 0.2528, 0.0734, 0.9438], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6154, 29.6147],\n",
      "        [29.7260, 24.7213],\n",
      "        [24.6589, 29.6550],\n",
      "        [27.4164, 27.4142]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9911, 0.2528, 0.0734, 0.9438], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6170, 29.6144],\n",
      "        [29.7320, 24.7180],\n",
      "        [24.6611, 29.6543],\n",
      "        [27.4185, 27.4138]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9912, 0.2541, 0.0735, 0.9439], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6167, 29.6159],\n",
      "        [29.7287, 24.7239],\n",
      "        [24.6604, 29.6565],\n",
      "        [27.4181, 27.4159]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9912, 0.2541, 0.0735, 0.9439], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6182, 29.6156],\n",
      "        [29.7348, 24.7206],\n",
      "        [24.6627, 29.6559],\n",
      "        [27.4202, 27.4154]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9912, 0.2554, 0.0735, 0.9440], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6179, 29.6171],\n",
      "        [29.7315, 24.7264],\n",
      "        [24.6620, 29.6580],\n",
      "        [27.4198, 27.4175]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9912, 0.2554, 0.0735, 0.9440], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6194, 29.6168],\n",
      "        [29.7376, 24.7231],\n",
      "        [24.6642, 29.6574],\n",
      "        [27.4219, 27.4171]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9912, 0.2567, 0.0735, 0.9442], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6191, 29.6183],\n",
      "        [29.7343, 24.7290],\n",
      "        [24.6635, 29.6596],\n",
      "        [27.4214, 27.4192]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9912, 0.2567, 0.0735, 0.9442], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6206, 29.6180],\n",
      "        [29.7404, 24.7257],\n",
      "        [24.6658, 29.6589],\n",
      "        [27.4235, 27.4187]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9912, 0.2581, 0.0736, 0.9443], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6203, 29.6195],\n",
      "        [29.7371, 24.7316],\n",
      "        [24.6651, 29.6611],\n",
      "        [27.4231, 27.4208]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9912, 0.2581, 0.0736, 0.9443], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6219, 29.6192],\n",
      "        [29.7433, 24.7282],\n",
      "        [24.6673, 29.6604],\n",
      "        [27.4252, 27.4203]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9913, 0.2594, 0.0736, 0.9444], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6215, 29.6207],\n",
      "        [29.7399, 24.7342],\n",
      "        [24.6666, 29.6625],\n",
      "        [27.4247, 27.4224]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9913, 0.2594, 0.0736, 0.9444], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6231, 29.6204],\n",
      "        [29.7462, 24.7308],\n",
      "        [24.6689, 29.6619],\n",
      "        [27.4268, 27.4219]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9913, 0.2608, 0.0736, 0.9445], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6227, 29.6219],\n",
      "        [29.7427, 24.7368],\n",
      "        [24.6682, 29.6640],\n",
      "        [27.4264, 27.4240]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9913, 0.2608, 0.0736, 0.9445], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6242, 29.6216],\n",
      "        [29.7490, 24.7334],\n",
      "        [24.6704, 29.6634],\n",
      "        [27.4285, 27.4235]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9913, 0.2622, 0.0737, 0.9446], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6239, 29.6230],\n",
      "        [29.7456, 24.7395],\n",
      "        [24.6697, 29.6655],\n",
      "        [27.4280, 27.4256]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9913, 0.2622, 0.0737, 0.9446], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6255, 29.6228],\n",
      "        [29.7519, 24.7360],\n",
      "        [24.6720, 29.6649],\n",
      "        [27.4301, 27.4251]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9913, 0.2635, 0.0737, 0.9447], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6251, 29.6242],\n",
      "        [29.7485, 24.7421],\n",
      "        [24.6713, 29.6670],\n",
      "        [27.4296, 27.4272]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9913, 0.2635, 0.0737, 0.9447], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6266, 29.6239],\n",
      "        [29.7549, 24.7386],\n",
      "        [24.6735, 29.6663],\n",
      "        [27.4317, 27.4267]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9914, 0.2649, 0.0738, 0.9448], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6263, 29.6254],\n",
      "        [29.7514, 24.7448],\n",
      "        [24.6728, 29.6685],\n",
      "        [27.4313, 27.4288]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9914, 0.2649, 0.0738, 0.9448], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6278, 29.6251],\n",
      "        [29.7578, 24.7413],\n",
      "        [24.6750, 29.6678],\n",
      "        [27.4334, 27.4283]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9914, 0.2663, 0.0738, 0.9450], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6275, 29.6265],\n",
      "        [29.7543, 24.7474],\n",
      "        [24.6743, 29.6700],\n",
      "        [27.4329, 27.4303]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9914, 0.2663, 0.0738, 0.9450], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6290, 29.6262],\n",
      "        [29.7608, 24.7439],\n",
      "        [24.6766, 29.6693],\n",
      "        [27.4350, 27.4299]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9914, 0.2677, 0.0738, 0.9451], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6287, 29.6277],\n",
      "        [29.7572, 24.7502],\n",
      "        [24.6759, 29.6714],\n",
      "        [27.4345, 27.4319]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9914, 0.2677, 0.0738, 0.9451], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6302, 29.6274],\n",
      "        [29.7638, 24.7466],\n",
      "        [24.6781, 29.6707],\n",
      "        [27.4366, 27.4315]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9914, 0.2692, 0.0739, 0.9452], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6299, 29.6288],\n",
      "        [29.7602, 24.7529],\n",
      "        [24.6774, 29.6729],\n",
      "        [27.4361, 27.4335]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9914, 0.2692, 0.0739, 0.9452], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6314, 29.6285],\n",
      "        [29.7668, 24.7493],\n",
      "        [24.6796, 29.6722],\n",
      "        [27.4382, 27.4330]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9915, 0.2706, 0.0739, 0.9453], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6310, 29.6299],\n",
      "        [29.7632, 24.7556],\n",
      "        [24.6789, 29.6744],\n",
      "        [27.4377, 27.4350]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9915, 0.2706, 0.0739, 0.9453], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6325, 29.6297],\n",
      "        [29.7699, 24.7520],\n",
      "        [24.6812, 29.6737],\n",
      "        [27.4398, 27.4346]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9915, 0.2721, 0.0739, 0.9454], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6322, 29.6311],\n",
      "        [29.7662, 24.7583],\n",
      "        [24.6804, 29.6758],\n",
      "        [27.4393, 27.4366]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9915, 0.2721, 0.0739, 0.9454], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6337, 29.6308],\n",
      "        [29.7729, 24.7547],\n",
      "        [24.6827, 29.6751],\n",
      "        [27.4414, 27.4361]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9915, 0.2735, 0.0740, 0.9455], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6334, 29.6322],\n",
      "        [29.7693, 24.7611],\n",
      "        [24.6820, 29.6773],\n",
      "        [27.4409, 27.4382]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9915, 0.2735, 0.0740, 0.9455], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6349, 29.6319],\n",
      "        [29.7760, 24.7575],\n",
      "        [24.6842, 29.6766],\n",
      "        [27.4430, 27.4377]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9915, 0.2750, 0.0740, 0.9456], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6345, 29.6334],\n",
      "        [29.7724, 24.7639],\n",
      "        [24.6835, 29.6787],\n",
      "        [27.4425, 27.4397]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9915, 0.2750, 0.0740, 0.9456], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6360, 29.6331],\n",
      "        [29.7792, 24.7603],\n",
      "        [24.6857, 29.6780],\n",
      "        [27.4446, 27.4392]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9915, 0.2765, 0.0741, 0.9457], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6357, 29.6345],\n",
      "        [29.7755, 24.7667],\n",
      "        [24.6850, 29.6802],\n",
      "        [27.4441, 27.4412]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9915, 0.2765, 0.0741, 0.9457], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6372, 29.6342],\n",
      "        [29.7823, 24.7630],\n",
      "        [24.6873, 29.6795],\n",
      "        [27.4462, 27.4408]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9916, 0.2780, 0.0741, 0.9458], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6369, 29.6356],\n",
      "        [29.7786, 24.7695],\n",
      "        [24.6865, 29.6816],\n",
      "        [27.4457, 27.4428]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9916, 0.2780, 0.0741, 0.9458], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6383, 29.6353],\n",
      "        [29.7855, 24.7658],\n",
      "        [24.6888, 29.6809],\n",
      "        [27.4477, 27.4423]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9916, 0.2795, 0.0741, 0.9459], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6380, 29.6367],\n",
      "        [29.7818, 24.7724],\n",
      "        [24.6880, 29.6831],\n",
      "        [27.4473, 27.4443]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9916, 0.2795, 0.0741, 0.9459], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6395, 29.6364],\n",
      "        [29.7888, 24.7687],\n",
      "        [24.6903, 29.6824],\n",
      "        [27.4493, 27.4438]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9916, 0.2811, 0.0742, 0.9460], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6392, 29.6378],\n",
      "        [29.7850, 24.7753],\n",
      "        [24.6896, 29.6845],\n",
      "        [27.4488, 27.4458]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9916, 0.2811, 0.0742, 0.9460], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6406, 29.6375],\n",
      "        [29.7920, 24.7715],\n",
      "        [24.6918, 29.6838],\n",
      "        [27.4509, 27.4453]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9916, 0.2826, 0.0742, 0.9461], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6403, 29.6389],\n",
      "        [29.7882, 24.7782],\n",
      "        [24.6911, 29.6860],\n",
      "        [27.4504, 27.4473]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9916, 0.2826, 0.0742, 0.9461], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6418, 29.6386],\n",
      "        [29.7953, 24.7744],\n",
      "        [24.6933, 29.6852],\n",
      "        [27.4525, 27.4468]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9917, 0.2842, 0.0743, 0.9462], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6415, 29.6400],\n",
      "        [29.7914, 24.7811],\n",
      "        [24.6926, 29.6874],\n",
      "        [27.4520, 27.4488]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9917, 0.2842, 0.0743, 0.9462], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6429, 29.6397],\n",
      "        [29.7986, 24.7773],\n",
      "        [24.6949, 29.6867],\n",
      "        [27.4540, 27.4484]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9917, 0.2858, 0.0743, 0.9463], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6426, 29.6411],\n",
      "        [29.7947, 24.7840],\n",
      "        [24.6941, 29.6888],\n",
      "        [27.4535, 27.4503]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9917, 0.2858, 0.0743, 0.9463], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6441, 29.6408],\n",
      "        [29.8019, 24.7802],\n",
      "        [24.6964, 29.6881],\n",
      "        [27.4556, 27.4499]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9917, 0.2873, 0.0743, 0.9464], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6437, 29.6422],\n",
      "        [29.7980, 24.7870],\n",
      "        [24.6956, 29.6903],\n",
      "        [27.4551, 27.4519]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9917, 0.2873, 0.0743, 0.9464], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6452, 29.6419],\n",
      "        [29.8053, 24.7831],\n",
      "        [24.6979, 29.6895],\n",
      "        [27.4571, 27.4514]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9917, 0.2889, 0.0744, 0.9465], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6449, 29.6433],\n",
      "        [29.8014, 24.7900],\n",
      "        [24.6971, 29.6917],\n",
      "        [27.4566, 27.4534]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9917, 0.2889, 0.0744, 0.9465], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6463, 29.6430],\n",
      "        [29.8087, 24.7861],\n",
      "        [24.6994, 29.6909],\n",
      "        [27.4587, 27.4529]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9917, 0.2906, 0.0744, 0.9466], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6460, 29.6444],\n",
      "        [29.8048, 24.7930],\n",
      "        [24.6986, 29.6931],\n",
      "        [27.4582, 27.4548]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9917, 0.2906, 0.0744, 0.9466], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6474, 29.6441],\n",
      "        [29.8122, 24.7891],\n",
      "        [24.7009, 29.6924],\n",
      "        [27.4602, 27.4544]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9918, 0.2922, 0.0745, 0.9467], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6471, 29.6455],\n",
      "        [29.8082, 24.7960],\n",
      "        [24.7001, 29.6945],\n",
      "        [27.4597, 27.4563]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9918, 0.2922, 0.0745, 0.9467], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6486, 29.6452],\n",
      "        [29.8156, 24.7921],\n",
      "        [24.7024, 29.6938],\n",
      "        [27.4618, 27.4558]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9918, 0.2938, 0.0745, 0.9468], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6482, 29.6466],\n",
      "        [29.8116, 24.7991],\n",
      "        [24.7016, 29.6960],\n",
      "        [27.4613, 27.4578]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9918, 0.2938, 0.0745, 0.9468], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6497, 29.6463],\n",
      "        [29.8192, 24.7951],\n",
      "        [24.7039, 29.6952],\n",
      "        [27.4633, 27.4573]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9918, 0.2955, 0.0745, 0.9469], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6494, 29.6477],\n",
      "        [29.8151, 24.8022],\n",
      "        [24.7031, 29.6974],\n",
      "        [27.4628, 27.4593]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9918, 0.2955, 0.0745, 0.9469], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6508, 29.6473],\n",
      "        [29.8227, 24.7982],\n",
      "        [24.7054, 29.6966],\n",
      "        [27.4649, 27.4588]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9918, 0.2972, 0.0746, 0.9470], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6505, 29.6487],\n",
      "        [29.8187, 24.8053],\n",
      "        [24.7046, 29.6988],\n",
      "        [27.4643, 27.4608]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9918, 0.2972, 0.0746, 0.9470], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6519, 29.6484],\n",
      "        [29.8263, 24.8013],\n",
      "        [24.7069, 29.6980],\n",
      "        [27.4664, 27.4603]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9919, 0.2989, 0.0746, 0.9471], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6516, 29.6498],\n",
      "        [29.8222, 24.8084],\n",
      "        [24.7062, 29.7002],\n",
      "        [27.4659, 27.4622]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9919, 0.2989, 0.0746, 0.9471], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6531, 29.6495],\n",
      "        [29.8300, 24.8044],\n",
      "        [24.7085, 29.6995],\n",
      "        [27.4680, 27.4618]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9919, 0.3006, 0.0747, 0.9472], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6527, 29.6509],\n",
      "        [29.8258, 24.8116],\n",
      "        [24.7077, 29.7016],\n",
      "        [27.4674, 27.4637]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9919, 0.3006, 0.0747, 0.9472], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6542, 29.6506],\n",
      "        [29.8336, 24.8075],\n",
      "        [24.7100, 29.7009],\n",
      "        [27.4695, 27.4632]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9919, 0.3023, 0.0747, 0.9473], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6538, 29.6519],\n",
      "        [29.8295, 24.8148],\n",
      "        [24.7092, 29.7030],\n",
      "        [27.4689, 27.4652]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9919, 0.3023, 0.0747, 0.9473], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6553, 29.6516],\n",
      "        [29.8373, 24.8107],\n",
      "        [24.7115, 29.7023],\n",
      "        [27.4710, 27.4647]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9919, 0.3040, 0.0747, 0.9474], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6549, 29.6530],\n",
      "        [29.8332, 24.8180],\n",
      "        [24.7107, 29.7044],\n",
      "        [27.4705, 27.4666]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9919, 0.3040, 0.0747, 0.9474], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6564, 29.6527],\n",
      "        [29.8411, 24.8139],\n",
      "        [24.7130, 29.7037],\n",
      "        [27.4725, 27.4661]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9919, 0.3058, 0.0748, 0.9475], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6560, 29.6541],\n",
      "        [29.8369, 24.8213],\n",
      "        [24.7122, 29.7059],\n",
      "        [27.4720, 27.4681]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9919, 0.3058, 0.0748, 0.9475], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6575, 29.6538],\n",
      "        [29.8449, 24.8171],\n",
      "        [24.7145, 29.7051],\n",
      "        [27.4741, 27.4676]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9920, 0.3075, 0.0748, 0.9476], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6571, 29.6551],\n",
      "        [29.8407, 24.8246],\n",
      "        [24.7137, 29.7073],\n",
      "        [27.4735, 27.4695]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9920, 0.3075, 0.0748, 0.9476], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6586, 29.6548],\n",
      "        [29.8488, 24.8204],\n",
      "        [24.7160, 29.7065],\n",
      "        [27.4756, 27.4690]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9920, 0.3093, 0.0749, 0.9477], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6583, 29.6562],\n",
      "        [29.8445, 24.8279],\n",
      "        [24.7152, 29.7087],\n",
      "        [27.4750, 27.4710]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9920, 0.3093, 0.0749, 0.9477], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6597, 29.6558],\n",
      "        [29.8527, 24.8237],\n",
      "        [24.7176, 29.7079],\n",
      "        [27.4771, 27.4705]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9920, 0.3111, 0.0749, 0.9478], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6593, 29.6572],\n",
      "        [29.8484, 24.8312],\n",
      "        [24.7167, 29.7101],\n",
      "        [27.4765, 27.4724]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9920, 0.3111, 0.0749, 0.9478], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6608, 29.6569],\n",
      "        [29.8566, 24.8270],\n",
      "        [24.7191, 29.7093],\n",
      "        [27.4786, 27.4719]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9920, 0.3129, 0.0750, 0.9479], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6604, 29.6583],\n",
      "        [29.8523, 24.8346],\n",
      "        [24.7182, 29.7115],\n",
      "        [27.4781, 27.4739]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9920, 0.3129, 0.0750, 0.9479], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6619, 29.6580],\n",
      "        [29.8606, 24.8304],\n",
      "        [24.7206, 29.7107],\n",
      "        [27.4801, 27.4734]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9920, 0.3148, 0.0750, 0.9480], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6615, 29.6593],\n",
      "        [29.8562, 24.8380],\n",
      "        [24.7197, 29.7129],\n",
      "        [27.4796, 27.4753]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9920, 0.3148, 0.0750, 0.9480], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6630, 29.6590],\n",
      "        [29.8646, 24.8337],\n",
      "        [24.7221, 29.7121],\n",
      "        [27.4816, 27.4748]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9921, 0.3166, 0.0750, 0.9481], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6626, 29.6604],\n",
      "        [29.8602, 24.8415],\n",
      "        [24.7213, 29.7143],\n",
      "        [27.4811, 27.4767]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9921, 0.3166, 0.0750, 0.9481], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6641, 29.6600],\n",
      "        [29.8687, 24.8372],\n",
      "        [24.7236, 29.7135],\n",
      "        [27.4831, 27.4762]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9921, 0.3185, 0.0751, 0.9482], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6637, 29.6614],\n",
      "        [29.8643, 24.8450],\n",
      "        [24.7228, 29.7157],\n",
      "        [27.4826, 27.4782]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9921, 0.3185, 0.0751, 0.9482], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6652, 29.6611],\n",
      "        [29.8728, 24.8406],\n",
      "        [24.7252, 29.7149],\n",
      "        [27.4846, 27.4776]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9921, 0.3204, 0.0751, 0.9483], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6648, 29.6624],\n",
      "        [29.8684, 24.8485],\n",
      "        [24.7243, 29.7171],\n",
      "        [27.4841, 27.4796]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9921, 0.3204, 0.0751, 0.9483], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6663, 29.6621],\n",
      "        [29.8770, 24.8441],\n",
      "        [24.7267, 29.7163],\n",
      "        [27.4862, 27.4791]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9921, 0.3223, 0.0752, 0.9484], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6659, 29.6635],\n",
      "        [29.8725, 24.8520],\n",
      "        [24.7258, 29.7185],\n",
      "        [27.4856, 27.4810]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9921, 0.3223, 0.0752, 0.9484], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6674, 29.6631],\n",
      "        [29.8812, 24.8477],\n",
      "        [24.7282, 29.7177],\n",
      "        [27.4877, 27.4805]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9921, 0.3242, 0.0752, 0.9485], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6670, 29.6645],\n",
      "        [29.8767, 24.8556],\n",
      "        [24.7274, 29.7199],\n",
      "        [27.4871, 27.4824]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9921, 0.3242, 0.0752, 0.9485], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6685, 29.6642],\n",
      "        [29.8855, 24.8512],\n",
      "        [24.7298, 29.7191],\n",
      "        [27.4892, 27.4819]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9922, 0.3261, 0.0753, 0.9486], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6681, 29.6655],\n",
      "        [29.8810, 24.8593],\n",
      "        [24.7289, 29.7213],\n",
      "        [27.4886, 27.4838]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9922, 0.3261, 0.0753, 0.9486], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6695, 29.6652],\n",
      "        [29.8898, 24.8548],\n",
      "        [24.7313, 29.7205],\n",
      "        [27.4907, 27.4833]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9922, 0.3280, 0.0753, 0.9486], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6692, 29.6666],\n",
      "        [29.8853, 24.8629],\n",
      "        [24.7304, 29.7227],\n",
      "        [27.4901, 27.4852]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9922, 0.3280, 0.0753, 0.9486], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6706, 29.6662],\n",
      "        [29.8942, 24.8584],\n",
      "        [24.7329, 29.7219],\n",
      "        [27.4922, 27.4847]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9922, 0.3300, 0.0753, 0.9487], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6703, 29.6676],\n",
      "        [29.8896, 24.8666],\n",
      "        [24.7320, 29.7241],\n",
      "        [27.4916, 27.4867]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9922, 0.3300, 0.0753, 0.9487], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6717, 29.6672],\n",
      "        [29.8987, 24.8621],\n",
      "        [24.7344, 29.7233],\n",
      "        [27.4937, 27.4861]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9922, 0.3320, 0.0754, 0.9488], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6714, 29.6686],\n",
      "        [29.8941, 24.8704],\n",
      "        [24.7335, 29.7255],\n",
      "        [27.4931, 27.4881]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9922, 0.3320, 0.0754, 0.9488], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6728, 29.6683],\n",
      "        [29.9032, 24.8658],\n",
      "        [24.7360, 29.7247],\n",
      "        [27.4952, 27.4875]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9922, 0.3340, 0.0754, 0.9489], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6724, 29.6696],\n",
      "        [29.8985, 24.8741],\n",
      "        [24.7351, 29.7269],\n",
      "        [27.4946, 27.4895]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9922, 0.3340, 0.0754, 0.9489], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6739, 29.6693],\n",
      "        [29.9077, 24.8696],\n",
      "        [24.7375, 29.7261],\n",
      "        [27.4967, 27.4889]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9923, 0.3360, 0.0755, 0.9490], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6735, 29.6706],\n",
      "        [29.9031, 24.8780],\n",
      "        [24.7366, 29.7283],\n",
      "        [27.4961, 27.4909]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9923, 0.3360, 0.0755, 0.9490], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6750, 29.6703],\n",
      "        [29.9123, 24.8734],\n",
      "        [24.7391, 29.7275],\n",
      "        [27.4982, 27.4903]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9923, 0.3380, 0.0755, 0.9491], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6746, 29.6716],\n",
      "        [29.9076, 24.8818],\n",
      "        [24.7382, 29.7297],\n",
      "        [27.4976, 27.4923]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9923, 0.3380, 0.0755, 0.9491], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6761, 29.6713],\n",
      "        [29.9170, 24.8772],\n",
      "        [24.7406, 29.7289],\n",
      "        [27.4997, 27.4917]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9923, 0.3401, 0.0756, 0.9492], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6757, 29.6727],\n",
      "        [29.9123, 24.8857],\n",
      "        [24.7397, 29.7311],\n",
      "        [27.4991, 27.4937]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9923, 0.3401, 0.0756, 0.9492], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6771, 29.6723],\n",
      "        [29.9217, 24.8811],\n",
      "        [24.7422, 29.7303],\n",
      "        [27.5012, 27.4931]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9923, 0.3421, 0.0756, 0.9493], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6768, 29.6737],\n",
      "        [29.9170, 24.8897],\n",
      "        [24.7413, 29.7326],\n",
      "        [27.5006, 27.4951]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9923, 0.3421, 0.0756, 0.9493], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6782, 29.6733],\n",
      "        [29.9265, 24.8850],\n",
      "        [24.7438, 29.7317],\n",
      "        [27.5027, 27.4945]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9923, 0.3442, 0.0757, 0.9493], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6778, 29.6747],\n",
      "        [29.9218, 24.8937],\n",
      "        [24.7428, 29.7340],\n",
      "        [27.5021, 27.4965]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9923, 0.3442, 0.0757, 0.9493], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6793, 29.6744],\n",
      "        [29.9314, 24.8890],\n",
      "        [24.7453, 29.7331],\n",
      "        [27.5042, 27.4959]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9924, 0.3463, 0.0757, 0.9494], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6789, 29.6757],\n",
      "        [29.9266, 24.8977],\n",
      "        [24.7444, 29.7354],\n",
      "        [27.5036, 27.4978]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9924, 0.3463, 0.0757, 0.9494], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6804, 29.6754],\n",
      "        [29.9363, 24.8930],\n",
      "        [24.7469, 29.7345],\n",
      "        [27.5057, 27.4973]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9924, 0.3485, 0.0757, 0.9495], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6800, 29.6767],\n",
      "        [29.9315, 24.9018],\n",
      "        [24.7460, 29.7368],\n",
      "        [27.5051, 27.4992]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9924, 0.3485, 0.0757, 0.9495], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6815, 29.6763],\n",
      "        [29.9413, 24.8971],\n",
      "        [24.7485, 29.7359],\n",
      "        [27.5072, 27.4987]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9924, 0.3506, 0.0758, 0.9496], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6811, 29.6777],\n",
      "        [29.9364, 24.9059],\n",
      "        [24.7476, 29.7382],\n",
      "        [27.5066, 27.5006]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9924, 0.3506, 0.0758, 0.9496], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6825, 29.6774],\n",
      "        [29.9464, 24.9012],\n",
      "        [24.7501, 29.7373],\n",
      "        [27.5087, 27.5001]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9924, 0.3528, 0.0758, 0.9497], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6821, 29.6787],\n",
      "        [29.9414, 24.9101],\n",
      "        [24.7491, 29.7396],\n",
      "        [27.5081, 27.5020]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9924, 0.3528, 0.0758, 0.9497], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6836, 29.6784],\n",
      "        [29.9515, 24.9053],\n",
      "        [24.7517, 29.7387],\n",
      "        [27.5102, 27.5015]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9924, 0.3549, 0.0759, 0.9498], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6832, 29.6797],\n",
      "        [29.9465, 24.9143],\n",
      "        [24.7507, 29.7410],\n",
      "        [27.5096, 27.5034]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9924, 0.3549, 0.0759, 0.9498], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6847, 29.6794],\n",
      "        [29.9566, 24.9095],\n",
      "        [24.7533, 29.7401],\n",
      "        [27.5117, 27.5028]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9924, 0.3571, 0.0759, 0.9498], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6843, 29.6807],\n",
      "        [29.9517, 24.9186],\n",
      "        [24.7523, 29.7424],\n",
      "        [27.5111, 27.5048]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9924, 0.3571, 0.0759, 0.9498], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6858, 29.6804],\n",
      "        [29.9619, 24.9138],\n",
      "        [24.7549, 29.7416],\n",
      "        [27.5132, 27.5042]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9925, 0.3593, 0.0760, 0.9499], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6854, 29.6817],\n",
      "        [29.9569, 24.9229],\n",
      "        [24.7539, 29.7439],\n",
      "        [27.5126, 27.5061]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9925, 0.3593, 0.0760, 0.9499], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6869, 29.6814],\n",
      "        [29.9672, 24.9180],\n",
      "        [24.7565, 29.7430],\n",
      "        [27.5147, 27.5056]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9925, 0.3616, 0.0760, 0.9500], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6865, 29.6827],\n",
      "        [29.9622, 24.9272],\n",
      "        [24.7555, 29.7453],\n",
      "        [27.5140, 27.5075]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9925, 0.3616, 0.0760, 0.9500], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6879, 29.6824],\n",
      "        [29.9726, 24.9224],\n",
      "        [24.7581, 29.7444],\n",
      "        [27.5162, 27.5070]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9925, 0.3638, 0.0761, 0.9501], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6875, 29.6837],\n",
      "        [29.9676, 24.9317],\n",
      "        [24.7571, 29.7467],\n",
      "        [27.5156, 27.5089]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9925, 0.3638, 0.0761, 0.9501], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6890, 29.6833],\n",
      "        [29.9781, 24.9268],\n",
      "        [24.7597, 29.7458],\n",
      "        [27.5177, 27.5083]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9925, 0.3661, 0.0761, 0.9502], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6886, 29.6847],\n",
      "        [29.9730, 24.9361],\n",
      "        [24.7588, 29.7481],\n",
      "        [27.5171, 27.5103]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9925, 0.3661, 0.0761, 0.9502], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6901, 29.6843],\n",
      "        [29.9836, 24.9312],\n",
      "        [24.7613, 29.7473],\n",
      "        [27.5192, 27.5097]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9925, 0.3684, 0.0762, 0.9502], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6897, 29.6857],\n",
      "        [29.9785, 24.9406],\n",
      "        [24.7604, 29.7496],\n",
      "        [27.5186, 27.5117]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9925, 0.3684, 0.0762, 0.9502], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6912, 29.6853],\n",
      "        [29.9892, 24.9357],\n",
      "        [24.7630, 29.7487],\n",
      "        [27.5207, 27.5111]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9926, 0.3707, 0.0762, 0.9503], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6908, 29.6867],\n",
      "        [29.9841, 24.9452],\n",
      "        [24.7620, 29.7510],\n",
      "        [27.5200, 27.5130]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9926, 0.3707, 0.0762, 0.9503], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6923, 29.6863],\n",
      "        [29.9949, 24.9403],\n",
      "        [24.7646, 29.7501],\n",
      "        [27.5222, 27.5125]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9926, 0.3730, 0.0763, 0.9504], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6919, 29.6877],\n",
      "        [29.9897, 24.9498],\n",
      "        [24.7637, 29.7524],\n",
      "        [27.5216, 27.5144]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9926, 0.3730, 0.0763, 0.9504], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6933, 29.6873],\n",
      "        [30.0007, 24.9448],\n",
      "        [24.7663, 29.7515],\n",
      "        [27.5237, 27.5138]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9926, 0.3753, 0.0763, 0.9505], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6929, 29.6887],\n",
      "        [29.9955, 24.9545],\n",
      "        [24.7653, 29.7539],\n",
      "        [27.5231, 27.5158]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9926, 0.3753, 0.0763, 0.9505], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6944, 29.6883],\n",
      "        [30.0065, 24.9495],\n",
      "        [24.7679, 29.7530],\n",
      "        [27.5252, 27.5152]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9926, 0.3777, 0.0763, 0.9506], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6940, 29.6896],\n",
      "        [30.0013, 24.9592],\n",
      "        [24.7669, 29.7553],\n",
      "        [27.5246, 27.5171]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9926, 0.3777, 0.0763, 0.9506], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6955, 29.6893],\n",
      "        [30.0124, 24.9542],\n",
      "        [24.7696, 29.7544],\n",
      "        [27.5267, 27.5166]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9926, 0.3801, 0.0764, 0.9506], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6951, 29.6907],\n",
      "        [30.0072, 24.9640],\n",
      "        [24.7686, 29.7568],\n",
      "        [27.5261, 27.5185]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9926, 0.3801, 0.0764, 0.9506], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6966, 29.6903],\n",
      "        [30.0184, 24.9590],\n",
      "        [24.7713, 29.7558],\n",
      "        [27.5282, 27.5179]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9926, 0.3825, 0.0764, 0.9507], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6962, 29.6916],\n",
      "        [30.0131, 24.9688],\n",
      "        [24.7703, 29.7582],\n",
      "        [27.5276, 27.5199]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9926, 0.3825, 0.0764, 0.9507], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6977, 29.6913],\n",
      "        [30.0245, 24.9638],\n",
      "        [24.7729, 29.7573],\n",
      "        [27.5297, 27.5193]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9927, 0.3849, 0.0765, 0.9508], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6972, 29.6926],\n",
      "        [30.0192, 24.9737],\n",
      "        [24.7719, 29.7596],\n",
      "        [27.5291, 27.5212]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9927, 0.3849, 0.0765, 0.9508], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6987, 29.6922],\n",
      "        [30.0306, 24.9686],\n",
      "        [24.7746, 29.7587],\n",
      "        [27.5312, 27.5207]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9927, 0.3873, 0.0765, 0.9509], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6983, 29.6936],\n",
      "        [30.0253, 24.9786],\n",
      "        [24.7736, 29.7611],\n",
      "        [27.5306, 27.5226]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9927, 0.3873, 0.0765, 0.9509], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.6998, 29.6932],\n",
      "        [30.0368, 24.9736],\n",
      "        [24.7763, 29.7602],\n",
      "        [27.5327, 27.5220]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9927, 0.3898, 0.0766, 0.9509], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.6994, 29.6946],\n",
      "        [30.0315, 24.9836],\n",
      "        [24.7753, 29.7626],\n",
      "        [27.5321, 27.5240]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9927, 0.3898, 0.0766, 0.9509], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7009, 29.6942],\n",
      "        [30.0431, 24.9785],\n",
      "        [24.7780, 29.7616],\n",
      "        [27.5343, 27.5234]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9927, 0.3922, 0.0766, 0.9510], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7005, 29.6956],\n",
      "        [30.0378, 24.9887],\n",
      "        [24.7770, 29.7640],\n",
      "        [27.5336, 27.5253]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9927, 0.3922, 0.0766, 0.9510], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7020, 29.6952],\n",
      "        [30.0495, 24.9836],\n",
      "        [24.7797, 29.7631],\n",
      "        [27.5358, 27.5248]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9927, 0.3947, 0.0767, 0.9511], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7016, 29.6966],\n",
      "        [30.0441, 24.9938],\n",
      "        [24.7787, 29.7655],\n",
      "        [27.5352, 27.5267]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9927, 0.3947, 0.0767, 0.9511], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7031, 29.6962],\n",
      "        [30.0560, 24.9887],\n",
      "        [24.7814, 29.7645],\n",
      "        [27.5373, 27.5261]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9927, 0.3972, 0.0767, 0.9512], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7027, 29.6975],\n",
      "        [30.0506, 24.9990],\n",
      "        [24.7804, 29.7669],\n",
      "        [27.5367, 27.5280]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9927, 0.3972, 0.0767, 0.9512], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7042, 29.6972],\n",
      "        [30.0626, 24.9938],\n",
      "        [24.7831, 29.7660],\n",
      "        [27.5388, 27.5275]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9928, 0.3997, 0.0768, 0.9512], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7038, 29.6985],\n",
      "        [30.0571, 25.0042],\n",
      "        [24.7821, 29.7684],\n",
      "        [27.5382, 27.5294]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9928, 0.3997, 0.0768, 0.9512], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7053, 29.6982],\n",
      "        [30.0692, 24.9990],\n",
      "        [24.7849, 29.7675],\n",
      "        [27.5404, 27.5288]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9928, 0.4023, 0.0768, 0.9513], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7049, 29.6995],\n",
      "        [30.0637, 25.0095],\n",
      "        [24.7838, 29.7699],\n",
      "        [27.5397, 27.5308]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9928, 0.4023, 0.0768, 0.9513], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7064, 29.6991],\n",
      "        [30.0759, 25.0043],\n",
      "        [24.7866, 29.7689],\n",
      "        [27.5419, 27.5302]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9928, 0.4049, 0.0769, 0.9514], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7059, 29.7005],\n",
      "        [30.0704, 25.0148],\n",
      "        [24.7856, 29.7713],\n",
      "        [27.5412, 27.5321]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9928, 0.4049, 0.0769, 0.9514], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7075, 29.7001],\n",
      "        [30.0827, 25.0096],\n",
      "        [24.7883, 29.7704],\n",
      "        [27.5434, 27.5316]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9928, 0.4074, 0.0769, 0.9514], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7070, 29.7015],\n",
      "        [30.0772, 25.0202],\n",
      "        [24.7873, 29.7728],\n",
      "        [27.5428, 27.5335]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9928, 0.4074, 0.0769, 0.9514], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7086, 29.7011],\n",
      "        [30.0896, 25.0150],\n",
      "        [24.7901, 29.7719],\n",
      "        [27.5449, 27.5329]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9928, 0.4100, 0.0770, 0.9515], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7081, 29.7024],\n",
      "        [30.0841, 25.0257],\n",
      "        [24.7891, 29.7743],\n",
      "        [27.5443, 27.5348]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9928, 0.4100, 0.0770, 0.9515], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7097, 29.7021],\n",
      "        [30.0966, 25.0205],\n",
      "        [24.7919, 29.7734],\n",
      "        [27.5465, 27.5343]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9928, 0.4126, 0.0770, 0.9516], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7092, 29.7034],\n",
      "        [30.0910, 25.0312],\n",
      "        [24.7908, 29.7758],\n",
      "        [27.5458, 27.5362]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9928, 0.4126, 0.0770, 0.9516], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7107, 29.7031],\n",
      "        [30.1036, 25.0260],\n",
      "        [24.7936, 29.7749],\n",
      "        [27.5480, 27.5356]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9929, 0.4153, 0.0771, 0.9517], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7103, 29.7044],\n",
      "        [30.0981, 25.0368],\n",
      "        [24.7926, 29.7773],\n",
      "        [27.5473, 27.5375]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9929, 0.4153, 0.0771, 0.9517], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7118, 29.7040],\n",
      "        [30.1108, 25.0316],\n",
      "        [24.7954, 29.7763],\n",
      "        [27.5495, 27.5370]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9929, 0.4179, 0.0771, 0.9517], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7114, 29.7054],\n",
      "        [30.1052, 25.0424],\n",
      "        [24.7944, 29.7788],\n",
      "        [27.5489, 27.5389]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9929, 0.4179, 0.0771, 0.9517], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7129, 29.7050],\n",
      "        [30.1180, 25.0372],\n",
      "        [24.7972, 29.7778],\n",
      "        [27.5511, 27.5383]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9929, 0.4206, 0.0772, 0.9518], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7125, 29.7063],\n",
      "        [30.1124, 25.0482],\n",
      "        [24.7962, 29.7803],\n",
      "        [27.5504, 27.5403]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9929, 0.4206, 0.0772, 0.9518], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7140, 29.7060],\n",
      "        [30.1253, 25.0429],\n",
      "        [24.7990, 29.7793],\n",
      "        [27.5526, 27.5397]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9929, 0.4233, 0.0772, 0.9519], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7136, 29.7073],\n",
      "        [30.1197, 25.0539],\n",
      "        [24.7979, 29.7818],\n",
      "        [27.5520, 27.5416]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9929, 0.4233, 0.0772, 0.9519], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7151, 29.7070],\n",
      "        [30.1328, 25.0487],\n",
      "        [24.8008, 29.7808],\n",
      "        [27.5542, 27.5411]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9929, 0.4260, 0.0773, 0.9519], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7147, 29.7083],\n",
      "        [30.1271, 25.0598],\n",
      "        [24.7998, 29.7833],\n",
      "        [27.5535, 27.5430]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9929, 0.4260, 0.0773, 0.9519], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7162, 29.7079],\n",
      "        [30.1403, 25.0545],\n",
      "        [24.8026, 29.7824],\n",
      "        [27.5557, 27.5424]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9929, 0.4287, 0.0773, 0.9520], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7158, 29.7093],\n",
      "        [30.1346, 25.0657],\n",
      "        [24.8016, 29.7848],\n",
      "        [27.5550, 27.5443]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9929, 0.4287, 0.0773, 0.9520], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7173, 29.7089],\n",
      "        [30.1479, 25.0604],\n",
      "        [24.8044, 29.7839],\n",
      "        [27.5573, 27.5438]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9930, 0.4314, 0.0774, 0.9521], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7169, 29.7102],\n",
      "        [30.1421, 25.0716],\n",
      "        [24.8034, 29.7863],\n",
      "        [27.5566, 27.5457]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9930, 0.4314, 0.0774, 0.9521], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7184, 29.7099],\n",
      "        [30.1555, 25.0664],\n",
      "        [24.8062, 29.7854],\n",
      "        [27.5588, 27.5451]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9930, 0.4342, 0.0774, 0.9521], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7180, 29.7112],\n",
      "        [30.1498, 25.0777],\n",
      "        [24.8052, 29.7878],\n",
      "        [27.5582, 27.5471]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9930, 0.4342, 0.0774, 0.9521], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7195, 29.7109],\n",
      "        [30.1633, 25.0724],\n",
      "        [24.8081, 29.7869],\n",
      "        [27.5604, 27.5465]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9930, 0.4370, 0.0775, 0.9522], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7191, 29.7122],\n",
      "        [30.1575, 25.0837],\n",
      "        [24.8070, 29.7893],\n",
      "        [27.5597, 27.5484]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9930, 0.4370, 0.0775, 0.9522], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7207, 29.7118],\n",
      "        [30.1712, 25.0785],\n",
      "        [24.8100, 29.7884],\n",
      "        [27.5619, 27.5479]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9930, 0.4397, 0.0775, 0.9523], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7202, 29.7132],\n",
      "        [30.1654, 25.0899],\n",
      "        [24.8089, 29.7909],\n",
      "        [27.5613, 27.5498]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9930, 0.4397, 0.0775, 0.9523], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7217, 29.7128],\n",
      "        [30.1791, 25.0846],\n",
      "        [24.8118, 29.7899],\n",
      "        [27.5635, 27.5492]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9930, 0.4425, 0.0776, 0.9523], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7213, 29.7141],\n",
      "        [30.1733, 25.0961],\n",
      "        [24.8108, 29.7924],\n",
      "        [27.5628, 27.5511]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9930, 0.4425, 0.0776, 0.9523], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7229, 29.7138],\n",
      "        [30.1871, 25.0908],\n",
      "        [24.8137, 29.7915],\n",
      "        [27.5651, 27.5506]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9930, 0.4454, 0.0777, 0.9524], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7224, 29.7151],\n",
      "        [30.1813, 25.1024],\n",
      "        [24.8126, 29.7939],\n",
      "        [27.5644, 27.5525]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9930, 0.4454, 0.0777, 0.9524], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7240, 29.7148],\n",
      "        [30.1952, 25.0971],\n",
      "        [24.8156, 29.7930],\n",
      "        [27.5666, 27.5519]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9931, 0.4482, 0.0777, 0.9525], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7235, 29.7161],\n",
      "        [30.1894, 25.1087],\n",
      "        [24.8145, 29.7955],\n",
      "        [27.5659, 27.5538]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9931, 0.4482, 0.0777, 0.9525], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7251, 29.7157],\n",
      "        [30.2034, 25.1035],\n",
      "        [24.8174, 29.7946],\n",
      "        [27.5682, 27.5533]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9931, 0.4510, 0.0778, 0.9525], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7246, 29.7171],\n",
      "        [30.1976, 25.1151],\n",
      "        [24.8164, 29.7970],\n",
      "        [27.5675, 27.5552]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9931, 0.4510, 0.0778, 0.9525], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7262, 29.7167],\n",
      "        [30.2117, 25.1099],\n",
      "        [24.8193, 29.7961],\n",
      "        [27.5698, 27.5546]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9931, 0.4539, 0.0778, 0.9526], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7257, 29.7180],\n",
      "        [30.2059, 25.1216],\n",
      "        [24.8183, 29.7986],\n",
      "        [27.5691, 27.5565]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9931, 0.4539, 0.0778, 0.9526], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7273, 29.7177],\n",
      "        [30.2201, 25.1163],\n",
      "        [24.8212, 29.7977],\n",
      "        [27.5713, 27.5560]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9931, 0.4568, 0.0779, 0.9526], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7269, 29.7190],\n",
      "        [30.2142, 25.1281],\n",
      "        [24.8202, 29.8001],\n",
      "        [27.5707, 27.5579]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9931, 0.4568, 0.0779, 0.9526], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7284, 29.7187],\n",
      "        [30.2286, 25.1229],\n",
      "        [24.8232, 29.7992],\n",
      "        [27.5729, 27.5573]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9931, 0.4597, 0.0779, 0.9527], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7280, 29.7200],\n",
      "        [30.2227, 25.1347],\n",
      "        [24.8221, 29.8017],\n",
      "        [27.5722, 27.5592]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9931, 0.4597, 0.0779, 0.9527], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7295, 29.7196],\n",
      "        [30.2371, 25.1295],\n",
      "        [24.8251, 29.8008],\n",
      "        [27.5745, 27.5587]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9931, 0.4626, 0.0780, 0.9528], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7291, 29.7209],\n",
      "        [30.2312, 25.1413],\n",
      "        [24.8240, 29.8033],\n",
      "        [27.5738, 27.5606]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9931, 0.4626, 0.0780, 0.9528], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7307, 29.7206],\n",
      "        [30.2457, 25.1361],\n",
      "        [24.8270, 29.8023],\n",
      "        [27.5761, 27.5601]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9931, 0.4655, 0.0780, 0.9528], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7302, 29.7219],\n",
      "        [30.2398, 25.1480],\n",
      "        [24.8259, 29.8048],\n",
      "        [27.5754, 27.5620]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9931, 0.4655, 0.0780, 0.9528], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7318, 29.7216],\n",
      "        [30.2544, 25.1428],\n",
      "        [24.8289, 29.8039],\n",
      "        [27.5776, 27.5614]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9932, 0.4684, 0.0781, 0.9529], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7313, 29.7229],\n",
      "        [30.2485, 25.1548],\n",
      "        [24.8279, 29.8064],\n",
      "        [27.5769, 27.5633]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9932, 0.4684, 0.0781, 0.9529], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7329, 29.7225],\n",
      "        [30.2632, 25.1496],\n",
      "        [24.8309, 29.8055],\n",
      "        [27.5792, 27.5628]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9932, 0.4713, 0.0781, 0.9530], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7325, 29.7239],\n",
      "        [30.2573, 25.1616],\n",
      "        [24.8298, 29.8080],\n",
      "        [27.5785, 27.5647]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9932, 0.4713, 0.0781, 0.9530], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7340, 29.7235],\n",
      "        [30.2721, 25.1565],\n",
      "        [24.8328, 29.8071],\n",
      "        [27.5808, 27.5641]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9932, 0.4743, 0.0782, 0.9530], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7336, 29.7248],\n",
      "        [30.2662, 25.1685],\n",
      "        [24.8318, 29.8096],\n",
      "        [27.5801, 27.5660]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9932, 0.4743, 0.0782, 0.9530], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7351, 29.7245],\n",
      "        [30.2811, 25.1634],\n",
      "        [24.8348, 29.8086],\n",
      "        [27.5824, 27.5655]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9932, 0.4773, 0.0782, 0.9531], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7347, 29.7258],\n",
      "        [30.2751, 25.1755],\n",
      "        [24.8337, 29.8112],\n",
      "        [27.5817, 27.5674]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9932, 0.4773, 0.0782, 0.9531], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7363, 29.7255],\n",
      "        [30.2901, 25.1703],\n",
      "        [24.8368, 29.8102],\n",
      "        [27.5840, 27.5668]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9932, 0.4802, 0.0783, 0.9531], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7358, 29.7268],\n",
      "        [30.2842, 25.1825],\n",
      "        [24.8357, 29.8127],\n",
      "        [27.5833, 27.5687]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9932, 0.4802, 0.0783, 0.9531], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7374, 29.7264],\n",
      "        [30.2992, 25.1774],\n",
      "        [24.8388, 29.8118],\n",
      "        [27.5855, 27.5682]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9932, 0.4832, 0.0784, 0.9532], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7369, 29.7277],\n",
      "        [30.2933, 25.1896],\n",
      "        [24.8377, 29.8143],\n",
      "        [27.5849, 27.5701]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9932, 0.4832, 0.0784, 0.9532], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7385, 29.7274],\n",
      "        [30.3084, 25.1845],\n",
      "        [24.8407, 29.8134],\n",
      "        [27.5871, 27.5695]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9933, 0.4862, 0.0784, 0.9532], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7381, 29.7287],\n",
      "        [30.3024, 25.1967],\n",
      "        [24.8397, 29.8159],\n",
      "        [27.5865, 27.5714]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9933, 0.4862, 0.0784, 0.9532], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7396, 29.7284],\n",
      "        [30.3177, 25.1916],\n",
      "        [24.8427, 29.8150],\n",
      "        [27.5887, 27.5709]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9933, 0.4892, 0.0785, 0.9533], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7392, 29.7297],\n",
      "        [30.3117, 25.2039],\n",
      "        [24.8416, 29.8175],\n",
      "        [27.5880, 27.5728]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9933, 0.4892, 0.0785, 0.9533], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7408, 29.7293],\n",
      "        [30.3270, 25.1988],\n",
      "        [24.8447, 29.8166],\n",
      "        [27.5903, 27.5723]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9933, 0.4922, 0.0785, 0.9534], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7403, 29.7306],\n",
      "        [30.3210, 25.2111],\n",
      "        [24.8436, 29.8191],\n",
      "        [27.5896, 27.5741]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9933, 0.4922, 0.0785, 0.9534], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7419, 29.7303],\n",
      "        [30.3364, 25.2061],\n",
      "        [24.8468, 29.8182],\n",
      "        [27.5919, 27.5736]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9933, 0.4953, 0.0786, 0.9534], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7414, 29.7316],\n",
      "        [30.3304, 25.2184],\n",
      "        [24.8457, 29.8207],\n",
      "        [27.5912, 27.5755]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9933, 0.4953, 0.0786, 0.9534], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7430, 29.7313],\n",
      "        [30.3459, 25.2134],\n",
      "        [24.8488, 29.8198],\n",
      "        [27.5935, 27.5750]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9933, 0.4983, 0.0786, 0.9535], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7426, 29.7326],\n",
      "        [30.3399, 25.2258],\n",
      "        [24.8477, 29.8223],\n",
      "        [27.5928, 27.5768]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9933, 0.4983, 0.0786, 0.9535], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7441, 29.7323],\n",
      "        [30.3555, 25.2208],\n",
      "        [24.8508, 29.8215],\n",
      "        [27.5951, 27.5763]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9933, 0.5014, 0.0787, 0.9535], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7437, 29.7335],\n",
      "        [30.3495, 25.2332],\n",
      "        [24.8497, 29.8240],\n",
      "        [27.5944, 27.5782]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9933, 0.5014, 0.0787, 0.9535], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7453, 29.7332],\n",
      "        [30.3651, 25.2282],\n",
      "        [24.8528, 29.8231],\n",
      "        [27.5967, 27.5777]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9933, 0.5044, 0.0787, 0.9536], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7448, 29.7345],\n",
      "        [30.3591, 25.2407],\n",
      "        [24.8517, 29.8256],\n",
      "        [27.5960, 27.5795]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9933, 0.5044, 0.0787, 0.9536], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7464, 29.7342],\n",
      "        [30.3748, 25.2357],\n",
      "        [24.8548, 29.8247],\n",
      "        [27.5983, 27.5790]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9934, 0.5075, 0.0788, 0.9536], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7459, 29.7355],\n",
      "        [30.3688, 25.2482],\n",
      "        [24.8538, 29.8272],\n",
      "        [27.5976, 27.5809]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9934, 0.5075, 0.0788, 0.9536], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7475, 29.7352],\n",
      "        [30.3845, 25.2432],\n",
      "        [24.8569, 29.8263],\n",
      "        [27.5999, 27.5804]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9934, 0.5105, 0.0789, 0.9537], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7471, 29.7364],\n",
      "        [30.3785, 25.2558],\n",
      "        [24.8558, 29.8288],\n",
      "        [27.5992, 27.5822]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9934, 0.5105, 0.0789, 0.9537], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7486, 29.7361],\n",
      "        [30.3943, 25.2508],\n",
      "        [24.8589, 29.8279],\n",
      "        [27.6015, 27.5817]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9934, 0.5136, 0.0789, 0.9537], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7482, 29.7374],\n",
      "        [30.3883, 25.2634],\n",
      "        [24.8578, 29.8304],\n",
      "        [27.6008, 27.5836]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9934, 0.5136, 0.0789, 0.9537], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7497, 29.7371],\n",
      "        [30.4042, 25.2585],\n",
      "        [24.8610, 29.8296],\n",
      "        [27.6031, 27.5831]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9934, 0.5167, 0.0790, 0.9538], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7493, 29.7383],\n",
      "        [30.3982, 25.2710],\n",
      "        [24.8599, 29.8321],\n",
      "        [27.6024, 27.5849]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9934, 0.5167, 0.0790, 0.9538], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7509, 29.7380],\n",
      "        [30.4141, 25.2662],\n",
      "        [24.8630, 29.8312],\n",
      "        [27.6047, 27.5844]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9934, 0.5198, 0.0790, 0.9538], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7504, 29.7393],\n",
      "        [30.4081, 25.2788],\n",
      "        [24.8619, 29.8337],\n",
      "        [27.6040, 27.5862]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9934, 0.5198, 0.0790, 0.9538], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7520, 29.7390],\n",
      "        [30.4241, 25.2739],\n",
      "        [24.8651, 29.8329],\n",
      "        [27.6063, 27.5858]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9934, 0.5228, 0.0791, 0.9539], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7515, 29.7403],\n",
      "        [30.4181, 25.2865],\n",
      "        [24.8640, 29.8353],\n",
      "        [27.6056, 27.5876]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9934, 0.5228, 0.0791, 0.9539], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7531, 29.7400],\n",
      "        [30.4341, 25.2817],\n",
      "        [24.8672, 29.8345],\n",
      "        [27.6079, 27.5871]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9934, 0.5259, 0.0791, 0.9539], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7527, 29.7412],\n",
      "        [30.4282, 25.2943],\n",
      "        [24.8661, 29.8370],\n",
      "        [27.6072, 27.5889]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9934, 0.5259, 0.0791, 0.9539], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7542, 29.7409],\n",
      "        [30.4442, 25.2896],\n",
      "        [24.8692, 29.8361],\n",
      "        [27.6095, 27.5885]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9935, 0.5290, 0.0792, 0.9540], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7538, 29.7422],\n",
      "        [30.4383, 25.3022],\n",
      "        [24.8681, 29.8386],\n",
      "        [27.6088, 27.5903]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9935, 0.5290, 0.0792, 0.9540], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7554, 29.7419],\n",
      "        [30.4544, 25.2974],\n",
      "        [24.8713, 29.8378],\n",
      "        [27.6110, 27.5898]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9935, 0.5321, 0.0793, 0.9540], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7549, 29.7431],\n",
      "        [30.4484, 25.3101],\n",
      "        [24.8702, 29.8403],\n",
      "        [27.6103, 27.5916]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9935, 0.5321, 0.0793, 0.9540], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7565, 29.7428],\n",
      "        [30.4646, 25.3054],\n",
      "        [24.8734, 29.8394],\n",
      "        [27.6126, 27.5911]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9935, 0.5352, 0.0793, 0.9541], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7560, 29.7441],\n",
      "        [30.4586, 25.3180],\n",
      "        [24.8723, 29.8419],\n",
      "        [27.6119, 27.5929]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9935, 0.5352, 0.0793, 0.9541], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7576, 29.7438],\n",
      "        [30.4748, 25.3133],\n",
      "        [24.8754, 29.8411],\n",
      "        [27.6142, 27.5925]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9935, 0.5383, 0.0794, 0.9541], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7571, 29.7450],\n",
      "        [30.4688, 25.3260],\n",
      "        [24.8744, 29.8435],\n",
      "        [27.6135, 27.5943]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9935, 0.5383, 0.0794, 0.9541], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7587, 29.7448],\n",
      "        [30.4851, 25.3214],\n",
      "        [24.8775, 29.8427],\n",
      "        [27.6158, 27.5938]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9935, 0.5414, 0.0794, 0.9542], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7583, 29.7460],\n",
      "        [30.4791, 25.3340],\n",
      "        [24.8764, 29.8452],\n",
      "        [27.6151, 27.5956]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9935, 0.5414, 0.0794, 0.9542], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7598, 29.7457],\n",
      "        [30.4953, 25.3294],\n",
      "        [24.8796, 29.8444],\n",
      "        [27.6174, 27.5951]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9935, 0.5445, 0.0795, 0.9542], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7594, 29.7469],\n",
      "        [30.4894, 25.3420],\n",
      "        [24.8785, 29.8468],\n",
      "        [27.6167, 27.5969]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9935, 0.5445, 0.0795, 0.9542], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7609, 29.7466],\n",
      "        [30.5057, 25.3375],\n",
      "        [24.8817, 29.8460],\n",
      "        [27.6190, 27.5965]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9935, 0.5476, 0.0796, 0.9543], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7605, 29.7479],\n",
      "        [30.4997, 25.3501],\n",
      "        [24.8806, 29.8485],\n",
      "        [27.6183, 27.5983]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9935, 0.5476, 0.0796, 0.9543], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7620, 29.7476],\n",
      "        [30.5160, 25.3456],\n",
      "        [24.8838, 29.8477],\n",
      "        [27.6205, 27.5978]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9936, 0.5507, 0.0796, 0.9543], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7616, 29.7488],\n",
      "        [30.5101, 25.3582],\n",
      "        [24.8827, 29.8501],\n",
      "        [27.6199, 27.5996]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9936, 0.5507, 0.0796, 0.9543], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7631, 29.7485],\n",
      "        [30.5264, 25.3537],\n",
      "        [24.8859, 29.8493],\n",
      "        [27.6221, 27.5991]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9936, 0.5538, 0.0797, 0.9544], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7627, 29.7498],\n",
      "        [30.5205, 25.3664],\n",
      "        [24.8848, 29.8518],\n",
      "        [27.6214, 27.6009]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9936, 0.5538, 0.0797, 0.9544], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7643, 29.7495],\n",
      "        [30.5369, 25.3619],\n",
      "        [24.8880, 29.8510],\n",
      "        [27.6237, 27.6004]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9936, 0.5569, 0.0797, 0.9544], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7638, 29.7507],\n",
      "        [30.5310, 25.3746],\n",
      "        [24.8869, 29.8534],\n",
      "        [27.6230, 27.6022]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9936, 0.5569, 0.0797, 0.9544], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7654, 29.7504],\n",
      "        [30.5473, 25.3702],\n",
      "        [24.8901, 29.8526],\n",
      "        [27.6253, 27.6018]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9936, 0.5600, 0.0798, 0.9545], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7649, 29.7516],\n",
      "        [30.5414, 25.3828],\n",
      "        [24.8890, 29.8551],\n",
      "        [27.6246, 27.6035]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9936, 0.5600, 0.0798, 0.9545], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7665, 29.7514],\n",
      "        [30.5578, 25.3784],\n",
      "        [24.8921, 29.8543],\n",
      "        [27.6268, 27.6031]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9936, 0.5631, 0.0798, 0.9545], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7660, 29.7526],\n",
      "        [30.5519, 25.3910],\n",
      "        [24.8911, 29.8567],\n",
      "        [27.6262, 27.6048]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9936, 0.5631, 0.0798, 0.9545], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7676, 29.7523],\n",
      "        [30.5683, 25.3867],\n",
      "        [24.8942, 29.8559],\n",
      "        [27.6284, 27.6044]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9936, 0.5662, 0.0799, 0.9546], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7671, 29.7535],\n",
      "        [30.5624, 25.3993],\n",
      "        [24.8932, 29.8584],\n",
      "        [27.6277, 27.6062]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9936, 0.5662, 0.0799, 0.9546], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7687, 29.7532],\n",
      "        [30.5788, 25.3950],\n",
      "        [24.8963, 29.8576],\n",
      "        [27.6299, 27.6057]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9936, 0.5692, 0.0800, 0.9546], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7682, 29.7544],\n",
      "        [30.5729, 25.4076],\n",
      "        [24.8952, 29.8600],\n",
      "        [27.6293, 27.6074]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9936, 0.5692, 0.0800, 0.9546], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7698, 29.7542],\n",
      "        [30.5893, 25.4033],\n",
      "        [24.8984, 29.8592],\n",
      "        [27.6315, 27.6070]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9936, 0.5723, 0.0800, 0.9547], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7693, 29.7554],\n",
      "        [30.5835, 25.4159],\n",
      "        [24.8973, 29.8617],\n",
      "        [27.6308, 27.6088]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9936, 0.5723, 0.0800, 0.9547], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7708, 29.7551],\n",
      "        [30.5998, 25.4117],\n",
      "        [24.9005, 29.8609],\n",
      "        [27.6330, 27.6083]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9937, 0.5754, 0.0801, 0.9547], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7704, 29.7563],\n",
      "        [30.5940, 25.4242],\n",
      "        [24.8994, 29.8633],\n",
      "        [27.6324, 27.6100]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9937, 0.5754, 0.0801, 0.9547], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7719, 29.7560],\n",
      "        [30.6104, 25.4200],\n",
      "        [24.9026, 29.8625],\n",
      "        [27.6346, 27.6096]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9937, 0.5785, 0.0801, 0.9548], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7715, 29.7572],\n",
      "        [30.6046, 25.4325],\n",
      "        [24.9015, 29.8650],\n",
      "        [27.6339, 27.6114]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9937, 0.5785, 0.0801, 0.9548], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7730, 29.7570],\n",
      "        [30.6209, 25.4284],\n",
      "        [24.9046, 29.8642],\n",
      "        [27.6361, 27.6109]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9937, 0.5815, 0.0802, 0.9548], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7726, 29.7582],\n",
      "        [30.6151, 25.4409],\n",
      "        [24.9036, 29.8666],\n",
      "        [27.6355, 27.6126]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9937, 0.5815, 0.0802, 0.9548], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7741, 29.7579],\n",
      "        [30.6315, 25.4368],\n",
      "        [24.9067, 29.8658],\n",
      "        [27.6377, 27.6122]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9937, 0.5846, 0.0803, 0.9548], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7737, 29.7591],\n",
      "        [30.6257, 25.4492],\n",
      "        [24.9057, 29.8682],\n",
      "        [27.6370, 27.6139]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9937, 0.5846, 0.0803, 0.9548], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7752, 29.7588],\n",
      "        [30.6420, 25.4452],\n",
      "        [24.9088, 29.8675],\n",
      "        [27.6392, 27.6135]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9937, 0.5876, 0.0803, 0.9549], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7747, 29.7600],\n",
      "        [30.6362, 25.4576],\n",
      "        [24.9077, 29.8699],\n",
      "        [27.6385, 27.6152]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9937, 0.5876, 0.0803, 0.9549], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7762, 29.7597],\n",
      "        [30.6525, 25.4537],\n",
      "        [24.9109, 29.8691],\n",
      "        [27.6407, 27.6148]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9937, 0.5906, 0.0804, 0.9549], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7758, 29.7609],\n",
      "        [30.6468, 25.4660],\n",
      "        [24.9098, 29.8715],\n",
      "        [27.6401, 27.6165]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9937, 0.5906, 0.0804, 0.9549], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7773, 29.7607],\n",
      "        [30.6631, 25.4621],\n",
      "        [24.9129, 29.8708],\n",
      "        [27.6422, 27.6161]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9937, 0.5937, 0.0804, 0.9550], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7769, 29.7618],\n",
      "        [30.6573, 25.4744],\n",
      "        [24.9119, 29.8731],\n",
      "        [27.6416, 27.6177]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9937, 0.5937, 0.0804, 0.9550], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7784, 29.7615],\n",
      "        [30.6736, 25.4706],\n",
      "        [24.9150, 29.8724],\n",
      "        [27.6438, 27.6174]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9938, 0.5967, 0.0805, 0.9550], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7780, 29.7627],\n",
      "        [30.6679, 25.4829],\n",
      "        [24.9140, 29.8748],\n",
      "        [27.6431, 27.6190]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9938, 0.5967, 0.0805, 0.9550], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7794, 29.7625],\n",
      "        [30.6841, 25.4790],\n",
      "        [24.9171, 29.8741],\n",
      "        [27.6453, 27.6186]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9938, 0.5997, 0.0806, 0.9550], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7790, 29.7636],\n",
      "        [30.6784, 25.4913],\n",
      "        [24.9160, 29.8764],\n",
      "        [27.6446, 27.6203]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9938, 0.5997, 0.0806, 0.9550], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7805, 29.7634],\n",
      "        [30.6946, 25.4875],\n",
      "        [24.9191, 29.8757],\n",
      "        [27.6468, 27.6199]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9938, 0.6027, 0.0806, 0.9551], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7801, 29.7645],\n",
      "        [30.6889, 25.4997],\n",
      "        [24.9181, 29.8780],\n",
      "        [27.6461, 27.6216]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9938, 0.6027, 0.0806, 0.9551], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7815, 29.7643],\n",
      "        [30.7050, 25.4959],\n",
      "        [24.9212, 29.8773],\n",
      "        [27.6482, 27.6212]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9938, 0.6056, 0.0807, 0.9551], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7811, 29.7654],\n",
      "        [30.6994, 25.5081],\n",
      "        [24.9201, 29.8796],\n",
      "        [27.6476, 27.6228]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9938, 0.6056, 0.0807, 0.9551], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7826, 29.7652],\n",
      "        [30.7155, 25.5044],\n",
      "        [24.9232, 29.8789],\n",
      "        [27.6497, 27.6224]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9938, 0.6086, 0.0807, 0.9552], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7822, 29.7663],\n",
      "        [30.7098, 25.5165],\n",
      "        [24.9222, 29.8813],\n",
      "        [27.6491, 27.6241]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9938, 0.6086, 0.0807, 0.9552], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7836, 29.7661],\n",
      "        [30.7259, 25.5129],\n",
      "        [24.9252, 29.8806],\n",
      "        [27.6512, 27.6237]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9938, 0.6116, 0.0808, 0.9552], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7832, 29.7672],\n",
      "        [30.7203, 25.5249],\n",
      "        [24.9242, 29.8829],\n",
      "        [27.6506, 27.6253]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9938, 0.6116, 0.0808, 0.9552], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7847, 29.7670],\n",
      "        [30.7363, 25.5214],\n",
      "        [24.9273, 29.8822],\n",
      "        [27.6527, 27.6250]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9938, 0.6145, 0.0809, 0.9552], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7842, 29.7681],\n",
      "        [30.7307, 25.5333],\n",
      "        [24.9262, 29.8845],\n",
      "        [27.6520, 27.6265]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9938, 0.6145, 0.0809, 0.9552], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7857, 29.7678],\n",
      "        [30.7466, 25.5298],\n",
      "        [24.9293, 29.8838],\n",
      "        [27.6542, 27.6262]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9938, 0.6175, 0.0809, 0.9553], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7853, 29.7689],\n",
      "        [30.7411, 25.5418],\n",
      "        [24.9283, 29.8861],\n",
      "        [27.6535, 27.6278]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9938, 0.6175, 0.0809, 0.9553], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7867, 29.7687],\n",
      "        [30.7570, 25.5383],\n",
      "        [24.9313, 29.8854],\n",
      "        [27.6556, 27.6274]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9939, 0.6204, 0.0810, 0.9553], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7863, 29.7698],\n",
      "        [30.7514, 25.5502],\n",
      "        [24.9303, 29.8877],\n",
      "        [27.6550, 27.6290]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9939, 0.6204, 0.0810, 0.9553], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7877, 29.7696],\n",
      "        [30.7673, 25.5467],\n",
      "        [24.9333, 29.8870],\n",
      "        [27.6571, 27.6287]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9939, 0.6233, 0.0810, 0.9554], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7873, 29.7707],\n",
      "        [30.7618, 25.5586],\n",
      "        [24.9323, 29.8893],\n",
      "        [27.6564, 27.6302]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9939, 0.6233, 0.0810, 0.9554], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7888, 29.7705],\n",
      "        [30.7775, 25.5552],\n",
      "        [24.9353, 29.8886],\n",
      "        [27.6585, 27.6299]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9939, 0.6262, 0.0811, 0.9554], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7883, 29.7716],\n",
      "        [30.7720, 25.5669],\n",
      "        [24.9343, 29.8909],\n",
      "        [27.6579, 27.6314]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9939, 0.6262, 0.0811, 0.9554], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7898, 29.7713],\n",
      "        [30.7877, 25.5636],\n",
      "        [24.9373, 29.8902],\n",
      "        [27.6599, 27.6311]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9939, 0.6290, 0.0812, 0.9554], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7894, 29.7724],\n",
      "        [30.7823, 25.5753],\n",
      "        [24.9363, 29.8924],\n",
      "        [27.6593, 27.6327]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9939, 0.6290, 0.0812, 0.9554], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7908, 29.7722],\n",
      "        [30.7979, 25.5720],\n",
      "        [24.9393, 29.8918],\n",
      "        [27.6614, 27.6323]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9939, 0.6319, 0.0812, 0.9555], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7904, 29.7733],\n",
      "        [30.7925, 25.5837],\n",
      "        [24.9383, 29.8940],\n",
      "        [27.6607, 27.6339]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9939, 0.6319, 0.0812, 0.9555], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7918, 29.7731],\n",
      "        [30.8080, 25.5804],\n",
      "        [24.9412, 29.8934],\n",
      "        [27.6628, 27.6335]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9939, 0.6347, 0.0813, 0.9555], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7914, 29.7742],\n",
      "        [30.8027, 25.5920],\n",
      "        [24.9402, 29.8956],\n",
      "        [27.6622, 27.6351]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9939, 0.6347, 0.0813, 0.9555], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7928, 29.7739],\n",
      "        [30.8181, 25.5888],\n",
      "        [24.9432, 29.8950],\n",
      "        [27.6642, 27.6347]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9939, 0.6376, 0.0813, 0.9555], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7924, 29.7750],\n",
      "        [30.8128, 25.6003],\n",
      "        [24.9422, 29.8972],\n",
      "        [27.6636, 27.6363]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9939, 0.6376, 0.0813, 0.9555], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7938, 29.7748],\n",
      "        [30.8282, 25.5971],\n",
      "        [24.9452, 29.8966],\n",
      "        [27.6656, 27.6359]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9939, 0.6404, 0.0814, 0.9556], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7933, 29.7758],\n",
      "        [30.8228, 25.6086],\n",
      "        [24.9442, 29.8987],\n",
      "        [27.6650, 27.6374]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9939, 0.6404, 0.0814, 0.9556], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7947, 29.7756],\n",
      "        [30.8382, 25.6055],\n",
      "        [24.9471, 29.8981],\n",
      "        [27.6670, 27.6371]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9940, 0.6432, 0.0815, 0.9556], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7943, 29.7767],\n",
      "        [30.8329, 25.6169],\n",
      "        [24.9461, 29.9003],\n",
      "        [27.6664, 27.6386]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9940, 0.6432, 0.0815, 0.9556], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7957, 29.7765],\n",
      "        [30.8481, 25.6138],\n",
      "        [24.9490, 29.8997],\n",
      "        [27.6683, 27.6383]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9940, 0.6460, 0.0815, 0.9556], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7953, 29.7775],\n",
      "        [30.8428, 25.6251],\n",
      "        [24.9481, 29.9018],\n",
      "        [27.6677, 27.6398]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9940, 0.6460, 0.0815, 0.9556], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7967, 29.7773],\n",
      "        [30.8580, 25.6221],\n",
      "        [24.9510, 29.9013],\n",
      "        [27.6697, 27.6395]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9940, 0.6487, 0.0816, 0.9557], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7963, 29.7784],\n",
      "        [30.8527, 25.6334],\n",
      "        [24.9500, 29.9034],\n",
      "        [27.6691, 27.6410]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9940, 0.6487, 0.0816, 0.9557], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7976, 29.7782],\n",
      "        [30.8678, 25.6304],\n",
      "        [24.9529, 29.9028],\n",
      "        [27.6711, 27.6407]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9940, 0.6515, 0.0816, 0.9557], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7972, 29.7792],\n",
      "        [30.8626, 25.6416],\n",
      "        [24.9519, 29.9049],\n",
      "        [27.6705, 27.6421]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9940, 0.6515, 0.0816, 0.9557], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7986, 29.7790],\n",
      "        [30.8776, 25.6386],\n",
      "        [24.9548, 29.9043],\n",
      "        [27.6724, 27.6418]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9940, 0.6542, 0.0817, 0.9557], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7982, 29.7800],\n",
      "        [30.8724, 25.6498],\n",
      "        [24.9538, 29.9064],\n",
      "        [27.6718, 27.6433]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9940, 0.6542, 0.0817, 0.9557], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.7995, 29.7798],\n",
      "        [30.8873, 25.6469],\n",
      "        [24.9567, 29.9059],\n",
      "        [27.6738, 27.6430]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9940, 0.6569, 0.0817, 0.9558], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.7991, 29.7808],\n",
      "        [30.8821, 25.6579],\n",
      "        [24.9557, 29.9079],\n",
      "        [27.6732, 27.6444]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9940, 0.6569, 0.0817, 0.9558], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8005, 29.7807],\n",
      "        [30.8969, 25.6551],\n",
      "        [24.9585, 29.9074],\n",
      "        [27.6751, 27.6441]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9940, 0.6596, 0.0818, 0.9558], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8001, 29.7817],\n",
      "        [30.8918, 25.6660],\n",
      "        [24.9576, 29.9095],\n",
      "        [27.6745, 27.6456]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9940, 0.6596, 0.0818, 0.9558], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8014, 29.7815],\n",
      "        [30.9065, 25.6632],\n",
      "        [24.9604, 29.9089],\n",
      "        [27.6764, 27.6453]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9940, 0.6623, 0.0819, 0.9558], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8010, 29.7825],\n",
      "        [30.9014, 25.6741],\n",
      "        [24.9595, 29.9110],\n",
      "        [27.6759, 27.6467]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9940, 0.6623, 0.0819, 0.9558], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8023, 29.7823],\n",
      "        [30.9160, 25.6714],\n",
      "        [24.9623, 29.9104],\n",
      "        [27.6777, 27.6464]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9941, 0.6649, 0.0819, 0.9559], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8020, 29.7833],\n",
      "        [30.9110, 25.6822],\n",
      "        [24.9613, 29.9125],\n",
      "        [27.6772, 27.6478]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9941, 0.6649, 0.0819, 0.9559], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8033, 29.7831],\n",
      "        [30.9255, 25.6795],\n",
      "        [24.9641, 29.9119],\n",
      "        [27.6790, 27.6476]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9941, 0.6675, 0.0820, 0.9559], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8029, 29.7841],\n",
      "        [30.9205, 25.6902],\n",
      "        [24.9632, 29.9140],\n",
      "        [27.6785, 27.6490]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9941, 0.6675, 0.0820, 0.9559], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8042, 29.7839],\n",
      "        [30.9349, 25.6876],\n",
      "        [24.9659, 29.9135],\n",
      "        [27.6803, 27.6487]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9941, 0.6702, 0.0820, 0.9559], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8038, 29.7849],\n",
      "        [30.9299, 25.6982],\n",
      "        [24.9650, 29.9154],\n",
      "        [27.6798, 27.6501]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9941, 0.6702, 0.0820, 0.9559], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8051, 29.7847],\n",
      "        [30.9442, 25.6956],\n",
      "        [24.9678, 29.9149],\n",
      "        [27.6816, 27.6498]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9941, 0.6727, 0.0821, 0.9560], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8047, 29.7857],\n",
      "        [30.9392, 25.7062],\n",
      "        [24.9668, 29.9169],\n",
      "        [27.6811, 27.6512]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9941, 0.6727, 0.0821, 0.9560], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8060, 29.7855],\n",
      "        [30.9535, 25.7036],\n",
      "        [24.9696, 29.9164],\n",
      "        [27.6829, 27.6509]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9941, 0.6753, 0.0822, 0.9560], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8056, 29.7864],\n",
      "        [30.9485, 25.7141],\n",
      "        [24.9686, 29.9184],\n",
      "        [27.6823, 27.6523]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9941, 0.6753, 0.0822, 0.9560], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8069, 29.7863],\n",
      "        [30.9626, 25.7116],\n",
      "        [24.9714, 29.9179],\n",
      "        [27.6842, 27.6520]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9941, 0.6779, 0.0822, 0.9560], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8065, 29.7872],\n",
      "        [30.9577, 25.7220],\n",
      "        [24.9704, 29.9198],\n",
      "        [27.6836, 27.6534]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9941, 0.6779, 0.0822, 0.9560], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8078, 29.7871],\n",
      "        [30.9717, 25.7195],\n",
      "        [24.9731, 29.9194],\n",
      "        [27.6854, 27.6531]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9941, 0.6804, 0.0823, 0.9561], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8074, 29.7880],\n",
      "        [30.9669, 25.7298],\n",
      "        [24.9722, 29.9213],\n",
      "        [27.6849, 27.6545]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9941, 0.6804, 0.0823, 0.9561], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8087, 29.7879],\n",
      "        [30.9808, 25.7274],\n",
      "        [24.9749, 29.9208],\n",
      "        [27.6867, 27.6542]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9941, 0.6829, 0.0823, 0.9561], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8083, 29.7888],\n",
      "        [30.9760, 25.7376],\n",
      "        [24.9740, 29.9228],\n",
      "        [27.6861, 27.6555]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9941, 0.6829, 0.0823, 0.9561], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8096, 29.7886],\n",
      "        [30.9897, 25.7352],\n",
      "        [24.9767, 29.9223],\n",
      "        [27.6879, 27.6553]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9941, 0.6854, 0.0824, 0.9561], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8092, 29.7896],\n",
      "        [30.9849, 25.7454],\n",
      "        [24.9758, 29.9242],\n",
      "        [27.6873, 27.6566]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9941, 0.6854, 0.0824, 0.9561], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8104, 29.7894],\n",
      "        [30.9986, 25.7430],\n",
      "        [24.9784, 29.9237],\n",
      "        [27.6891, 27.6563]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9942, 0.6879, 0.0825, 0.9562], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8101, 29.7903],\n",
      "        [30.9939, 25.7531],\n",
      "        [24.9775, 29.9256],\n",
      "        [27.6885, 27.6576]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9942, 0.6879, 0.0825, 0.9562], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8113, 29.7902],\n",
      "        [31.0074, 25.7508],\n",
      "        [24.9801, 29.9251],\n",
      "        [27.6903, 27.6574]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9942, 0.6903, 0.0825, 0.9562], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8109, 29.7911],\n",
      "        [31.0027, 25.7608],\n",
      "        [24.9792, 29.9270],\n",
      "        [27.6898, 27.6587]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9942, 0.6903, 0.0825, 0.9562], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8122, 29.7909],\n",
      "        [31.0162, 25.7585],\n",
      "        [24.9819, 29.9266],\n",
      "        [27.6915, 27.6585]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9942, 0.6928, 0.0826, 0.9562], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8118, 29.7918],\n",
      "        [31.0115, 25.7684],\n",
      "        [24.9810, 29.9284],\n",
      "        [27.6910, 27.6598]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9942, 0.6928, 0.0826, 0.9562], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8130, 29.7917],\n",
      "        [31.0248, 25.7662],\n",
      "        [24.9836, 29.9280],\n",
      "        [27.6927, 27.6595]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9942, 0.6952, 0.0826, 0.9562], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8126, 29.7926],\n",
      "        [31.0202, 25.7760],\n",
      "        [24.9827, 29.9298],\n",
      "        [27.6922, 27.6608]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9942, 0.6952, 0.0826, 0.9562], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8139, 29.7924],\n",
      "        [31.0334, 25.7738],\n",
      "        [24.9853, 29.9294],\n",
      "        [27.6939, 27.6606]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9942, 0.6976, 0.0827, 0.9563], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8135, 29.7933],\n",
      "        [31.0288, 25.7836],\n",
      "        [24.9844, 29.9312],\n",
      "        [27.6934, 27.6618]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9942, 0.6976, 0.0827, 0.9563], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8147, 29.7932],\n",
      "        [31.0419, 25.7814],\n",
      "        [24.9869, 29.9308],\n",
      "        [27.6951, 27.6616]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9942, 0.6999, 0.0827, 0.9563], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8143, 29.7940],\n",
      "        [31.0373, 25.7911],\n",
      "        [24.9861, 29.9326],\n",
      "        [27.6945, 27.6629]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9942, 0.6999, 0.0827, 0.9563], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8155, 29.7939],\n",
      "        [31.0503, 25.7889],\n",
      "        [24.9886, 29.9322],\n",
      "        [27.6962, 27.6626]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9942, 0.7023, 0.0828, 0.9563], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8152, 29.7948],\n",
      "        [31.0458, 25.7986],\n",
      "        [24.9877, 29.9340],\n",
      "        [27.6957, 27.6639]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9942, 0.7023, 0.0828, 0.9563], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8163, 29.7946],\n",
      "        [31.0587, 25.7965],\n",
      "        [24.9903, 29.9336],\n",
      "        [27.6974, 27.6637]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9942, 0.7046, 0.0829, 0.9563], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8160, 29.7955],\n",
      "        [31.0542, 25.8060],\n",
      "        [24.9894, 29.9353],\n",
      "        [27.6968, 27.6649]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9942, 0.7046, 0.0829, 0.9563], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8172, 29.7954],\n",
      "        [31.0670, 25.8039],\n",
      "        [24.9919, 29.9349],\n",
      "        [27.6985, 27.6647]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9942, 0.7069, 0.0829, 0.9564], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8168, 29.7962],\n",
      "        [31.0625, 25.8133],\n",
      "        [24.9910, 29.9367],\n",
      "        [27.6980, 27.6659]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9942, 0.7069, 0.0829, 0.9564], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8180, 29.7961],\n",
      "        [31.0752, 25.8113],\n",
      "        [24.9935, 29.9363],\n",
      "        [27.6996, 27.6657]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9943, 0.7092, 0.0830, 0.9564], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8176, 29.7969],\n",
      "        [31.0707, 25.8206],\n",
      "        [24.9927, 29.9380],\n",
      "        [27.6991, 27.6669]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9943, 0.7092, 0.0830, 0.9564], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8188, 29.7968],\n",
      "        [31.0833, 25.8186],\n",
      "        [24.9951, 29.9376],\n",
      "        [27.7008, 27.6667]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9943, 0.7115, 0.0830, 0.9564], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8184, 29.7976],\n",
      "        [31.0788, 25.8279],\n",
      "        [24.9943, 29.9394],\n",
      "        [27.7002, 27.6679]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9943, 0.7115, 0.0830, 0.9564], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8195, 29.7975],\n",
      "        [31.0913, 25.8259],\n",
      "        [24.9967, 29.9389],\n",
      "        [27.7019, 27.6677]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9943, 0.7137, 0.0831, 0.9565], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8192, 29.7983],\n",
      "        [31.0869, 25.8351],\n",
      "        [24.9959, 29.9407],\n",
      "        [27.7014, 27.6688]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9943, 0.7137, 0.0831, 0.9565], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8203, 29.7982],\n",
      "        [31.0992, 25.8332],\n",
      "        [24.9983, 29.9403],\n",
      "        [27.7030, 27.6687]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9943, 0.7159, 0.0831, 0.9565], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8200, 29.7991],\n",
      "        [31.0949, 25.8423],\n",
      "        [24.9975, 29.9420],\n",
      "        [27.7025, 27.6698]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9943, 0.7159, 0.0831, 0.9565], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8211, 29.7989],\n",
      "        [31.1071, 25.8404],\n",
      "        [24.9999, 29.9416],\n",
      "        [27.7041, 27.6696]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9943, 0.7181, 0.0832, 0.9565], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8208, 29.7997],\n",
      "        [31.1028, 25.8494],\n",
      "        [24.9990, 29.9433],\n",
      "        [27.7035, 27.6708]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9943, 0.7181, 0.0832, 0.9565], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8219, 29.7996],\n",
      "        [31.1149, 25.8476],\n",
      "        [25.0014, 29.9429],\n",
      "        [27.7051, 27.6706]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9943, 0.7203, 0.0833, 0.9565], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8215, 29.8004],\n",
      "        [31.1106, 25.8565],\n",
      "        [25.0006, 29.9446],\n",
      "        [27.7046, 27.6717]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9943, 0.7203, 0.0833, 0.9565], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8227, 29.8003],\n",
      "        [31.1226, 25.8547],\n",
      "        [25.0030, 29.9442],\n",
      "        [27.7062, 27.6716]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9943, 0.7225, 0.0833, 0.9566], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8223, 29.8011],\n",
      "        [31.1184, 25.8635],\n",
      "        [25.0022, 29.9459],\n",
      "        [27.7057, 27.6727]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9943, 0.7225, 0.0833, 0.9566], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8234, 29.8010],\n",
      "        [31.1302, 25.8617],\n",
      "        [25.0045, 29.9455],\n",
      "        [27.7073, 27.6725]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9943, 0.7246, 0.0834, 0.9566], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8231, 29.8018],\n",
      "        [31.1260, 25.8705],\n",
      "        [25.0037, 29.9472],\n",
      "        [27.7068, 27.6736]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9943, 0.7246, 0.0834, 0.9566], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8242, 29.8017],\n",
      "        [31.1378, 25.8687],\n",
      "        [25.0060, 29.9468],\n",
      "        [27.7083, 27.6734]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9943, 0.7267, 0.0834, 0.9566], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8239, 29.8025],\n",
      "        [31.1336, 25.8774],\n",
      "        [25.0052, 29.9484],\n",
      "        [27.7078, 27.6746]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9943, 0.7267, 0.0834, 0.9566], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8249, 29.8023],\n",
      "        [31.1453, 25.8757],\n",
      "        [25.0075, 29.9481],\n",
      "        [27.7093, 27.6744]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9944, 0.7288, 0.0835, 0.9566], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8246, 29.8031],\n",
      "        [31.1411, 25.8843],\n",
      "        [25.0067, 29.9497],\n",
      "        [27.7089, 27.6755]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9944, 0.7288, 0.0835, 0.9566], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8257, 29.8030],\n",
      "        [31.1527, 25.8826],\n",
      "        [25.0090, 29.9493],\n",
      "        [27.7104, 27.6753]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9944, 0.7309, 0.0835, 0.9567], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8254, 29.8038],\n",
      "        [31.1485, 25.8911],\n",
      "        [25.0082, 29.9510],\n",
      "        [27.7099, 27.6764]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9944, 0.7309, 0.0835, 0.9567], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8264, 29.8037],\n",
      "        [31.1600, 25.8894],\n",
      "        [25.0105, 29.9506],\n",
      "        [27.7114, 27.6762]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9944, 0.7330, 0.0836, 0.9567], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8261, 29.8045],\n",
      "        [31.1559, 25.8979],\n",
      "        [25.0097, 29.9522],\n",
      "        [27.7109, 27.6773]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9944, 0.7330, 0.0836, 0.9567], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8272, 29.8044],\n",
      "        [31.1672, 25.8962],\n",
      "        [25.0120, 29.9519],\n",
      "        [27.7124, 27.6772]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9944, 0.7350, 0.0837, 0.9567], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8268, 29.8051],\n",
      "        [31.1631, 25.9046],\n",
      "        [25.0112, 29.9534],\n",
      "        [27.7119, 27.6782]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9944, 0.7350, 0.0837, 0.9567], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8279, 29.8050],\n",
      "        [31.1744, 25.9030],\n",
      "        [25.0134, 29.9531],\n",
      "        [27.7134, 27.6781]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9944, 0.7370, 0.0837, 0.9567], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8276, 29.8058],\n",
      "        [31.1703, 25.9113],\n",
      "        [25.0126, 29.9547],\n",
      "        [27.7129, 27.6791]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9944, 0.7370, 0.0837, 0.9567], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8286, 29.8057],\n",
      "        [31.1815, 25.9097],\n",
      "        [25.0148, 29.9543],\n",
      "        [27.7144, 27.6790]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9944, 0.7390, 0.0838, 0.9568], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8283, 29.8064],\n",
      "        [31.1775, 25.9179],\n",
      "        [25.0141, 29.9559],\n",
      "        [27.7139, 27.6800]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9944, 0.7390, 0.0838, 0.9568], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8293, 29.8063],\n",
      "        [31.1884, 25.9163],\n",
      "        [25.0163, 29.9555],\n",
      "        [27.7154, 27.6799]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9944, 0.7410, 0.0838, 0.9568], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8290, 29.8071],\n",
      "        [31.1845, 25.9244],\n",
      "        [25.0155, 29.9571],\n",
      "        [27.7149, 27.6809]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9944, 0.7410, 0.0838, 0.9568], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8300, 29.8070],\n",
      "        [31.1954, 25.9229],\n",
      "        [25.0177, 29.9567],\n",
      "        [27.7163, 27.6808]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9944, 0.7430, 0.0839, 0.9568], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8297, 29.8077],\n",
      "        [31.1914, 25.9310],\n",
      "        [25.0169, 29.9583],\n",
      "        [27.7159, 27.6818]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9944, 0.7430, 0.0839, 0.9568], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8307, 29.8076],\n",
      "        [31.2022, 25.9294],\n",
      "        [25.0191, 29.9579],\n",
      "        [27.7173, 27.6816]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9944, 0.7449, 0.0839, 0.9568], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8304, 29.8083],\n",
      "        [31.1983, 25.9374],\n",
      "        [25.0183, 29.9595],\n",
      "        [27.7168, 27.6827]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9944, 0.7449, 0.0839, 0.9568], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8314, 29.8082],\n",
      "        [31.2090, 25.9359],\n",
      "        [25.0204, 29.9591],\n",
      "        [27.7183, 27.6825]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9945, 0.7468, 0.0840, 0.9568], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8311, 29.8089],\n",
      "        [31.2051, 25.9438],\n",
      "        [25.0197, 29.9606],\n",
      "        [27.7178, 27.6835]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9945, 0.7468, 0.0840, 0.9568], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8321, 29.8088],\n",
      "        [31.2157, 25.9424],\n",
      "        [25.0218, 29.9603],\n",
      "        [27.7192, 27.6834]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9945, 0.7487, 0.0840, 0.9569], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8318, 29.8096],\n",
      "        [31.2118, 25.9502],\n",
      "        [25.0211, 29.9618],\n",
      "        [27.7187, 27.6844]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9945, 0.7487, 0.0840, 0.9569], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8328, 29.8095],\n",
      "        [31.2223, 25.9488],\n",
      "        [25.0232, 29.9615],\n",
      "        [27.7201, 27.6842]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9945, 0.7506, 0.0841, 0.9569], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8325, 29.8102],\n",
      "        [31.2185, 25.9565],\n",
      "        [25.0224, 29.9629],\n",
      "        [27.7197, 27.6852]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9945, 0.7506, 0.0841, 0.9569], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8334, 29.8101],\n",
      "        [31.2288, 25.9551],\n",
      "        [25.0245, 29.9627],\n",
      "        [27.7211, 27.6851]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9945, 0.7525, 0.0841, 0.9569], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8331, 29.8108],\n",
      "        [31.2251, 25.9627],\n",
      "        [25.0238, 29.9641],\n",
      "        [27.7206, 27.6861]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9945, 0.7525, 0.0841, 0.9569], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8341, 29.8107],\n",
      "        [31.2353, 25.9613],\n",
      "        [25.0259, 29.9638],\n",
      "        [27.7220, 27.6859]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9945, 0.7543, 0.0842, 0.9569], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8338, 29.8114],\n",
      "        [31.2316, 25.9689],\n",
      "        [25.0251, 29.9652],\n",
      "        [27.7215, 27.6869]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9945, 0.7543, 0.0842, 0.9569], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8348, 29.8113],\n",
      "        [31.2417, 25.9676],\n",
      "        [25.0272, 29.9649],\n",
      "        [27.7229, 27.6868]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9945, 0.7561, 0.0843, 0.9570], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8345, 29.8120],\n",
      "        [31.2380, 25.9751],\n",
      "        [25.0265, 29.9664],\n",
      "        [27.7224, 27.6877]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9945, 0.7561, 0.0843, 0.9570], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8354, 29.8119],\n",
      "        [31.2480, 25.9737],\n",
      "        [25.0285, 29.9661],\n",
      "        [27.7238, 27.6876]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9945, 0.7579, 0.0843, 0.9570], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8351, 29.8126],\n",
      "        [31.2443, 25.9812],\n",
      "        [25.0278, 29.9675],\n",
      "        [27.7233, 27.6885]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9945, 0.7579, 0.0843, 0.9570], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8361, 29.8125],\n",
      "        [31.2543, 25.9799],\n",
      "        [25.0298, 29.9672],\n",
      "        [27.7247, 27.6884]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9945, 0.7597, 0.0844, 0.9570], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8358, 29.8132],\n",
      "        [31.2506, 25.9872],\n",
      "        [25.0291, 29.9686],\n",
      "        [27.7242, 27.6893]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9945, 0.7597, 0.0844, 0.9570], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8367, 29.8131],\n",
      "        [31.2604, 25.9859],\n",
      "        [25.0311, 29.9683],\n",
      "        [27.7255, 27.6892]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9945, 0.7615, 0.0844, 0.9570], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8364, 29.8138],\n",
      "        [31.2568, 25.9932],\n",
      "        [25.0304, 29.9697],\n",
      "        [27.7251, 27.6902]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9945, 0.7615, 0.0844, 0.9570], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8374, 29.8137],\n",
      "        [31.2665, 25.9920],\n",
      "        [25.0323, 29.9694],\n",
      "        [27.7264, 27.6900]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9946, 0.7632, 0.0845, 0.9570], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8371, 29.8144],\n",
      "        [31.2630, 25.9992],\n",
      "        [25.0316, 29.9708],\n",
      "        [27.7260, 27.6910]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9946, 0.7632, 0.0845, 0.9570], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8380, 29.8143],\n",
      "        [31.2726, 25.9979],\n",
      "        [25.0336, 29.9705],\n",
      "        [27.7273, 27.6908]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9946, 0.7649, 0.0845, 0.9571], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8377, 29.8149],\n",
      "        [31.2690, 26.0050],\n",
      "        [25.0329, 29.9719],\n",
      "        [27.7269, 27.6917]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9946, 0.7649, 0.0845, 0.9571], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8386, 29.8148],\n",
      "        [31.2785, 26.0038],\n",
      "        [25.0348, 29.9716],\n",
      "        [27.7281, 27.6916]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9946, 0.7667, 0.0846, 0.9571], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8383, 29.8155],\n",
      "        [31.2750, 26.0109],\n",
      "        [25.0341, 29.9729],\n",
      "        [27.7277, 27.6925]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9946, 0.7667, 0.0846, 0.9571], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8392, 29.8154],\n",
      "        [31.2844, 26.0097],\n",
      "        [25.0361, 29.9727],\n",
      "        [27.7290, 27.6924]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9946, 0.7683, 0.0846, 0.9571], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8390, 29.8161],\n",
      "        [31.2809, 26.0167],\n",
      "        [25.0354, 29.9740],\n",
      "        [27.7286, 27.6933]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9946, 0.7683, 0.0846, 0.9571], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8399, 29.8160],\n",
      "        [31.2902, 26.0155],\n",
      "        [25.0373, 29.9738],\n",
      "        [27.7298, 27.6932]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9946, 0.7700, 0.0847, 0.9571], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8396, 29.8166],\n",
      "        [31.2868, 26.0224],\n",
      "        [25.0366, 29.9751],\n",
      "        [27.7294, 27.6941]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9946, 0.7700, 0.0847, 0.9571], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8405, 29.8166],\n",
      "        [31.2960, 26.0213],\n",
      "        [25.0385, 29.9748],\n",
      "        [27.7307, 27.6940]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9946, 0.7717, 0.0847, 0.9571], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8402, 29.8172],\n",
      "        [31.2925, 26.0281],\n",
      "        [25.0378, 29.9761],\n",
      "        [27.7302, 27.6948]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9946, 0.7717, 0.0847, 0.9571], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8411, 29.8171],\n",
      "        [31.3017, 26.0270],\n",
      "        [25.0397, 29.9759],\n",
      "        [27.7315, 27.6947]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9946, 0.7733, 0.0848, 0.9572], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8408, 29.8177],\n",
      "        [31.2983, 26.0338],\n",
      "        [25.0391, 29.9772],\n",
      "        [27.7311, 27.6956]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9946, 0.7733, 0.0848, 0.9572], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8417, 29.8177],\n",
      "        [31.3073, 26.0326],\n",
      "        [25.0409, 29.9769],\n",
      "        [27.7323, 27.6955]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9946, 0.7749, 0.0848, 0.9572], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8414, 29.8183],\n",
      "        [31.3039, 26.0394],\n",
      "        [25.0403, 29.9782],\n",
      "        [27.7319, 27.6964]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9946, 0.7749, 0.0848, 0.9572], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8423, 29.8182],\n",
      "        [31.3128, 26.0383],\n",
      "        [25.0421, 29.9780],\n",
      "        [27.7331, 27.6963]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9946, 0.7766, 0.0849, 0.9572], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8420, 29.8188],\n",
      "        [31.3095, 26.0449],\n",
      "        [25.0414, 29.9792],\n",
      "        [27.7327, 27.6971]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9946, 0.7766, 0.0849, 0.9572], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8429, 29.8188],\n",
      "        [31.3183, 26.0438],\n",
      "        [25.0433, 29.9790],\n",
      "        [27.7339, 27.6970]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9946, 0.7781, 0.0849, 0.9572], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8426, 29.8194],\n",
      "        [31.3150, 26.0504],\n",
      "        [25.0426, 29.9802],\n",
      "        [27.7335, 27.6978]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9946, 0.7781, 0.0849, 0.9572], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8434, 29.8193],\n",
      "        [31.3237, 26.0493],\n",
      "        [25.0444, 29.9800],\n",
      "        [27.7347, 27.6977]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9947, 0.7797, 0.0850, 0.9572], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8432, 29.8199],\n",
      "        [31.3204, 26.0558],\n",
      "        [25.0438, 29.9812],\n",
      "        [27.7343, 27.6986]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9947, 0.7797, 0.0850, 0.9572], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8440, 29.8198],\n",
      "        [31.3291, 26.0548],\n",
      "        [25.0456, 29.9810],\n",
      "        [27.7355, 27.6985]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9947, 0.7813, 0.0850, 0.9573], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8438, 29.8205],\n",
      "        [31.3258, 26.0612],\n",
      "        [25.0449, 29.9822],\n",
      "        [27.7351, 27.6993]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9947, 0.7813, 0.0850, 0.9573], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8446, 29.8204],\n",
      "        [31.3344, 26.0602],\n",
      "        [25.0467, 29.9820],\n",
      "        [27.7362, 27.6992]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9947, 0.7828, 0.0851, 0.9573], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8443, 29.8210],\n",
      "        [31.3311, 26.0666],\n",
      "        [25.0461, 29.9832],\n",
      "        [27.7358, 27.7000]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9947, 0.7828, 0.0851, 0.9573], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8452, 29.8209],\n",
      "        [31.3396, 26.0656],\n",
      "        [25.0478, 29.9830],\n",
      "        [27.7370, 27.6999]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9947, 0.7843, 0.0851, 0.9573], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8449, 29.8215],\n",
      "        [31.3364, 26.0719],\n",
      "        [25.0472, 29.9842],\n",
      "        [27.7366, 27.7008]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9947, 0.7843, 0.0851, 0.9573], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8458, 29.8214],\n",
      "        [31.3448, 26.0709],\n",
      "        [25.0490, 29.9840],\n",
      "        [27.7378, 27.7006]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9947, 0.7858, 0.0852, 0.9573], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8455, 29.8220],\n",
      "        [31.3416, 26.0771],\n",
      "        [25.0483, 29.9852],\n",
      "        [27.7374, 27.7015]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9947, 0.7858, 0.0852, 0.9573], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8463, 29.8220],\n",
      "        [31.3499, 26.0762],\n",
      "        [25.0501, 29.9850],\n",
      "        [27.7385, 27.7014]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9947, 0.7873, 0.0853, 0.9573], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8460, 29.8225],\n",
      "        [31.3467, 26.0823],\n",
      "        [25.0494, 29.9861],\n",
      "        [27.7381, 27.7022]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9947, 0.7873, 0.0853, 0.9573], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8469, 29.8225],\n",
      "        [31.3549, 26.0814],\n",
      "        [25.0511, 29.9859],\n",
      "        [27.7393, 27.7021]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9947, 0.7888, 0.0853, 0.9573], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8466, 29.8231],\n",
      "        [31.3518, 26.0875],\n",
      "        [25.0505, 29.9871],\n",
      "        [27.7389, 27.7029]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9947, 0.7888, 0.0853, 0.9573], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8474, 29.8230],\n",
      "        [31.3599, 26.0866],\n",
      "        [25.0522, 29.9869],\n",
      "        [27.7400, 27.7027]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9947, 0.7903, 0.0854, 0.9574], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8472, 29.8236],\n",
      "        [31.3568, 26.0926],\n",
      "        [25.0516, 29.9881],\n",
      "        [27.7396, 27.7036]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9947, 0.7903, 0.0854, 0.9574], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8480, 29.8235],\n",
      "        [31.3648, 26.0917],\n",
      "        [25.0533, 29.9878],\n",
      "        [27.7407, 27.7034]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9947, 0.7917, 0.0854, 0.9574], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8477, 29.8241],\n",
      "        [31.3617, 26.0977],\n",
      "        [25.0527, 29.9890],\n",
      "        [27.7404, 27.7042]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9947, 0.7917, 0.0854, 0.9574], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8485, 29.8240],\n",
      "        [31.3697, 26.0968],\n",
      "        [25.0544, 29.9888],\n",
      "        [27.7415, 27.7041]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9947, 0.7931, 0.0855, 0.9574], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8482, 29.8246],\n",
      "        [31.3666, 26.1027],\n",
      "        [25.0538, 29.9899],\n",
      "        [27.7411, 27.7049]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9947, 0.7931, 0.0855, 0.9574], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8491, 29.8245],\n",
      "        [31.3745, 26.1018],\n",
      "        [25.0554, 29.9897],\n",
      "        [27.7422, 27.7048]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9947, 0.7945, 0.0855, 0.9574], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8488, 29.8251],\n",
      "        [31.3715, 26.1077],\n",
      "        [25.0548, 29.9908],\n",
      "        [27.7418, 27.7056]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9947, 0.7945, 0.0855, 0.9574], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8496, 29.8250],\n",
      "        [31.3792, 26.1068],\n",
      "        [25.0565, 29.9906],\n",
      "        [27.7429, 27.7055]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9948, 0.7959, 0.0856, 0.9574], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8493, 29.8256],\n",
      "        [31.3762, 26.1126],\n",
      "        [25.0559, 29.9918],\n",
      "        [27.7425, 27.7063]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9948, 0.7959, 0.0856, 0.9574], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8501, 29.8255],\n",
      "        [31.3839, 26.1117],\n",
      "        [25.0575, 29.9916],\n",
      "        [27.7436, 27.7062]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9948, 0.7973, 0.0856, 0.9575], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8498, 29.8261],\n",
      "        [31.3809, 26.1175],\n",
      "        [25.0569, 29.9927],\n",
      "        [27.7432, 27.7069]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9948, 0.7973, 0.0856, 0.9575], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8506, 29.8260],\n",
      "        [31.3885, 26.1166],\n",
      "        [25.0585, 29.9925],\n",
      "        [27.7443, 27.7068]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9948, 0.7987, 0.0857, 0.9575], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8504, 29.8265],\n",
      "        [31.3856, 26.1223],\n",
      "        [25.0579, 29.9936],\n",
      "        [27.7439, 27.7076]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9948, 0.7987, 0.0857, 0.9575], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8512, 29.8265],\n",
      "        [31.3931, 26.1215],\n",
      "        [25.0595, 29.9934],\n",
      "        [27.7450, 27.7075]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9948, 0.8000, 0.0857, 0.9575], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8509, 29.8270],\n",
      "        [31.3902, 26.1271],\n",
      "        [25.0590, 29.9945],\n",
      "        [27.7446, 27.7082]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9948, 0.8000, 0.0857, 0.9575], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8517, 29.8270],\n",
      "        [31.3976, 26.1263],\n",
      "        [25.0605, 29.9943],\n",
      "        [27.7457, 27.7081]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9948, 0.8014, 0.0858, 0.9575], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8514, 29.8275],\n",
      "        [31.3948, 26.1319],\n",
      "        [25.0600, 29.9954],\n",
      "        [27.7453, 27.7089]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9948, 0.8014, 0.0858, 0.9575], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8522, 29.8274],\n",
      "        [31.4021, 26.1311],\n",
      "        [25.0615, 29.9951],\n",
      "        [27.7463, 27.7088]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9948, 0.8027, 0.0858, 0.9575], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8519, 29.8280],\n",
      "        [31.3993, 26.1366],\n",
      "        [25.0610, 29.9963],\n",
      "        [27.7460, 27.7095]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9948, 0.8027, 0.0858, 0.9575], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8527, 29.8279],\n",
      "        [31.4065, 26.1358],\n",
      "        [25.0625, 29.9960],\n",
      "        [27.7470, 27.7094]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9948, 0.8040, 0.0859, 0.9575], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8524, 29.8285],\n",
      "        [31.4037, 26.1413],\n",
      "        [25.0620, 29.9971],\n",
      "        [27.7467, 27.7102]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9948, 0.8040, 0.0859, 0.9575], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8532, 29.8284],\n",
      "        [31.4109, 26.1405],\n",
      "        [25.0635, 29.9969],\n",
      "        [27.7477, 27.7101]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9948, 0.8053, 0.0859, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8530, 29.8289],\n",
      "        [31.4081, 26.1459],\n",
      "        [25.0630, 29.9980],\n",
      "        [27.7474, 27.7108]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9948, 0.8053, 0.0859, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8537, 29.8289],\n",
      "        [31.4152, 26.1452],\n",
      "        [25.0645, 29.9978],\n",
      "        [27.7484, 27.7107]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9948, 0.8066, 0.0860, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8534, 29.8294],\n",
      "        [31.4124, 26.1505],\n",
      "        [25.0639, 29.9988],\n",
      "        [27.7480, 27.7114]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9948, 0.8066, 0.0860, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8542, 29.8293],\n",
      "        [31.4195, 26.1497],\n",
      "        [25.0654, 29.9986],\n",
      "        [27.7490, 27.7113]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9948, 0.8079, 0.0860, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8539, 29.8298],\n",
      "        [31.4167, 26.1550],\n",
      "        [25.0649, 29.9997],\n",
      "        [27.7487, 27.7120]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9948, 0.8079, 0.0860, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8547, 29.8298],\n",
      "        [31.4237, 26.1543],\n",
      "        [25.0664, 29.9995],\n",
      "        [27.7497, 27.7119]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9949, 0.8091, 0.0860, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8544, 29.8303],\n",
      "        [31.4209, 26.1595],\n",
      "        [25.0658, 30.0005],\n",
      "        [27.7493, 27.7126]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9949, 0.8091, 0.0860, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8552, 29.8302],\n",
      "        [31.4278, 26.1588],\n",
      "        [25.0673, 30.0003],\n",
      "        [27.7503, 27.7126]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9949, 0.8104, 0.0861, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8549, 29.8308],\n",
      "        [31.4251, 26.1640],\n",
      "        [25.0668, 30.0014],\n",
      "        [27.7500, 27.7133]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9949, 0.8104, 0.0861, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8556, 29.8307],\n",
      "        [31.4319, 26.1633],\n",
      "        [25.0683, 30.0012],\n",
      "        [27.7509, 27.7132]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9949, 0.8116, 0.0861, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8554, 29.8312],\n",
      "        [31.4292, 26.1684],\n",
      "        [25.0677, 30.0022],\n",
      "        [27.7506, 27.7139]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9949, 0.8116, 0.0861, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8561, 29.8312],\n",
      "        [31.4360, 26.1677],\n",
      "        [25.0692, 30.0020],\n",
      "        [27.7516, 27.7138]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9949, 0.8128, 0.0862, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8559, 29.8316],\n",
      "        [31.4333, 26.1728],\n",
      "        [25.0687, 30.0030],\n",
      "        [27.7512, 27.7145]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9949, 0.8128, 0.0862, 0.9576], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8566, 29.8316],\n",
      "        [31.4400, 26.1721],\n",
      "        [25.0701, 30.0029],\n",
      "        [27.7522, 27.7144]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9949, 0.8140, 0.0862, 0.9577], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8564, 29.8321],\n",
      "        [31.4374, 26.1772],\n",
      "        [25.0696, 30.0038],\n",
      "        [27.7519, 27.7151]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9949, 0.8140, 0.0862, 0.9577], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8571, 29.8320],\n",
      "        [31.4440, 26.1765],\n",
      "        [25.0710, 30.0037],\n",
      "        [27.7528, 27.7150]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9949, 0.8152, 0.0863, 0.9577], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8568, 29.8325],\n",
      "        [31.4413, 26.1814],\n",
      "        [25.0705, 30.0046],\n",
      "        [27.7525, 27.7156]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9949, 0.8152, 0.0863, 0.9577], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8575, 29.8325],\n",
      "        [31.4479, 26.1808],\n",
      "        [25.0719, 30.0045],\n",
      "        [27.7534, 27.7156]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9949, 0.8164, 0.0863, 0.9577], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8573, 29.8330],\n",
      "        [31.4453, 26.1857],\n",
      "        [25.0714, 30.0054],\n",
      "        [27.7531, 27.7162]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9949, 0.8164, 0.0863, 0.9577], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8580, 29.8329],\n",
      "        [31.4518, 26.1850],\n",
      "        [25.0728, 30.0053],\n",
      "        [27.7540, 27.7161]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9949, 0.8176, 0.0864, 0.9577], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8578, 29.8334],\n",
      "        [31.4492, 26.1899],\n",
      "        [25.0723, 30.0062],\n",
      "        [27.7537, 27.7168]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9949, 0.8176, 0.0864, 0.9577], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8585, 29.8334],\n",
      "        [31.4556, 26.1893],\n",
      "        [25.0737, 30.0061],\n",
      "        [27.7546, 27.7167]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9949, 0.8187, 0.0864, 0.9577], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8582, 29.8338],\n",
      "        [31.4530, 26.1941],\n",
      "        [25.0732, 30.0070],\n",
      "        [27.7543, 27.7174]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9949, 0.8187, 0.0864, 0.9577], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8589, 29.8338],\n",
      "        [31.4594, 26.1935],\n",
      "        [25.0746, 30.0069],\n",
      "        [27.7552, 27.7173]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9949, 0.8199, 0.0865, 0.9577], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8587, 29.8343],\n",
      "        [31.4569, 26.1983],\n",
      "        [25.0741, 30.0078],\n",
      "        [27.7549, 27.7180]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9949, 0.8199, 0.0865, 0.9577], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8594, 29.8342],\n",
      "        [31.4631, 26.1976],\n",
      "        [25.0755, 30.0077],\n",
      "        [27.7558, 27.7179]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9949, 0.8210, 0.0865, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8591, 29.8347],\n",
      "        [31.4606, 26.2024],\n",
      "        [25.0750, 30.0086],\n",
      "        [27.7555, 27.7185]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9949, 0.8210, 0.0865, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8598, 29.8346],\n",
      "        [31.4668, 26.2018],\n",
      "        [25.0763, 30.0084],\n",
      "        [27.7564, 27.7184]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9950, 0.8221, 0.0866, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8596, 29.8351],\n",
      "        [31.4643, 26.2065],\n",
      "        [25.0758, 30.0094],\n",
      "        [27.7561, 27.7191]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9950, 0.8221, 0.0866, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8603, 29.8351],\n",
      "        [31.4705, 26.2058],\n",
      "        [25.0772, 30.0092],\n",
      "        [27.7570, 27.7190]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9950, 0.8232, 0.0866, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8601, 29.8355],\n",
      "        [31.4680, 26.2105],\n",
      "        [25.0767, 30.0101],\n",
      "        [27.7567, 27.7196]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9950, 0.8232, 0.0866, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8607, 29.8355],\n",
      "        [31.4741, 26.2099],\n",
      "        [25.0781, 30.0100],\n",
      "        [27.7576, 27.7196]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9950, 0.8243, 0.0867, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8605, 29.8359],\n",
      "        [31.4716, 26.2145],\n",
      "        [25.0775, 30.0109],\n",
      "        [27.7573, 27.7202]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9950, 0.8243, 0.0867, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8612, 29.8359],\n",
      "        [31.4776, 26.2139],\n",
      "        [25.0789, 30.0107],\n",
      "        [27.7581, 27.7201]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9950, 0.8254, 0.0867, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8609, 29.8363],\n",
      "        [31.4752, 26.2185],\n",
      "        [25.0784, 30.0116],\n",
      "        [27.7578, 27.7207]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9950, 0.8254, 0.0867, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8616, 29.8363],\n",
      "        [31.4812, 26.2179],\n",
      "        [25.0797, 30.0115],\n",
      "        [27.7587, 27.7207]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9950, 0.8265, 0.0868, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8614, 29.8368],\n",
      "        [31.4788, 26.2224],\n",
      "        [25.0792, 30.0124],\n",
      "        [27.7584, 27.7213]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9950, 0.8265, 0.0868, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8620, 29.8367],\n",
      "        [31.4846, 26.2218],\n",
      "        [25.0806, 30.0122],\n",
      "        [27.7593, 27.7212]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9950, 0.8276, 0.0868, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8618, 29.8372],\n",
      "        [31.4823, 26.2263],\n",
      "        [25.0801, 30.0131],\n",
      "        [27.7590, 27.7218]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9950, 0.8276, 0.0868, 0.9578], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8625, 29.8371],\n",
      "        [31.4881, 26.2257],\n",
      "        [25.0814, 30.0130],\n",
      "        [27.7599, 27.7218]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9950, 0.8286, 0.0868, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8622, 29.8376],\n",
      "        [31.4857, 26.2301],\n",
      "        [25.0809, 30.0139],\n",
      "        [27.7595, 27.7224]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9950, 0.8286, 0.0868, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8629, 29.8375],\n",
      "        [31.4915, 26.2296],\n",
      "        [25.0822, 30.0137],\n",
      "        [27.7604, 27.7223]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9950, 0.8296, 0.0869, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8627, 29.8380],\n",
      "        [31.4892, 26.2340],\n",
      "        [25.0817, 30.0146],\n",
      "        [27.7601, 27.7229]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9950, 0.8296, 0.0869, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8633, 29.8379],\n",
      "        [31.4949, 26.2334],\n",
      "        [25.0830, 30.0144],\n",
      "        [27.7609, 27.7228]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9950, 0.8307, 0.0869, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8631, 29.8383],\n",
      "        [31.4925, 26.2377],\n",
      "        [25.0825, 30.0153],\n",
      "        [27.7606, 27.7234]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9950, 0.8307, 0.0869, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8638, 29.8383],\n",
      "        [31.4982, 26.2372],\n",
      "        [25.0838, 30.0152],\n",
      "        [27.7615, 27.7234]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9950, 0.8317, 0.0870, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8635, 29.8387],\n",
      "        [31.4959, 26.2415],\n",
      "        [25.0833, 30.0160],\n",
      "        [27.7612, 27.7239]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9950, 0.8317, 0.0870, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8642, 29.8387],\n",
      "        [31.5015, 26.2410],\n",
      "        [25.0846, 30.0159],\n",
      "        [27.7620, 27.7239]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9950, 0.8327, 0.0870, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8640, 29.8392],\n",
      "        [31.4992, 26.2452],\n",
      "        [25.0841, 30.0167],\n",
      "        [27.7617, 27.7245]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9950, 0.8327, 0.0870, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8646, 29.8391],\n",
      "        [31.5047, 26.2447],\n",
      "        [25.0854, 30.0166],\n",
      "        [27.7626, 27.7244]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9951, 0.8337, 0.0871, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8644, 29.8395],\n",
      "        [31.5025, 26.2489],\n",
      "        [25.0849, 30.0174],\n",
      "        [27.7623, 27.7250]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9951, 0.8337, 0.0871, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8650, 29.8395],\n",
      "        [31.5079, 26.2484],\n",
      "        [25.0862, 30.0173],\n",
      "        [27.7631, 27.7249]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9951, 0.8347, 0.0871, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8648, 29.8399],\n",
      "        [31.5057, 26.2526],\n",
      "        [25.0857, 30.0181],\n",
      "        [27.7628, 27.7255]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9951, 0.8347, 0.0871, 0.9579], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8654, 29.8399],\n",
      "        [31.5111, 26.2521],\n",
      "        [25.0869, 30.0180],\n",
      "        [27.7636, 27.7254]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9951, 0.8357, 0.0872, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8652, 29.8403],\n",
      "        [31.5089, 26.2562],\n",
      "        [25.0865, 30.0188],\n",
      "        [27.7633, 27.7260]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9951, 0.8357, 0.0872, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8658, 29.8403],\n",
      "        [31.5143, 26.2557],\n",
      "        [25.0877, 30.0187],\n",
      "        [27.7642, 27.7259]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9951, 0.8367, 0.0872, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8656, 29.8407],\n",
      "        [31.5121, 26.2598],\n",
      "        [25.0872, 30.0195],\n",
      "        [27.7639, 27.7265]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9951, 0.8367, 0.0872, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8662, 29.8406],\n",
      "        [31.5174, 26.2593],\n",
      "        [25.0885, 30.0194],\n",
      "        [27.7646, 27.7264]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9951, 0.8376, 0.0873, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8660, 29.8411],\n",
      "        [31.5152, 26.2633],\n",
      "        [25.0880, 30.0202],\n",
      "        [27.7644, 27.7270]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9951, 0.8376, 0.0873, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8666, 29.8410],\n",
      "        [31.5204, 26.2628],\n",
      "        [25.0892, 30.0201],\n",
      "        [27.7652, 27.7269]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9951, 0.8386, 0.0873, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8664, 29.8414],\n",
      "        [31.5183, 26.2669],\n",
      "        [25.0888, 30.0209],\n",
      "        [27.7649, 27.7275]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9951, 0.8386, 0.0873, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8670, 29.8414],\n",
      "        [31.5235, 26.2664],\n",
      "        [25.0900, 30.0207],\n",
      "        [27.7657, 27.7275]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9951, 0.8395, 0.0873, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8668, 29.8418],\n",
      "        [31.5213, 26.2704],\n",
      "        [25.0895, 30.0216],\n",
      "        [27.7654, 27.7280]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9951, 0.8395, 0.0873, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8674, 29.8418],\n",
      "        [31.5265, 26.2699],\n",
      "        [25.0907, 30.0214],\n",
      "        [27.7662, 27.7279]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9951, 0.8404, 0.0874, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8672, 29.8422],\n",
      "        [31.5244, 26.2738],\n",
      "        [25.0903, 30.0222],\n",
      "        [27.7659, 27.7285]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9951, 0.8404, 0.0874, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8678, 29.8421],\n",
      "        [31.5295, 26.2734],\n",
      "        [25.0915, 30.0221],\n",
      "        [27.7667, 27.7284]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9951, 0.8414, 0.0874, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8676, 29.8426],\n",
      "        [31.5274, 26.2773],\n",
      "        [25.0910, 30.0229],\n",
      "        [27.7664, 27.7290]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9951, 0.8414, 0.0874, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8682, 29.8425],\n",
      "        [31.5324, 26.2768],\n",
      "        [25.0922, 30.0227],\n",
      "        [27.7672, 27.7289]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9951, 0.8423, 0.0875, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8680, 29.8429],\n",
      "        [31.5303, 26.2807],\n",
      "        [25.0917, 30.0235],\n",
      "        [27.7669, 27.7294]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9951, 0.8423, 0.0875, 0.9580], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8686, 29.8429],\n",
      "        [31.5353, 26.2802],\n",
      "        [25.0929, 30.0234],\n",
      "        [27.7677, 27.7294]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9951, 0.8432, 0.0875, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8684, 29.8433],\n",
      "        [31.5332, 26.2841],\n",
      "        [25.0925, 30.0242],\n",
      "        [27.7674, 27.7299]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9951, 0.8432, 0.0875, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8689, 29.8432],\n",
      "        [31.5382, 26.2836],\n",
      "        [25.0936, 30.0241],\n",
      "        [27.7682, 27.7299]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9951, 0.8441, 0.0876, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8688, 29.8436],\n",
      "        [31.5361, 26.2874],\n",
      "        [25.0932, 30.0248],\n",
      "        [27.7679, 27.7304]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9951, 0.8441, 0.0876, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8693, 29.8436],\n",
      "        [31.5410, 26.2870],\n",
      "        [25.0944, 30.0247],\n",
      "        [27.7687, 27.7303]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9952, 0.8450, 0.0876, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8691, 29.8440],\n",
      "        [31.5389, 26.2907],\n",
      "        [25.0939, 30.0255],\n",
      "        [27.7684, 27.7309]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9952, 0.8450, 0.0876, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8697, 29.8440],\n",
      "        [31.5438, 26.2903],\n",
      "        [25.0951, 30.0253],\n",
      "        [27.7691, 27.7308]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9952, 0.8458, 0.0877, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8695, 29.8444],\n",
      "        [31.5418, 26.2940],\n",
      "        [25.0946, 30.0261],\n",
      "        [27.7689, 27.7313]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9952, 0.8458, 0.0877, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8701, 29.8443],\n",
      "        [31.5466, 26.2936],\n",
      "        [25.0958, 30.0260],\n",
      "        [27.7696, 27.7313]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9952, 0.8467, 0.0877, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8699, 29.8447],\n",
      "        [31.5446, 26.2973],\n",
      "        [25.0953, 30.0267],\n",
      "        [27.7693, 27.7318]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9952, 0.8467, 0.0877, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8705, 29.8447],\n",
      "        [31.5493, 26.2968],\n",
      "        [25.0965, 30.0266],\n",
      "        [27.7701, 27.7317]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9952, 0.8476, 0.0877, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8703, 29.8451],\n",
      "        [31.5474, 26.3005],\n",
      "        [25.0960, 30.0274],\n",
      "        [27.7698, 27.7323]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9952, 0.8476, 0.0877, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8708, 29.8450],\n",
      "        [31.5520, 26.3001],\n",
      "        [25.0972, 30.0272],\n",
      "        [27.7706, 27.7322]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9952, 0.8484, 0.0878, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8706, 29.8454],\n",
      "        [31.5501, 26.3037],\n",
      "        [25.0967, 30.0280],\n",
      "        [27.7703, 27.7327]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9952, 0.8484, 0.0878, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8712, 29.8454],\n",
      "        [31.5548, 26.3033],\n",
      "        [25.0979, 30.0279],\n",
      "        [27.7710, 27.7327]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9952, 0.8493, 0.0878, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8710, 29.8457],\n",
      "        [31.5528, 26.3069],\n",
      "        [25.0974, 30.0286],\n",
      "        [27.7708, 27.7332]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9952, 0.8493, 0.0878, 0.9581], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8716, 29.8457],\n",
      "        [31.5574, 26.3065],\n",
      "        [25.0985, 30.0285],\n",
      "        [27.7715, 27.7331]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9952, 0.8501, 0.0879, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8714, 29.8461],\n",
      "        [31.5555, 26.3100],\n",
      "        [25.0981, 30.0292],\n",
      "        [27.7712, 27.7336]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9952, 0.8501, 0.0879, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8719, 29.8460],\n",
      "        [31.5600, 26.3096],\n",
      "        [25.0992, 30.0291],\n",
      "        [27.7719, 27.7336]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9952, 0.8509, 0.0879, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8718, 29.8464],\n",
      "        [31.5581, 26.3132],\n",
      "        [25.0988, 30.0298],\n",
      "        [27.7717, 27.7341]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9952, 0.8509, 0.0879, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8723, 29.8464],\n",
      "        [31.5626, 26.3127],\n",
      "        [25.0999, 30.0297],\n",
      "        [27.7724, 27.7340]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9952, 0.8518, 0.0880, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8721, 29.8468],\n",
      "        [31.5607, 26.3162],\n",
      "        [25.0995, 30.0304],\n",
      "        [27.7721, 27.7345]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9952, 0.8518, 0.0880, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8727, 29.8467],\n",
      "        [31.5652, 26.3158],\n",
      "        [25.1005, 30.0303],\n",
      "        [27.7729, 27.7345]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9952, 0.8526, 0.0880, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8725, 29.8471],\n",
      "        [31.5633, 26.3193],\n",
      "        [25.1001, 30.0310],\n",
      "        [27.7726, 27.7349]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9952, 0.8526, 0.0880, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8730, 29.8471],\n",
      "        [31.5678, 26.3189],\n",
      "        [25.1012, 30.0309],\n",
      "        [27.7733, 27.7349]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9952, 0.8534, 0.0880, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8728, 29.8475],\n",
      "        [31.5659, 26.3224],\n",
      "        [25.1008, 30.0316],\n",
      "        [27.7731, 27.7354]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9952, 0.8534, 0.0880, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8734, 29.8474],\n",
      "        [31.5703, 26.3220],\n",
      "        [25.1019, 30.0315],\n",
      "        [27.7738, 27.7353]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9952, 0.8542, 0.0881, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8732, 29.8478],\n",
      "        [31.5684, 26.3254],\n",
      "        [25.1014, 30.0322],\n",
      "        [27.7735, 27.7358]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9952, 0.8542, 0.0881, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8737, 29.8478],\n",
      "        [31.5728, 26.3250],\n",
      "        [25.1025, 30.0321],\n",
      "        [27.7742, 27.7358]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9953, 0.8550, 0.0881, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8735, 29.8481],\n",
      "        [31.5709, 26.3284],\n",
      "        [25.1021, 30.0328],\n",
      "        [27.7739, 27.7363]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9953, 0.8550, 0.0881, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8741, 29.8481],\n",
      "        [31.5752, 26.3280],\n",
      "        [25.1032, 30.0327],\n",
      "        [27.7746, 27.7362]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9953, 0.8557, 0.0882, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8739, 29.8484],\n",
      "        [31.5734, 26.3313],\n",
      "        [25.1028, 30.0334],\n",
      "        [27.7744, 27.7367]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9953, 0.8557, 0.0882, 0.9582], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8744, 29.8484],\n",
      "        [31.5777, 26.3309],\n",
      "        [25.1038, 30.0333],\n",
      "        [27.7751, 27.7366]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9953, 0.8565, 0.0882, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8742, 29.8488],\n",
      "        [31.5758, 26.3343],\n",
      "        [25.1034, 30.0340],\n",
      "        [27.7748, 27.7371]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9953, 0.8565, 0.0882, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8748, 29.8487],\n",
      "        [31.5801, 26.3339],\n",
      "        [25.1044, 30.0338],\n",
      "        [27.7755, 27.7370]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9953, 0.8573, 0.0882, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8746, 29.8491],\n",
      "        [31.5783, 26.3372],\n",
      "        [25.1040, 30.0345],\n",
      "        [27.7753, 27.7375]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9953, 0.8573, 0.0882, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8751, 29.8491],\n",
      "        [31.5825, 26.3368],\n",
      "        [25.1051, 30.0344],\n",
      "        [27.7759, 27.7375]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9953, 0.8581, 0.0883, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8749, 29.8494],\n",
      "        [31.5807, 26.3401],\n",
      "        [25.1047, 30.0351],\n",
      "        [27.7757, 27.7380]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9953, 0.8581, 0.0883, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8754, 29.8494],\n",
      "        [31.5848, 26.3397],\n",
      "        [25.1057, 30.0350],\n",
      "        [27.7764, 27.7379]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9953, 0.8588, 0.0883, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8753, 29.8497],\n",
      "        [31.5831, 26.3429],\n",
      "        [25.1053, 30.0357],\n",
      "        [27.7761, 27.7384]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9953, 0.8588, 0.0883, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8758, 29.8497],\n",
      "        [31.5872, 26.3426],\n",
      "        [25.1063, 30.0356],\n",
      "        [27.7768, 27.7383]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9953, 0.8596, 0.0884, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8756, 29.8500],\n",
      "        [31.5854, 26.3458],\n",
      "        [25.1059, 30.0362],\n",
      "        [27.7765, 27.7388]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9953, 0.8596, 0.0884, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8761, 29.8500],\n",
      "        [31.5895, 26.3454],\n",
      "        [25.1069, 30.0361],\n",
      "        [27.7772, 27.7387]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9953, 0.8603, 0.0884, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8760, 29.8504],\n",
      "        [31.5877, 26.3486],\n",
      "        [25.1066, 30.0368],\n",
      "        [27.7770, 27.7392]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9953, 0.8603, 0.0884, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8765, 29.8503],\n",
      "        [31.5918, 26.3483],\n",
      "        [25.1076, 30.0367],\n",
      "        [27.7776, 27.7391]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9953, 0.8610, 0.0885, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8763, 29.8507],\n",
      "        [31.5901, 26.3514],\n",
      "        [25.1072, 30.0374],\n",
      "        [27.7774, 27.7396]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9953, 0.8610, 0.0885, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8768, 29.8507],\n",
      "        [31.5941, 26.3510],\n",
      "        [25.1082, 30.0372],\n",
      "        [27.7780, 27.7395]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9953, 0.8617, 0.0885, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8766, 29.8510],\n",
      "        [31.5923, 26.3542],\n",
      "        [25.1078, 30.0379],\n",
      "        [27.7778, 27.7400]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9953, 0.8617, 0.0885, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8771, 29.8510],\n",
      "        [31.5963, 26.3538],\n",
      "        [25.1088, 30.0378],\n",
      "        [27.7785, 27.7400]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9953, 0.8625, 0.0885, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8769, 29.8513],\n",
      "        [31.5946, 26.3569],\n",
      "        [25.1084, 30.0384],\n",
      "        [27.7782, 27.7404]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9953, 0.8625, 0.0885, 0.9583], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8775, 29.8513],\n",
      "        [31.5985, 26.3566],\n",
      "        [25.1094, 30.0383],\n",
      "        [27.7789, 27.7404]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9953, 0.8632, 0.0886, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8773, 29.8516],\n",
      "        [31.5968, 26.3596],\n",
      "        [25.1090, 30.0390],\n",
      "        [27.7786, 27.7408]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9953, 0.8632, 0.0886, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8778, 29.8516],\n",
      "        [31.6007, 26.3593],\n",
      "        [25.1100, 30.0389],\n",
      "        [27.7793, 27.7408]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9953, 0.8639, 0.0886, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8776, 29.8519],\n",
      "        [31.5990, 26.3623],\n",
      "        [25.1096, 30.0395],\n",
      "        [27.7790, 27.7412]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9953, 0.8639, 0.0886, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8781, 29.8519],\n",
      "        [31.6029, 26.3620],\n",
      "        [25.1106, 30.0394],\n",
      "        [27.7797, 27.7411]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9954, 0.8646, 0.0887, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8779, 29.8522],\n",
      "        [31.6012, 26.3650],\n",
      "        [25.1102, 30.0400],\n",
      "        [27.7794, 27.7416]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9954, 0.8646, 0.0887, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8784, 29.8522],\n",
      "        [31.6050, 26.3647],\n",
      "        [25.1112, 30.0399],\n",
      "        [27.7801, 27.7415]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9954, 0.8653, 0.0887, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8783, 29.8525],\n",
      "        [31.6034, 26.3677],\n",
      "        [25.1108, 30.0406],\n",
      "        [27.7798, 27.7420]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9954, 0.8653, 0.0887, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8787, 29.8525],\n",
      "        [31.6072, 26.3674],\n",
      "        [25.1118, 30.0405],\n",
      "        [27.7805, 27.7419]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9954, 0.8660, 0.0887, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8786, 29.8528],\n",
      "        [31.6055, 26.3703],\n",
      "        [25.1114, 30.0411],\n",
      "        [27.7802, 27.7424]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9954, 0.8660, 0.0887, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8791, 29.8528],\n",
      "        [31.6093, 26.3700],\n",
      "        [25.1123, 30.0410],\n",
      "        [27.7809, 27.7423]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9954, 0.8666, 0.0888, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8789, 29.8531],\n",
      "        [31.6077, 26.3729],\n",
      "        [25.1120, 30.0416],\n",
      "        [27.7806, 27.7428]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9954, 0.8666, 0.0888, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8794, 29.8531],\n",
      "        [31.6114, 26.3726],\n",
      "        [25.1129, 30.0415],\n",
      "        [27.7813, 27.7427]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9954, 0.8673, 0.0888, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8792, 29.8534],\n",
      "        [31.6098, 26.3755],\n",
      "        [25.1125, 30.0421],\n",
      "        [27.7810, 27.7431]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9954, 0.8673, 0.0888, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8797, 29.8534],\n",
      "        [31.6135, 26.3752],\n",
      "        [25.1135, 30.0420],\n",
      "        [27.7816, 27.7431]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9954, 0.8680, 0.0889, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8795, 29.8537],\n",
      "        [31.6118, 26.3781],\n",
      "        [25.1131, 30.0426],\n",
      "        [27.7814, 27.7435]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9954, 0.8680, 0.0889, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8800, 29.8537],\n",
      "        [31.6155, 26.3778],\n",
      "        [25.1141, 30.0426],\n",
      "        [27.7820, 27.7435]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9954, 0.8686, 0.0889, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8798, 29.8540],\n",
      "        [31.6139, 26.3807],\n",
      "        [25.1137, 30.0432],\n",
      "        [27.7818, 27.7439]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9954, 0.8686, 0.0889, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8803, 29.8540],\n",
      "        [31.6175, 26.3804],\n",
      "        [25.1146, 30.0431],\n",
      "        [27.7824, 27.7439]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9954, 0.8693, 0.0889, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8802, 29.8543],\n",
      "        [31.6159, 26.3832],\n",
      "        [25.1143, 30.0437],\n",
      "        [27.7822, 27.7443]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9954, 0.8693, 0.0889, 0.9584], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8806, 29.8543],\n",
      "        [31.6195, 26.3829],\n",
      "        [25.1152, 30.0436],\n",
      "        [27.7828, 27.7442]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9954, 0.8700, 0.0890, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8805, 29.8546],\n",
      "        [31.6180, 26.3857],\n",
      "        [25.1148, 30.0442],\n",
      "        [27.7826, 27.7447]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9954, 0.8700, 0.0890, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8809, 29.8546],\n",
      "        [31.6215, 26.3854],\n",
      "        [25.1157, 30.0441],\n",
      "        [27.7832, 27.7446]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9954, 0.8706, 0.0890, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8808, 29.8549],\n",
      "        [31.6200, 26.3882],\n",
      "        [25.1154, 30.0447],\n",
      "        [27.7830, 27.7450]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9954, 0.8706, 0.0890, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8813, 29.8549],\n",
      "        [31.6235, 26.3879],\n",
      "        [25.1163, 30.0446],\n",
      "        [27.7836, 27.7450]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9954, 0.8712, 0.0891, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8811, 29.8552],\n",
      "        [31.6220, 26.3907],\n",
      "        [25.1160, 30.0452],\n",
      "        [27.7833, 27.7454]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9954, 0.8712, 0.0891, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8816, 29.8551],\n",
      "        [31.6254, 26.3904],\n",
      "        [25.1169, 30.0451],\n",
      "        [27.7839, 27.7453]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9954, 0.8719, 0.0891, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8814, 29.8555],\n",
      "        [31.6239, 26.3931],\n",
      "        [25.1165, 30.0457],\n",
      "        [27.7837, 27.7458]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9954, 0.8719, 0.0891, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8819, 29.8554],\n",
      "        [31.6274, 26.3928],\n",
      "        [25.1174, 30.0456],\n",
      "        [27.7843, 27.7457]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9954, 0.8725, 0.0891, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8817, 29.8558],\n",
      "        [31.6259, 26.3956],\n",
      "        [25.1171, 30.0462],\n",
      "        [27.7841, 27.7461]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9954, 0.8725, 0.0891, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8822, 29.8557],\n",
      "        [31.6293, 26.3953],\n",
      "        [25.1179, 30.0461],\n",
      "        [27.7847, 27.7461]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8731, 0.0892, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8820, 29.8560],\n",
      "        [31.6278, 26.3980],\n",
      "        [25.1176, 30.0466],\n",
      "        [27.7845, 27.7465]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8731, 0.0892, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8825, 29.8560],\n",
      "        [31.6312, 26.3977],\n",
      "        [25.1185, 30.0465],\n",
      "        [27.7850, 27.7464]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8737, 0.0892, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8823, 29.8563],\n",
      "        [31.6297, 26.4004],\n",
      "        [25.1181, 30.0471],\n",
      "        [27.7848, 27.7468]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8737, 0.0892, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8828, 29.8563],\n",
      "        [31.6330, 26.4001],\n",
      "        [25.1190, 30.0470],\n",
      "        [27.7854, 27.7468]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8743, 0.0893, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8826, 29.8566],\n",
      "        [31.6315, 26.4027],\n",
      "        [25.1187, 30.0476],\n",
      "        [27.7852, 27.7472]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8743, 0.0893, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8831, 29.8566],\n",
      "        [31.6349, 26.4025],\n",
      "        [25.1196, 30.0475],\n",
      "        [27.7858, 27.7472]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8750, 0.0893, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8829, 29.8569],\n",
      "        [31.6334, 26.4051],\n",
      "        [25.1192, 30.0481],\n",
      "        [27.7856, 27.7476]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8750, 0.0893, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8834, 29.8568],\n",
      "        [31.6367, 26.4048],\n",
      "        [25.1201, 30.0480],\n",
      "        [27.7861, 27.7475]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8756, 0.0893, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8832, 29.8571],\n",
      "        [31.6353, 26.4074],\n",
      "        [25.1198, 30.0486],\n",
      "        [27.7859, 27.7479]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8756, 0.0893, 0.9585], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8837, 29.8571],\n",
      "        [31.6386, 26.4072],\n",
      "        [25.1206, 30.0485],\n",
      "        [27.7865, 27.7479]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8762, 0.0894, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8835, 29.8574],\n",
      "        [31.6371, 26.4098],\n",
      "        [25.1203, 30.0490],\n",
      "        [27.7863, 27.7482]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8762, 0.0894, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8839, 29.8574],\n",
      "        [31.6403, 26.4095],\n",
      "        [25.1211, 30.0489],\n",
      "        [27.7868, 27.7482]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8767, 0.0894, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8838, 29.8577],\n",
      "        [31.6389, 26.4121],\n",
      "        [25.1208, 30.0495],\n",
      "        [27.7866, 27.7486]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8767, 0.0894, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8842, 29.8577],\n",
      "        [31.6421, 26.4118],\n",
      "        [25.1217, 30.0494],\n",
      "        [27.7872, 27.7486]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8773, 0.0894, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8841, 29.8580],\n",
      "        [31.6407, 26.4143],\n",
      "        [25.1213, 30.0500],\n",
      "        [27.7870, 27.7489]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8773, 0.0894, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8845, 29.8579],\n",
      "        [31.6439, 26.4141],\n",
      "        [25.1222, 30.0499],\n",
      "        [27.7875, 27.7489]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8779, 0.0895, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8844, 29.8582],\n",
      "        [31.6425, 26.4166],\n",
      "        [25.1219, 30.0504],\n",
      "        [27.7873, 27.7493]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8779, 0.0895, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8848, 29.8582],\n",
      "        [31.6457, 26.4163],\n",
      "        [25.1227, 30.0503],\n",
      "        [27.7879, 27.7492]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8785, 0.0895, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8846, 29.8585],\n",
      "        [31.6443, 26.4189],\n",
      "        [25.1224, 30.0509],\n",
      "        [27.7877, 27.7496]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8785, 0.0895, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8851, 29.8585],\n",
      "        [31.6474, 26.4186],\n",
      "        [25.1232, 30.0508],\n",
      "        [27.7882, 27.7496]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8791, 0.0896, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8849, 29.8588],\n",
      "        [31.6460, 26.4211],\n",
      "        [25.1229, 30.0513],\n",
      "        [27.7880, 27.7500]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8791, 0.0896, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8854, 29.8587],\n",
      "        [31.6491, 26.4208],\n",
      "        [25.1237, 30.0512],\n",
      "        [27.7886, 27.7499]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8796, 0.0896, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8852, 29.8590],\n",
      "        [31.6477, 26.4233],\n",
      "        [25.1234, 30.0518],\n",
      "        [27.7884, 27.7503]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8796, 0.0896, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8856, 29.8590],\n",
      "        [31.6508, 26.4231],\n",
      "        [25.1242, 30.0517],\n",
      "        [27.7889, 27.7503]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8802, 0.0896, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8855, 29.8593],\n",
      "        [31.6495, 26.4255],\n",
      "        [25.1239, 30.0522],\n",
      "        [27.7887, 27.7506]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8802, 0.0896, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8859, 29.8593],\n",
      "        [31.6525, 26.4253],\n",
      "        [25.1247, 30.0522],\n",
      "        [27.7893, 27.7506]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9955, 0.8807, 0.0897, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8858, 29.8596],\n",
      "        [31.6512, 26.4277],\n",
      "        [25.1244, 30.0527],\n",
      "        [27.7891, 27.7510]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9955, 0.8807, 0.0897, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8862, 29.8595],\n",
      "        [31.6542, 26.4274],\n",
      "        [25.1252, 30.0526],\n",
      "        [27.7896, 27.7509]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8813, 0.0897, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8861, 29.8598],\n",
      "        [31.6528, 26.4298],\n",
      "        [25.1249, 30.0531],\n",
      "        [27.7894, 27.7513]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8813, 0.0897, 0.9586], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8865, 29.8598],\n",
      "        [31.6558, 26.4296],\n",
      "        [25.1257, 30.0530],\n",
      "        [27.7899, 27.7513]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8818, 0.0897, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8863, 29.8601],\n",
      "        [31.6545, 26.4320],\n",
      "        [25.1254, 30.0536],\n",
      "        [27.7897, 27.7516]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8818, 0.0897, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8868, 29.8600],\n",
      "        [31.6575, 26.4318],\n",
      "        [25.1262, 30.0535],\n",
      "        [27.7903, 27.7516]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8824, 0.0898, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8866, 29.8603],\n",
      "        [31.6562, 26.4341],\n",
      "        [25.1259, 30.0540],\n",
      "        [27.7901, 27.7520]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8824, 0.0898, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8870, 29.8603],\n",
      "        [31.6591, 26.4339],\n",
      "        [25.1267, 30.0539],\n",
      "        [27.7906, 27.7519]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8829, 0.0898, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8869, 29.8606],\n",
      "        [31.6578, 26.4362],\n",
      "        [25.1264, 30.0544],\n",
      "        [27.7904, 27.7523]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8829, 0.0898, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8873, 29.8606],\n",
      "        [31.6607, 26.4360],\n",
      "        [25.1272, 30.0544],\n",
      "        [27.7909, 27.7522]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8834, 0.0899, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8872, 29.8609],\n",
      "        [31.6594, 26.4383],\n",
      "        [25.1269, 30.0549],\n",
      "        [27.7907, 27.7526]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8834, 0.0899, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8876, 29.8608],\n",
      "        [31.6623, 26.4381],\n",
      "        [25.1277, 30.0548],\n",
      "        [27.7913, 27.7526]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8840, 0.0899, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8874, 29.8611],\n",
      "        [31.6610, 26.4404],\n",
      "        [25.1274, 30.0553],\n",
      "        [27.7911, 27.7529]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8840, 0.0899, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8878, 29.8611],\n",
      "        [31.6639, 26.4402],\n",
      "        [25.1281, 30.0552],\n",
      "        [27.7916, 27.7529]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8845, 0.0899, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8877, 29.8614],\n",
      "        [31.6626, 26.4425],\n",
      "        [25.1278, 30.0557],\n",
      "        [27.7914, 27.7533]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8845, 0.0899, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8881, 29.8613],\n",
      "        [31.6655, 26.4423],\n",
      "        [25.1286, 30.0556],\n",
      "        [27.7919, 27.7532]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8850, 0.0900, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8880, 29.8616],\n",
      "        [31.6642, 26.4445],\n",
      "        [25.1283, 30.0562],\n",
      "        [27.7917, 27.7536]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8850, 0.0900, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8884, 29.8616],\n",
      "        [31.6670, 26.4443],\n",
      "        [25.1291, 30.0561],\n",
      "        [27.7922, 27.7535]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8855, 0.0900, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8882, 29.8619],\n",
      "        [31.6657, 26.4466],\n",
      "        [25.1288, 30.0566],\n",
      "        [27.7920, 27.7539]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8855, 0.0900, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8886, 29.8618],\n",
      "        [31.6686, 26.4464],\n",
      "        [25.1296, 30.0565],\n",
      "        [27.7925, 27.7538]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8860, 0.0900, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8885, 29.8621],\n",
      "        [31.6673, 26.4486],\n",
      "        [25.1293, 30.0570],\n",
      "        [27.7924, 27.7542]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8860, 0.0900, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8889, 29.8621],\n",
      "        [31.6701, 26.4484],\n",
      "        [25.1300, 30.0569],\n",
      "        [27.7929, 27.7542]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8865, 0.0901, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8888, 29.8624],\n",
      "        [31.6688, 26.4506],\n",
      "        [25.1297, 30.0574],\n",
      "        [27.7927, 27.7545]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8865, 0.0901, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8892, 29.8623],\n",
      "        [31.6716, 26.4504],\n",
      "        [25.1305, 30.0573],\n",
      "        [27.7932, 27.7545]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8870, 0.0901, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8890, 29.8626],\n",
      "        [31.6704, 26.4526],\n",
      "        [25.1302, 30.0578],\n",
      "        [27.7930, 27.7548]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8870, 0.0901, 0.9587], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8894, 29.8626],\n",
      "        [31.6731, 26.4524],\n",
      "        [25.1310, 30.0578],\n",
      "        [27.7935, 27.7548]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8875, 0.0901, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8893, 29.8628],\n",
      "        [31.6719, 26.4546],\n",
      "        [25.1307, 30.0583],\n",
      "        [27.7933, 27.7551]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8875, 0.0901, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8897, 29.8628],\n",
      "        [31.6746, 26.4544],\n",
      "        [25.1314, 30.0582],\n",
      "        [27.7938, 27.7551]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9956, 0.8880, 0.0902, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8896, 29.8631],\n",
      "        [31.6734, 26.4565],\n",
      "        [25.1311, 30.0587],\n",
      "        [27.7936, 27.7554]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9956, 0.8880, 0.0902, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8899, 29.8630],\n",
      "        [31.6761, 26.4563],\n",
      "        [25.1319, 30.0586],\n",
      "        [27.7941, 27.7554]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8885, 0.0902, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8898, 29.8633],\n",
      "        [31.6748, 26.4585],\n",
      "        [25.1316, 30.0591],\n",
      "        [27.7939, 27.7557]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8885, 0.0902, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8902, 29.8633],\n",
      "        [31.6775, 26.4583],\n",
      "        [25.1323, 30.0590],\n",
      "        [27.7944, 27.7557]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8890, 0.0903, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8901, 29.8636],\n",
      "        [31.6763, 26.4604],\n",
      "        [25.1321, 30.0595],\n",
      "        [27.7943, 27.7560]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8890, 0.0903, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8905, 29.8635],\n",
      "        [31.6790, 26.4602],\n",
      "        [25.1328, 30.0594],\n",
      "        [27.7947, 27.7560]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8895, 0.0903, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8903, 29.8638],\n",
      "        [31.6778, 26.4624],\n",
      "        [25.1325, 30.0599],\n",
      "        [27.7946, 27.7563]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8895, 0.0903, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8907, 29.8638],\n",
      "        [31.6804, 26.4622],\n",
      "        [25.1333, 30.0598],\n",
      "        [27.7951, 27.7563]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8900, 0.0903, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8906, 29.8640],\n",
      "        [31.6792, 26.4643],\n",
      "        [25.1330, 30.0603],\n",
      "        [27.7949, 27.7566]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8900, 0.0903, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8910, 29.8640],\n",
      "        [31.6818, 26.4641],\n",
      "        [25.1337, 30.0602],\n",
      "        [27.7954, 27.7566]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8905, 0.0904, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8908, 29.8643],\n",
      "        [31.6806, 26.4661],\n",
      "        [25.1334, 30.0607],\n",
      "        [27.7952, 27.7569]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8905, 0.0904, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8912, 29.8643],\n",
      "        [31.6833, 26.4660],\n",
      "        [25.1342, 30.0606],\n",
      "        [27.7957, 27.7569]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8909, 0.0904, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8911, 29.8645],\n",
      "        [31.6820, 26.4680],\n",
      "        [25.1339, 30.0611],\n",
      "        [27.7955, 27.7572]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8909, 0.0904, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8915, 29.8645],\n",
      "        [31.6846, 26.4678],\n",
      "        [25.1346, 30.0610],\n",
      "        [27.7960, 27.7572]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8914, 0.0904, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8913, 29.8648],\n",
      "        [31.6835, 26.4699],\n",
      "        [25.1343, 30.0615],\n",
      "        [27.7958, 27.7575]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8914, 0.0904, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8917, 29.8647],\n",
      "        [31.6860, 26.4697],\n",
      "        [25.1350, 30.0614],\n",
      "        [27.7963, 27.7575]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8919, 0.0905, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8916, 29.8650],\n",
      "        [31.6848, 26.4717],\n",
      "        [25.1348, 30.0618],\n",
      "        [27.7961, 27.7578]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8919, 0.0905, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8920, 29.8650],\n",
      "        [31.6874, 26.4716],\n",
      "        [25.1355, 30.0618],\n",
      "        [27.7966, 27.7578]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8923, 0.0905, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8918, 29.8652],\n",
      "        [31.6862, 26.4736],\n",
      "        [25.1352, 30.0622],\n",
      "        [27.7964, 27.7581]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8923, 0.0905, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8922, 29.8652],\n",
      "        [31.6888, 26.4734],\n",
      "        [25.1359, 30.0622],\n",
      "        [27.7969, 27.7581]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8928, 0.0905, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8921, 29.8655],\n",
      "        [31.6876, 26.4754],\n",
      "        [25.1356, 30.0626],\n",
      "        [27.7967, 27.7584]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8928, 0.0905, 0.9588], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8925, 29.8654],\n",
      "        [31.6901, 26.4752],\n",
      "        [25.1363, 30.0625],\n",
      "        [27.7971, 27.7584]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8932, 0.0906, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8923, 29.8657],\n",
      "        [31.6889, 26.4772],\n",
      "        [25.1360, 30.0630],\n",
      "        [27.7970, 27.7587]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8932, 0.0906, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8927, 29.8657],\n",
      "        [31.6914, 26.4770],\n",
      "        [25.1368, 30.0629],\n",
      "        [27.7974, 27.7587]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8937, 0.0906, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8926, 29.8659],\n",
      "        [31.6903, 26.4790],\n",
      "        [25.1365, 30.0634],\n",
      "        [27.7973, 27.7590]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8937, 0.0906, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8930, 29.8659],\n",
      "        [31.6928, 26.4788],\n",
      "        [25.1372, 30.0633],\n",
      "        [27.7977, 27.7589]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8941, 0.0906, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8928, 29.8662],\n",
      "        [31.6917, 26.4808],\n",
      "        [25.1369, 30.0638],\n",
      "        [27.7976, 27.7593]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8941, 0.0906, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8932, 29.8661],\n",
      "        [31.6941, 26.4806],\n",
      "        [25.1376, 30.0637],\n",
      "        [27.7980, 27.7592]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8946, 0.0907, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8931, 29.8664],\n",
      "        [31.6930, 26.4826],\n",
      "        [25.1374, 30.0641],\n",
      "        [27.7978, 27.7595]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8946, 0.0907, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8934, 29.8663],\n",
      "        [31.6954, 26.4824],\n",
      "        [25.1381, 30.0641],\n",
      "        [27.7983, 27.7595]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9957, 0.8950, 0.0907, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8933, 29.8666],\n",
      "        [31.6943, 26.4843],\n",
      "        [25.1378, 30.0645],\n",
      "        [27.7981, 27.7598]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9957, 0.8950, 0.0907, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8937, 29.8666],\n",
      "        [31.6967, 26.4842],\n",
      "        [25.1385, 30.0644],\n",
      "        [27.7986, 27.7598]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.8954, 0.0908, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8936, 29.8668],\n",
      "        [31.6956, 26.4861],\n",
      "        [25.1382, 30.0649],\n",
      "        [27.7984, 27.7601]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.8954, 0.0908, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8939, 29.8668],\n",
      "        [31.6980, 26.4859],\n",
      "        [25.1389, 30.0648],\n",
      "        [27.7989, 27.7601]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.8959, 0.0908, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8938, 29.8671],\n",
      "        [31.6969, 26.4878],\n",
      "        [25.1386, 30.0653],\n",
      "        [27.7987, 27.7604]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.8959, 0.0908, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8942, 29.8670],\n",
      "        [31.6993, 26.4877],\n",
      "        [25.1393, 30.0652],\n",
      "        [27.7992, 27.7604]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.8963, 0.0908, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8940, 29.8673],\n",
      "        [31.6982, 26.4896],\n",
      "        [25.1390, 30.0656],\n",
      "        [27.7990, 27.7607]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.8963, 0.0908, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8944, 29.8673],\n",
      "        [31.7005, 26.4894],\n",
      "        [25.1397, 30.0655],\n",
      "        [27.7995, 27.7606]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.8967, 0.0909, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8943, 29.8675],\n",
      "        [31.6994, 26.4913],\n",
      "        [25.1395, 30.0660],\n",
      "        [27.7993, 27.7609]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.8967, 0.0909, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8946, 29.8675],\n",
      "        [31.7018, 26.4911],\n",
      "        [25.1402, 30.0659],\n",
      "        [27.7997, 27.7609]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.8972, 0.0909, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8945, 29.8677],\n",
      "        [31.7007, 26.4930],\n",
      "        [25.1399, 30.0663],\n",
      "        [27.7996, 27.7612]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.8972, 0.0909, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8949, 29.8677],\n",
      "        [31.7030, 26.4928],\n",
      "        [25.1406, 30.0663],\n",
      "        [27.8000, 27.7612]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.8976, 0.0909, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8947, 29.8679],\n",
      "        [31.7019, 26.4947],\n",
      "        [25.1403, 30.0667],\n",
      "        [27.7998, 27.7615]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.8976, 0.0909, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8951, 29.8679],\n",
      "        [31.7043, 26.4945],\n",
      "        [25.1410, 30.0666],\n",
      "        [27.8003, 27.7615]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.8980, 0.0910, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8950, 29.8682],\n",
      "        [31.7032, 26.4964],\n",
      "        [25.1407, 30.0671],\n",
      "        [27.8001, 27.7618]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.8980, 0.0910, 0.9589], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8953, 29.8681],\n",
      "        [31.7055, 26.4962],\n",
      "        [25.1414, 30.0670],\n",
      "        [27.8005, 27.7617]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.8984, 0.0910, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8952, 29.8684],\n",
      "        [31.7044, 26.4980],\n",
      "        [25.1411, 30.0674],\n",
      "        [27.8004, 27.7620]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.8984, 0.0910, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8956, 29.8684],\n",
      "        [31.7067, 26.4979],\n",
      "        [25.1418, 30.0674],\n",
      "        [27.8008, 27.7620]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.8988, 0.0910, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8954, 29.8686],\n",
      "        [31.7056, 26.4997],\n",
      "        [25.1415, 30.0678],\n",
      "        [27.8007, 27.7623]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.8988, 0.0910, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8958, 29.8686],\n",
      "        [31.7079, 26.4995],\n",
      "        [25.1422, 30.0677],\n",
      "        [27.8011, 27.7623]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.8992, 0.0911, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8957, 29.8688],\n",
      "        [31.7068, 26.5013],\n",
      "        [25.1419, 30.0681],\n",
      "        [27.8009, 27.7626]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.8992, 0.0911, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8960, 29.8688],\n",
      "        [31.7091, 26.5012],\n",
      "        [25.1426, 30.0681],\n",
      "        [27.8014, 27.7625]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.8996, 0.0911, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8959, 29.8690],\n",
      "        [31.7080, 26.5029],\n",
      "        [25.1423, 30.0685],\n",
      "        [27.8012, 27.7628]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.8996, 0.0911, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8963, 29.8690],\n",
      "        [31.7103, 26.5028],\n",
      "        [25.1430, 30.0684],\n",
      "        [27.8016, 27.7628]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.9000, 0.0911, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8961, 29.8692],\n",
      "        [31.7092, 26.5046],\n",
      "        [25.1427, 30.0688],\n",
      "        [27.8015, 27.7631]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.9000, 0.0911, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8965, 29.8692],\n",
      "        [31.7114, 26.5044],\n",
      "        [25.1434, 30.0688],\n",
      "        [27.8019, 27.7631]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.9004, 0.0912, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8964, 29.8694],\n",
      "        [31.7104, 26.5062],\n",
      "        [25.1431, 30.0692],\n",
      "        [27.8017, 27.7633]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.9004, 0.0912, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8967, 29.8694],\n",
      "        [31.7126, 26.5060],\n",
      "        [25.1438, 30.0691],\n",
      "        [27.8022, 27.7633]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.9008, 0.0912, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8966, 29.8697],\n",
      "        [31.7116, 26.5078],\n",
      "        [25.1435, 30.0695],\n",
      "        [27.8020, 27.7636]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.9008, 0.0912, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8969, 29.8696],\n",
      "        [31.7138, 26.5076],\n",
      "        [25.1442, 30.0694],\n",
      "        [27.8024, 27.7636]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9958, 0.9012, 0.0912, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8968, 29.8699],\n",
      "        [31.7127, 26.5094],\n",
      "        [25.1439, 30.0699],\n",
      "        [27.8023, 27.7639]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9958, 0.9012, 0.0912, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8972, 29.8699],\n",
      "        [31.7149, 26.5092],\n",
      "        [25.1446, 30.0698],\n",
      "        [27.8027, 27.7639]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9016, 0.0913, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8971, 29.8701],\n",
      "        [31.7139, 26.5110],\n",
      "        [25.1443, 30.0702],\n",
      "        [27.8026, 27.7641]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9016, 0.0913, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8974, 29.8701],\n",
      "        [31.7160, 26.5108],\n",
      "        [25.1449, 30.0701],\n",
      "        [27.8030, 27.7641]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9020, 0.0913, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8973, 29.8703],\n",
      "        [31.7150, 26.5125],\n",
      "        [25.1447, 30.0705],\n",
      "        [27.8028, 27.7644]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9020, 0.0913, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8976, 29.8703],\n",
      "        [31.7172, 26.5124],\n",
      "        [25.1453, 30.0705],\n",
      "        [27.8032, 27.7644]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9024, 0.0913, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8975, 29.8705],\n",
      "        [31.7162, 26.5141],\n",
      "        [25.1451, 30.0709],\n",
      "        [27.8031, 27.7646]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9024, 0.0913, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8978, 29.8705],\n",
      "        [31.7183, 26.5139],\n",
      "        [25.1457, 30.0708],\n",
      "        [27.8035, 27.7646]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9027, 0.0914, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8977, 29.8707],\n",
      "        [31.7173, 26.5156],\n",
      "        [25.1455, 30.0712],\n",
      "        [27.8033, 27.7649]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9027, 0.0914, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8981, 29.8707],\n",
      "        [31.7194, 26.5155],\n",
      "        [25.1461, 30.0712],\n",
      "        [27.8038, 27.7649]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9031, 0.0914, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8979, 29.8709],\n",
      "        [31.7184, 26.5172],\n",
      "        [25.1458, 30.0716],\n",
      "        [27.8036, 27.7652]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9031, 0.0914, 0.9590], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8983, 29.8709],\n",
      "        [31.7205, 26.5170],\n",
      "        [25.1465, 30.0715],\n",
      "        [27.8040, 27.7651]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9035, 0.0914, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8982, 29.8711],\n",
      "        [31.7195, 26.5187],\n",
      "        [25.1463, 30.0719],\n",
      "        [27.8039, 27.7654]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9035, 0.0914, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8985, 29.8711],\n",
      "        [31.7216, 26.5185],\n",
      "        [25.1469, 30.0718],\n",
      "        [27.8043, 27.7654]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9039, 0.0915, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8984, 29.8713],\n",
      "        [31.7206, 26.5202],\n",
      "        [25.1466, 30.0722],\n",
      "        [27.8041, 27.7657]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9039, 0.0915, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8987, 29.8713],\n",
      "        [31.7227, 26.5201],\n",
      "        [25.1472, 30.0721],\n",
      "        [27.8045, 27.7656]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9042, 0.0915, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8986, 29.8715],\n",
      "        [31.7217, 26.5217],\n",
      "        [25.1470, 30.0726],\n",
      "        [27.8044, 27.7659]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9042, 0.0915, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8989, 29.8715],\n",
      "        [31.7237, 26.5216],\n",
      "        [25.1476, 30.0725],\n",
      "        [27.8048, 27.7659]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9046, 0.0915, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8988, 29.8717],\n",
      "        [31.7228, 26.5232],\n",
      "        [25.1474, 30.0729],\n",
      "        [27.8046, 27.7662]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9046, 0.0915, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8992, 29.8717],\n",
      "        [31.7248, 26.5231],\n",
      "        [25.1480, 30.0728],\n",
      "        [27.8050, 27.7661]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9050, 0.0916, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8990, 29.8719],\n",
      "        [31.7239, 26.5247],\n",
      "        [25.1477, 30.0732],\n",
      "        [27.8049, 27.7664]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9050, 0.0916, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8994, 29.8719],\n",
      "        [31.7259, 26.5246],\n",
      "        [25.1484, 30.0731],\n",
      "        [27.8053, 27.7664]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9053, 0.0916, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8992, 29.8721],\n",
      "        [31.7249, 26.5262],\n",
      "        [25.1481, 30.0735],\n",
      "        [27.8051, 27.7666]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9053, 0.0916, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8996, 29.8721],\n",
      "        [31.7269, 26.5261],\n",
      "        [25.1487, 30.0735],\n",
      "        [27.8055, 27.7666]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9057, 0.0916, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8995, 29.8723],\n",
      "        [31.7260, 26.5277],\n",
      "        [25.1485, 30.0739],\n",
      "        [27.8054, 27.7669]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9057, 0.0916, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.8998, 29.8723],\n",
      "        [31.7280, 26.5275],\n",
      "        [25.1491, 30.0738],\n",
      "        [27.8058, 27.7669]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9060, 0.0917, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8997, 29.8725],\n",
      "        [31.7270, 26.5291],\n",
      "        [25.1489, 30.0742],\n",
      "        [27.8056, 27.7671]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9060, 0.0917, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9000, 29.8725],\n",
      "        [31.7290, 26.5290],\n",
      "        [25.1495, 30.0741],\n",
      "        [27.8060, 27.7671]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9064, 0.0917, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.8999, 29.8727],\n",
      "        [31.7281, 26.5306],\n",
      "        [25.1492, 30.0745],\n",
      "        [27.8059, 27.7674]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9064, 0.0917, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9002, 29.8727],\n",
      "        [31.7301, 26.5304],\n",
      "        [25.1499, 30.0744],\n",
      "        [27.8063, 27.7674]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9068, 0.0917, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9001, 29.8729],\n",
      "        [31.7291, 26.5320],\n",
      "        [25.1496, 30.0748],\n",
      "        [27.8061, 27.7676]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9068, 0.0917, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9004, 29.8729],\n",
      "        [31.7311, 26.5319],\n",
      "        [25.1502, 30.0747],\n",
      "        [27.8065, 27.7676]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9071, 0.0918, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9003, 29.8731],\n",
      "        [31.7301, 26.5334],\n",
      "        [25.1500, 30.0751],\n",
      "        [27.8064, 27.7679]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9071, 0.0918, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9006, 29.8731],\n",
      "        [31.7321, 26.5333],\n",
      "        [25.1506, 30.0750],\n",
      "        [27.8068, 27.7678]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9959, 0.9074, 0.0918, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9005, 29.8733],\n",
      "        [31.7312, 26.5349],\n",
      "        [25.1503, 30.0754],\n",
      "        [27.8066, 27.7681]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9959, 0.9074, 0.0918, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9008, 29.8733],\n",
      "        [31.7331, 26.5347],\n",
      "        [25.1509, 30.0754],\n",
      "        [27.8070, 27.7681]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9078, 0.0918, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9007, 29.8735],\n",
      "        [31.7322, 26.5363],\n",
      "        [25.1507, 30.0757],\n",
      "        [27.8069, 27.7683]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9078, 0.0918, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9010, 29.8735],\n",
      "        [31.7341, 26.5361],\n",
      "        [25.1513, 30.0757],\n",
      "        [27.8073, 27.7683]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9081, 0.0919, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9009, 29.8737],\n",
      "        [31.7332, 26.5377],\n",
      "        [25.1510, 30.0760],\n",
      "        [27.8071, 27.7686]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9081, 0.0919, 0.9591], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9013, 29.8737],\n",
      "        [31.7351, 26.5376],\n",
      "        [25.1516, 30.0760],\n",
      "        [27.8075, 27.7686]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9085, 0.0919, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9011, 29.8739],\n",
      "        [31.7342, 26.5391],\n",
      "        [25.1514, 30.0764],\n",
      "        [27.8073, 27.7688]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9085, 0.0919, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9015, 29.8739],\n",
      "        [31.7360, 26.5389],\n",
      "        [25.1520, 30.0763],\n",
      "        [27.8077, 27.7688]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9088, 0.0919, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9013, 29.8741],\n",
      "        [31.7352, 26.5405],\n",
      "        [25.1518, 30.0767],\n",
      "        [27.8076, 27.7691]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9088, 0.0919, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9017, 29.8741],\n",
      "        [31.7370, 26.5403],\n",
      "        [25.1523, 30.0766],\n",
      "        [27.8080, 27.7690]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9091, 0.0920, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9015, 29.8743],\n",
      "        [31.7361, 26.5418],\n",
      "        [25.1521, 30.0770],\n",
      "        [27.8078, 27.7693]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9091, 0.0920, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9019, 29.8743],\n",
      "        [31.7380, 26.5417],\n",
      "        [25.1527, 30.0769],\n",
      "        [27.8082, 27.7693]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9095, 0.0920, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9018, 29.8745],\n",
      "        [31.7371, 26.5432],\n",
      "        [25.1525, 30.0773],\n",
      "        [27.8081, 27.7695]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9095, 0.0920, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9021, 29.8745],\n",
      "        [31.7390, 26.5431],\n",
      "        [25.1531, 30.0772],\n",
      "        [27.8085, 27.7695]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9098, 0.0920, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9019, 29.8747],\n",
      "        [31.7381, 26.5446],\n",
      "        [25.1528, 30.0776],\n",
      "        [27.8083, 27.7697]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9098, 0.0920, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9023, 29.8747],\n",
      "        [31.7399, 26.5445],\n",
      "        [25.1534, 30.0775],\n",
      "        [27.8087, 27.7697]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9101, 0.0920, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9022, 29.8749],\n",
      "        [31.7390, 26.5459],\n",
      "        [25.1532, 30.0779],\n",
      "        [27.8085, 27.7700]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9101, 0.0920, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9025, 29.8748],\n",
      "        [31.7409, 26.5458],\n",
      "        [25.1538, 30.0778],\n",
      "        [27.8089, 27.7700]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9105, 0.0921, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9024, 29.8750],\n",
      "        [31.7400, 26.5473],\n",
      "        [25.1535, 30.0782],\n",
      "        [27.8088, 27.7702]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9105, 0.0921, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9027, 29.8750],\n",
      "        [31.7418, 26.5471],\n",
      "        [25.1541, 30.0781],\n",
      "        [27.8091, 27.7702]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9108, 0.0921, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9026, 29.8752],\n",
      "        [31.7409, 26.5486],\n",
      "        [25.1539, 30.0785],\n",
      "        [27.8090, 27.7704]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9108, 0.0921, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9029, 29.8752],\n",
      "        [31.7427, 26.5485],\n",
      "        [25.1544, 30.0784],\n",
      "        [27.8094, 27.7704]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9111, 0.0921, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9028, 29.8754],\n",
      "        [31.7419, 26.5499],\n",
      "        [25.1542, 30.0788],\n",
      "        [27.8092, 27.7707]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9111, 0.0921, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9031, 29.8754],\n",
      "        [31.7437, 26.5498],\n",
      "        [25.1548, 30.0787],\n",
      "        [27.8096, 27.7706]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9114, 0.0922, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9029, 29.8756],\n",
      "        [31.7428, 26.5512],\n",
      "        [25.1546, 30.0791],\n",
      "        [27.8095, 27.7709]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9114, 0.0922, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9033, 29.8756],\n",
      "        [31.7446, 26.5511],\n",
      "        [25.1551, 30.0790],\n",
      "        [27.8098, 27.7709]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9117, 0.0922, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9032, 29.8758],\n",
      "        [31.7437, 26.5526],\n",
      "        [25.1549, 30.0794],\n",
      "        [27.8097, 27.7711]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9117, 0.0922, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9035, 29.8758],\n",
      "        [31.7455, 26.5524],\n",
      "        [25.1555, 30.0793],\n",
      "        [27.8101, 27.7711]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9121, 0.0922, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9034, 29.8760],\n",
      "        [31.7447, 26.5539],\n",
      "        [25.1552, 30.0797],\n",
      "        [27.8099, 27.7713]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9121, 0.0922, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9037, 29.8759],\n",
      "        [31.7464, 26.5537],\n",
      "        [25.1558, 30.0796],\n",
      "        [27.8103, 27.7713]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9124, 0.0923, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9036, 29.8762],\n",
      "        [31.7456, 26.5552],\n",
      "        [25.1556, 30.0800],\n",
      "        [27.8102, 27.7716]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9124, 0.0923, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9039, 29.8761],\n",
      "        [31.7473, 26.5550],\n",
      "        [25.1561, 30.0799],\n",
      "        [27.8105, 27.7715]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9127, 0.0923, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9037, 29.8763],\n",
      "        [31.7465, 26.5564],\n",
      "        [25.1559, 30.0802],\n",
      "        [27.8104, 27.7718]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9127, 0.0923, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9041, 29.8763],\n",
      "        [31.7482, 26.5563],\n",
      "        [25.1565, 30.0802],\n",
      "        [27.8107, 27.7718]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9960, 0.9130, 0.0923, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9039, 29.8765],\n",
      "        [31.7474, 26.5577],\n",
      "        [25.1563, 30.0805],\n",
      "        [27.8106, 27.7720]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9960, 0.9130, 0.0923, 0.9592], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9042, 29.8765],\n",
      "        [31.7491, 26.5576],\n",
      "        [25.1568, 30.0805],\n",
      "        [27.8110, 27.7720]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9133, 0.0924, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9041, 29.8767],\n",
      "        [31.7483, 26.5590],\n",
      "        [25.1566, 30.0808],\n",
      "        [27.8108, 27.7722]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9133, 0.0924, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9044, 29.8767],\n",
      "        [31.7500, 26.5589],\n",
      "        [25.1571, 30.0807],\n",
      "        [27.8112, 27.7722]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9136, 0.0924, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9043, 29.8769],\n",
      "        [31.7492, 26.5603],\n",
      "        [25.1569, 30.0811],\n",
      "        [27.8111, 27.7724]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9136, 0.0924, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9046, 29.8769],\n",
      "        [31.7508, 26.5601],\n",
      "        [25.1575, 30.0810],\n",
      "        [27.8114, 27.7724]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9139, 0.0924, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9045, 29.8771],\n",
      "        [31.7500, 26.5615],\n",
      "        [25.1573, 30.0814],\n",
      "        [27.8113, 27.7727]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9139, 0.0924, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9048, 29.8771],\n",
      "        [31.7517, 26.5614],\n",
      "        [25.1578, 30.0813],\n",
      "        [27.8116, 27.7726]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9142, 0.0925, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9047, 29.8773],\n",
      "        [31.7509, 26.5628],\n",
      "        [25.1576, 30.0817],\n",
      "        [27.8115, 27.7729]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9142, 0.0925, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9050, 29.8772],\n",
      "        [31.7526, 26.5627],\n",
      "        [25.1581, 30.0816],\n",
      "        [27.8118, 27.7728]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9145, 0.0925, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9049, 29.8774],\n",
      "        [31.7518, 26.5640],\n",
      "        [25.1579, 30.0819],\n",
      "        [27.8117, 27.7731]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9145, 0.0925, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9052, 29.8774],\n",
      "        [31.7534, 26.5639],\n",
      "        [25.1585, 30.0819],\n",
      "        [27.8121, 27.7731]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9148, 0.0925, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9051, 29.8776],\n",
      "        [31.7526, 26.5652],\n",
      "        [25.1582, 30.0822],\n",
      "        [27.8119, 27.7733]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9148, 0.0925, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9054, 29.8776],\n",
      "        [31.7543, 26.5651],\n",
      "        [25.1588, 30.0822],\n",
      "        [27.8123, 27.7733]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9151, 0.0925, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9053, 29.8778],\n",
      "        [31.7535, 26.5665],\n",
      "        [25.1586, 30.0825],\n",
      "        [27.8122, 27.7735]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9151, 0.0925, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9056, 29.8778],\n",
      "        [31.7551, 26.5664],\n",
      "        [25.1591, 30.0824],\n",
      "        [27.8125, 27.7735]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9154, 0.0926, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9055, 29.8780],\n",
      "        [31.7543, 26.5677],\n",
      "        [25.1589, 30.0828],\n",
      "        [27.8124, 27.7737]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9154, 0.0926, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9058, 29.8779],\n",
      "        [31.7560, 26.5676],\n",
      "        [25.1594, 30.0827],\n",
      "        [27.8127, 27.7737]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9157, 0.0926, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9057, 29.8781],\n",
      "        [31.7552, 26.5689],\n",
      "        [25.1592, 30.0831],\n",
      "        [27.8126, 27.7740]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9157, 0.0926, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9060, 29.8781],\n",
      "        [31.7568, 26.5688],\n",
      "        [25.1598, 30.0830],\n",
      "        [27.8130, 27.7739]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9160, 0.0926, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9058, 29.8783],\n",
      "        [31.7560, 26.5701],\n",
      "        [25.1595, 30.0833],\n",
      "        [27.8128, 27.7742]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9160, 0.0926, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9061, 29.8783],\n",
      "        [31.7576, 26.5700],\n",
      "        [25.1601, 30.0833],\n",
      "        [27.8132, 27.7741]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9162, 0.0927, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9060, 29.8785],\n",
      "        [31.7569, 26.5713],\n",
      "        [25.1599, 30.0836],\n",
      "        [27.8130, 27.7744]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9162, 0.0927, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9063, 29.8785],\n",
      "        [31.7585, 26.5712],\n",
      "        [25.1604, 30.0835],\n",
      "        [27.8134, 27.7743]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9165, 0.0927, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9062, 29.8787],\n",
      "        [31.7577, 26.5725],\n",
      "        [25.1602, 30.0839],\n",
      "        [27.8132, 27.7746]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9165, 0.0927, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9065, 29.8786],\n",
      "        [31.7593, 26.5724],\n",
      "        [25.1607, 30.0838],\n",
      "        [27.8136, 27.7746]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9168, 0.0927, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9064, 29.8788],\n",
      "        [31.7585, 26.5737],\n",
      "        [25.1605, 30.0841],\n",
      "        [27.8135, 27.7748]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9168, 0.0927, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9067, 29.8788],\n",
      "        [31.7601, 26.5736],\n",
      "        [25.1610, 30.0841],\n",
      "        [27.8138, 27.7748]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9171, 0.0928, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9066, 29.8790],\n",
      "        [31.7593, 26.5748],\n",
      "        [25.1608, 30.0844],\n",
      "        [27.8137, 27.7750]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9171, 0.0928, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9069, 29.8790],\n",
      "        [31.7609, 26.5748],\n",
      "        [25.1613, 30.0844],\n",
      "        [27.8140, 27.7750]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9174, 0.0928, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9068, 29.8792],\n",
      "        [31.7601, 26.5760],\n",
      "        [25.1611, 30.0847],\n",
      "        [27.8139, 27.7752]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9174, 0.0928, 0.9593], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9071, 29.8792],\n",
      "        [31.7617, 26.5759],\n",
      "        [25.1617, 30.0846],\n",
      "        [27.8142, 27.7752]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9176, 0.0928, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9070, 29.8793],\n",
      "        [31.7609, 26.5772],\n",
      "        [25.1615, 30.0849],\n",
      "        [27.8141, 27.7754]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9176, 0.0928, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9072, 29.8793],\n",
      "        [31.7625, 26.5771],\n",
      "        [25.1620, 30.0849],\n",
      "        [27.8144, 27.7754]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9179, 0.0929, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9071, 29.8795],\n",
      "        [31.7617, 26.5783],\n",
      "        [25.1618, 30.0852],\n",
      "        [27.8143, 27.7756]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9179, 0.0929, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9074, 29.8795],\n",
      "        [31.7633, 26.5782],\n",
      "        [25.1623, 30.0851],\n",
      "        [27.8146, 27.7756]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9961, 0.9182, 0.0929, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9073, 29.8797],\n",
      "        [31.7626, 26.5795],\n",
      "        [25.1621, 30.0855],\n",
      "        [27.8145, 27.7758]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9961, 0.9182, 0.0929, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9076, 29.8797],\n",
      "        [31.7641, 26.5794],\n",
      "        [25.1626, 30.0854],\n",
      "        [27.8148, 27.7758]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9185, 0.0929, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9075, 29.8798],\n",
      "        [31.7633, 26.5806],\n",
      "        [25.1624, 30.0857],\n",
      "        [27.8147, 27.7760]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9185, 0.0929, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9078, 29.8798],\n",
      "        [31.7649, 26.5805],\n",
      "        [25.1629, 30.0857],\n",
      "        [27.8151, 27.7760]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9187, 0.0929, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9077, 29.8800],\n",
      "        [31.7641, 26.5818],\n",
      "        [25.1627, 30.0860],\n",
      "        [27.8149, 27.7762]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9187, 0.0929, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9080, 29.8800],\n",
      "        [31.7656, 26.5817],\n",
      "        [25.1632, 30.0859],\n",
      "        [27.8153, 27.7762]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9190, 0.0930, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9079, 29.8802],\n",
      "        [31.7649, 26.5829],\n",
      "        [25.1630, 30.0863],\n",
      "        [27.8151, 27.7764]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9190, 0.0930, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9081, 29.8802],\n",
      "        [31.7664, 26.5828],\n",
      "        [25.1635, 30.0862],\n",
      "        [27.8155, 27.7764]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9193, 0.0930, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9080, 29.8804],\n",
      "        [31.7656, 26.5840],\n",
      "        [25.1633, 30.0865],\n",
      "        [27.8153, 27.7766]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9193, 0.0930, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9083, 29.8804],\n",
      "        [31.7672, 26.5839],\n",
      "        [25.1638, 30.0865],\n",
      "        [27.8157, 27.7766]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9195, 0.0930, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9082, 29.8805],\n",
      "        [31.7664, 26.5851],\n",
      "        [25.1636, 30.0868],\n",
      "        [27.8155, 27.7768]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9195, 0.0930, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9085, 29.8805],\n",
      "        [31.7679, 26.5851],\n",
      "        [25.1641, 30.0867],\n",
      "        [27.8159, 27.7768]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9198, 0.0931, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9084, 29.8807],\n",
      "        [31.7672, 26.5863],\n",
      "        [25.1639, 30.0870],\n",
      "        [27.8158, 27.7770]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9198, 0.0931, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9087, 29.8807],\n",
      "        [31.7687, 26.5862],\n",
      "        [25.1644, 30.0870],\n",
      "        [27.8161, 27.7770]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9201, 0.0931, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9086, 29.8808],\n",
      "        [31.7679, 26.5874],\n",
      "        [25.1642, 30.0873],\n",
      "        [27.8159, 27.7772]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9201, 0.0931, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9088, 29.8808],\n",
      "        [31.7694, 26.5873],\n",
      "        [25.1647, 30.0872],\n",
      "        [27.8163, 27.7772]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9203, 0.0931, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9087, 29.8810],\n",
      "        [31.7687, 26.5885],\n",
      "        [25.1645, 30.0875],\n",
      "        [27.8162, 27.7774]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9203, 0.0931, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9090, 29.8810],\n",
      "        [31.7702, 26.5884],\n",
      "        [25.1650, 30.0875],\n",
      "        [27.8165, 27.7774]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9206, 0.0931, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9089, 29.8812],\n",
      "        [31.7695, 26.5896],\n",
      "        [25.1648, 30.0878],\n",
      "        [27.8164, 27.7776]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9206, 0.0931, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9092, 29.8812],\n",
      "        [31.7709, 26.5895],\n",
      "        [25.1653, 30.0877],\n",
      "        [27.8167, 27.7776]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9208, 0.0932, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9091, 29.8814],\n",
      "        [31.7702, 26.5906],\n",
      "        [25.1651, 30.0881],\n",
      "        [27.8166, 27.7778]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9208, 0.0932, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9094, 29.8813],\n",
      "        [31.7716, 26.5905],\n",
      "        [25.1656, 30.0880],\n",
      "        [27.8169, 27.7778]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9211, 0.0932, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9093, 29.8815],\n",
      "        [31.7709, 26.5917],\n",
      "        [25.1654, 30.0883],\n",
      "        [27.8167, 27.7780]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9211, 0.0932, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9095, 29.8815],\n",
      "        [31.7724, 26.5916],\n",
      "        [25.1659, 30.0882],\n",
      "        [27.8171, 27.7780]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9214, 0.0932, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9095, 29.8817],\n",
      "        [31.7717, 26.5928],\n",
      "        [25.1657, 30.0886],\n",
      "        [27.8170, 27.7782]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9214, 0.0932, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9097, 29.8816],\n",
      "        [31.7731, 26.5927],\n",
      "        [25.1662, 30.0885],\n",
      "        [27.8173, 27.7782]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9216, 0.0933, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9096, 29.8818],\n",
      "        [31.7724, 26.5939],\n",
      "        [25.1660, 30.0888],\n",
      "        [27.8171, 27.7784]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9216, 0.0933, 0.9594], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9099, 29.8818],\n",
      "        [31.7738, 26.5938],\n",
      "        [25.1665, 30.0887],\n",
      "        [27.8175, 27.7784]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9219, 0.0933, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9098, 29.8820],\n",
      "        [31.7731, 26.5949],\n",
      "        [25.1663, 30.0890],\n",
      "        [27.8173, 27.7786]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9219, 0.0933, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9101, 29.8820],\n",
      "        [31.7745, 26.5948],\n",
      "        [25.1668, 30.0890],\n",
      "        [27.8177, 27.7786]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9221, 0.0933, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9100, 29.8822],\n",
      "        [31.7738, 26.5960],\n",
      "        [25.1666, 30.0893],\n",
      "        [27.8176, 27.7788]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9221, 0.0933, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9102, 29.8821],\n",
      "        [31.7752, 26.5959],\n",
      "        [25.1671, 30.0892],\n",
      "        [27.8179, 27.7788]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9224, 0.0934, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9101, 29.8823],\n",
      "        [31.7746, 26.5970],\n",
      "        [25.1669, 30.0895],\n",
      "        [27.8177, 27.7790]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9224, 0.0934, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9104, 29.8823],\n",
      "        [31.7760, 26.5969],\n",
      "        [25.1674, 30.0895],\n",
      "        [27.8181, 27.7790]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9226, 0.0934, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9103, 29.8825],\n",
      "        [31.7753, 26.5981],\n",
      "        [25.1672, 30.0898],\n",
      "        [27.8179, 27.7792]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9226, 0.0934, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9106, 29.8825],\n",
      "        [31.7767, 26.5980],\n",
      "        [25.1677, 30.0897],\n",
      "        [27.8183, 27.7792]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9228, 0.0934, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9105, 29.8826],\n",
      "        [31.7760, 26.5991],\n",
      "        [25.1675, 30.0900],\n",
      "        [27.8181, 27.7794]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9228, 0.0934, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9107, 29.8826],\n",
      "        [31.7773, 26.5990],\n",
      "        [25.1680, 30.0900],\n",
      "        [27.8184, 27.7793]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9962, 0.9231, 0.0934, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9106, 29.8828],\n",
      "        [31.7767, 26.6001],\n",
      "        [25.1678, 30.0903],\n",
      "        [27.8183, 27.7795]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9962, 0.9231, 0.0934, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9109, 29.8828],\n",
      "        [31.7781, 26.6001],\n",
      "        [25.1683, 30.0902],\n",
      "        [27.8186, 27.7795]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9233, 0.0935, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9108, 29.8829],\n",
      "        [31.7774, 26.6012],\n",
      "        [25.1680, 30.0905],\n",
      "        [27.8185, 27.7797]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9233, 0.0935, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9111, 29.8829],\n",
      "        [31.7787, 26.6011],\n",
      "        [25.1685, 30.0904],\n",
      "        [27.8188, 27.7797]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9236, 0.0935, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9110, 29.8831],\n",
      "        [31.7781, 26.6022],\n",
      "        [25.1683, 30.0907],\n",
      "        [27.8187, 27.7799]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9236, 0.0935, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9112, 29.8831],\n",
      "        [31.7794, 26.6021],\n",
      "        [25.1688, 30.0907],\n",
      "        [27.8190, 27.7799]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9238, 0.0935, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9111, 29.8833],\n",
      "        [31.7788, 26.6032],\n",
      "        [25.1686, 30.0910],\n",
      "        [27.8189, 27.7801]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9238, 0.0935, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9114, 29.8833],\n",
      "        [31.7801, 26.6031],\n",
      "        [25.1691, 30.0909],\n",
      "        [27.8192, 27.7801]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9240, 0.0936, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9113, 29.8834],\n",
      "        [31.7794, 26.6042],\n",
      "        [25.1689, 30.0912],\n",
      "        [27.8191, 27.7803]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9240, 0.0936, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9116, 29.8834],\n",
      "        [31.7808, 26.6041],\n",
      "        [25.1694, 30.0912],\n",
      "        [27.8194, 27.7803]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9243, 0.0936, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9115, 29.8836],\n",
      "        [31.7801, 26.6052],\n",
      "        [25.1692, 30.0915],\n",
      "        [27.8193, 27.7805]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9243, 0.0936, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9117, 29.8836],\n",
      "        [31.7815, 26.6051],\n",
      "        [25.1697, 30.0914],\n",
      "        [27.8196, 27.7805]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9245, 0.0936, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9116, 29.8837],\n",
      "        [31.7808, 26.6062],\n",
      "        [25.1695, 30.0917],\n",
      "        [27.8195, 27.7807]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9245, 0.0936, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9119, 29.8837],\n",
      "        [31.7821, 26.6061],\n",
      "        [25.1700, 30.0917],\n",
      "        [27.8198, 27.7807]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9248, 0.0936, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9118, 29.8839],\n",
      "        [31.7815, 26.6072],\n",
      "        [25.1698, 30.0919],\n",
      "        [27.8196, 27.7808]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9248, 0.0936, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9121, 29.8839],\n",
      "        [31.7828, 26.6071],\n",
      "        [25.1702, 30.0919],\n",
      "        [27.8200, 27.7808]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9250, 0.0937, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9120, 29.8840],\n",
      "        [31.7821, 26.6082],\n",
      "        [25.1700, 30.0922],\n",
      "        [27.8198, 27.7810]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9250, 0.0937, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9122, 29.8840],\n",
      "        [31.7834, 26.6081],\n",
      "        [25.1705, 30.0921],\n",
      "        [27.8201, 27.7810]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9252, 0.0937, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9121, 29.8842],\n",
      "        [31.7828, 26.6092],\n",
      "        [25.1703, 30.0924],\n",
      "        [27.8200, 27.7812]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9252, 0.0937, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9124, 29.8842],\n",
      "        [31.7841, 26.6091],\n",
      "        [25.1708, 30.0924],\n",
      "        [27.8203, 27.7812]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9254, 0.0937, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9123, 29.8844],\n",
      "        [31.7835, 26.6102],\n",
      "        [25.1706, 30.0926],\n",
      "        [27.8202, 27.7814]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9254, 0.0937, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9125, 29.8843],\n",
      "        [31.7847, 26.6101],\n",
      "        [25.1710, 30.0926],\n",
      "        [27.8205, 27.7814]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9257, 0.0938, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9125, 29.8845],\n",
      "        [31.7841, 26.6111],\n",
      "        [25.1709, 30.0929],\n",
      "        [27.8204, 27.7816]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9257, 0.0938, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9127, 29.8845],\n",
      "        [31.7854, 26.6111],\n",
      "        [25.1713, 30.0928],\n",
      "        [27.8207, 27.7816]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9259, 0.0938, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9126, 29.8847],\n",
      "        [31.7848, 26.6121],\n",
      "        [25.1712, 30.0931],\n",
      "        [27.8206, 27.7818]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9259, 0.0938, 0.9595], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9129, 29.8846],\n",
      "        [31.7860, 26.6120],\n",
      "        [25.1716, 30.0930],\n",
      "        [27.8209, 27.7817]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9261, 0.0938, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9128, 29.8848],\n",
      "        [31.7854, 26.6131],\n",
      "        [25.1714, 30.0933],\n",
      "        [27.8208, 27.7819]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9261, 0.0938, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9130, 29.8848],\n",
      "        [31.7867, 26.6130],\n",
      "        [25.1719, 30.0933],\n",
      "        [27.8211, 27.7819]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9263, 0.0938, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9129, 29.8850],\n",
      "        [31.7861, 26.6140],\n",
      "        [25.1717, 30.0935],\n",
      "        [27.8209, 27.7821]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9263, 0.0938, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9132, 29.8849],\n",
      "        [31.7873, 26.6140],\n",
      "        [25.1722, 30.0935],\n",
      "        [27.8213, 27.7821]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9266, 0.0939, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9131, 29.8851],\n",
      "        [31.7867, 26.6150],\n",
      "        [25.1720, 30.0938],\n",
      "        [27.8211, 27.7823]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9266, 0.0939, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9134, 29.8851],\n",
      "        [31.7880, 26.6149],\n",
      "        [25.1724, 30.0937],\n",
      "        [27.8214, 27.7823]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9268, 0.0939, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9133, 29.8853],\n",
      "        [31.7873, 26.6159],\n",
      "        [25.1723, 30.0940],\n",
      "        [27.8213, 27.7825]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9268, 0.0939, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9135, 29.8853],\n",
      "        [31.7886, 26.6159],\n",
      "        [25.1727, 30.0940],\n",
      "        [27.8216, 27.7824]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9270, 0.0939, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9134, 29.8854],\n",
      "        [31.7880, 26.6169],\n",
      "        [25.1725, 30.0942],\n",
      "        [27.8215, 27.7826]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9270, 0.0939, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9137, 29.8854],\n",
      "        [31.7892, 26.6168],\n",
      "        [25.1730, 30.0942],\n",
      "        [27.8218, 27.7826]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9272, 0.0940, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9136, 29.8856],\n",
      "        [31.7886, 26.6178],\n",
      "        [25.1728, 30.0945],\n",
      "        [27.8217, 27.7828]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9272, 0.0940, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9138, 29.8855],\n",
      "        [31.7898, 26.6177],\n",
      "        [25.1732, 30.0944],\n",
      "        [27.8220, 27.7828]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9274, 0.0940, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9137, 29.8857],\n",
      "        [31.7892, 26.6187],\n",
      "        [25.1731, 30.0947],\n",
      "        [27.8218, 27.7830]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9274, 0.0940, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9140, 29.8857],\n",
      "        [31.7905, 26.6187],\n",
      "        [25.1735, 30.0946],\n",
      "        [27.8222, 27.7830]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9963, 0.9277, 0.0940, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9139, 29.8858],\n",
      "        [31.7898, 26.6197],\n",
      "        [25.1733, 30.0949],\n",
      "        [27.8220, 27.7832]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9963, 0.9277, 0.0940, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9141, 29.8858],\n",
      "        [31.7911, 26.6196],\n",
      "        [25.1738, 30.0948],\n",
      "        [27.8223, 27.7831]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9279, 0.0940, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9141, 29.8860],\n",
      "        [31.7905, 26.6206],\n",
      "        [25.1736, 30.0951],\n",
      "        [27.8222, 27.7833]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9279, 0.0940, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9143, 29.8860],\n",
      "        [31.7917, 26.6205],\n",
      "        [25.1741, 30.0951],\n",
      "        [27.8225, 27.7833]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9281, 0.0941, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9142, 29.8861],\n",
      "        [31.7911, 26.6215],\n",
      "        [25.1739, 30.0953],\n",
      "        [27.8224, 27.7835]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9281, 0.0941, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9145, 29.8861],\n",
      "        [31.7923, 26.6214],\n",
      "        [25.1743, 30.0953],\n",
      "        [27.8227, 27.7835]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9283, 0.0941, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9144, 29.8863],\n",
      "        [31.7917, 26.6224],\n",
      "        [25.1741, 30.0956],\n",
      "        [27.8226, 27.7837]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9283, 0.0941, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9146, 29.8863],\n",
      "        [31.7929, 26.6224],\n",
      "        [25.1746, 30.0955],\n",
      "        [27.8228, 27.7837]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9285, 0.0941, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9145, 29.8864],\n",
      "        [31.7923, 26.6233],\n",
      "        [25.1744, 30.0958],\n",
      "        [27.8227, 27.7838]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9285, 0.0941, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9148, 29.8864],\n",
      "        [31.7935, 26.6233],\n",
      "        [25.1748, 30.0957],\n",
      "        [27.8230, 27.7838]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9287, 0.0941, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9147, 29.8866],\n",
      "        [31.7929, 26.6242],\n",
      "        [25.1747, 30.0960],\n",
      "        [27.8229, 27.7840]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9287, 0.0941, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9149, 29.8866],\n",
      "        [31.7941, 26.6242],\n",
      "        [25.1751, 30.0959],\n",
      "        [27.8232, 27.7840]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9289, 0.0942, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9148, 29.8867],\n",
      "        [31.7935, 26.6251],\n",
      "        [25.1749, 30.0962],\n",
      "        [27.8231, 27.7842]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9289, 0.0942, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9151, 29.8867],\n",
      "        [31.7947, 26.6251],\n",
      "        [25.1754, 30.0962],\n",
      "        [27.8234, 27.7842]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9291, 0.0942, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9150, 29.8869],\n",
      "        [31.7941, 26.6260],\n",
      "        [25.1752, 30.0964],\n",
      "        [27.8233, 27.7844]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9291, 0.0942, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9152, 29.8869],\n",
      "        [31.7953, 26.6260],\n",
      "        [25.1756, 30.0964],\n",
      "        [27.8235, 27.7844]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9294, 0.0942, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9151, 29.8870],\n",
      "        [31.7947, 26.6269],\n",
      "        [25.1755, 30.0967],\n",
      "        [27.8234, 27.7845]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9294, 0.0942, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9154, 29.8870],\n",
      "        [31.7958, 26.6268],\n",
      "        [25.1759, 30.0966],\n",
      "        [27.8237, 27.7845]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9296, 0.0943, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9153, 29.8872],\n",
      "        [31.7953, 26.6278],\n",
      "        [25.1757, 30.0969],\n",
      "        [27.8236, 27.7847]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9296, 0.0943, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9155, 29.8872],\n",
      "        [31.7964, 26.6278],\n",
      "        [25.1761, 30.0968],\n",
      "        [27.8239, 27.7847]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9298, 0.0943, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9154, 29.8873],\n",
      "        [31.7959, 26.6287],\n",
      "        [25.1760, 30.0971],\n",
      "        [27.8238, 27.7849]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9298, 0.0943, 0.9596], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9157, 29.8873],\n",
      "        [31.7970, 26.6286],\n",
      "        [25.1764, 30.0970],\n",
      "        [27.8241, 27.7849]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9300, 0.0943, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9156, 29.8875],\n",
      "        [31.7964, 26.6296],\n",
      "        [25.1762, 30.0973],\n",
      "        [27.8239, 27.7850]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9300, 0.0943, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9158, 29.8874],\n",
      "        [31.7976, 26.6295],\n",
      "        [25.1767, 30.0973],\n",
      "        [27.8242, 27.7850]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9302, 0.0943, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9157, 29.8876],\n",
      "        [31.7970, 26.6304],\n",
      "        [25.1765, 30.0975],\n",
      "        [27.8241, 27.7852]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9302, 0.0943, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9160, 29.8876],\n",
      "        [31.7982, 26.6304],\n",
      "        [25.1769, 30.0975],\n",
      "        [27.8244, 27.7852]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9304, 0.0944, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9159, 29.8877],\n",
      "        [31.7976, 26.6313],\n",
      "        [25.1768, 30.0977],\n",
      "        [27.8243, 27.7854]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9304, 0.0944, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9161, 29.8877],\n",
      "        [31.7987, 26.6312],\n",
      "        [25.1772, 30.0977],\n",
      "        [27.8246, 27.7853]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9306, 0.0944, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9160, 29.8879],\n",
      "        [31.7982, 26.6322],\n",
      "        [25.1770, 30.0979],\n",
      "        [27.8244, 27.7855]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9306, 0.0944, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9163, 29.8879],\n",
      "        [31.7993, 26.6321],\n",
      "        [25.1774, 30.0979],\n",
      "        [27.8247, 27.7855]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9308, 0.0944, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9162, 29.8880],\n",
      "        [31.7987, 26.6330],\n",
      "        [25.1773, 30.0981],\n",
      "        [27.8246, 27.7857]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9308, 0.0944, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9164, 29.8880],\n",
      "        [31.7999, 26.6330],\n",
      "        [25.1777, 30.0981],\n",
      "        [27.8249, 27.7857]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9310, 0.0944, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9163, 29.8882],\n",
      "        [31.7993, 26.6339],\n",
      "        [25.1775, 30.0984],\n",
      "        [27.8248, 27.7859]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9310, 0.0944, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9166, 29.8882],\n",
      "        [31.8004, 26.6338],\n",
      "        [25.1779, 30.0983],\n",
      "        [27.8251, 27.7859]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9312, 0.0945, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9165, 29.8883],\n",
      "        [31.7999, 26.6348],\n",
      "        [25.1778, 30.0986],\n",
      "        [27.8250, 27.7860]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9312, 0.0945, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9167, 29.8883],\n",
      "        [31.8010, 26.6347],\n",
      "        [25.1782, 30.0985],\n",
      "        [27.8252, 27.7860]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9314, 0.0945, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9166, 29.8884],\n",
      "        [31.8004, 26.6356],\n",
      "        [25.1780, 30.0988],\n",
      "        [27.8251, 27.7862]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9314, 0.0945, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9169, 29.8884],\n",
      "        [31.8015, 26.6355],\n",
      "        [25.1784, 30.0987],\n",
      "        [27.8254, 27.7862]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9315, 0.0945, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9168, 29.8886],\n",
      "        [31.8010, 26.6364],\n",
      "        [25.1783, 30.0990],\n",
      "        [27.8253, 27.7864]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9315, 0.0945, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9170, 29.8886],\n",
      "        [31.8021, 26.6364],\n",
      "        [25.1787, 30.0989],\n",
      "        [27.8256, 27.7864]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9317, 0.0946, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9169, 29.8887],\n",
      "        [31.8015, 26.6373],\n",
      "        [25.1785, 30.0992],\n",
      "        [27.8255, 27.7865]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9317, 0.0946, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9172, 29.8887],\n",
      "        [31.8026, 26.6372],\n",
      "        [25.1789, 30.0991],\n",
      "        [27.8257, 27.7865]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9964, 0.9319, 0.0946, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9171, 29.8888],\n",
      "        [31.8021, 26.6381],\n",
      "        [25.1788, 30.0994],\n",
      "        [27.8256, 27.7867]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9964, 0.9319, 0.0946, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9173, 29.8888],\n",
      "        [31.8032, 26.6380],\n",
      "        [25.1792, 30.0993],\n",
      "        [27.8259, 27.7867]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9321, 0.0946, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9172, 29.8890],\n",
      "        [31.8026, 26.6389],\n",
      "        [25.1790, 30.0996],\n",
      "        [27.8258, 27.7869]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9321, 0.0946, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9174, 29.8890],\n",
      "        [31.8037, 26.6389],\n",
      "        [25.1794, 30.0995],\n",
      "        [27.8261, 27.7868]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9323, 0.0946, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9174, 29.8891],\n",
      "        [31.8032, 26.6398],\n",
      "        [25.1793, 30.0998],\n",
      "        [27.8260, 27.7870]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9323, 0.0946, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9176, 29.8891],\n",
      "        [31.8043, 26.6397],\n",
      "        [25.1797, 30.0997],\n",
      "        [27.8262, 27.7870]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9325, 0.0947, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9175, 29.8893],\n",
      "        [31.8037, 26.6406],\n",
      "        [25.1795, 30.1000],\n",
      "        [27.8261, 27.7872]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9325, 0.0947, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9177, 29.8893],\n",
      "        [31.8048, 26.6405],\n",
      "        [25.1799, 30.0999],\n",
      "        [27.8264, 27.7871]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9327, 0.0947, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9177, 29.8894],\n",
      "        [31.8043, 26.6414],\n",
      "        [25.1798, 30.1002],\n",
      "        [27.8263, 27.7873]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9327, 0.0947, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9179, 29.8894],\n",
      "        [31.8053, 26.6413],\n",
      "        [25.1802, 30.1001],\n",
      "        [27.8266, 27.7873]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9329, 0.0947, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9178, 29.8895],\n",
      "        [31.8048, 26.6422],\n",
      "        [25.1800, 30.1004],\n",
      "        [27.8264, 27.7875]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9329, 0.0947, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9180, 29.8895],\n",
      "        [31.8059, 26.6422],\n",
      "        [25.1804, 30.1003],\n",
      "        [27.8267, 27.7875]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9331, 0.0947, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9179, 29.8897],\n",
      "        [31.8053, 26.6430],\n",
      "        [25.1803, 30.1006],\n",
      "        [27.8266, 27.7876]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9331, 0.0947, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9182, 29.8897],\n",
      "        [31.8064, 26.6430],\n",
      "        [25.1807, 30.1005],\n",
      "        [27.8269, 27.7876]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9333, 0.0948, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9181, 29.8898],\n",
      "        [31.8059, 26.6438],\n",
      "        [25.1805, 30.1008],\n",
      "        [27.8268, 27.7878]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9333, 0.0948, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9183, 29.8898],\n",
      "        [31.8069, 26.6438],\n",
      "        [25.1809, 30.1007],\n",
      "        [27.8270, 27.7878]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9334, 0.0948, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9182, 29.8899],\n",
      "        [31.8064, 26.6446],\n",
      "        [25.1807, 30.1010],\n",
      "        [27.8269, 27.7880]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9334, 0.0948, 0.9597], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9185, 29.8899],\n",
      "        [31.8074, 26.6446],\n",
      "        [25.1812, 30.1010],\n",
      "        [27.8272, 27.7880]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9336, 0.0948, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9184, 29.8901],\n",
      "        [31.8069, 26.6454],\n",
      "        [25.1810, 30.1012],\n",
      "        [27.8271, 27.7881]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9336, 0.0948, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9186, 29.8901],\n",
      "        [31.8080, 26.6454],\n",
      "        [25.1814, 30.1011],\n",
      "        [27.8274, 27.7881]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9338, 0.0948, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9185, 29.8902],\n",
      "        [31.8074, 26.6462],\n",
      "        [25.1812, 30.1014],\n",
      "        [27.8273, 27.7883]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9338, 0.0948, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9187, 29.8902],\n",
      "        [31.8085, 26.6462],\n",
      "        [25.1816, 30.1013],\n",
      "        [27.8275, 27.7882]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9340, 0.0949, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9186, 29.8904],\n",
      "        [31.8079, 26.6470],\n",
      "        [25.1815, 30.1016],\n",
      "        [27.8274, 27.7884]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9340, 0.0949, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9189, 29.8903],\n",
      "        [31.8090, 26.6470],\n",
      "        [25.1819, 30.1015],\n",
      "        [27.8277, 27.7884]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9342, 0.0949, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9188, 29.8905],\n",
      "        [31.8085, 26.6478],\n",
      "        [25.1817, 30.1018],\n",
      "        [27.8276, 27.7886]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9342, 0.0949, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9190, 29.8905],\n",
      "        [31.8095, 26.6477],\n",
      "        [25.1821, 30.1017],\n",
      "        [27.8278, 27.7886]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9343, 0.0949, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9189, 29.8906],\n",
      "        [31.8090, 26.6486],\n",
      "        [25.1819, 30.1020],\n",
      "        [27.8277, 27.7887]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9343, 0.0949, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9192, 29.8906],\n",
      "        [31.8100, 26.6485],\n",
      "        [25.1824, 30.1019],\n",
      "        [27.8280, 27.7887]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9345, 0.0950, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9191, 29.8908],\n",
      "        [31.8095, 26.6494],\n",
      "        [25.1822, 30.1022],\n",
      "        [27.8279, 27.7889]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9345, 0.0950, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9193, 29.8907],\n",
      "        [31.8105, 26.6493],\n",
      "        [25.1826, 30.1021],\n",
      "        [27.8281, 27.7889]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9347, 0.0950, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9192, 29.8909],\n",
      "        [31.8100, 26.6502],\n",
      "        [25.1824, 30.1024],\n",
      "        [27.8280, 27.7890]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9347, 0.0950, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9194, 29.8909],\n",
      "        [31.8110, 26.6501],\n",
      "        [25.1828, 30.1023],\n",
      "        [27.8283, 27.7890]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9349, 0.0950, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9194, 29.8910],\n",
      "        [31.8105, 26.6509],\n",
      "        [25.1827, 30.1026],\n",
      "        [27.8282, 27.7892]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9349, 0.0950, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9196, 29.8910],\n",
      "        [31.8115, 26.6509],\n",
      "        [25.1831, 30.1025],\n",
      "        [27.8285, 27.7892]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9351, 0.0950, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9195, 29.8911],\n",
      "        [31.8110, 26.6517],\n",
      "        [25.1829, 30.1027],\n",
      "        [27.8284, 27.7894]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9351, 0.0950, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9197, 29.8911],\n",
      "        [31.8120, 26.6516],\n",
      "        [25.1833, 30.1027],\n",
      "        [27.8286, 27.7893]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9352, 0.0951, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9196, 29.8913],\n",
      "        [31.8115, 26.6525],\n",
      "        [25.1831, 30.1029],\n",
      "        [27.8285, 27.7895]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9352, 0.0951, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9198, 29.8912],\n",
      "        [31.8125, 26.6524],\n",
      "        [25.1835, 30.1029],\n",
      "        [27.8287, 27.7895]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9354, 0.0951, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9198, 29.8914],\n",
      "        [31.8120, 26.6532],\n",
      "        [25.1834, 30.1031],\n",
      "        [27.8287, 27.7897]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9354, 0.0951, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9200, 29.8914],\n",
      "        [31.8130, 26.6532],\n",
      "        [25.1838, 30.1031],\n",
      "        [27.8289, 27.7896]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9356, 0.0951, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9199, 29.8915],\n",
      "        [31.8125, 26.6540],\n",
      "        [25.1836, 30.1033],\n",
      "        [27.8288, 27.7898]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9356, 0.0951, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9201, 29.8915],\n",
      "        [31.8135, 26.6539],\n",
      "        [25.1840, 30.1033],\n",
      "        [27.8291, 27.7898]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9357, 0.0951, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9200, 29.8917],\n",
      "        [31.8130, 26.6547],\n",
      "        [25.1838, 30.1035],\n",
      "        [27.8290, 27.7900]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9357, 0.0951, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9203, 29.8917],\n",
      "        [31.8140, 26.6547],\n",
      "        [25.1842, 30.1035],\n",
      "        [27.8292, 27.7899]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9965, 0.9359, 0.0952, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9202, 29.8918],\n",
      "        [31.8135, 26.6555],\n",
      "        [25.1841, 30.1037],\n",
      "        [27.8291, 27.7901]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9965, 0.9359, 0.0952, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9204, 29.8918],\n",
      "        [31.8144, 26.6554],\n",
      "        [25.1845, 30.1037],\n",
      "        [27.8294, 27.7901]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9361, 0.0952, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9203, 29.8919],\n",
      "        [31.8140, 26.6562],\n",
      "        [25.1843, 30.1039],\n",
      "        [27.8293, 27.7903]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9361, 0.0952, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9205, 29.8919],\n",
      "        [31.8149, 26.6562],\n",
      "        [25.1847, 30.1038],\n",
      "        [27.8295, 27.7903]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9363, 0.0952, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9204, 29.8920],\n",
      "        [31.8144, 26.6570],\n",
      "        [25.1845, 30.1041],\n",
      "        [27.8294, 27.7904]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9363, 0.0952, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9206, 29.8920],\n",
      "        [31.8154, 26.6569],\n",
      "        [25.1849, 30.1040],\n",
      "        [27.8297, 27.7904]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9364, 0.0952, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9206, 29.8922],\n",
      "        [31.8149, 26.6577],\n",
      "        [25.1848, 30.1043],\n",
      "        [27.8296, 27.7906]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9364, 0.0952, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9208, 29.8922],\n",
      "        [31.8159, 26.6577],\n",
      "        [25.1851, 30.1042],\n",
      "        [27.8298, 27.7905]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9366, 0.0953, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9207, 29.8923],\n",
      "        [31.8154, 26.6584],\n",
      "        [25.1850, 30.1044],\n",
      "        [27.8297, 27.7907]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9366, 0.0953, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9209, 29.8923],\n",
      "        [31.8163, 26.6584],\n",
      "        [25.1854, 30.1044],\n",
      "        [27.8300, 27.7907]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9368, 0.0953, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9208, 29.8924],\n",
      "        [31.8159, 26.6592],\n",
      "        [25.1852, 30.1046],\n",
      "        [27.8299, 27.7909]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9368, 0.0953, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9211, 29.8924],\n",
      "        [31.8168, 26.6591],\n",
      "        [25.1856, 30.1046],\n",
      "        [27.8301, 27.7908]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9369, 0.0953, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9210, 29.8925],\n",
      "        [31.8163, 26.6599],\n",
      "        [25.1854, 30.1048],\n",
      "        [27.8300, 27.7910]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9369, 0.0953, 0.9598], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9212, 29.8925],\n",
      "        [31.8173, 26.6599],\n",
      "        [25.1858, 30.1048],\n",
      "        [27.8303, 27.7910]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9371, 0.0953, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9211, 29.8927],\n",
      "        [31.8168, 26.6606],\n",
      "        [25.1857, 30.1050],\n",
      "        [27.8302, 27.7912]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9371, 0.0953, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9213, 29.8927],\n",
      "        [31.8178, 26.6606],\n",
      "        [25.1861, 30.1050],\n",
      "        [27.8304, 27.7911]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9373, 0.0954, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9212, 29.8928],\n",
      "        [31.8173, 26.6614],\n",
      "        [25.1859, 30.1052],\n",
      "        [27.8303, 27.7913]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9373, 0.0954, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9215, 29.8928],\n",
      "        [31.8182, 26.6613],\n",
      "        [25.1863, 30.1051],\n",
      "        [27.8306, 27.7913]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9374, 0.0954, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9214, 29.8929],\n",
      "        [31.8177, 26.6621],\n",
      "        [25.1861, 30.1054],\n",
      "        [27.8305, 27.7914]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9374, 0.0954, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9216, 29.8929],\n",
      "        [31.8187, 26.6620],\n",
      "        [25.1865, 30.1053],\n",
      "        [27.8307, 27.7914]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9376, 0.0954, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9215, 29.8931],\n",
      "        [31.8182, 26.6628],\n",
      "        [25.1864, 30.1055],\n",
      "        [27.8306, 27.7916]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9376, 0.0954, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9217, 29.8931],\n",
      "        [31.8191, 26.6627],\n",
      "        [25.1867, 30.1055],\n",
      "        [27.8309, 27.7916]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9377, 0.0954, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9216, 29.8932],\n",
      "        [31.8187, 26.6635],\n",
      "        [25.1866, 30.1057],\n",
      "        [27.8308, 27.7917]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9377, 0.0954, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9218, 29.8932],\n",
      "        [31.8196, 26.6635],\n",
      "        [25.1870, 30.1057],\n",
      "        [27.8310, 27.7917]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9379, 0.0955, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9218, 29.8933],\n",
      "        [31.8191, 26.6642],\n",
      "        [25.1868, 30.1059],\n",
      "        [27.8309, 27.7919]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9379, 0.0955, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9220, 29.8933],\n",
      "        [31.8201, 26.6642],\n",
      "        [25.1872, 30.1059],\n",
      "        [27.8312, 27.7919]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9381, 0.0955, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9219, 29.8934],\n",
      "        [31.8196, 26.6649],\n",
      "        [25.1870, 30.1061],\n",
      "        [27.8311, 27.7920]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9381, 0.0955, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9221, 29.8934],\n",
      "        [31.8205, 26.6649],\n",
      "        [25.1874, 30.1060],\n",
      "        [27.8313, 27.7920]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9382, 0.0955, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9220, 29.8936],\n",
      "        [31.8200, 26.6656],\n",
      "        [25.1873, 30.1063],\n",
      "        [27.8312, 27.7921]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9382, 0.0955, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9222, 29.8935],\n",
      "        [31.8210, 26.6656],\n",
      "        [25.1876, 30.1062],\n",
      "        [27.8314, 27.7921]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9384, 0.0955, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9222, 29.8937],\n",
      "        [31.8205, 26.6663],\n",
      "        [25.1875, 30.1064],\n",
      "        [27.8314, 27.7923]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9384, 0.0955, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9224, 29.8937],\n",
      "        [31.8214, 26.6663],\n",
      "        [25.1879, 30.1064],\n",
      "        [27.8316, 27.7923]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9385, 0.0956, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9223, 29.8938],\n",
      "        [31.8209, 26.6670],\n",
      "        [25.1877, 30.1066],\n",
      "        [27.8315, 27.7924]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9385, 0.0956, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9225, 29.8938],\n",
      "        [31.8218, 26.6670],\n",
      "        [25.1881, 30.1066],\n",
      "        [27.8317, 27.7924]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9387, 0.0956, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9224, 29.8939],\n",
      "        [31.8214, 26.6677],\n",
      "        [25.1879, 30.1068],\n",
      "        [27.8316, 27.7926]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9387, 0.0956, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9226, 29.8939],\n",
      "        [31.8223, 26.6677],\n",
      "        [25.1883, 30.1068],\n",
      "        [27.8319, 27.7926]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9388, 0.0956, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9225, 29.8940],\n",
      "        [31.8218, 26.6684],\n",
      "        [25.1881, 30.1070],\n",
      "        [27.8318, 27.7927]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9388, 0.0956, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9227, 29.8940],\n",
      "        [31.8227, 26.6684],\n",
      "        [25.1885, 30.1069],\n",
      "        [27.8320, 27.7927]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9390, 0.0956, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9227, 29.8942],\n",
      "        [31.8223, 26.6691],\n",
      "        [25.1884, 30.1071],\n",
      "        [27.8319, 27.7929]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9390, 0.0956, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9229, 29.8942],\n",
      "        [31.8232, 26.6691],\n",
      "        [25.1887, 30.1071],\n",
      "        [27.8322, 27.7929]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9392, 0.0957, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9228, 29.8943],\n",
      "        [31.8227, 26.6698],\n",
      "        [25.1886, 30.1073],\n",
      "        [27.8321, 27.7930]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9392, 0.0957, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9230, 29.8943],\n",
      "        [31.8236, 26.6697],\n",
      "        [25.1889, 30.1073],\n",
      "        [27.8323, 27.7930]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9393, 0.0957, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9229, 29.8944],\n",
      "        [31.8232, 26.6705],\n",
      "        [25.1888, 30.1075],\n",
      "        [27.8322, 27.7931]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9393, 0.0957, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9231, 29.8944],\n",
      "        [31.8241, 26.6704],\n",
      "        [25.1892, 30.1075],\n",
      "        [27.8324, 27.7931]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9395, 0.0957, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9230, 29.8945],\n",
      "        [31.8236, 26.6712],\n",
      "        [25.1890, 30.1077],\n",
      "        [27.8324, 27.7933]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9395, 0.0957, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9233, 29.8945],\n",
      "        [31.8245, 26.6711],\n",
      "        [25.1894, 30.1076],\n",
      "        [27.8326, 27.7933]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9966, 0.9396, 0.0957, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9232, 29.8947],\n",
      "        [31.8240, 26.6718],\n",
      "        [25.1892, 30.1078],\n",
      "        [27.8325, 27.7934]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9966, 0.9396, 0.0957, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9234, 29.8947],\n",
      "        [31.8249, 26.6718],\n",
      "        [25.1896, 30.1078],\n",
      "        [27.8327, 27.7934]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9398, 0.0958, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9233, 29.8948],\n",
      "        [31.8245, 26.6725],\n",
      "        [25.1895, 30.1080],\n",
      "        [27.8326, 27.7936]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9398, 0.0958, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9235, 29.8948],\n",
      "        [31.8253, 26.6724],\n",
      "        [25.1898, 30.1080],\n",
      "        [27.8329, 27.7935]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9399, 0.0958, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9234, 29.8949],\n",
      "        [31.8249, 26.6732],\n",
      "        [25.1897, 30.1082],\n",
      "        [27.8328, 27.7937]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9399, 0.0958, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9236, 29.8949],\n",
      "        [31.8258, 26.6731],\n",
      "        [25.1900, 30.1082],\n",
      "        [27.8330, 27.7937]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9401, 0.0958, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9236, 29.8950],\n",
      "        [31.8253, 26.6738],\n",
      "        [25.1899, 30.1084],\n",
      "        [27.8329, 27.7938]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9401, 0.0958, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9237, 29.8950],\n",
      "        [31.8262, 26.6738],\n",
      "        [25.1902, 30.1083],\n",
      "        [27.8331, 27.7938]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9402, 0.0958, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9237, 29.8951],\n",
      "        [31.8258, 26.6745],\n",
      "        [25.1901, 30.1085],\n",
      "        [27.8331, 27.7940]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9402, 0.0958, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9239, 29.8951],\n",
      "        [31.8266, 26.6745],\n",
      "        [25.1905, 30.1085],\n",
      "        [27.8333, 27.7940]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9404, 0.0959, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9238, 29.8953],\n",
      "        [31.8262, 26.6752],\n",
      "        [25.1903, 30.1087],\n",
      "        [27.8332, 27.7941]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9404, 0.0959, 0.9599], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9240, 29.8952],\n",
      "        [31.8270, 26.6751],\n",
      "        [25.1907, 30.1087],\n",
      "        [27.8334, 27.7941]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9405, 0.0959, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9239, 29.8954],\n",
      "        [31.8266, 26.6758],\n",
      "        [25.1905, 30.1089],\n",
      "        [27.8333, 27.7943]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9405, 0.0959, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9241, 29.8954],\n",
      "        [31.8275, 26.6758],\n",
      "        [25.1909, 30.1088],\n",
      "        [27.8336, 27.7942]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9407, 0.0959, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9241, 29.8955],\n",
      "        [31.8270, 26.6765],\n",
      "        [25.1908, 30.1091],\n",
      "        [27.8335, 27.7944]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9407, 0.0959, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9242, 29.8955],\n",
      "        [31.8279, 26.6764],\n",
      "        [25.1911, 30.1090],\n",
      "        [27.8337, 27.7944]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9408, 0.0959, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9242, 29.8956],\n",
      "        [31.8274, 26.6771],\n",
      "        [25.1910, 30.1092],\n",
      "        [27.8336, 27.7945]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9408, 0.0959, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9244, 29.8956],\n",
      "        [31.8283, 26.6771],\n",
      "        [25.1913, 30.1092],\n",
      "        [27.8338, 27.7945]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9410, 0.0960, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9243, 29.8957],\n",
      "        [31.8279, 26.6778],\n",
      "        [25.1912, 30.1094],\n",
      "        [27.8337, 27.7947]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9410, 0.0960, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9245, 29.8957],\n",
      "        [31.8287, 26.6777],\n",
      "        [25.1915, 30.1094],\n",
      "        [27.8340, 27.7947]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9411, 0.0960, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9244, 29.8959],\n",
      "        [31.8283, 26.6784],\n",
      "        [25.1914, 30.1096],\n",
      "        [27.8339, 27.7948]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9411, 0.0960, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9246, 29.8958],\n",
      "        [31.8291, 26.6784],\n",
      "        [25.1917, 30.1095],\n",
      "        [27.8341, 27.7948]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9412, 0.0960, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9245, 29.8960],\n",
      "        [31.8287, 26.6791],\n",
      "        [25.1916, 30.1097],\n",
      "        [27.8340, 27.7949]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9412, 0.0960, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9247, 29.8960],\n",
      "        [31.8295, 26.6790],\n",
      "        [25.1919, 30.1097],\n",
      "        [27.8342, 27.7949]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9414, 0.0960, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9247, 29.8961],\n",
      "        [31.8291, 26.6797],\n",
      "        [25.1918, 30.1099],\n",
      "        [27.8342, 27.7950]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9414, 0.0960, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9249, 29.8961],\n",
      "        [31.8299, 26.6797],\n",
      "        [25.1922, 30.1099],\n",
      "        [27.8344, 27.7950]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9415, 0.0961, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9248, 29.8962],\n",
      "        [31.8295, 26.6803],\n",
      "        [25.1920, 30.1100],\n",
      "        [27.8343, 27.7952]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9415, 0.0961, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9250, 29.8962],\n",
      "        [31.8303, 26.6803],\n",
      "        [25.1924, 30.1100],\n",
      "        [27.8345, 27.7952]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9417, 0.0961, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9249, 29.8963],\n",
      "        [31.8299, 26.6810],\n",
      "        [25.1922, 30.1102],\n",
      "        [27.8344, 27.7953]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9417, 0.0961, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9251, 29.8963],\n",
      "        [31.8307, 26.6809],\n",
      "        [25.1926, 30.1102],\n",
      "        [27.8346, 27.7953]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9418, 0.0961, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9250, 29.8964],\n",
      "        [31.8303, 26.6816],\n",
      "        [25.1924, 30.1104],\n",
      "        [27.8346, 27.7955]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9418, 0.0961, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9252, 29.8964],\n",
      "        [31.8311, 26.6816],\n",
      "        [25.1928, 30.1103],\n",
      "        [27.8348, 27.7955]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9420, 0.0961, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9251, 29.8966],\n",
      "        [31.8307, 26.6823],\n",
      "        [25.1926, 30.1106],\n",
      "        [27.8347, 27.7956]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9420, 0.0961, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9253, 29.8965],\n",
      "        [31.8315, 26.6822],\n",
      "        [25.1930, 30.1105],\n",
      "        [27.8349, 27.7956]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9421, 0.0962, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9253, 29.8967],\n",
      "        [31.8311, 26.6829],\n",
      "        [25.1928, 30.1107],\n",
      "        [27.8348, 27.7957]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9421, 0.0962, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9255, 29.8967],\n",
      "        [31.8319, 26.6828],\n",
      "        [25.1932, 30.1107],\n",
      "        [27.8351, 27.7957]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9422, 0.0962, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9254, 29.8968],\n",
      "        [31.8315, 26.6835],\n",
      "        [25.1931, 30.1109],\n",
      "        [27.8350, 27.7959]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9422, 0.0962, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9256, 29.8968],\n",
      "        [31.8323, 26.6835],\n",
      "        [25.1934, 30.1108],\n",
      "        [27.8352, 27.7958]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9424, 0.0962, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9255, 29.8969],\n",
      "        [31.8319, 26.6841],\n",
      "        [25.1932, 30.1110],\n",
      "        [27.8351, 27.7960]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9424, 0.0962, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9257, 29.8969],\n",
      "        [31.8327, 26.6841],\n",
      "        [25.1936, 30.1110],\n",
      "        [27.8353, 27.7960]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9425, 0.0962, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9256, 29.8970],\n",
      "        [31.8323, 26.6848],\n",
      "        [25.1935, 30.1112],\n",
      "        [27.8352, 27.7961]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9425, 0.0962, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9258, 29.8970],\n",
      "        [31.8331, 26.6847],\n",
      "        [25.1938, 30.1112],\n",
      "        [27.8355, 27.7961]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9427, 0.0963, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9257, 29.8971],\n",
      "        [31.8327, 26.6854],\n",
      "        [25.1937, 30.1114],\n",
      "        [27.8354, 27.7962]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9427, 0.0963, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9259, 29.8971],\n",
      "        [31.8335, 26.6853],\n",
      "        [25.1940, 30.1113],\n",
      "        [27.8356, 27.7962]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9428, 0.0963, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9258, 29.8972],\n",
      "        [31.8331, 26.6860],\n",
      "        [25.1939, 30.1115],\n",
      "        [27.8355, 27.7964]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9428, 0.0963, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9261, 29.8972],\n",
      "        [31.8339, 26.6859],\n",
      "        [25.1942, 30.1115],\n",
      "        [27.8357, 27.7964]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9429, 0.0963, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9260, 29.8973],\n",
      "        [31.8335, 26.6866],\n",
      "        [25.1941, 30.1117],\n",
      "        [27.8356, 27.7965]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9429, 0.0963, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9262, 29.8973],\n",
      "        [31.8342, 26.6865],\n",
      "        [25.1944, 30.1116],\n",
      "        [27.8358, 27.7965]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9431, 0.0963, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9261, 29.8975],\n",
      "        [31.8338, 26.6872],\n",
      "        [25.1943, 30.1118],\n",
      "        [27.8358, 27.7966]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9431, 0.0963, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9263, 29.8975],\n",
      "        [31.8346, 26.6872],\n",
      "        [25.1946, 30.1118],\n",
      "        [27.8360, 27.7966]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9967, 0.9432, 0.0964, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9262, 29.8976],\n",
      "        [31.8342, 26.6878],\n",
      "        [25.1945, 30.1120],\n",
      "        [27.8359, 27.7968]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9967, 0.9432, 0.0964, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9264, 29.8976],\n",
      "        [31.8350, 26.6878],\n",
      "        [25.1948, 30.1120],\n",
      "        [27.8361, 27.7967]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9433, 0.0964, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9263, 29.8977],\n",
      "        [31.8346, 26.6884],\n",
      "        [25.1947, 30.1122],\n",
      "        [27.8360, 27.7969]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9433, 0.0964, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9265, 29.8977],\n",
      "        [31.8354, 26.6884],\n",
      "        [25.1950, 30.1121],\n",
      "        [27.8362, 27.7969]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9435, 0.0964, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9264, 29.8978],\n",
      "        [31.8350, 26.6890],\n",
      "        [25.1949, 30.1123],\n",
      "        [27.8362, 27.7970]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9435, 0.0964, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9266, 29.8978],\n",
      "        [31.8358, 26.6890],\n",
      "        [25.1952, 30.1123],\n",
      "        [27.8364, 27.7970]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9436, 0.0964, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9266, 29.8979],\n",
      "        [31.8354, 26.6896],\n",
      "        [25.1951, 30.1125],\n",
      "        [27.8363, 27.7972]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9436, 0.0964, 0.9600], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9267, 29.8979],\n",
      "        [31.8361, 26.6896],\n",
      "        [25.1954, 30.1124],\n",
      "        [27.8365, 27.7971]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9437, 0.0965, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9267, 29.8980],\n",
      "        [31.8358, 26.6902],\n",
      "        [25.1953, 30.1126],\n",
      "        [27.8364, 27.7973]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9437, 0.0965, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9269, 29.8980],\n",
      "        [31.8365, 26.6902],\n",
      "        [25.1956, 30.1126],\n",
      "        [27.8366, 27.7973]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9439, 0.0965, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9268, 29.8981],\n",
      "        [31.8361, 26.6908],\n",
      "        [25.1955, 30.1128],\n",
      "        [27.8365, 27.7974]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9439, 0.0965, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9270, 29.8981],\n",
      "        [31.8369, 26.6908],\n",
      "        [25.1958, 30.1128],\n",
      "        [27.8367, 27.7974]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9440, 0.0965, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9269, 29.8983],\n",
      "        [31.8365, 26.6914],\n",
      "        [25.1957, 30.1130],\n",
      "        [27.8367, 27.7975]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9440, 0.0965, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9271, 29.8982],\n",
      "        [31.8373, 26.6914],\n",
      "        [25.1960, 30.1129],\n",
      "        [27.8369, 27.7975]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9441, 0.0965, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9270, 29.8983],\n",
      "        [31.8369, 26.6920],\n",
      "        [25.1959, 30.1131],\n",
      "        [27.8368, 27.7976]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9441, 0.0965, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9272, 29.8983],\n",
      "        [31.8376, 26.6919],\n",
      "        [25.1962, 30.1131],\n",
      "        [27.8370, 27.7976]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9443, 0.0965, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9271, 29.8985],\n",
      "        [31.8372, 26.6926],\n",
      "        [25.1961, 30.1133],\n",
      "        [27.8369, 27.7978]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9443, 0.0965, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9273, 29.8985],\n",
      "        [31.8380, 26.6925],\n",
      "        [25.1964, 30.1132],\n",
      "        [27.8371, 27.7978]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9444, 0.0966, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9273, 29.8986],\n",
      "        [31.8376, 26.6932],\n",
      "        [25.1963, 30.1134],\n",
      "        [27.8371, 27.7979]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9444, 0.0966, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9274, 29.8986],\n",
      "        [31.8384, 26.6931],\n",
      "        [25.1966, 30.1134],\n",
      "        [27.8372, 27.7979]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9445, 0.0966, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9274, 29.8987],\n",
      "        [31.8380, 26.6938],\n",
      "        [25.1965, 30.1136],\n",
      "        [27.8372, 27.7980]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9445, 0.0966, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9275, 29.8987],\n",
      "        [31.8387, 26.6937],\n",
      "        [25.1968, 30.1135],\n",
      "        [27.8374, 27.7980]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9446, 0.0966, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9275, 29.8988],\n",
      "        [31.8384, 26.6943],\n",
      "        [25.1967, 30.1137],\n",
      "        [27.8373, 27.7982]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9446, 0.0966, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9277, 29.8988],\n",
      "        [31.8391, 26.6943],\n",
      "        [25.1970, 30.1137],\n",
      "        [27.8375, 27.7982]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9448, 0.0966, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9276, 29.8989],\n",
      "        [31.8387, 26.6949],\n",
      "        [25.1969, 30.1139],\n",
      "        [27.8374, 27.7983]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9448, 0.0966, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9278, 29.8989],\n",
      "        [31.8395, 26.6949],\n",
      "        [25.1972, 30.1139],\n",
      "        [27.8376, 27.7983]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9449, 0.0967, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9277, 29.8990],\n",
      "        [31.8391, 26.6955],\n",
      "        [25.1971, 30.1140],\n",
      "        [27.8376, 27.7984]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9449, 0.0967, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9279, 29.8990],\n",
      "        [31.8398, 26.6954],\n",
      "        [25.1974, 30.1140],\n",
      "        [27.8378, 27.7984]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9450, 0.0967, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9278, 29.8991],\n",
      "        [31.8394, 26.6961],\n",
      "        [25.1973, 30.1142],\n",
      "        [27.8377, 27.7985]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9450, 0.0967, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9280, 29.8991],\n",
      "        [31.8402, 26.6960],\n",
      "        [25.1976, 30.1142],\n",
      "        [27.8379, 27.7985]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9451, 0.0967, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9279, 29.8992],\n",
      "        [31.8398, 26.6966],\n",
      "        [25.1975, 30.1144],\n",
      "        [27.8378, 27.7987]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9451, 0.0967, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9281, 29.8992],\n",
      "        [31.8405, 26.6966],\n",
      "        [25.1978, 30.1143],\n",
      "        [27.8380, 27.7986]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9453, 0.0967, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9280, 29.8994],\n",
      "        [31.8402, 26.6972],\n",
      "        [25.1977, 30.1145],\n",
      "        [27.8379, 27.7988]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9453, 0.0967, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9282, 29.8993],\n",
      "        [31.8409, 26.6972],\n",
      "        [25.1980, 30.1145],\n",
      "        [27.8381, 27.7988]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9454, 0.0968, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9281, 29.8995],\n",
      "        [31.8405, 26.6978],\n",
      "        [25.1978, 30.1147],\n",
      "        [27.8380, 27.7989]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9454, 0.0968, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9283, 29.8994],\n",
      "        [31.8412, 26.6977],\n",
      "        [25.1981, 30.1146],\n",
      "        [27.8382, 27.7989]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9455, 0.0968, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9283, 29.8996],\n",
      "        [31.8409, 26.6983],\n",
      "        [25.1980, 30.1148],\n",
      "        [27.8382, 27.7990]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9455, 0.0968, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9284, 29.8996],\n",
      "        [31.8416, 26.6983],\n",
      "        [25.1984, 30.1148],\n",
      "        [27.8384, 27.7990]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9456, 0.0968, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9284, 29.8997],\n",
      "        [31.8412, 26.6989],\n",
      "        [25.1982, 30.1150],\n",
      "        [27.8383, 27.7991]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9456, 0.0968, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9285, 29.8996],\n",
      "        [31.8419, 26.6988],\n",
      "        [25.1985, 30.1149],\n",
      "        [27.8385, 27.7991]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9458, 0.0968, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9285, 29.8998],\n",
      "        [31.8416, 26.6994],\n",
      "        [25.1984, 30.1151],\n",
      "        [27.8384, 27.7993]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9458, 0.0968, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9287, 29.8998],\n",
      "        [31.8423, 26.6994],\n",
      "        [25.1987, 30.1151],\n",
      "        [27.8386, 27.7993]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9459, 0.0969, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9286, 29.8999],\n",
      "        [31.8419, 26.7000],\n",
      "        [25.1986, 30.1153],\n",
      "        [27.8385, 27.7994]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9459, 0.0969, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9288, 29.8999],\n",
      "        [31.8426, 26.7000],\n",
      "        [25.1989, 30.1152],\n",
      "        [27.8387, 27.7994]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9460, 0.0969, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9287, 29.9000],\n",
      "        [31.8423, 26.7006],\n",
      "        [25.1988, 30.1154],\n",
      "        [27.8387, 27.7995]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9460, 0.0969, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9289, 29.9000],\n",
      "        [31.8430, 26.7005],\n",
      "        [25.1991, 30.1154],\n",
      "        [27.8389, 27.7995]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9461, 0.0969, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9288, 29.9001],\n",
      "        [31.8426, 26.7011],\n",
      "        [25.1990, 30.1156],\n",
      "        [27.8388, 27.7996]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9461, 0.0969, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9290, 29.9001],\n",
      "        [31.8433, 26.7011],\n",
      "        [25.1993, 30.1155],\n",
      "        [27.8390, 27.7996]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9463, 0.0969, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9289, 29.9002],\n",
      "        [31.8430, 26.7017],\n",
      "        [25.1992, 30.1157],\n",
      "        [27.8389, 27.7997]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9463, 0.0969, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9291, 29.9002],\n",
      "        [31.8437, 26.7016],\n",
      "        [25.1995, 30.1157],\n",
      "        [27.8391, 27.7997]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9464, 0.0969, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9290, 29.9003],\n",
      "        [31.8433, 26.7022],\n",
      "        [25.1994, 30.1158],\n",
      "        [27.8390, 27.7999]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9464, 0.0969, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9292, 29.9003],\n",
      "        [31.8440, 26.7022],\n",
      "        [25.1997, 30.1158],\n",
      "        [27.8392, 27.7999]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9465, 0.0970, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9291, 29.9004],\n",
      "        [31.8437, 26.7028],\n",
      "        [25.1996, 30.1160],\n",
      "        [27.8391, 27.8000]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9465, 0.0970, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9293, 29.9004],\n",
      "        [31.8443, 26.7027],\n",
      "        [25.1999, 30.1160],\n",
      "        [27.8393, 27.8000]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9968, 0.9466, 0.0970, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9292, 29.9005],\n",
      "        [31.8440, 26.7033],\n",
      "        [25.1997, 30.1161],\n",
      "        [27.8393, 27.8001]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9968, 0.9466, 0.0970, 0.9601], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9294, 29.9005],\n",
      "        [31.8447, 26.7033],\n",
      "        [25.2001, 30.1161],\n",
      "        [27.8395, 27.8001]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9467, 0.0970, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9294, 29.9006],\n",
      "        [31.8443, 26.7039],\n",
      "        [25.1999, 30.1163],\n",
      "        [27.8394, 27.8002]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9467, 0.0970, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9295, 29.9006],\n",
      "        [31.8450, 26.7038],\n",
      "        [25.2003, 30.1163],\n",
      "        [27.8396, 27.8002]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9469, 0.0970, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9295, 29.9007],\n",
      "        [31.8447, 26.7044],\n",
      "        [25.2001, 30.1164],\n",
      "        [27.8395, 27.8003]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9469, 0.0970, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9296, 29.9007],\n",
      "        [31.8454, 26.7043],\n",
      "        [25.2004, 30.1164],\n",
      "        [27.8397, 27.8003]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9470, 0.0971, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9296, 29.9008],\n",
      "        [31.8450, 26.7049],\n",
      "        [25.2003, 30.1166],\n",
      "        [27.8396, 27.8005]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9470, 0.0971, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9297, 29.9008],\n",
      "        [31.8457, 26.7049],\n",
      "        [25.2006, 30.1166],\n",
      "        [27.8398, 27.8005]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9471, 0.0971, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9297, 29.9009],\n",
      "        [31.8453, 26.7055],\n",
      "        [25.2005, 30.1167],\n",
      "        [27.8398, 27.8006]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9471, 0.0971, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9298, 29.9009],\n",
      "        [31.8460, 26.7054],\n",
      "        [25.2008, 30.1167],\n",
      "        [27.8399, 27.8006]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9472, 0.0971, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9298, 29.9010],\n",
      "        [31.8457, 26.7060],\n",
      "        [25.2007, 30.1169],\n",
      "        [27.8399, 27.8007]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9472, 0.0971, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9300, 29.9010],\n",
      "        [31.8464, 26.7059],\n",
      "        [25.2010, 30.1168],\n",
      "        [27.8401, 27.8007]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9473, 0.0971, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9299, 29.9011],\n",
      "        [31.8460, 26.7065],\n",
      "        [25.2009, 30.1170],\n",
      "        [27.8400, 27.8008]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9473, 0.0971, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9301, 29.9011],\n",
      "        [31.8467, 26.7065],\n",
      "        [25.2012, 30.1170],\n",
      "        [27.8402, 27.8008]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9474, 0.0972, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9300, 29.9012],\n",
      "        [31.8463, 26.7070],\n",
      "        [25.2010, 30.1172],\n",
      "        [27.8401, 27.8009]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9474, 0.0972, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9302, 29.9012],\n",
      "        [31.8470, 26.7070],\n",
      "        [25.2014, 30.1171],\n",
      "        [27.8403, 27.8009]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9476, 0.0972, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9301, 29.9013],\n",
      "        [31.8467, 26.7076],\n",
      "        [25.2012, 30.1173],\n",
      "        [27.8402, 27.8010]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9476, 0.0972, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9303, 29.9013],\n",
      "        [31.8473, 26.7075],\n",
      "        [25.2015, 30.1173],\n",
      "        [27.8404, 27.8010]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9477, 0.0972, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9302, 29.9015],\n",
      "        [31.8470, 26.7081],\n",
      "        [25.2014, 30.1175],\n",
      "        [27.8403, 27.8012]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9477, 0.0972, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9304, 29.9014],\n",
      "        [31.8477, 26.7081],\n",
      "        [25.2017, 30.1174],\n",
      "        [27.8405, 27.8011]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9478, 0.0972, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9303, 29.9015],\n",
      "        [31.8473, 26.7086],\n",
      "        [25.2016, 30.1176],\n",
      "        [27.8404, 27.8013]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9478, 0.0972, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9305, 29.9015],\n",
      "        [31.8480, 26.7086],\n",
      "        [25.2019, 30.1176],\n",
      "        [27.8406, 27.8013]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9479, 0.0972, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9304, 29.9017],\n",
      "        [31.8477, 26.7092],\n",
      "        [25.2018, 30.1177],\n",
      "        [27.8406, 27.8014]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9479, 0.0972, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9306, 29.9017],\n",
      "        [31.8483, 26.7091],\n",
      "        [25.2021, 30.1177],\n",
      "        [27.8408, 27.8014]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9480, 0.0973, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9305, 29.9018],\n",
      "        [31.8480, 26.7097],\n",
      "        [25.2020, 30.1179],\n",
      "        [27.8407, 27.8015]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9480, 0.0973, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9307, 29.9017],\n",
      "        [31.8486, 26.7096],\n",
      "        [25.2023, 30.1178],\n",
      "        [27.8409, 27.8015]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9481, 0.0973, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9306, 29.9019],\n",
      "        [31.8483, 26.7102],\n",
      "        [25.2022, 30.1180],\n",
      "        [27.8408, 27.8016]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9481, 0.0973, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9308, 29.9019],\n",
      "        [31.8490, 26.7102],\n",
      "        [25.2025, 30.1180],\n",
      "        [27.8410, 27.8016]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9482, 0.0973, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9307, 29.9020],\n",
      "        [31.8486, 26.7107],\n",
      "        [25.2023, 30.1182],\n",
      "        [27.8409, 27.8017]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9482, 0.0973, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9309, 29.9020],\n",
      "        [31.8493, 26.7107],\n",
      "        [25.2026, 30.1181],\n",
      "        [27.8411, 27.8017]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9484, 0.0973, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9308, 29.9021],\n",
      "        [31.8489, 26.7112],\n",
      "        [25.2025, 30.1183],\n",
      "        [27.8410, 27.8019]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9484, 0.0973, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9310, 29.9021],\n",
      "        [31.8496, 26.7112],\n",
      "        [25.2028, 30.1183],\n",
      "        [27.8412, 27.8019]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9485, 0.0974, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9309, 29.9022],\n",
      "        [31.8492, 26.7117],\n",
      "        [25.2027, 30.1184],\n",
      "        [27.8411, 27.8020]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9485, 0.0974, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9311, 29.9022],\n",
      "        [31.8499, 26.7117],\n",
      "        [25.2030, 30.1184],\n",
      "        [27.8413, 27.8020]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9486, 0.0974, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9310, 29.9023],\n",
      "        [31.8496, 26.7122],\n",
      "        [25.2029, 30.1186],\n",
      "        [27.8413, 27.8021]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9486, 0.0974, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9312, 29.9022],\n",
      "        [31.8502, 26.7122],\n",
      "        [25.2032, 30.1185],\n",
      "        [27.8414, 27.8021]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9487, 0.0974, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9311, 29.9024],\n",
      "        [31.8499, 26.7127],\n",
      "        [25.2031, 30.1187],\n",
      "        [27.8414, 27.8022]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9487, 0.0974, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9313, 29.9024],\n",
      "        [31.8505, 26.7127],\n",
      "        [25.2034, 30.1187],\n",
      "        [27.8416, 27.8022]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9488, 0.0974, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9313, 29.9025],\n",
      "        [31.8502, 26.7133],\n",
      "        [25.2032, 30.1189],\n",
      "        [27.8415, 27.8023]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9488, 0.0974, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9314, 29.9025],\n",
      "        [31.8508, 26.7132],\n",
      "        [25.2035, 30.1188],\n",
      "        [27.8417, 27.8023]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9489, 0.0974, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9313, 29.9026],\n",
      "        [31.8505, 26.7137],\n",
      "        [25.2034, 30.1190],\n",
      "        [27.8416, 27.8024]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9489, 0.0974, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9315, 29.9026],\n",
      "        [31.8512, 26.7137],\n",
      "        [25.2037, 30.1190],\n",
      "        [27.8418, 27.8024]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9490, 0.0975, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9314, 29.9027],\n",
      "        [31.8508, 26.7143],\n",
      "        [25.2036, 30.1191],\n",
      "        [27.8417, 27.8026]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9490, 0.0975, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9316, 29.9027],\n",
      "        [31.8515, 26.7142],\n",
      "        [25.2039, 30.1191],\n",
      "        [27.8419, 27.8025]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9491, 0.0975, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9316, 29.9028],\n",
      "        [31.8511, 26.7148],\n",
      "        [25.2038, 30.1193],\n",
      "        [27.8418, 27.8027]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9491, 0.0975, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9317, 29.9028],\n",
      "        [31.8518, 26.7147],\n",
      "        [25.2041, 30.1192],\n",
      "        [27.8420, 27.8026]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9492, 0.0975, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9316, 29.9029],\n",
      "        [31.8514, 26.7152],\n",
      "        [25.2039, 30.1194],\n",
      "        [27.8419, 27.8028]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9492, 0.0975, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9318, 29.9029],\n",
      "        [31.8521, 26.7152],\n",
      "        [25.2043, 30.1194],\n",
      "        [27.8421, 27.8028]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9493, 0.0975, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9317, 29.9030],\n",
      "        [31.8517, 26.7157],\n",
      "        [25.2041, 30.1195],\n",
      "        [27.8421, 27.8029]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9493, 0.0975, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9319, 29.9030],\n",
      "        [31.8524, 26.7157],\n",
      "        [25.2044, 30.1195],\n",
      "        [27.8422, 27.8029]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9495, 0.0976, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9318, 29.9031],\n",
      "        [31.8520, 26.7162],\n",
      "        [25.2043, 30.1197],\n",
      "        [27.8422, 27.8030]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9495, 0.0976, 0.9602], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9320, 29.9030],\n",
      "        [31.8527, 26.7162],\n",
      "        [25.2046, 30.1196],\n",
      "        [27.8423, 27.8030]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9496, 0.0976, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9319, 29.9032],\n",
      "        [31.8524, 26.7167],\n",
      "        [25.2045, 30.1198],\n",
      "        [27.8423, 27.8031]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9496, 0.0976, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9321, 29.9032],\n",
      "        [31.8530, 26.7167],\n",
      "        [25.2048, 30.1198],\n",
      "        [27.8425, 27.8031]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9497, 0.0976, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9321, 29.9033],\n",
      "        [31.8527, 26.7172],\n",
      "        [25.2047, 30.1200],\n",
      "        [27.8424, 27.8032]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9497, 0.0976, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9322, 29.9032],\n",
      "        [31.8533, 26.7172],\n",
      "        [25.2049, 30.1199],\n",
      "        [27.8426, 27.8032]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9969, 0.9498, 0.0976, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9322, 29.9034],\n",
      "        [31.8530, 26.7177],\n",
      "        [25.2048, 30.1201],\n",
      "        [27.8425, 27.8033]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9969, 0.9498, 0.0976, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9323, 29.9034],\n",
      "        [31.8536, 26.7177],\n",
      "        [25.2051, 30.1201],\n",
      "        [27.8427, 27.8033]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9499, 0.0976, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9323, 29.9035],\n",
      "        [31.8533, 26.7182],\n",
      "        [25.2050, 30.1202],\n",
      "        [27.8426, 27.8034]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9499, 0.0976, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9324, 29.9035],\n",
      "        [31.8539, 26.7182],\n",
      "        [25.2053, 30.1202],\n",
      "        [27.8428, 27.8034]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9500, 0.0977, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9323, 29.9036],\n",
      "        [31.8536, 26.7187],\n",
      "        [25.2052, 30.1204],\n",
      "        [27.8427, 27.8035]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9500, 0.0977, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9325, 29.9036],\n",
      "        [31.8542, 26.7187],\n",
      "        [25.2055, 30.1203],\n",
      "        [27.8429, 27.8035]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9501, 0.0977, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9324, 29.9036],\n",
      "        [31.8539, 26.7192],\n",
      "        [25.2054, 30.1205],\n",
      "        [27.8428, 27.8036]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9501, 0.0977, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9326, 29.9037],\n",
      "        [31.8545, 26.7191],\n",
      "        [25.2057, 30.1205],\n",
      "        [27.8430, 27.8036]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9502, 0.0977, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9325, 29.9037],\n",
      "        [31.8542, 26.7196],\n",
      "        [25.2055, 30.1206],\n",
      "        [27.8429, 27.8038]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9502, 0.0977, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9327, 29.9038],\n",
      "        [31.8548, 26.7196],\n",
      "        [25.2058, 30.1206],\n",
      "        [27.8431, 27.8038]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9503, 0.0977, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9326, 29.9038],\n",
      "        [31.8544, 26.7201],\n",
      "        [25.2057, 30.1207],\n",
      "        [27.8430, 27.8039]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9503, 0.0977, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9328, 29.9038],\n",
      "        [31.8551, 26.7201],\n",
      "        [25.2060, 30.1207],\n",
      "        [27.8432, 27.8039]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9504, 0.0978, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9327, 29.9039],\n",
      "        [31.8547, 26.7206],\n",
      "        [25.2059, 30.1209],\n",
      "        [27.8432, 27.8040]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9504, 0.0978, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9329, 29.9039],\n",
      "        [31.8554, 26.7206],\n",
      "        [25.2062, 30.1209],\n",
      "        [27.8434, 27.8040]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9505, 0.0978, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9328, 29.9040],\n",
      "        [31.8550, 26.7211],\n",
      "        [25.2060, 30.1210],\n",
      "        [27.8433, 27.8041]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9505, 0.0978, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9330, 29.9040],\n",
      "        [31.8557, 26.7211],\n",
      "        [25.2063, 30.1210],\n",
      "        [27.8435, 27.8041]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9506, 0.0978, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9329, 29.9041],\n",
      "        [31.8553, 26.7216],\n",
      "        [25.2062, 30.1212],\n",
      "        [27.8434, 27.8042]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9506, 0.0978, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9331, 29.9041],\n",
      "        [31.8559, 26.7215],\n",
      "        [25.2065, 30.1211],\n",
      "        [27.8436, 27.8042]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9507, 0.0978, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9330, 29.9042],\n",
      "        [31.8556, 26.7220],\n",
      "        [25.2064, 30.1213],\n",
      "        [27.8435, 27.8043]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9507, 0.0978, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9332, 29.9042],\n",
      "        [31.8562, 26.7220],\n",
      "        [25.2067, 30.1213],\n",
      "        [27.8437, 27.8043]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9508, 0.0978, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9331, 29.9043],\n",
      "        [31.8559, 26.7225],\n",
      "        [25.2066, 30.1214],\n",
      "        [27.8436, 27.8044]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9508, 0.0978, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9333, 29.9043],\n",
      "        [31.8565, 26.7225],\n",
      "        [25.2068, 30.1214],\n",
      "        [27.8438, 27.8044]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9509, 0.0979, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9332, 29.9044],\n",
      "        [31.8562, 26.7230],\n",
      "        [25.2067, 30.1216],\n",
      "        [27.8437, 27.8045]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9509, 0.0979, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9334, 29.9044],\n",
      "        [31.8568, 26.7229],\n",
      "        [25.2070, 30.1215],\n",
      "        [27.8439, 27.8045]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9510, 0.0979, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9333, 29.9045],\n",
      "        [31.8565, 26.7234],\n",
      "        [25.2069, 30.1217],\n",
      "        [27.8438, 27.8046]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9510, 0.0979, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9335, 29.9045],\n",
      "        [31.8571, 26.7234],\n",
      "        [25.2072, 30.1217],\n",
      "        [27.8440, 27.8046]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9511, 0.0979, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9334, 29.9046],\n",
      "        [31.8568, 26.7239],\n",
      "        [25.2071, 30.1218],\n",
      "        [27.8439, 27.8047]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9511, 0.0979, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9336, 29.9046],\n",
      "        [31.8574, 26.7239],\n",
      "        [25.2074, 30.1218],\n",
      "        [27.8441, 27.8047]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9512, 0.0979, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9335, 29.9047],\n",
      "        [31.8571, 26.7244],\n",
      "        [25.2072, 30.1219],\n",
      "        [27.8440, 27.8048]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9512, 0.0979, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9337, 29.9047],\n",
      "        [31.8577, 26.7243],\n",
      "        [25.2075, 30.1219],\n",
      "        [27.8442, 27.8048]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9513, 0.0980, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9336, 29.9048],\n",
      "        [31.8574, 26.7248],\n",
      "        [25.2074, 30.1221],\n",
      "        [27.8441, 27.8050]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9513, 0.0980, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9338, 29.9048],\n",
      "        [31.8580, 26.7248],\n",
      "        [25.2077, 30.1220],\n",
      "        [27.8443, 27.8049]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9514, 0.0980, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9337, 29.9049],\n",
      "        [31.8577, 26.7253],\n",
      "        [25.2076, 30.1222],\n",
      "        [27.8443, 27.8051]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9514, 0.0980, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9339, 29.9049],\n",
      "        [31.8582, 26.7252],\n",
      "        [25.2079, 30.1222],\n",
      "        [27.8444, 27.8050]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9515, 0.0980, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9338, 29.9050],\n",
      "        [31.8579, 26.7257],\n",
      "        [25.2078, 30.1223],\n",
      "        [27.8443, 27.8052]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9515, 0.0980, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9340, 29.9050],\n",
      "        [31.8585, 26.7257],\n",
      "        [25.2080, 30.1223],\n",
      "        [27.8445, 27.8052]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9516, 0.0980, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9339, 29.9051],\n",
      "        [31.8582, 26.7262],\n",
      "        [25.2079, 30.1225],\n",
      "        [27.8444, 27.8053]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9516, 0.0980, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9341, 29.9051],\n",
      "        [31.8588, 26.7262],\n",
      "        [25.2082, 30.1224],\n",
      "        [27.8446, 27.8053]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9517, 0.0980, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9340, 29.9052],\n",
      "        [31.8585, 26.7267],\n",
      "        [25.2081, 30.1226],\n",
      "        [27.8446, 27.8054]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9517, 0.0980, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9342, 29.9052],\n",
      "        [31.8591, 26.7266],\n",
      "        [25.2084, 30.1225],\n",
      "        [27.8447, 27.8054]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9518, 0.0981, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9341, 29.9053],\n",
      "        [31.8588, 26.7271],\n",
      "        [25.2083, 30.1227],\n",
      "        [27.8447, 27.8055]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9518, 0.0981, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9343, 29.9053],\n",
      "        [31.8594, 26.7271],\n",
      "        [25.2085, 30.1227],\n",
      "        [27.8448, 27.8055]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9519, 0.0981, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9342, 29.9054],\n",
      "        [31.8591, 26.7276],\n",
      "        [25.2084, 30.1228],\n",
      "        [27.8448, 27.8056]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9519, 0.0981, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9343, 29.9054],\n",
      "        [31.8596, 26.7275],\n",
      "        [25.2087, 30.1228],\n",
      "        [27.8449, 27.8056]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9520, 0.0981, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9343, 29.9055],\n",
      "        [31.8593, 26.7280],\n",
      "        [25.2086, 30.1230],\n",
      "        [27.8449, 27.8057]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9520, 0.0981, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9344, 29.9055],\n",
      "        [31.8599, 26.7280],\n",
      "        [25.2089, 30.1229],\n",
      "        [27.8450, 27.8057]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9521, 0.0981, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9344, 29.9056],\n",
      "        [31.8596, 26.7285],\n",
      "        [25.2088, 30.1231],\n",
      "        [27.8450, 27.8058]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9521, 0.0981, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9345, 29.9056],\n",
      "        [31.8602, 26.7284],\n",
      "        [25.2090, 30.1231],\n",
      "        [27.8452, 27.8058]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9522, 0.0982, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9345, 29.9057],\n",
      "        [31.8599, 26.7289],\n",
      "        [25.2089, 30.1232],\n",
      "        [27.8451, 27.8059]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9522, 0.0982, 0.9603], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9346, 29.9057],\n",
      "        [31.8605, 26.7289],\n",
      "        [25.2092, 30.1232],\n",
      "        [27.8453, 27.8059]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9523, 0.0982, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9346, 29.9057],\n",
      "        [31.8601, 26.7294],\n",
      "        [25.2091, 30.1234],\n",
      "        [27.8452, 27.8060]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9523, 0.0982, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9347, 29.9057],\n",
      "        [31.8607, 26.7293],\n",
      "        [25.2094, 30.1233],\n",
      "        [27.8454, 27.8060]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9524, 0.0982, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9347, 29.9058],\n",
      "        [31.8604, 26.7298],\n",
      "        [25.2093, 30.1235],\n",
      "        [27.8453, 27.8061]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9524, 0.0982, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9348, 29.9058],\n",
      "        [31.8610, 26.7298],\n",
      "        [25.2095, 30.1235],\n",
      "        [27.8455, 27.8061]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9525, 0.0982, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9348, 29.9059],\n",
      "        [31.8607, 26.7303],\n",
      "        [25.2094, 30.1236],\n",
      "        [27.8454, 27.8062]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9525, 0.0982, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9349, 29.9059],\n",
      "        [31.8613, 26.7302],\n",
      "        [25.2097, 30.1236],\n",
      "        [27.8456, 27.8062]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9526, 0.0982, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9348, 29.9060],\n",
      "        [31.8610, 26.7307],\n",
      "        [25.2096, 30.1237],\n",
      "        [27.8455, 27.8063]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9526, 0.0982, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9350, 29.9060],\n",
      "        [31.8615, 26.7307],\n",
      "        [25.2099, 30.1237],\n",
      "        [27.8457, 27.8063]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9527, 0.0983, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9349, 29.9061],\n",
      "        [31.8612, 26.7311],\n",
      "        [25.2098, 30.1239],\n",
      "        [27.8456, 27.8064]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9527, 0.0983, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9351, 29.9061],\n",
      "        [31.8618, 26.7311],\n",
      "        [25.2100, 30.1238],\n",
      "        [27.8458, 27.8064]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9970, 0.9528, 0.0983, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9350, 29.9062],\n",
      "        [31.8615, 26.7316],\n",
      "        [25.2099, 30.1240],\n",
      "        [27.8457, 27.8065]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9970, 0.9528, 0.0983, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9352, 29.9062],\n",
      "        [31.8621, 26.7315],\n",
      "        [25.2102, 30.1239],\n",
      "        [27.8459, 27.8065]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9529, 0.0983, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9351, 29.9063],\n",
      "        [31.8618, 26.7320],\n",
      "        [25.2101, 30.1241],\n",
      "        [27.8458, 27.8066]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9529, 0.0983, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9353, 29.9063],\n",
      "        [31.8623, 26.7320],\n",
      "        [25.2103, 30.1241],\n",
      "        [27.8460, 27.8066]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9529, 0.0983, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9352, 29.9064],\n",
      "        [31.8620, 26.7324],\n",
      "        [25.2102, 30.1242],\n",
      "        [27.8459, 27.8067]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9529, 0.0983, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9354, 29.9064],\n",
      "        [31.8626, 26.7324],\n",
      "        [25.2105, 30.1242],\n",
      "        [27.8461, 27.8067]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9530, 0.0983, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9353, 29.9065],\n",
      "        [31.8623, 26.7329],\n",
      "        [25.2104, 30.1244],\n",
      "        [27.8460, 27.8068]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9530, 0.0983, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9354, 29.9065],\n",
      "        [31.8629, 26.7328],\n",
      "        [25.2107, 30.1243],\n",
      "        [27.8462, 27.8068]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9531, 0.0984, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9354, 29.9066],\n",
      "        [31.8626, 26.7333],\n",
      "        [25.2106, 30.1245],\n",
      "        [27.8461, 27.8069]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9531, 0.0984, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9355, 29.9066],\n",
      "        [31.8631, 26.7333],\n",
      "        [25.2108, 30.1244],\n",
      "        [27.8463, 27.8069]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9532, 0.0984, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9355, 29.9067],\n",
      "        [31.8628, 26.7337],\n",
      "        [25.2107, 30.1246],\n",
      "        [27.8462, 27.8070]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9532, 0.0984, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9356, 29.9067],\n",
      "        [31.8634, 26.7337],\n",
      "        [25.2110, 30.1246],\n",
      "        [27.8464, 27.8070]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9533, 0.0984, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9356, 29.9068],\n",
      "        [31.8631, 26.7342],\n",
      "        [25.2109, 30.1247],\n",
      "        [27.8463, 27.8071]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9533, 0.0984, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9357, 29.9067],\n",
      "        [31.8636, 26.7341],\n",
      "        [25.2112, 30.1247],\n",
      "        [27.8465, 27.8071]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9534, 0.0984, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9357, 29.9068],\n",
      "        [31.8634, 26.7346],\n",
      "        [25.2111, 30.1248],\n",
      "        [27.8464, 27.8072]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9534, 0.0984, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9358, 29.9068],\n",
      "        [31.8639, 26.7346],\n",
      "        [25.2113, 30.1248],\n",
      "        [27.8466, 27.8072]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9535, 0.0985, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9357, 29.9069],\n",
      "        [31.8636, 26.7350],\n",
      "        [25.2112, 30.1250],\n",
      "        [27.8465, 27.8073]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9535, 0.0985, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9359, 29.9069],\n",
      "        [31.8642, 26.7350],\n",
      "        [25.2115, 30.1249],\n",
      "        [27.8467, 27.8073]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9536, 0.0985, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9359, 29.9070],\n",
      "        [31.8639, 26.7355],\n",
      "        [25.2114, 30.1251],\n",
      "        [27.8466, 27.8074]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9536, 0.0985, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9360, 29.9070],\n",
      "        [31.8644, 26.7354],\n",
      "        [25.2116, 30.1250],\n",
      "        [27.8468, 27.8074]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9537, 0.0985, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9359, 29.9071],\n",
      "        [31.8641, 26.7359],\n",
      "        [25.2115, 30.1252],\n",
      "        [27.8467, 27.8075]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9537, 0.0985, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9361, 29.9071],\n",
      "        [31.8647, 26.7358],\n",
      "        [25.2118, 30.1252],\n",
      "        [27.8469, 27.8075]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9538, 0.0985, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9360, 29.9072],\n",
      "        [31.8644, 26.7363],\n",
      "        [25.2117, 30.1253],\n",
      "        [27.8468, 27.8076]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9538, 0.0985, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9362, 29.9072],\n",
      "        [31.8649, 26.7363],\n",
      "        [25.2120, 30.1253],\n",
      "        [27.8470, 27.8076]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9539, 0.0985, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9361, 29.9073],\n",
      "        [31.8646, 26.7367],\n",
      "        [25.2119, 30.1254],\n",
      "        [27.8469, 27.8077]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9539, 0.0985, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9363, 29.9073],\n",
      "        [31.8652, 26.7367],\n",
      "        [25.2121, 30.1254],\n",
      "        [27.8471, 27.8077]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9540, 0.0986, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9362, 29.9074],\n",
      "        [31.8649, 26.7371],\n",
      "        [25.2120, 30.1256],\n",
      "        [27.8470, 27.8078]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9540, 0.0986, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9363, 29.9074],\n",
      "        [31.8654, 26.7371],\n",
      "        [25.2123, 30.1255],\n",
      "        [27.8472, 27.8078]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9540, 0.0986, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9363, 29.9075],\n",
      "        [31.8652, 26.7376],\n",
      "        [25.2122, 30.1257],\n",
      "        [27.8471, 27.8079]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9540, 0.0986, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9364, 29.9075],\n",
      "        [31.8657, 26.7375],\n",
      "        [25.2124, 30.1257],\n",
      "        [27.8473, 27.8079]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9541, 0.0986, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9364, 29.9076],\n",
      "        [31.8654, 26.7380],\n",
      "        [25.2123, 30.1258],\n",
      "        [27.8472, 27.8080]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9541, 0.0986, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9365, 29.9076],\n",
      "        [31.8659, 26.7379],\n",
      "        [25.2126, 30.1258],\n",
      "        [27.8474, 27.8080]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9542, 0.0986, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9365, 29.9077],\n",
      "        [31.8657, 26.7384],\n",
      "        [25.2125, 30.1259],\n",
      "        [27.8473, 27.8081]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9542, 0.0986, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9366, 29.9076],\n",
      "        [31.8662, 26.7384],\n",
      "        [25.2128, 30.1259],\n",
      "        [27.8475, 27.8081]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9543, 0.0986, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9366, 29.9077],\n",
      "        [31.8659, 26.7388],\n",
      "        [25.2127, 30.1261],\n",
      "        [27.8474, 27.8082]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9543, 0.0986, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9367, 29.9077],\n",
      "        [31.8664, 26.7388],\n",
      "        [25.2129, 30.1260],\n",
      "        [27.8476, 27.8082]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9544, 0.0987, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9366, 29.9078],\n",
      "        [31.8662, 26.7392],\n",
      "        [25.2128, 30.1262],\n",
      "        [27.8475, 27.8083]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9544, 0.0987, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9368, 29.9078],\n",
      "        [31.8667, 26.7392],\n",
      "        [25.2131, 30.1261],\n",
      "        [27.8477, 27.8083]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9545, 0.0987, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9367, 29.9079],\n",
      "        [31.8664, 26.7396],\n",
      "        [25.2130, 30.1263],\n",
      "        [27.8476, 27.8084]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9545, 0.0987, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9369, 29.9079],\n",
      "        [31.8669, 26.7396],\n",
      "        [25.2132, 30.1262],\n",
      "        [27.8477, 27.8084]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9546, 0.0987, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9368, 29.9080],\n",
      "        [31.8667, 26.7400],\n",
      "        [25.2131, 30.1264],\n",
      "        [27.8477, 27.8085]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9546, 0.0987, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9370, 29.9080],\n",
      "        [31.8672, 26.7400],\n",
      "        [25.2134, 30.1264],\n",
      "        [27.8479, 27.8085]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9547, 0.0987, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9369, 29.9081],\n",
      "        [31.8669, 26.7404],\n",
      "        [25.2133, 30.1265],\n",
      "        [27.8478, 27.8086]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9547, 0.0987, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9371, 29.9081],\n",
      "        [31.8674, 26.7404],\n",
      "        [25.2135, 30.1265],\n",
      "        [27.8480, 27.8086]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9547, 0.0987, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9370, 29.9082],\n",
      "        [31.8672, 26.7408],\n",
      "        [25.2134, 30.1266],\n",
      "        [27.8479, 27.8087]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9547, 0.0987, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9371, 29.9082],\n",
      "        [31.8677, 26.7408],\n",
      "        [25.2137, 30.1266],\n",
      "        [27.8480, 27.8087]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9548, 0.0988, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9371, 29.9083],\n",
      "        [31.8674, 26.7413],\n",
      "        [25.2136, 30.1268],\n",
      "        [27.8480, 27.8088]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9548, 0.0988, 0.9604], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9372, 29.9083],\n",
      "        [31.8679, 26.7412],\n",
      "        [25.2139, 30.1267],\n",
      "        [27.8481, 27.8088]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9549, 0.0988, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9372, 29.9083],\n",
      "        [31.8677, 26.7417],\n",
      "        [25.2137, 30.1269],\n",
      "        [27.8481, 27.8089]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9549, 0.0988, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9373, 29.9083],\n",
      "        [31.8682, 26.7416],\n",
      "        [25.2140, 30.1268],\n",
      "        [27.8482, 27.8089]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9550, 0.0988, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9373, 29.9084],\n",
      "        [31.8679, 26.7421],\n",
      "        [25.2139, 30.1270],\n",
      "        [27.8482, 27.8090]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9550, 0.0988, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9374, 29.9084],\n",
      "        [31.8684, 26.7420],\n",
      "        [25.2142, 30.1270],\n",
      "        [27.8483, 27.8090]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9551, 0.0988, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9373, 29.9085],\n",
      "        [31.8681, 26.7425],\n",
      "        [25.2140, 30.1271],\n",
      "        [27.8483, 27.8091]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9551, 0.0988, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9375, 29.9085],\n",
      "        [31.8686, 26.7424],\n",
      "        [25.2143, 30.1271],\n",
      "        [27.8484, 27.8091]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9552, 0.0988, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9374, 29.9086],\n",
      "        [31.8684, 26.7429],\n",
      "        [25.2142, 30.1272],\n",
      "        [27.8484, 27.8092]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9552, 0.0988, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9376, 29.9086],\n",
      "        [31.8689, 26.7428],\n",
      "        [25.2145, 30.1272],\n",
      "        [27.8485, 27.8092]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9553, 0.0989, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9375, 29.9087],\n",
      "        [31.8686, 26.7433],\n",
      "        [25.2144, 30.1273],\n",
      "        [27.8485, 27.8093]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9553, 0.0989, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9376, 29.9087],\n",
      "        [31.8691, 26.7432],\n",
      "        [25.2146, 30.1273],\n",
      "        [27.8486, 27.8093]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9553, 0.0989, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9376, 29.9088],\n",
      "        [31.8689, 26.7437],\n",
      "        [25.2145, 30.1275],\n",
      "        [27.8486, 27.8094]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9553, 0.0989, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9377, 29.9088],\n",
      "        [31.8694, 26.7436],\n",
      "        [25.2148, 30.1274],\n",
      "        [27.8487, 27.8094]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9554, 0.0989, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9377, 29.9089],\n",
      "        [31.8691, 26.7441],\n",
      "        [25.2147, 30.1276],\n",
      "        [27.8486, 27.8095]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9554, 0.0989, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9378, 29.9089],\n",
      "        [31.8696, 26.7440],\n",
      "        [25.2149, 30.1275],\n",
      "        [27.8488, 27.8095]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9555, 0.0989, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9378, 29.9090],\n",
      "        [31.8693, 26.7445],\n",
      "        [25.2148, 30.1277],\n",
      "        [27.8487, 27.8096]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9555, 0.0989, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9379, 29.9089],\n",
      "        [31.8698, 26.7444],\n",
      "        [25.2151, 30.1276],\n",
      "        [27.8489, 27.8096]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9971, 0.9556, 0.0990, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9379, 29.9090],\n",
      "        [31.8696, 26.7448],\n",
      "        [25.2150, 30.1278],\n",
      "        [27.8488, 27.8097]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9971, 0.9556, 0.0990, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9380, 29.9090],\n",
      "        [31.8701, 26.7448],\n",
      "        [25.2152, 30.1278],\n",
      "        [27.8490, 27.8097]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9557, 0.0990, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9379, 29.9091],\n",
      "        [31.8698, 26.7452],\n",
      "        [25.2151, 30.1279],\n",
      "        [27.8489, 27.8098]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9557, 0.0990, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9381, 29.9091],\n",
      "        [31.8703, 26.7452],\n",
      "        [25.2154, 30.1279],\n",
      "        [27.8491, 27.8098]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9558, 0.0990, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9380, 29.9092],\n",
      "        [31.8701, 26.7456],\n",
      "        [25.2153, 30.1280],\n",
      "        [27.8490, 27.8099]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9558, 0.0990, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9382, 29.9092],\n",
      "        [31.8706, 26.7456],\n",
      "        [25.2155, 30.1280],\n",
      "        [27.8492, 27.8099]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9558, 0.0990, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9381, 29.9093],\n",
      "        [31.8703, 26.7460],\n",
      "        [25.2154, 30.1281],\n",
      "        [27.8491, 27.8100]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9558, 0.0990, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9383, 29.9093],\n",
      "        [31.8708, 26.7460],\n",
      "        [25.2157, 30.1281],\n",
      "        [27.8493, 27.8099]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9559, 0.0990, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9382, 29.9094],\n",
      "        [31.8705, 26.7464],\n",
      "        [25.2156, 30.1283],\n",
      "        [27.8492, 27.8100]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9559, 0.0990, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9383, 29.9094],\n",
      "        [31.8710, 26.7464],\n",
      "        [25.2158, 30.1282],\n",
      "        [27.8494, 27.8100]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9560, 0.0991, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9383, 29.9095],\n",
      "        [31.8708, 26.7468],\n",
      "        [25.2157, 30.1284],\n",
      "        [27.8493, 27.8101]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9560, 0.0991, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9384, 29.9095],\n",
      "        [31.8713, 26.7468],\n",
      "        [25.2160, 30.1283],\n",
      "        [27.8495, 27.8101]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9561, 0.0991, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9384, 29.9095],\n",
      "        [31.8710, 26.7472],\n",
      "        [25.2159, 30.1285],\n",
      "        [27.8494, 27.8102]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9561, 0.0991, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9385, 29.9095],\n",
      "        [31.8715, 26.7471],\n",
      "        [25.2161, 30.1284],\n",
      "        [27.8495, 27.8102]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9562, 0.0991, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9385, 29.9096],\n",
      "        [31.8712, 26.7476],\n",
      "        [25.2160, 30.1286],\n",
      "        [27.8495, 27.8103]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9562, 0.0991, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9386, 29.9096],\n",
      "        [31.8717, 26.7475],\n",
      "        [25.2163, 30.1286],\n",
      "        [27.8496, 27.8103]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9562, 0.0991, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9385, 29.9097],\n",
      "        [31.8715, 26.7479],\n",
      "        [25.2162, 30.1287],\n",
      "        [27.8496, 27.8104]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9562, 0.0991, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9387, 29.9097],\n",
      "        [31.8720, 26.7479],\n",
      "        [25.2164, 30.1287],\n",
      "        [27.8497, 27.8104]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9563, 0.0991, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9386, 29.9098],\n",
      "        [31.8717, 26.7483],\n",
      "        [25.2163, 30.1288],\n",
      "        [27.8497, 27.8105]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9563, 0.0991, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9387, 29.9098],\n",
      "        [31.8722, 26.7483],\n",
      "        [25.2166, 30.1288],\n",
      "        [27.8498, 27.8105]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9564, 0.0992, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9387, 29.9099],\n",
      "        [31.8719, 26.7487],\n",
      "        [25.2165, 30.1289],\n",
      "        [27.8498, 27.8106]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9564, 0.0992, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9388, 29.9099],\n",
      "        [31.8724, 26.7487],\n",
      "        [25.2167, 30.1289],\n",
      "        [27.8499, 27.8106]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9565, 0.0992, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9388, 29.9100],\n",
      "        [31.8722, 26.7491],\n",
      "        [25.2166, 30.1290],\n",
      "        [27.8499, 27.8107]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9565, 0.0992, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9389, 29.9100],\n",
      "        [31.8726, 26.7491],\n",
      "        [25.2169, 30.1290],\n",
      "        [27.8500, 27.8107]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9566, 0.0992, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9389, 29.9101],\n",
      "        [31.8724, 26.7495],\n",
      "        [25.2168, 30.1292],\n",
      "        [27.8499, 27.8108]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9566, 0.0992, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9390, 29.9100],\n",
      "        [31.8729, 26.7494],\n",
      "        [25.2170, 30.1291],\n",
      "        [27.8501, 27.8108]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9566, 0.0992, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9389, 29.9101],\n",
      "        [31.8726, 26.7498],\n",
      "        [25.2169, 30.1293],\n",
      "        [27.8500, 27.8109]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9566, 0.0992, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9391, 29.9101],\n",
      "        [31.8731, 26.7498],\n",
      "        [25.2172, 30.1292],\n",
      "        [27.8502, 27.8109]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9567, 0.0992, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9390, 29.9102],\n",
      "        [31.8728, 26.7502],\n",
      "        [25.2171, 30.1294],\n",
      "        [27.8501, 27.8110]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9567, 0.0992, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9392, 29.9102],\n",
      "        [31.8733, 26.7502],\n",
      "        [25.2173, 30.1293],\n",
      "        [27.8503, 27.8110]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9568, 0.0993, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9391, 29.9103],\n",
      "        [31.8731, 26.7506],\n",
      "        [25.2172, 30.1295],\n",
      "        [27.8502, 27.8111]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9568, 0.0993, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9392, 29.9103],\n",
      "        [31.8735, 26.7506],\n",
      "        [25.2175, 30.1295],\n",
      "        [27.8504, 27.8111]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9569, 0.0993, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9392, 29.9104],\n",
      "        [31.8733, 26.7510],\n",
      "        [25.2174, 30.1296],\n",
      "        [27.8503, 27.8112]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9569, 0.0993, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9393, 29.9104],\n",
      "        [31.8737, 26.7509],\n",
      "        [25.2176, 30.1296],\n",
      "        [27.8504, 27.8111]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9570, 0.0993, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9393, 29.9105],\n",
      "        [31.8735, 26.7513],\n",
      "        [25.2175, 30.1297],\n",
      "        [27.8504, 27.8113]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9570, 0.0993, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9394, 29.9105],\n",
      "        [31.8740, 26.7513],\n",
      "        [25.2178, 30.1297],\n",
      "        [27.8506, 27.8112]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9570, 0.0993, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9394, 29.9106],\n",
      "        [31.8737, 26.7517],\n",
      "        [25.2177, 30.1298],\n",
      "        [27.8505, 27.8113]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9570, 0.0993, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9395, 29.9105],\n",
      "        [31.8742, 26.7517],\n",
      "        [25.2179, 30.1298],\n",
      "        [27.8506, 27.8113]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9571, 0.0993, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9394, 29.9106],\n",
      "        [31.8740, 26.7521],\n",
      "        [25.2178, 30.1299],\n",
      "        [27.8506, 27.8114]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9571, 0.0993, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9396, 29.9106],\n",
      "        [31.8744, 26.7520],\n",
      "        [25.2181, 30.1299],\n",
      "        [27.8507, 27.8114]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9572, 0.0994, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9395, 29.9107],\n",
      "        [31.8742, 26.7524],\n",
      "        [25.2180, 30.1300],\n",
      "        [27.8507, 27.8115]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9572, 0.0994, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9396, 29.9107],\n",
      "        [31.8746, 26.7524],\n",
      "        [25.2182, 30.1300],\n",
      "        [27.8508, 27.8115]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9573, 0.0994, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9396, 29.9108],\n",
      "        [31.8744, 26.7528],\n",
      "        [25.2181, 30.1301],\n",
      "        [27.8508, 27.8116]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9573, 0.0994, 0.9605], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9397, 29.9108],\n",
      "        [31.8749, 26.7528],\n",
      "        [25.2184, 30.1301],\n",
      "        [27.8509, 27.8116]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9573, 0.0994, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9397, 29.9109],\n",
      "        [31.8746, 26.7532],\n",
      "        [25.2183, 30.1302],\n",
      "        [27.8508, 27.8117]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9573, 0.0994, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9398, 29.9109],\n",
      "        [31.8751, 26.7531],\n",
      "        [25.2185, 30.1302],\n",
      "        [27.8510, 27.8117]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9574, 0.0994, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9397, 29.9110],\n",
      "        [31.8748, 26.7535],\n",
      "        [25.2184, 30.1304],\n",
      "        [27.8509, 27.8118]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9574, 0.0994, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9399, 29.9109],\n",
      "        [31.8753, 26.7535],\n",
      "        [25.2186, 30.1303],\n",
      "        [27.8511, 27.8118]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9575, 0.0994, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9398, 29.9110],\n",
      "        [31.8750, 26.7539],\n",
      "        [25.2185, 30.1305],\n",
      "        [27.8510, 27.8119]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9575, 0.0994, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9400, 29.9110],\n",
      "        [31.8755, 26.7539],\n",
      "        [25.2188, 30.1304],\n",
      "        [27.8512, 27.8119]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9576, 0.0995, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9399, 29.9111],\n",
      "        [31.8753, 26.7543],\n",
      "        [25.2187, 30.1306],\n",
      "        [27.8511, 27.8120]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9576, 0.0995, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9400, 29.9111],\n",
      "        [31.8757, 26.7542],\n",
      "        [25.2189, 30.1305],\n",
      "        [27.8513, 27.8120]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9577, 0.0995, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9400, 29.9112],\n",
      "        [31.8755, 26.7546],\n",
      "        [25.2189, 30.1307],\n",
      "        [27.8512, 27.8121]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9577, 0.0995, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9401, 29.9112],\n",
      "        [31.8759, 26.7546],\n",
      "        [25.2191, 30.1306],\n",
      "        [27.8513, 27.8121]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9577, 0.0995, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9401, 29.9113],\n",
      "        [31.8757, 26.7550],\n",
      "        [25.2190, 30.1308],\n",
      "        [27.8513, 27.8121]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9577, 0.0995, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9402, 29.9113],\n",
      "        [31.8762, 26.7550],\n",
      "        [25.2192, 30.1308],\n",
      "        [27.8514, 27.8122]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9578, 0.0995, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9401, 29.9114],\n",
      "        [31.8759, 26.7553],\n",
      "        [25.2191, 30.1309],\n",
      "        [27.8514, 27.8122]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9578, 0.0995, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9403, 29.9114],\n",
      "        [31.8764, 26.7553],\n",
      "        [25.2194, 30.1309],\n",
      "        [27.8515, 27.8122]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9579, 0.0995, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9402, 29.9115],\n",
      "        [31.8761, 26.7557],\n",
      "        [25.2193, 30.1310],\n",
      "        [27.8515, 27.8123]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9579, 0.0995, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9404, 29.9114],\n",
      "        [31.8766, 26.7557],\n",
      "        [25.2195, 30.1310],\n",
      "        [27.8516, 27.8123]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9580, 0.0996, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9403, 29.9115],\n",
      "        [31.8763, 26.7561],\n",
      "        [25.2194, 30.1311],\n",
      "        [27.8515, 27.8124]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9580, 0.0996, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9404, 29.9115],\n",
      "        [31.8768, 26.7560],\n",
      "        [25.2197, 30.1311],\n",
      "        [27.8517, 27.8124]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9580, 0.0996, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9404, 29.9116],\n",
      "        [31.8766, 26.7564],\n",
      "        [25.2196, 30.1312],\n",
      "        [27.8516, 27.8125]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9580, 0.0996, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9405, 29.9116],\n",
      "        [31.8770, 26.7564],\n",
      "        [25.2198, 30.1312],\n",
      "        [27.8518, 27.8125]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9581, 0.0996, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9405, 29.9117],\n",
      "        [31.8768, 26.7568],\n",
      "        [25.2197, 30.1313],\n",
      "        [27.8517, 27.8126]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9581, 0.0996, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9406, 29.9117],\n",
      "        [31.8772, 26.7567],\n",
      "        [25.2200, 30.1313],\n",
      "        [27.8519, 27.8126]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9582, 0.0996, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9406, 29.9118],\n",
      "        [31.8770, 26.7571],\n",
      "        [25.2199, 30.1314],\n",
      "        [27.8518, 27.8127]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9582, 0.0996, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9407, 29.9117],\n",
      "        [31.8774, 26.7571],\n",
      "        [25.2201, 30.1314],\n",
      "        [27.8519, 27.8127]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9972, 0.9582, 0.0996, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9406, 29.9118],\n",
      "        [31.8772, 26.7575],\n",
      "        [25.2200, 30.1315],\n",
      "        [27.8519, 27.8128]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9972, 0.9582, 0.0996, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9408, 29.9118],\n",
      "        [31.8776, 26.7574],\n",
      "        [25.2202, 30.1315],\n",
      "        [27.8520, 27.8128]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9583, 0.0997, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9407, 29.9119],\n",
      "        [31.8774, 26.7578],\n",
      "        [25.2201, 30.1316],\n",
      "        [27.8520, 27.8129]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9583, 0.0997, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9408, 29.9119],\n",
      "        [31.8778, 26.7578],\n",
      "        [25.2204, 30.1316],\n",
      "        [27.8521, 27.8129]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9584, 0.0997, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9408, 29.9120],\n",
      "        [31.8776, 26.7582],\n",
      "        [25.2203, 30.1317],\n",
      "        [27.8521, 27.8130]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9584, 0.0997, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9409, 29.9120],\n",
      "        [31.8781, 26.7581],\n",
      "        [25.2205, 30.1317],\n",
      "        [27.8522, 27.8129]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9585, 0.0997, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9409, 29.9121],\n",
      "        [31.8778, 26.7585],\n",
      "        [25.2204, 30.1318],\n",
      "        [27.8522, 27.8130]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9585, 0.0997, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9410, 29.9121],\n",
      "        [31.8783, 26.7585],\n",
      "        [25.2206, 30.1318],\n",
      "        [27.8523, 27.8130]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9585, 0.0997, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9409, 29.9122],\n",
      "        [31.8780, 26.7589],\n",
      "        [25.2206, 30.1320],\n",
      "        [27.8522, 27.8131]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9585, 0.0997, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9411, 29.9122],\n",
      "        [31.8785, 26.7588],\n",
      "        [25.2208, 30.1319],\n",
      "        [27.8524, 27.8131]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9586, 0.0997, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9410, 29.9122],\n",
      "        [31.8782, 26.7592],\n",
      "        [25.2207, 30.1320],\n",
      "        [27.8523, 27.8132]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9586, 0.0997, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9411, 29.9122],\n",
      "        [31.8787, 26.7592],\n",
      "        [25.2209, 30.1320],\n",
      "        [27.8525, 27.8132]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9587, 0.0998, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9411, 29.9123],\n",
      "        [31.8784, 26.7596],\n",
      "        [25.2208, 30.1322],\n",
      "        [27.8524, 27.8133]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9587, 0.0998, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9412, 29.9123],\n",
      "        [31.8789, 26.7595],\n",
      "        [25.2211, 30.1321],\n",
      "        [27.8526, 27.8133]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9588, 0.0998, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9411, 29.9124],\n",
      "        [31.8786, 26.7599],\n",
      "        [25.2210, 30.1322],\n",
      "        [27.8525, 27.8134]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9588, 0.0998, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9413, 29.9124],\n",
      "        [31.8791, 26.7599],\n",
      "        [25.2212, 30.1322],\n",
      "        [27.8526, 27.8134]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9588, 0.0998, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9412, 29.9125],\n",
      "        [31.8789, 26.7602],\n",
      "        [25.2211, 30.1324],\n",
      "        [27.8526, 27.8135]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9588, 0.0998, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9414, 29.9125],\n",
      "        [31.8793, 26.7602],\n",
      "        [25.2214, 30.1323],\n",
      "        [27.8527, 27.8135]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9589, 0.0998, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9413, 29.9126],\n",
      "        [31.8791, 26.7606],\n",
      "        [25.2213, 30.1325],\n",
      "        [27.8527, 27.8136]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9589, 0.0998, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9414, 29.9125],\n",
      "        [31.8795, 26.7606],\n",
      "        [25.2215, 30.1324],\n",
      "        [27.8528, 27.8136]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9590, 0.0998, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9414, 29.9126],\n",
      "        [31.8793, 26.7609],\n",
      "        [25.2214, 30.1326],\n",
      "        [27.8528, 27.8137]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9590, 0.0998, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9415, 29.9126],\n",
      "        [31.8797, 26.7609],\n",
      "        [25.2216, 30.1325],\n",
      "        [27.8529, 27.8136]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9590, 0.0999, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9415, 29.9127],\n",
      "        [31.8795, 26.7613],\n",
      "        [25.2215, 30.1327],\n",
      "        [27.8528, 27.8137]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9590, 0.0999, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9416, 29.9127],\n",
      "        [31.8799, 26.7612],\n",
      "        [25.2218, 30.1326],\n",
      "        [27.8530, 27.8137]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9591, 0.0999, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9415, 29.9128],\n",
      "        [31.8797, 26.7616],\n",
      "        [25.2217, 30.1328],\n",
      "        [27.8529, 27.8138]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9591, 0.0999, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9417, 29.9128],\n",
      "        [31.8801, 26.7616],\n",
      "        [25.2219, 30.1327],\n",
      "        [27.8531, 27.8138]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9592, 0.0999, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9416, 29.9129],\n",
      "        [31.8799, 26.7620],\n",
      "        [25.2218, 30.1329],\n",
      "        [27.8530, 27.8139]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9592, 0.0999, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9417, 29.9129],\n",
      "        [31.8803, 26.7619],\n",
      "        [25.2220, 30.1328],\n",
      "        [27.8531, 27.8139]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9593, 0.0999, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9417, 29.9129],\n",
      "        [31.8801, 26.7623],\n",
      "        [25.2220, 30.1330],\n",
      "        [27.8531, 27.8140]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9593, 0.0999, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9418, 29.9129],\n",
      "        [31.8805, 26.7623],\n",
      "        [25.2222, 30.1329],\n",
      "        [27.8532, 27.8140]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9593, 0.0999, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9418, 29.9130],\n",
      "        [31.8803, 26.7626],\n",
      "        [25.2221, 30.1331],\n",
      "        [27.8532, 27.8141]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9593, 0.0999, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9419, 29.9130],\n",
      "        [31.8807, 26.7626],\n",
      "        [25.2223, 30.1330],\n",
      "        [27.8533, 27.8141]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9594, 0.1000, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9418, 29.9131],\n",
      "        [31.8805, 26.7630],\n",
      "        [25.2222, 30.1332],\n",
      "        [27.8533, 27.8142]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9594, 0.1000, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9420, 29.9131],\n",
      "        [31.8809, 26.7629],\n",
      "        [25.2225, 30.1332],\n",
      "        [27.8534, 27.8141]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9595, 0.1000, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9419, 29.9132],\n",
      "        [31.8807, 26.7633],\n",
      "        [25.2224, 30.1333],\n",
      "        [27.8533, 27.8142]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9595, 0.1000, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9421, 29.9132],\n",
      "        [31.8811, 26.7633],\n",
      "        [25.2226, 30.1333],\n",
      "        [27.8535, 27.8143]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9595, 0.1000, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9420, 29.9132],\n",
      "        [31.8809, 26.7636],\n",
      "        [25.2225, 30.1334],\n",
      "        [27.8534, 27.8143]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9595, 0.1000, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9421, 29.9132],\n",
      "        [31.8813, 26.7636],\n",
      "        [25.2227, 30.1334],\n",
      "        [27.8536, 27.8143]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9596, 0.1000, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9421, 29.9133],\n",
      "        [31.8811, 26.7640],\n",
      "        [25.2226, 30.1335],\n",
      "        [27.8535, 27.8144]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9596, 0.1000, 0.9606], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9422, 29.9133],\n",
      "        [31.8815, 26.7639],\n",
      "        [25.2229, 30.1335],\n",
      "        [27.8536, 27.8144]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9597, 0.1000, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9421, 29.9134],\n",
      "        [31.8813, 26.7643],\n",
      "        [25.2228, 30.1336],\n",
      "        [27.8536, 27.8145]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9597, 0.1000, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9423, 29.9134],\n",
      "        [31.8817, 26.7643],\n",
      "        [25.2230, 30.1336],\n",
      "        [27.8537, 27.8145]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9597, 0.1000, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9422, 29.9135],\n",
      "        [31.8815, 26.7646],\n",
      "        [25.2229, 30.1337],\n",
      "        [27.8537, 27.8146]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9597, 0.1000, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9423, 29.9135],\n",
      "        [31.8819, 26.7646],\n",
      "        [25.2231, 30.1337],\n",
      "        [27.8538, 27.8146]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9598, 0.1001, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9423, 29.9136],\n",
      "        [31.8817, 26.7650],\n",
      "        [25.2231, 30.1338],\n",
      "        [27.8538, 27.8147]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9598, 0.1001, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9424, 29.9135],\n",
      "        [31.8821, 26.7649],\n",
      "        [25.2233, 30.1338],\n",
      "        [27.8539, 27.8147]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9599, 0.1001, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9424, 29.9136],\n",
      "        [31.8819, 26.7653],\n",
      "        [25.2232, 30.1339],\n",
      "        [27.8538, 27.8148]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9599, 0.1001, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9425, 29.9136],\n",
      "        [31.8823, 26.7653],\n",
      "        [25.2234, 30.1339],\n",
      "        [27.8540, 27.8147]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9599, 0.1001, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9424, 29.9137],\n",
      "        [31.8821, 26.7656],\n",
      "        [25.2233, 30.1340],\n",
      "        [27.8539, 27.8148]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9599, 0.1001, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9426, 29.9137],\n",
      "        [31.8825, 26.7656],\n",
      "        [25.2236, 30.1340],\n",
      "        [27.8541, 27.8148]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9600, 0.1001, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9425, 29.9138],\n",
      "        [31.8823, 26.7659],\n",
      "        [25.2235, 30.1341],\n",
      "        [27.8540, 27.8149]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9600, 0.1001, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9426, 29.9138],\n",
      "        [31.8827, 26.7659],\n",
      "        [25.2237, 30.1341],\n",
      "        [27.8541, 27.8149]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9601, 0.1001, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9426, 29.9139],\n",
      "        [31.8824, 26.7663],\n",
      "        [25.2236, 30.1342],\n",
      "        [27.8541, 27.8150]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9601, 0.1001, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9427, 29.9139],\n",
      "        [31.8829, 26.7662],\n",
      "        [25.2238, 30.1342],\n",
      "        [27.8542, 27.8150]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9601, 0.1002, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9427, 29.9139],\n",
      "        [31.8827, 26.7666],\n",
      "        [25.2237, 30.1343],\n",
      "        [27.8542, 27.8151]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9601, 0.1002, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9428, 29.9139],\n",
      "        [31.8831, 26.7666],\n",
      "        [25.2240, 30.1343],\n",
      "        [27.8543, 27.8151]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9602, 0.1002, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9427, 29.9140],\n",
      "        [31.8828, 26.7669],\n",
      "        [25.2239, 30.1344],\n",
      "        [27.8542, 27.8152]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9602, 0.1002, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9429, 29.9140],\n",
      "        [31.8832, 26.7669],\n",
      "        [25.2241, 30.1344],\n",
      "        [27.8544, 27.8152]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9603, 0.1002, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9428, 29.9141],\n",
      "        [31.8830, 26.7672],\n",
      "        [25.2240, 30.1345],\n",
      "        [27.8543, 27.8152]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9603, 0.1002, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9429, 29.9141],\n",
      "        [31.8834, 26.7672],\n",
      "        [25.2242, 30.1345],\n",
      "        [27.8545, 27.8152]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9603, 0.1002, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9429, 29.9142],\n",
      "        [31.8832, 26.7675],\n",
      "        [25.2241, 30.1346],\n",
      "        [27.8544, 27.8153]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9603, 0.1002, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9430, 29.9142],\n",
      "        [31.8836, 26.7675],\n",
      "        [25.2244, 30.1346],\n",
      "        [27.8545, 27.8153]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9604, 0.1002, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9430, 29.9142],\n",
      "        [31.8834, 26.7679],\n",
      "        [25.2243, 30.1347],\n",
      "        [27.8545, 27.8154]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9604, 0.1002, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9431, 29.9142],\n",
      "        [31.8838, 26.7678],\n",
      "        [25.2245, 30.1347],\n",
      "        [27.8546, 27.8154]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9605, 0.1003, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9430, 29.9143],\n",
      "        [31.8836, 26.7682],\n",
      "        [25.2244, 30.1348],\n",
      "        [27.8546, 27.8155]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9605, 0.1003, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9432, 29.9143],\n",
      "        [31.8840, 26.7682],\n",
      "        [25.2246, 30.1348],\n",
      "        [27.8547, 27.8155]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9605, 0.1003, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9431, 29.9144],\n",
      "        [31.8838, 26.7685],\n",
      "        [25.2245, 30.1349],\n",
      "        [27.8546, 27.8156]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9605, 0.1003, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9432, 29.9144],\n",
      "        [31.8842, 26.7685],\n",
      "        [25.2248, 30.1348],\n",
      "        [27.8548, 27.8156]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9606, 0.1003, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9432, 29.9145],\n",
      "        [31.8840, 26.7688],\n",
      "        [25.2247, 30.1350],\n",
      "        [27.8547, 27.8157]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9606, 0.1003, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9433, 29.9144],\n",
      "        [31.8844, 26.7688],\n",
      "        [25.2249, 30.1349],\n",
      "        [27.8549, 27.8156]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9607, 0.1003, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9432, 29.9145],\n",
      "        [31.8842, 26.7692],\n",
      "        [25.2248, 30.1351],\n",
      "        [27.8548, 27.8157]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9607, 0.1003, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9434, 29.9145],\n",
      "        [31.8846, 26.7691],\n",
      "        [25.2250, 30.1350],\n",
      "        [27.8549, 27.8157]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9607, 0.1003, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9433, 29.9146],\n",
      "        [31.8844, 26.7695],\n",
      "        [25.2249, 30.1352],\n",
      "        [27.8549, 27.8158]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9607, 0.1003, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9434, 29.9146],\n",
      "        [31.8848, 26.7695],\n",
      "        [25.2252, 30.1352],\n",
      "        [27.8550, 27.8158]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9973, 0.9608, 0.1004, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9434, 29.9147],\n",
      "        [31.8845, 26.7698],\n",
      "        [25.2251, 30.1353],\n",
      "        [27.8550, 27.8159]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9973, 0.9608, 0.1004, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9435, 29.9147],\n",
      "        [31.8849, 26.7698],\n",
      "        [25.2253, 30.1352],\n",
      "        [27.8551, 27.8159]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9609, 0.1004, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9434, 29.9147],\n",
      "        [31.8847, 26.7701],\n",
      "        [25.2252, 30.1354],\n",
      "        [27.8550, 27.8160]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9609, 0.1004, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9436, 29.9148],\n",
      "        [31.8851, 26.7701],\n",
      "        [25.2254, 30.1353],\n",
      "        [27.8552, 27.8160]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9609, 0.1004, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9435, 29.9148],\n",
      "        [31.8849, 26.7704],\n",
      "        [25.2253, 30.1354],\n",
      "        [27.8551, 27.8161]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9609, 0.1004, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9436, 29.9148],\n",
      "        [31.8853, 26.7704],\n",
      "        [25.2256, 30.1354],\n",
      "        [27.8552, 27.8161]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9610, 0.1004, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9436, 29.9149],\n",
      "        [31.8851, 26.7707],\n",
      "        [25.2255, 30.1356],\n",
      "        [27.8552, 27.8162]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9610, 0.1004, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9437, 29.9149],\n",
      "        [31.8855, 26.7707],\n",
      "        [25.2257, 30.1355],\n",
      "        [27.8553, 27.8161]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9611, 0.1004, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9437, 29.9150],\n",
      "        [31.8853, 26.7710],\n",
      "        [25.2256, 30.1356],\n",
      "        [27.8553, 27.8162]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9611, 0.1004, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9438, 29.9150],\n",
      "        [31.8857, 26.7710],\n",
      "        [25.2258, 30.1356],\n",
      "        [27.8554, 27.8162]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9611, 0.1005, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9437, 29.9150],\n",
      "        [31.8855, 26.7713],\n",
      "        [25.2257, 30.1357],\n",
      "        [27.8554, 27.8163]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9611, 0.1005, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9439, 29.9151],\n",
      "        [31.8859, 26.7713],\n",
      "        [25.2260, 30.1357],\n",
      "        [27.8555, 27.8163]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9612, 0.1005, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9438, 29.9151],\n",
      "        [31.8856, 26.7717],\n",
      "        [25.2259, 30.1358],\n",
      "        [27.8554, 27.8164]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9612, 0.1005, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9439, 29.9151],\n",
      "        [31.8861, 26.7716],\n",
      "        [25.2261, 30.1358],\n",
      "        [27.8556, 27.8164]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9613, 0.1005, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9439, 29.9152],\n",
      "        [31.8858, 26.7720],\n",
      "        [25.2260, 30.1359],\n",
      "        [27.8555, 27.8165]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9613, 0.1005, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9440, 29.9152],\n",
      "        [31.8862, 26.7719],\n",
      "        [25.2262, 30.1359],\n",
      "        [27.8556, 27.8165]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9613, 0.1005, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9439, 29.9153],\n",
      "        [31.8860, 26.7723],\n",
      "        [25.2261, 30.1360],\n",
      "        [27.8556, 27.8165]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9613, 0.1005, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9441, 29.9153],\n",
      "        [31.8864, 26.7722],\n",
      "        [25.2263, 30.1360],\n",
      "        [27.8557, 27.8165]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9614, 0.1005, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9440, 29.9153],\n",
      "        [31.8862, 26.7726],\n",
      "        [25.2263, 30.1361],\n",
      "        [27.8557, 27.8166]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9614, 0.1005, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9441, 29.9153],\n",
      "        [31.8866, 26.7725],\n",
      "        [25.2265, 30.1361],\n",
      "        [27.8558, 27.8166]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9614, 0.1005, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9441, 29.9154],\n",
      "        [31.8864, 26.7729],\n",
      "        [25.2264, 30.1362],\n",
      "        [27.8557, 27.8167]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9614, 0.1005, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9442, 29.9154],\n",
      "        [31.8868, 26.7729],\n",
      "        [25.2266, 30.1362],\n",
      "        [27.8559, 27.8167]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9615, 0.1006, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9442, 29.9155],\n",
      "        [31.8866, 26.7732],\n",
      "        [25.2265, 30.1363],\n",
      "        [27.8558, 27.8168]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9615, 0.1006, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9443, 29.9155],\n",
      "        [31.8869, 26.7732],\n",
      "        [25.2267, 30.1363],\n",
      "        [27.8559, 27.8168]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9616, 0.1006, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9442, 29.9155],\n",
      "        [31.8867, 26.7735],\n",
      "        [25.2266, 30.1364],\n",
      "        [27.8559, 27.8169]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9616, 0.1006, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9443, 29.9155],\n",
      "        [31.8871, 26.7735],\n",
      "        [25.2269, 30.1364],\n",
      "        [27.8560, 27.8169]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9616, 0.1006, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9443, 29.9156],\n",
      "        [31.8869, 26.7738],\n",
      "        [25.2268, 30.1365],\n",
      "        [27.8560, 27.8169]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9616, 0.1006, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9444, 29.9156],\n",
      "        [31.8873, 26.7738],\n",
      "        [25.2270, 30.1365],\n",
      "        [27.8561, 27.8169]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9617, 0.1006, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9444, 29.9157],\n",
      "        [31.8871, 26.7741],\n",
      "        [25.2269, 30.1366],\n",
      "        [27.8560, 27.8170]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9617, 0.1006, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9445, 29.9157],\n",
      "        [31.8875, 26.7741],\n",
      "        [25.2271, 30.1366],\n",
      "        [27.8562, 27.8170]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9618, 0.1006, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9444, 29.9158],\n",
      "        [31.8873, 26.7744],\n",
      "        [25.2270, 30.1367],\n",
      "        [27.8561, 27.8171]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9618, 0.1006, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9446, 29.9158],\n",
      "        [31.8877, 26.7744],\n",
      "        [25.2273, 30.1367],\n",
      "        [27.8563, 27.8171]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9618, 0.1007, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9445, 29.9159],\n",
      "        [31.8875, 26.7747],\n",
      "        [25.2272, 30.1368],\n",
      "        [27.8562, 27.8172]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9618, 0.1007, 0.9607], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9446, 29.9158],\n",
      "        [31.8878, 26.7747],\n",
      "        [25.2274, 30.1368],\n",
      "        [27.8563, 27.8172]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9619, 0.1007, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9446, 29.9159],\n",
      "        [31.8876, 26.7750],\n",
      "        [25.2273, 30.1369],\n",
      "        [27.8563, 27.8173]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9619, 0.1007, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9447, 29.9159],\n",
      "        [31.8880, 26.7750],\n",
      "        [25.2275, 30.1369],\n",
      "        [27.8564, 27.8172]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9619, 0.1007, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9446, 29.9160],\n",
      "        [31.8878, 26.7753],\n",
      "        [25.2274, 30.1370],\n",
      "        [27.8563, 27.8173]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9619, 0.1007, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9448, 29.9160],\n",
      "        [31.8882, 26.7753],\n",
      "        [25.2276, 30.1370],\n",
      "        [27.8565, 27.8173]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9620, 0.1007, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9447, 29.9161],\n",
      "        [31.8880, 26.7756],\n",
      "        [25.2276, 30.1371],\n",
      "        [27.8564, 27.8174]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9620, 0.1007, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9448, 29.9161],\n",
      "        [31.8884, 26.7756],\n",
      "        [25.2278, 30.1370],\n",
      "        [27.8566, 27.8174]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9621, 0.1007, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9448, 29.9161],\n",
      "        [31.8882, 26.7759],\n",
      "        [25.2277, 30.1372],\n",
      "        [27.8565, 27.8175]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9621, 0.1007, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9449, 29.9161],\n",
      "        [31.8885, 26.7759],\n",
      "        [25.2279, 30.1371],\n",
      "        [27.8566, 27.8175]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9621, 0.1008, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9448, 29.9162],\n",
      "        [31.8883, 26.7762],\n",
      "        [25.2278, 30.1372],\n",
      "        [27.8566, 27.8176]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9621, 0.1008, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9450, 29.9162],\n",
      "        [31.8887, 26.7762],\n",
      "        [25.2280, 30.1372],\n",
      "        [27.8567, 27.8176]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9622, 0.1008, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9449, 29.9163],\n",
      "        [31.8885, 26.7765],\n",
      "        [25.2279, 30.1374],\n",
      "        [27.8567, 27.8177]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9622, 0.1008, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9450, 29.9163],\n",
      "        [31.8889, 26.7765],\n",
      "        [25.2281, 30.1373],\n",
      "        [27.8568, 27.8176]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9622, 0.1008, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9450, 29.9163],\n",
      "        [31.8887, 26.7768],\n",
      "        [25.2281, 30.1374],\n",
      "        [27.8567, 27.8177]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9622, 0.1008, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9451, 29.9163],\n",
      "        [31.8891, 26.7768],\n",
      "        [25.2283, 30.1374],\n",
      "        [27.8569, 27.8177]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9623, 0.1008, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9451, 29.9164],\n",
      "        [31.8889, 26.7771],\n",
      "        [25.2282, 30.1375],\n",
      "        [27.8568, 27.8178]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9623, 0.1008, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9452, 29.9164],\n",
      "        [31.8892, 26.7771],\n",
      "        [25.2284, 30.1375],\n",
      "        [27.8569, 27.8178]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9624, 0.1008, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9451, 29.9165],\n",
      "        [31.8890, 26.7774],\n",
      "        [25.2283, 30.1376],\n",
      "        [27.8569, 27.8179]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9624, 0.1008, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9452, 29.9165],\n",
      "        [31.8894, 26.7774],\n",
      "        [25.2285, 30.1376],\n",
      "        [27.8570, 27.8179]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9624, 0.1008, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9452, 29.9166],\n",
      "        [31.8892, 26.7777],\n",
      "        [25.2284, 30.1377],\n",
      "        [27.8570, 27.8180]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9624, 0.1008, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9453, 29.9165],\n",
      "        [31.8896, 26.7776],\n",
      "        [25.2286, 30.1377],\n",
      "        [27.8571, 27.8179]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9625, 0.1009, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9452, 29.9166],\n",
      "        [31.8894, 26.7780],\n",
      "        [25.2286, 30.1378],\n",
      "        [27.8570, 27.8180]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9625, 0.1009, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9454, 29.9166],\n",
      "        [31.8897, 26.7779],\n",
      "        [25.2288, 30.1378],\n",
      "        [27.8572, 27.8180]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9625, 0.1009, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9453, 29.9167],\n",
      "        [31.8895, 26.7782],\n",
      "        [25.2287, 30.1379],\n",
      "        [27.8571, 27.8181]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9625, 0.1009, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9454, 29.9167],\n",
      "        [31.8899, 26.7782],\n",
      "        [25.2289, 30.1379],\n",
      "        [27.8572, 27.8181]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9626, 0.1009, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9454, 29.9168],\n",
      "        [31.8897, 26.7785],\n",
      "        [25.2288, 30.1380],\n",
      "        [27.8572, 27.8182]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9626, 0.1009, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9455, 29.9168],\n",
      "        [31.8901, 26.7785],\n",
      "        [25.2290, 30.1380],\n",
      "        [27.8573, 27.8182]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9627, 0.1009, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9455, 29.9168],\n",
      "        [31.8899, 26.7788],\n",
      "        [25.2290, 30.1381],\n",
      "        [27.8573, 27.8183]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9627, 0.1009, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9456, 29.9168],\n",
      "        [31.8903, 26.7788],\n",
      "        [25.2292, 30.1380],\n",
      "        [27.8574, 27.8183]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9627, 0.1009, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9455, 29.9169],\n",
      "        [31.8901, 26.7791],\n",
      "        [25.2291, 30.1382],\n",
      "        [27.8573, 27.8183]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9627, 0.1009, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9456, 29.9169],\n",
      "        [31.8904, 26.7791],\n",
      "        [25.2293, 30.1381],\n",
      "        [27.8575, 27.8183]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9628, 0.1010, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9456, 29.9170],\n",
      "        [31.8902, 26.7794],\n",
      "        [25.2292, 30.1383],\n",
      "        [27.8574, 27.8184]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9628, 0.1010, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9457, 29.9170],\n",
      "        [31.8906, 26.7794],\n",
      "        [25.2294, 30.1382],\n",
      "        [27.8575, 27.8184]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9628, 0.1010, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9456, 29.9170],\n",
      "        [31.8904, 26.7797],\n",
      "        [25.2293, 30.1383],\n",
      "        [27.8575, 27.8185]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9628, 0.1010, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9457, 29.9170],\n",
      "        [31.8907, 26.7797],\n",
      "        [25.2295, 30.1383],\n",
      "        [27.8576, 27.8185]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9629, 0.1010, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9457, 29.9171],\n",
      "        [31.8906, 26.7800],\n",
      "        [25.2294, 30.1384],\n",
      "        [27.8575, 27.8186]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9629, 0.1010, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9458, 29.9171],\n",
      "        [31.8909, 26.7799],\n",
      "        [25.2297, 30.1384],\n",
      "        [27.8577, 27.8186]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9630, 0.1010, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9458, 29.9172],\n",
      "        [31.8907, 26.7803],\n",
      "        [25.2296, 30.1385],\n",
      "        [27.8576, 27.8186]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9630, 0.1010, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9459, 29.9172],\n",
      "        [31.8911, 26.7802],\n",
      "        [25.2298, 30.1385],\n",
      "        [27.8577, 27.8186]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9630, 0.1010, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9458, 29.9173],\n",
      "        [31.8909, 26.7805],\n",
      "        [25.2297, 30.1386],\n",
      "        [27.8577, 27.8187]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9630, 0.1010, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9460, 29.9173],\n",
      "        [31.8913, 26.7805],\n",
      "        [25.2299, 30.1386],\n",
      "        [27.8578, 27.8187]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9631, 0.1010, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9459, 29.9173],\n",
      "        [31.8911, 26.7808],\n",
      "        [25.2298, 30.1387],\n",
      "        [27.8578, 27.8188]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9631, 0.1010, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9460, 29.9173],\n",
      "        [31.8914, 26.7808],\n",
      "        [25.2300, 30.1387],\n",
      "        [27.8579, 27.8188]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9631, 0.1011, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9460, 29.9174],\n",
      "        [31.8912, 26.7811],\n",
      "        [25.2299, 30.1388],\n",
      "        [27.8578, 27.8189]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9631, 0.1011, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9461, 29.9174],\n",
      "        [31.8916, 26.7811],\n",
      "        [25.2301, 30.1388],\n",
      "        [27.8580, 27.8189]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9632, 0.1011, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9460, 29.9175],\n",
      "        [31.8914, 26.7814],\n",
      "        [25.2301, 30.1389],\n",
      "        [27.8579, 27.8189]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9632, 0.1011, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9462, 29.9175],\n",
      "        [31.8918, 26.7814],\n",
      "        [25.2303, 30.1389],\n",
      "        [27.8580, 27.8189]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9974, 0.9632, 0.1011, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9461, 29.9175],\n",
      "        [31.8916, 26.7817],\n",
      "        [25.2302, 30.1390],\n",
      "        [27.8580, 27.8190]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9974, 0.9632, 0.1011, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9462, 29.9175],\n",
      "        [31.8919, 26.7817],\n",
      "        [25.2304, 30.1389],\n",
      "        [27.8581, 27.8190]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9633, 0.1011, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9462, 29.9176],\n",
      "        [31.8917, 26.7820],\n",
      "        [25.2303, 30.1391],\n",
      "        [27.8581, 27.8191]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9633, 0.1011, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9463, 29.9176],\n",
      "        [31.8921, 26.7819],\n",
      "        [25.2305, 30.1390],\n",
      "        [27.8582, 27.8191]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9634, 0.1011, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9462, 29.9177],\n",
      "        [31.8919, 26.7822],\n",
      "        [25.2304, 30.1391],\n",
      "        [27.8581, 27.8192]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9634, 0.1011, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9464, 29.9177],\n",
      "        [31.8922, 26.7822],\n",
      "        [25.2306, 30.1391],\n",
      "        [27.8583, 27.8192]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9634, 0.1012, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9463, 29.9177],\n",
      "        [31.8921, 26.7825],\n",
      "        [25.2306, 30.1392],\n",
      "        [27.8582, 27.8192]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9634, 0.1012, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9464, 29.9177],\n",
      "        [31.8924, 26.7825],\n",
      "        [25.2308, 30.1392],\n",
      "        [27.8583, 27.8192]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9635, 0.1012, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9464, 29.9178],\n",
      "        [31.8922, 26.7828],\n",
      "        [25.2307, 30.1393],\n",
      "        [27.8583, 27.8193]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9635, 0.1012, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9465, 29.9178],\n",
      "        [31.8926, 26.7828],\n",
      "        [25.2309, 30.1393],\n",
      "        [27.8584, 27.8193]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9635, 0.1012, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9464, 29.9179],\n",
      "        [31.8924, 26.7831],\n",
      "        [25.2308, 30.1394],\n",
      "        [27.8583, 27.8194]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9635, 0.1012, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9466, 29.9179],\n",
      "        [31.8927, 26.7831],\n",
      "        [25.2310, 30.1394],\n",
      "        [27.8585, 27.8194]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9636, 0.1012, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9465, 29.9180],\n",
      "        [31.8926, 26.7834],\n",
      "        [25.2309, 30.1395],\n",
      "        [27.8584, 27.8195]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9636, 0.1012, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9466, 29.9179],\n",
      "        [31.8929, 26.7833],\n",
      "        [25.2311, 30.1395],\n",
      "        [27.8585, 27.8195]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9636, 0.1012, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9466, 29.9180],\n",
      "        [31.8927, 26.7836],\n",
      "        [25.2311, 30.1396],\n",
      "        [27.8585, 27.8195]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9636, 0.1012, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9467, 29.9180],\n",
      "        [31.8931, 26.7836],\n",
      "        [25.2313, 30.1396],\n",
      "        [27.8586, 27.8195]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9637, 0.1012, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9466, 29.9181],\n",
      "        [31.8929, 26.7839],\n",
      "        [25.2312, 30.1397],\n",
      "        [27.8586, 27.8196]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9637, 0.1012, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9467, 29.9181],\n",
      "        [31.8932, 26.7839],\n",
      "        [25.2314, 30.1397],\n",
      "        [27.8587, 27.8196]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9637, 0.1013, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9467, 29.9181],\n",
      "        [31.8930, 26.7842],\n",
      "        [25.2313, 30.1398],\n",
      "        [27.8586, 27.8197]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9637, 0.1013, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9468, 29.9181],\n",
      "        [31.8934, 26.7842],\n",
      "        [25.2315, 30.1397],\n",
      "        [27.8587, 27.8197]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9638, 0.1013, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9468, 29.9182],\n",
      "        [31.8932, 26.7844],\n",
      "        [25.2314, 30.1398],\n",
      "        [27.8587, 27.8198]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9638, 0.1013, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9468, 29.9182],\n",
      "        [31.8935, 26.7844],\n",
      "        [25.2316, 30.1398],\n",
      "        [27.8588, 27.8197]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9639, 0.1013, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9468, 29.9183],\n",
      "        [31.8933, 26.7847],\n",
      "        [25.2315, 30.1399],\n",
      "        [27.8588, 27.8198]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9639, 0.1013, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9469, 29.9183],\n",
      "        [31.8937, 26.7847],\n",
      "        [25.2317, 30.1399],\n",
      "        [27.8589, 27.8198]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9639, 0.1013, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9469, 29.9183],\n",
      "        [31.8935, 26.7850],\n",
      "        [25.2316, 30.1400],\n",
      "        [27.8588, 27.8199]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9639, 0.1013, 0.9608], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9470, 29.9183],\n",
      "        [31.8938, 26.7850],\n",
      "        [25.2318, 30.1400],\n",
      "        [27.8589, 27.8199]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9640, 0.1013, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9469, 29.9184],\n",
      "        [31.8937, 26.7853],\n",
      "        [25.2318, 30.1401],\n",
      "        [27.8589, 27.8200]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9640, 0.1013, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9470, 29.9184],\n",
      "        [31.8940, 26.7852],\n",
      "        [25.2320, 30.1401],\n",
      "        [27.8590, 27.8200]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9640, 0.1014, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9470, 29.9185],\n",
      "        [31.8938, 26.7855],\n",
      "        [25.2319, 30.1402],\n",
      "        [27.8590, 27.8201]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9640, 0.1014, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9471, 29.9185],\n",
      "        [31.8942, 26.7855],\n",
      "        [25.2321, 30.1402],\n",
      "        [27.8591, 27.8201]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9641, 0.1014, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9471, 29.9186],\n",
      "        [31.8940, 26.7858],\n",
      "        [25.2320, 30.1403],\n",
      "        [27.8591, 27.8201]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9641, 0.1014, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9472, 29.9185],\n",
      "        [31.8943, 26.7858],\n",
      "        [25.2322, 30.1403],\n",
      "        [27.8592, 27.8201]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9641, 0.1014, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9471, 29.9186],\n",
      "        [31.8941, 26.7861],\n",
      "        [25.2321, 30.1404],\n",
      "        [27.8591, 27.8202]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9641, 0.1014, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9472, 29.9186],\n",
      "        [31.8945, 26.7860],\n",
      "        [25.2323, 30.1403],\n",
      "        [27.8592, 27.8202]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9642, 0.1014, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9472, 29.9187],\n",
      "        [31.8943, 26.7863],\n",
      "        [25.2323, 30.1404],\n",
      "        [27.8592, 27.8203]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9642, 0.1014, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9473, 29.9187],\n",
      "        [31.8946, 26.7863],\n",
      "        [25.2325, 30.1404],\n",
      "        [27.8593, 27.8203]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9642, 0.1014, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9473, 29.9187],\n",
      "        [31.8944, 26.7866],\n",
      "        [25.2324, 30.1405],\n",
      "        [27.8593, 27.8203]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9642, 0.1014, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9474, 29.9187],\n",
      "        [31.8948, 26.7866],\n",
      "        [25.2326, 30.1405],\n",
      "        [27.8594, 27.8203]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9643, 0.1014, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9473, 29.9188],\n",
      "        [31.8946, 26.7869],\n",
      "        [25.2325, 30.1406],\n",
      "        [27.8593, 27.8204]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9643, 0.1014, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9474, 29.9188],\n",
      "        [31.8949, 26.7869],\n",
      "        [25.2327, 30.1406],\n",
      "        [27.8594, 27.8204]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9644, 0.1015, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9474, 29.9189],\n",
      "        [31.8948, 26.7871],\n",
      "        [25.2326, 30.1407],\n",
      "        [27.8594, 27.8205]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9644, 0.1015, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9475, 29.9189],\n",
      "        [31.8951, 26.7871],\n",
      "        [25.2328, 30.1407],\n",
      "        [27.8595, 27.8205]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9644, 0.1015, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9474, 29.9189],\n",
      "        [31.8949, 26.7874],\n",
      "        [25.2327, 30.1408],\n",
      "        [27.8595, 27.8206]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9644, 0.1015, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9475, 29.9189],\n",
      "        [31.8952, 26.7874],\n",
      "        [25.2329, 30.1408],\n",
      "        [27.8596, 27.8206]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9645, 0.1015, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9475, 29.9190],\n",
      "        [31.8951, 26.7877],\n",
      "        [25.2329, 30.1409],\n",
      "        [27.8595, 27.8206]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9645, 0.1015, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9476, 29.9190],\n",
      "        [31.8954, 26.7876],\n",
      "        [25.2330, 30.1408],\n",
      "        [27.8596, 27.8206]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9645, 0.1015, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9476, 29.9191],\n",
      "        [31.8952, 26.7879],\n",
      "        [25.2330, 30.1410],\n",
      "        [27.8596, 27.8207]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9645, 0.1015, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9477, 29.9191],\n",
      "        [31.8956, 26.7879],\n",
      "        [25.2332, 30.1409],\n",
      "        [27.8597, 27.8207]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9646, 0.1015, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9476, 29.9192],\n",
      "        [31.8954, 26.7882],\n",
      "        [25.2331, 30.1410],\n",
      "        [27.8597, 27.8208]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9646, 0.1015, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9477, 29.9191],\n",
      "        [31.8957, 26.7882],\n",
      "        [25.2333, 30.1410],\n",
      "        [27.8598, 27.8208]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9646, 0.1016, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9477, 29.9192],\n",
      "        [31.8955, 26.7884],\n",
      "        [25.2332, 30.1411],\n",
      "        [27.8597, 27.8208]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9646, 0.1016, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9478, 29.9192],\n",
      "        [31.8959, 26.7884],\n",
      "        [25.2334, 30.1411],\n",
      "        [27.8598, 27.8208]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9647, 0.1016, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9477, 29.9193],\n",
      "        [31.8957, 26.7887],\n",
      "        [25.2333, 30.1412],\n",
      "        [27.8598, 27.8209]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9647, 0.1016, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9479, 29.9193],\n",
      "        [31.8960, 26.7887],\n",
      "        [25.2335, 30.1412],\n",
      "        [27.8599, 27.8209]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9647, 0.1016, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9478, 29.9193],\n",
      "        [31.8958, 26.7890],\n",
      "        [25.2334, 30.1413],\n",
      "        [27.8599, 27.8210]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9647, 0.1016, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9479, 29.9193],\n",
      "        [31.8962, 26.7890],\n",
      "        [25.2337, 30.1413],\n",
      "        [27.8600, 27.8210]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9648, 0.1016, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9479, 29.9194],\n",
      "        [31.8960, 26.7892],\n",
      "        [25.2336, 30.1414],\n",
      "        [27.8599, 27.8211]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9648, 0.1016, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9480, 29.9194],\n",
      "        [31.8963, 26.7892],\n",
      "        [25.2338, 30.1414],\n",
      "        [27.8601, 27.8211]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9648, 0.1016, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9479, 29.9195],\n",
      "        [31.8961, 26.7895],\n",
      "        [25.2337, 30.1415],\n",
      "        [27.8600, 27.8211]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9648, 0.1016, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9480, 29.9195],\n",
      "        [31.8965, 26.7895],\n",
      "        [25.2339, 30.1414],\n",
      "        [27.8601, 27.8211]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9649, 0.1016, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9480, 29.9195],\n",
      "        [31.8963, 26.7898],\n",
      "        [25.2338, 30.1415],\n",
      "        [27.8601, 27.8212]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9649, 0.1016, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9481, 29.9195],\n",
      "        [31.8966, 26.7897],\n",
      "        [25.2340, 30.1415],\n",
      "        [27.8602, 27.8212]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9649, 0.1017, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9481, 29.9196],\n",
      "        [31.8965, 26.7900],\n",
      "        [25.2339, 30.1416],\n",
      "        [27.8601, 27.8213]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9649, 0.1017, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9482, 29.9196],\n",
      "        [31.8968, 26.7900],\n",
      "        [25.2341, 30.1416],\n",
      "        [27.8603, 27.8213]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9650, 0.1017, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9481, 29.9197],\n",
      "        [31.8966, 26.7903],\n",
      "        [25.2340, 30.1417],\n",
      "        [27.8602, 27.8214]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9650, 0.1017, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9482, 29.9197],\n",
      "        [31.8969, 26.7903],\n",
      "        [25.2342, 30.1417],\n",
      "        [27.8603, 27.8213]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9650, 0.1017, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9482, 29.9197],\n",
      "        [31.8968, 26.7905],\n",
      "        [25.2342, 30.1418],\n",
      "        [27.8603, 27.8214]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9650, 0.1017, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9483, 29.9197],\n",
      "        [31.8971, 26.7905],\n",
      "        [25.2344, 30.1418],\n",
      "        [27.8604, 27.8214]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9651, 0.1017, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9482, 29.9198],\n",
      "        [31.8969, 26.7908],\n",
      "        [25.2343, 30.1419],\n",
      "        [27.8603, 27.8215]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9651, 0.1017, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9483, 29.9198],\n",
      "        [31.8972, 26.7908],\n",
      "        [25.2345, 30.1418],\n",
      "        [27.8605, 27.8215]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9651, 0.1017, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9483, 29.9199],\n",
      "        [31.8971, 26.7911],\n",
      "        [25.2344, 30.1420],\n",
      "        [27.8604, 27.8216]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9651, 0.1017, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9484, 29.9199],\n",
      "        [31.8974, 26.7910],\n",
      "        [25.2346, 30.1419],\n",
      "        [27.8605, 27.8216]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9652, 0.1017, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9484, 29.9199],\n",
      "        [31.8972, 26.7913],\n",
      "        [25.2345, 30.1420],\n",
      "        [27.8605, 27.8216]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9652, 0.1017, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9485, 29.9199],\n",
      "        [31.8975, 26.7913],\n",
      "        [25.2347, 30.1420],\n",
      "        [27.8606, 27.8216]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9652, 0.1018, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9484, 29.9200],\n",
      "        [31.8974, 26.7916],\n",
      "        [25.2346, 30.1421],\n",
      "        [27.8606, 27.8217]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9652, 0.1018, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9485, 29.9200],\n",
      "        [31.8977, 26.7915],\n",
      "        [25.2348, 30.1421],\n",
      "        [27.8607, 27.8217]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9653, 0.1018, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9485, 29.9201],\n",
      "        [31.8975, 26.7918],\n",
      "        [25.2347, 30.1422],\n",
      "        [27.8606, 27.8218]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9653, 0.1018, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9486, 29.9200],\n",
      "        [31.8978, 26.7918],\n",
      "        [25.2349, 30.1422],\n",
      "        [27.8607, 27.8218]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9653, 0.1018, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9485, 29.9201],\n",
      "        [31.8976, 26.7921],\n",
      "        [25.2349, 30.1423],\n",
      "        [27.8607, 27.8218]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9653, 0.1018, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9486, 29.9201],\n",
      "        [31.8980, 26.7920],\n",
      "        [25.2350, 30.1423],\n",
      "        [27.8608, 27.8218]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9654, 0.1018, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9486, 29.9202],\n",
      "        [31.8978, 26.7923],\n",
      "        [25.2350, 30.1424],\n",
      "        [27.8608, 27.8219]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9654, 0.1018, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9487, 29.9202],\n",
      "        [31.8981, 26.7923],\n",
      "        [25.2352, 30.1423],\n",
      "        [27.8609, 27.8219]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9654, 0.1018, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9487, 29.9203],\n",
      "        [31.8979, 26.7926],\n",
      "        [25.2351, 30.1425],\n",
      "        [27.8608, 27.8220]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9654, 0.1018, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9488, 29.9202],\n",
      "        [31.8983, 26.7926],\n",
      "        [25.2353, 30.1424],\n",
      "        [27.8609, 27.8220]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9655, 0.1019, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9487, 29.9203],\n",
      "        [31.8981, 26.7928],\n",
      "        [25.2352, 30.1425],\n",
      "        [27.8609, 27.8221]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9655, 0.1019, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9488, 29.9203],\n",
      "        [31.8984, 26.7928],\n",
      "        [25.2354, 30.1425],\n",
      "        [27.8610, 27.8220]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9975, 0.9655, 0.1019, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9488, 29.9204],\n",
      "        [31.8982, 26.7931],\n",
      "        [25.2353, 30.1426],\n",
      "        [27.8610, 27.8221]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9975, 0.9655, 0.1019, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9489, 29.9204],\n",
      "        [31.8985, 26.7931],\n",
      "        [25.2355, 30.1426],\n",
      "        [27.8611, 27.8221]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9656, 0.1019, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9488, 29.9204],\n",
      "        [31.8984, 26.7933],\n",
      "        [25.2354, 30.1427],\n",
      "        [27.8610, 27.8222]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9656, 0.1019, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9489, 29.9204],\n",
      "        [31.8987, 26.7933],\n",
      "        [25.2356, 30.1427],\n",
      "        [27.8611, 27.8222]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9656, 0.1019, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9489, 29.9205],\n",
      "        [31.8985, 26.7936],\n",
      "        [25.2355, 30.1428],\n",
      "        [27.8611, 27.8223]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9656, 0.1019, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9490, 29.9205],\n",
      "        [31.8988, 26.7936],\n",
      "        [25.2357, 30.1428],\n",
      "        [27.8612, 27.8222]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9657, 0.1019, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9490, 29.9206],\n",
      "        [31.8987, 26.7938],\n",
      "        [25.2357, 30.1429],\n",
      "        [27.8611, 27.8223]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9657, 0.1019, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9491, 29.9206],\n",
      "        [31.8990, 26.7938],\n",
      "        [25.2358, 30.1428],\n",
      "        [27.8613, 27.8223]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9657, 0.1019, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9490, 29.9206],\n",
      "        [31.8988, 26.7941],\n",
      "        [25.2358, 30.1429],\n",
      "        [27.8612, 27.8224]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9657, 0.1019, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9491, 29.9206],\n",
      "        [31.8991, 26.7941],\n",
      "        [25.2360, 30.1429],\n",
      "        [27.8613, 27.8224]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9658, 0.1020, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9491, 29.9207],\n",
      "        [31.8989, 26.7943],\n",
      "        [25.2359, 30.1430],\n",
      "        [27.8613, 27.8225]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9658, 0.1020, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9492, 29.9207],\n",
      "        [31.8993, 26.7943],\n",
      "        [25.2361, 30.1430],\n",
      "        [27.8614, 27.8225]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9658, 0.1020, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9491, 29.9207],\n",
      "        [31.8991, 26.7946],\n",
      "        [25.2360, 30.1431],\n",
      "        [27.8613, 27.8225]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9658, 0.1020, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9492, 29.9207],\n",
      "        [31.8994, 26.7945],\n",
      "        [25.2362, 30.1431],\n",
      "        [27.8614, 27.8225]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9659, 0.1020, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9492, 29.9208],\n",
      "        [31.8992, 26.7948],\n",
      "        [25.2361, 30.1432],\n",
      "        [27.8614, 27.8226]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9659, 0.1020, 0.9609], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9493, 29.9208],\n",
      "        [31.8995, 26.7948],\n",
      "        [25.2363, 30.1432],\n",
      "        [27.8615, 27.8226]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9659, 0.1020, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9492, 29.9209],\n",
      "        [31.8994, 26.7951],\n",
      "        [25.2362, 30.1433],\n",
      "        [27.8615, 27.8227]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9659, 0.1020, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9494, 29.9209],\n",
      "        [31.8997, 26.7950],\n",
      "        [25.2364, 30.1432],\n",
      "        [27.8616, 27.8227]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9660, 0.1020, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9493, 29.9209],\n",
      "        [31.8995, 26.7953],\n",
      "        [25.2363, 30.1433],\n",
      "        [27.8615, 27.8227]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9660, 0.1020, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9494, 29.9209],\n",
      "        [31.8998, 26.7953],\n",
      "        [25.2365, 30.1433],\n",
      "        [27.8617, 27.8227]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9660, 0.1020, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9494, 29.9210],\n",
      "        [31.8997, 26.7955],\n",
      "        [25.2365, 30.1434],\n",
      "        [27.8616, 27.8228]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9660, 0.1020, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9495, 29.9210],\n",
      "        [31.9000, 26.7955],\n",
      "        [25.2366, 30.1434],\n",
      "        [27.8617, 27.8228]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9661, 0.1021, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9494, 29.9211],\n",
      "        [31.8998, 26.7958],\n",
      "        [25.2366, 30.1435],\n",
      "        [27.8617, 27.8229]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9661, 0.1021, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9495, 29.9211],\n",
      "        [31.9001, 26.7958],\n",
      "        [25.2367, 30.1435],\n",
      "        [27.8618, 27.8229]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9661, 0.1021, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9495, 29.9211],\n",
      "        [31.8999, 26.7960],\n",
      "        [25.2367, 30.1436],\n",
      "        [27.8617, 27.8229]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9661, 0.1021, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9496, 29.9211],\n",
      "        [31.9002, 26.7960],\n",
      "        [25.2369, 30.1436],\n",
      "        [27.8618, 27.8229]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9662, 0.1021, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9495, 29.9212],\n",
      "        [31.9001, 26.7963],\n",
      "        [25.2368, 30.1437],\n",
      "        [27.8618, 27.8230]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9662, 0.1021, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9496, 29.9212],\n",
      "        [31.9004, 26.7963],\n",
      "        [25.2370, 30.1436],\n",
      "        [27.8619, 27.8230]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9662, 0.1021, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9496, 29.9213],\n",
      "        [31.9002, 26.7965],\n",
      "        [25.2369, 30.1437],\n",
      "        [27.8619, 27.8231]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9662, 0.1021, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9497, 29.9212],\n",
      "        [31.9005, 26.7965],\n",
      "        [25.2371, 30.1437],\n",
      "        [27.8620, 27.8231]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9663, 0.1021, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9497, 29.9213],\n",
      "        [31.9004, 26.7968],\n",
      "        [25.2370, 30.1438],\n",
      "        [27.8619, 27.8231]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9663, 0.1021, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9497, 29.9213],\n",
      "        [31.9007, 26.7967],\n",
      "        [25.2372, 30.1438],\n",
      "        [27.8620, 27.8231]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9663, 0.1022, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9497, 29.9214],\n",
      "        [31.9005, 26.7970],\n",
      "        [25.2371, 30.1439],\n",
      "        [27.8620, 27.8232]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9663, 0.1022, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9498, 29.9214],\n",
      "        [31.9008, 26.7970],\n",
      "        [25.2373, 30.1439],\n",
      "        [27.8621, 27.8232]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9664, 0.1022, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9498, 29.9214],\n",
      "        [31.9006, 26.7972],\n",
      "        [25.2372, 30.1440],\n",
      "        [27.8620, 27.8233]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9664, 0.1022, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9499, 29.9214],\n",
      "        [31.9009, 26.7972],\n",
      "        [25.2374, 30.1440],\n",
      "        [27.8622, 27.8233]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9664, 0.1022, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9498, 29.9215],\n",
      "        [31.9008, 26.7975],\n",
      "        [25.2374, 30.1441],\n",
      "        [27.8621, 27.8233]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9664, 0.1022, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9499, 29.9215],\n",
      "        [31.9011, 26.7975],\n",
      "        [25.2375, 30.1440],\n",
      "        [27.8622, 27.8233]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9665, 0.1022, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9499, 29.9216],\n",
      "        [31.9009, 26.7977],\n",
      "        [25.2375, 30.1441],\n",
      "        [27.8622, 27.8234]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9665, 0.1022, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9500, 29.9216],\n",
      "        [31.9012, 26.7977],\n",
      "        [25.2376, 30.1441],\n",
      "        [27.8623, 27.8234]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9665, 0.1022, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9499, 29.9216],\n",
      "        [31.9011, 26.7980],\n",
      "        [25.2376, 30.1442],\n",
      "        [27.8622, 27.8235]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9665, 0.1022, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9500, 29.9216],\n",
      "        [31.9013, 26.7979],\n",
      "        [25.2378, 30.1442],\n",
      "        [27.8623, 27.8235]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9666, 0.1022, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9500, 29.9217],\n",
      "        [31.9012, 26.7982],\n",
      "        [25.2377, 30.1443],\n",
      "        [27.8623, 27.8235]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9666, 0.1022, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9501, 29.9217],\n",
      "        [31.9015, 26.7982],\n",
      "        [25.2379, 30.1443],\n",
      "        [27.8624, 27.8235]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9666, 0.1023, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9500, 29.9217],\n",
      "        [31.9013, 26.7984],\n",
      "        [25.2378, 30.1444],\n",
      "        [27.8624, 27.8236]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9666, 0.1023, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9502, 29.9217],\n",
      "        [31.9016, 26.7984],\n",
      "        [25.2380, 30.1443],\n",
      "        [27.8625, 27.8236]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9667, 0.1023, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9501, 29.9218],\n",
      "        [31.9015, 26.7987],\n",
      "        [25.2379, 30.1444],\n",
      "        [27.8624, 27.8237]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9667, 0.1023, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9502, 29.9218],\n",
      "        [31.9018, 26.7987],\n",
      "        [25.2381, 30.1444],\n",
      "        [27.8625, 27.8237]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9667, 0.1023, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9502, 29.9219],\n",
      "        [31.9016, 26.7989],\n",
      "        [25.2380, 30.1445],\n",
      "        [27.8625, 27.8238]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9667, 0.1023, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9503, 29.9219],\n",
      "        [31.9019, 26.7989],\n",
      "        [25.2382, 30.1445],\n",
      "        [27.8626, 27.8237]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9668, 0.1023, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9502, 29.9219],\n",
      "        [31.9017, 26.7991],\n",
      "        [25.2381, 30.1446],\n",
      "        [27.8626, 27.8238]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9668, 0.1023, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9503, 29.9219],\n",
      "        [31.9020, 26.7991],\n",
      "        [25.2383, 30.1446],\n",
      "        [27.8627, 27.8238]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9668, 0.1023, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9503, 29.9220],\n",
      "        [31.9019, 26.7994],\n",
      "        [25.2382, 30.1447],\n",
      "        [27.8626, 27.8239]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9668, 0.1023, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9504, 29.9220],\n",
      "        [31.9022, 26.7994],\n",
      "        [25.2384, 30.1447],\n",
      "        [27.8627, 27.8239]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9669, 0.1023, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9503, 29.9220],\n",
      "        [31.9020, 26.7996],\n",
      "        [25.2383, 30.1447],\n",
      "        [27.8627, 27.8239]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9669, 0.1023, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9504, 29.9221],\n",
      "        [31.9023, 26.7996],\n",
      "        [25.2385, 30.1447],\n",
      "        [27.8628, 27.8239]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9669, 0.1024, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9504, 29.9221],\n",
      "        [31.9021, 26.7998],\n",
      "        [25.2385, 30.1448],\n",
      "        [27.8627, 27.8240]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9669, 0.1024, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9505, 29.9221],\n",
      "        [31.9024, 26.7998],\n",
      "        [25.2386, 30.1448],\n",
      "        [27.8628, 27.8240]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9669, 0.1024, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9505, 29.9222],\n",
      "        [31.9023, 26.8001],\n",
      "        [25.2386, 30.1449],\n",
      "        [27.8628, 27.8241]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9669, 0.1024, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9505, 29.9222],\n",
      "        [31.9026, 26.8001],\n",
      "        [25.2387, 30.1449],\n",
      "        [27.8629, 27.8241]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9670, 0.1024, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9505, 29.9222],\n",
      "        [31.9024, 26.8003],\n",
      "        [25.2387, 30.1450],\n",
      "        [27.8629, 27.8241]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9670, 0.1024, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9506, 29.9222],\n",
      "        [31.9027, 26.8003],\n",
      "        [25.2389, 30.1450],\n",
      "        [27.8630, 27.8241]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9670, 0.1024, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9506, 29.9223],\n",
      "        [31.9025, 26.8005],\n",
      "        [25.2388, 30.1451],\n",
      "        [27.8629, 27.8242]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9670, 0.1024, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9506, 29.9223],\n",
      "        [31.9028, 26.8005],\n",
      "        [25.2390, 30.1450],\n",
      "        [27.8630, 27.8242]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9671, 0.1024, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9506, 29.9224],\n",
      "        [31.9027, 26.8008],\n",
      "        [25.2389, 30.1451],\n",
      "        [27.8630, 27.8243]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9671, 0.1024, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9507, 29.9223],\n",
      "        [31.9030, 26.8008],\n",
      "        [25.2391, 30.1451],\n",
      "        [27.8631, 27.8242]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9671, 0.1024, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9507, 29.9224],\n",
      "        [31.9028, 26.8010],\n",
      "        [25.2390, 30.1452],\n",
      "        [27.8631, 27.8243]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9671, 0.1024, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9508, 29.9224],\n",
      "        [31.9031, 26.8010],\n",
      "        [25.2392, 30.1452],\n",
      "        [27.8632, 27.8243]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9672, 0.1025, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9507, 29.9225],\n",
      "        [31.9029, 26.8012],\n",
      "        [25.2391, 30.1453],\n",
      "        [27.8631, 27.8244]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9672, 0.1025, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9508, 29.9225],\n",
      "        [31.9032, 26.8012],\n",
      "        [25.2393, 30.1453],\n",
      "        [27.8632, 27.8244]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9672, 0.1025, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9508, 29.9225],\n",
      "        [31.9031, 26.8015],\n",
      "        [25.2392, 30.1454],\n",
      "        [27.8632, 27.8245]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9672, 0.1025, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9509, 29.9225],\n",
      "        [31.9034, 26.8015],\n",
      "        [25.2394, 30.1453],\n",
      "        [27.8633, 27.8245]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9673, 0.1025, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9508, 29.9226],\n",
      "        [31.9032, 26.8017],\n",
      "        [25.2393, 30.1454],\n",
      "        [27.8632, 27.8245]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9673, 0.1025, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9509, 29.9226],\n",
      "        [31.9035, 26.8017],\n",
      "        [25.2395, 30.1454],\n",
      "        [27.8633, 27.8245]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9673, 0.1025, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9509, 29.9226],\n",
      "        [31.9033, 26.8019],\n",
      "        [25.2394, 30.1455],\n",
      "        [27.8633, 27.8246]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9673, 0.1025, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9510, 29.9226],\n",
      "        [31.9036, 26.8019],\n",
      "        [25.2396, 30.1455],\n",
      "        [27.8634, 27.8246]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9674, 0.1025, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9509, 29.9227],\n",
      "        [31.9035, 26.8021],\n",
      "        [25.2395, 30.1456],\n",
      "        [27.8633, 27.8246]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9674, 0.1025, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9510, 29.9227],\n",
      "        [31.9038, 26.8021],\n",
      "        [25.2397, 30.1456],\n",
      "        [27.8635, 27.8246]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9674, 0.1025, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9510, 29.9228],\n",
      "        [31.9036, 26.8024],\n",
      "        [25.2396, 30.1457],\n",
      "        [27.8634, 27.8247]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9674, 0.1025, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9511, 29.9228],\n",
      "        [31.9039, 26.8024],\n",
      "        [25.2398, 30.1456],\n",
      "        [27.8635, 27.8247]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9674, 0.1026, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9511, 29.9228],\n",
      "        [31.9037, 26.8026],\n",
      "        [25.2398, 30.1457],\n",
      "        [27.8635, 27.8248]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9674, 0.1026, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9512, 29.9228],\n",
      "        [31.9040, 26.8026],\n",
      "        [25.2399, 30.1457],\n",
      "        [27.8636, 27.8248]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9675, 0.1026, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9511, 29.9229],\n",
      "        [31.9039, 26.8028],\n",
      "        [25.2399, 30.1458],\n",
      "        [27.8635, 27.8248]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9675, 0.1026, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9512, 29.9229],\n",
      "        [31.9042, 26.8028],\n",
      "        [25.2401, 30.1458],\n",
      "        [27.8637, 27.8248]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9675, 0.1026, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9512, 29.9229],\n",
      "        [31.9040, 26.8030],\n",
      "        [25.2400, 30.1459],\n",
      "        [27.8636, 27.8249]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9675, 0.1026, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9513, 29.9229],\n",
      "        [31.9043, 26.8030],\n",
      "        [25.2402, 30.1459],\n",
      "        [27.8637, 27.8249]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9676, 0.1026, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9512, 29.9230],\n",
      "        [31.9041, 26.8033],\n",
      "        [25.2401, 30.1460],\n",
      "        [27.8636, 27.8250]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9676, 0.1026, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9513, 29.9230],\n",
      "        [31.9044, 26.8033],\n",
      "        [25.2403, 30.1459],\n",
      "        [27.8638, 27.8250]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9676, 0.1026, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9513, 29.9231],\n",
      "        [31.9042, 26.8035],\n",
      "        [25.2402, 30.1460],\n",
      "        [27.8637, 27.8250]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9676, 0.1026, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9514, 29.9231],\n",
      "        [31.9045, 26.8035],\n",
      "        [25.2404, 30.1460],\n",
      "        [27.8638, 27.8250]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9677, 0.1026, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9513, 29.9231],\n",
      "        [31.9044, 26.8037],\n",
      "        [25.2403, 30.1461],\n",
      "        [27.8638, 27.8251]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9677, 0.1026, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9514, 29.9231],\n",
      "        [31.9047, 26.8037],\n",
      "        [25.2405, 30.1461],\n",
      "        [27.8639, 27.8251]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9677, 0.1027, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9514, 29.9232],\n",
      "        [31.9045, 26.8040],\n",
      "        [25.2404, 30.1462],\n",
      "        [27.8638, 27.8252]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9677, 0.1027, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9515, 29.9232],\n",
      "        [31.9048, 26.8039],\n",
      "        [25.2406, 30.1462],\n",
      "        [27.8639, 27.8252]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9976, 0.9678, 0.1027, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9514, 29.9232],\n",
      "        [31.9046, 26.8042],\n",
      "        [25.2405, 30.1463],\n",
      "        [27.8639, 27.8252]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9976, 0.9678, 0.1027, 0.9610], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9515, 29.9232],\n",
      "        [31.9049, 26.8041],\n",
      "        [25.2407, 30.1462],\n",
      "        [27.8640, 27.8252]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9678, 0.1027, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9515, 29.9233],\n",
      "        [31.9048, 26.8044],\n",
      "        [25.2406, 30.1463],\n",
      "        [27.8640, 27.8253]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9678, 0.1027, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9516, 29.9233],\n",
      "        [31.9050, 26.8044],\n",
      "        [25.2408, 30.1463],\n",
      "        [27.8641, 27.8253]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9678, 0.1027, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9515, 29.9234],\n",
      "        [31.9049, 26.8046],\n",
      "        [25.2407, 30.1464],\n",
      "        [27.8640, 27.8254]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9678, 0.1027, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9516, 29.9233],\n",
      "        [31.9052, 26.8046],\n",
      "        [25.2409, 30.1464],\n",
      "        [27.8641, 27.8253]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9679, 0.1027, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9516, 29.9234],\n",
      "        [31.9050, 26.8048],\n",
      "        [25.2408, 30.1465],\n",
      "        [27.8641, 27.8254]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9679, 0.1027, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9517, 29.9234],\n",
      "        [31.9053, 26.8048],\n",
      "        [25.2410, 30.1465],\n",
      "        [27.8642, 27.8254]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9679, 0.1027, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9517, 29.9235],\n",
      "        [31.9052, 26.8051],\n",
      "        [25.2409, 30.1466],\n",
      "        [27.8641, 27.8255]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9679, 0.1027, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9517, 29.9235],\n",
      "        [31.9054, 26.8051],\n",
      "        [25.2411, 30.1466],\n",
      "        [27.8643, 27.8255]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9680, 0.1028, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9517, 29.9235],\n",
      "        [31.9053, 26.8053],\n",
      "        [25.2410, 30.1466],\n",
      "        [27.8642, 27.8255]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9680, 0.1028, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9518, 29.9235],\n",
      "        [31.9056, 26.8053],\n",
      "        [25.2412, 30.1466],\n",
      "        [27.8643, 27.8256]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9680, 0.1028, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9517, 29.9236],\n",
      "        [31.9054, 26.8055],\n",
      "        [25.2411, 30.1467],\n",
      "        [27.8642, 27.8256]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9680, 0.1028, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9518, 29.9236],\n",
      "        [31.9057, 26.8055],\n",
      "        [25.2413, 30.1467],\n",
      "        [27.8644, 27.8256]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9681, 0.1028, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9518, 29.9236],\n",
      "        [31.9055, 26.8057],\n",
      "        [25.2413, 30.1468],\n",
      "        [27.8643, 27.8257]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9681, 0.1028, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9519, 29.9236],\n",
      "        [31.9058, 26.8057],\n",
      "        [25.2414, 30.1468],\n",
      "        [27.8644, 27.8257]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9681, 0.1028, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9519, 29.9237],\n",
      "        [31.9057, 26.8059],\n",
      "        [25.2414, 30.1469],\n",
      "        [27.8644, 27.8257]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9681, 0.1028, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9520, 29.9237],\n",
      "        [31.9059, 26.8059],\n",
      "        [25.2415, 30.1468],\n",
      "        [27.8645, 27.8257]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9682, 0.1028, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9519, 29.9238],\n",
      "        [31.9058, 26.8062],\n",
      "        [25.2415, 30.1469],\n",
      "        [27.8644, 27.8258]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9682, 0.1028, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9520, 29.9238],\n",
      "        [31.9060, 26.8061],\n",
      "        [25.2416, 30.1469],\n",
      "        [27.8645, 27.8258]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9682, 0.1028, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9520, 29.9238],\n",
      "        [31.9059, 26.8064],\n",
      "        [25.2416, 30.1470],\n",
      "        [27.8645, 27.8259]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9682, 0.1028, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9521, 29.9238],\n",
      "        [31.9062, 26.8064],\n",
      "        [25.2417, 30.1470],\n",
      "        [27.8646, 27.8259]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9682, 0.1029, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9520, 29.9239],\n",
      "        [31.9060, 26.8066],\n",
      "        [25.2417, 30.1471],\n",
      "        [27.8646, 27.8259]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9682, 0.1029, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9521, 29.9239],\n",
      "        [31.9063, 26.8066],\n",
      "        [25.2418, 30.1470],\n",
      "        [27.8647, 27.8259]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9683, 0.1029, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9521, 29.9239],\n",
      "        [31.9061, 26.8068],\n",
      "        [25.2418, 30.1471],\n",
      "        [27.8646, 27.8260]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9683, 0.1029, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9522, 29.9239],\n",
      "        [31.9064, 26.8068],\n",
      "        [25.2420, 30.1471],\n",
      "        [27.8647, 27.8260]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9683, 0.1029, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9521, 29.9240],\n",
      "        [31.9063, 26.8070],\n",
      "        [25.2419, 30.1472],\n",
      "        [27.8647, 27.8260]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9683, 0.1029, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9522, 29.9240],\n",
      "        [31.9065, 26.8070],\n",
      "        [25.2421, 30.1472],\n",
      "        [27.8648, 27.8260]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9684, 0.1029, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9522, 29.9241],\n",
      "        [31.9064, 26.8072],\n",
      "        [25.2420, 30.1473],\n",
      "        [27.8647, 27.8261]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9684, 0.1029, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9523, 29.9240],\n",
      "        [31.9067, 26.8072],\n",
      "        [25.2422, 30.1473],\n",
      "        [27.8648, 27.8261]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9684, 0.1029, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9522, 29.9241],\n",
      "        [31.9065, 26.8075],\n",
      "        [25.2421, 30.1474],\n",
      "        [27.8648, 27.8262]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9684, 0.1029, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9523, 29.9241],\n",
      "        [31.9068, 26.8074],\n",
      "        [25.2423, 30.1474],\n",
      "        [27.8649, 27.8262]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9684, 0.1029, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9523, 29.9242],\n",
      "        [31.9066, 26.8077],\n",
      "        [25.2422, 30.1474],\n",
      "        [27.8648, 27.8262]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9684, 0.1029, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9524, 29.9242],\n",
      "        [31.9069, 26.8077],\n",
      "        [25.2424, 30.1474],\n",
      "        [27.8650, 27.8262]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9685, 0.1030, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9523, 29.9242],\n",
      "        [31.9068, 26.8079],\n",
      "        [25.2423, 30.1475],\n",
      "        [27.8649, 27.8263]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9685, 0.1030, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9524, 29.9242],\n",
      "        [31.9070, 26.8079],\n",
      "        [25.2425, 30.1475],\n",
      "        [27.8650, 27.8263]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9685, 0.1030, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9524, 29.9243],\n",
      "        [31.9069, 26.8081],\n",
      "        [25.2424, 30.1476],\n",
      "        [27.8650, 27.8263]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9685, 0.1030, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9525, 29.9243],\n",
      "        [31.9072, 26.8081],\n",
      "        [25.2426, 30.1476],\n",
      "        [27.8651, 27.8263]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9686, 0.1030, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9524, 29.9243],\n",
      "        [31.9070, 26.8083],\n",
      "        [25.2425, 30.1476],\n",
      "        [27.8650, 27.8264]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9686, 0.1030, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9525, 29.9243],\n",
      "        [31.9073, 26.8083],\n",
      "        [25.2427, 30.1476],\n",
      "        [27.8651, 27.8264]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9686, 0.1030, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9525, 29.9244],\n",
      "        [31.9071, 26.8085],\n",
      "        [25.2426, 30.1477],\n",
      "        [27.8651, 27.8265]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9686, 0.1030, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9526, 29.9244],\n",
      "        [31.9074, 26.8085],\n",
      "        [25.2428, 30.1477],\n",
      "        [27.8652, 27.8265]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9687, 0.1030, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9526, 29.9245],\n",
      "        [31.9073, 26.8087],\n",
      "        [25.2427, 30.1478],\n",
      "        [27.8651, 27.8265]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9687, 0.1030, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9526, 29.9244],\n",
      "        [31.9075, 26.8087],\n",
      "        [25.2429, 30.1478],\n",
      "        [27.8652, 27.8265]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9687, 0.1030, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9526, 29.9245],\n",
      "        [31.9074, 26.8089],\n",
      "        [25.2428, 30.1479],\n",
      "        [27.8652, 27.8266]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9687, 0.1030, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9527, 29.9245],\n",
      "        [31.9077, 26.8089],\n",
      "        [25.2430, 30.1479],\n",
      "        [27.8653, 27.8266]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9687, 0.1031, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9526, 29.9246],\n",
      "        [31.9075, 26.8091],\n",
      "        [25.2429, 30.1479],\n",
      "        [27.8652, 27.8266]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9687, 0.1031, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9527, 29.9246],\n",
      "        [31.9078, 26.8091],\n",
      "        [25.2431, 30.1479],\n",
      "        [27.8653, 27.8266]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9688, 0.1031, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9527, 29.9246],\n",
      "        [31.9076, 26.8094],\n",
      "        [25.2430, 30.1480],\n",
      "        [27.8653, 27.8267]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9688, 0.1031, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9528, 29.9246],\n",
      "        [31.9079, 26.8093],\n",
      "        [25.2432, 30.1480],\n",
      "        [27.8654, 27.8267]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9688, 0.1031, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9527, 29.9247],\n",
      "        [31.9077, 26.8096],\n",
      "        [25.2431, 30.1481],\n",
      "        [27.8654, 27.8268]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9688, 0.1031, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9528, 29.9247],\n",
      "        [31.9080, 26.8096],\n",
      "        [25.2433, 30.1481],\n",
      "        [27.8655, 27.8268]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9689, 0.1031, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9528, 29.9247],\n",
      "        [31.9079, 26.8098],\n",
      "        [25.2432, 30.1481],\n",
      "        [27.8654, 27.8268]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9689, 0.1031, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9529, 29.9247],\n",
      "        [31.9081, 26.8098],\n",
      "        [25.2434, 30.1481],\n",
      "        [27.8655, 27.8268]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9689, 0.1031, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9528, 29.9248],\n",
      "        [31.9080, 26.8100],\n",
      "        [25.2433, 30.1482],\n",
      "        [27.8655, 27.8269]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9689, 0.1031, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9529, 29.9248],\n",
      "        [31.9082, 26.8100],\n",
      "        [25.2435, 30.1482],\n",
      "        [27.8656, 27.8269]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9689, 0.1031, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9529, 29.9249],\n",
      "        [31.9081, 26.8102],\n",
      "        [25.2434, 30.1483],\n",
      "        [27.8655, 27.8270]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9689, 0.1031, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9530, 29.9248],\n",
      "        [31.9084, 26.8102],\n",
      "        [25.2436, 30.1483],\n",
      "        [27.8656, 27.8270]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9690, 0.1032, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9529, 29.9249],\n",
      "        [31.9082, 26.8104],\n",
      "        [25.2435, 30.1484],\n",
      "        [27.8656, 27.8270]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9690, 0.1032, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9530, 29.9249],\n",
      "        [31.9085, 26.8104],\n",
      "        [25.2437, 30.1483],\n",
      "        [27.8657, 27.8270]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9690, 0.1032, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9530, 29.9250],\n",
      "        [31.9083, 26.8106],\n",
      "        [25.2436, 30.1484],\n",
      "        [27.8656, 27.8271]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9690, 0.1032, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9531, 29.9249],\n",
      "        [31.9086, 26.8106],\n",
      "        [25.2438, 30.1484],\n",
      "        [27.8657, 27.8271]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9691, 0.1032, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9530, 29.9250],\n",
      "        [31.9085, 26.8108],\n",
      "        [25.2437, 30.1485],\n",
      "        [27.8657, 27.8271]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9691, 0.1032, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9531, 29.9250],\n",
      "        [31.9087, 26.8108],\n",
      "        [25.2439, 30.1485],\n",
      "        [27.8658, 27.8271]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9691, 0.1032, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9531, 29.9251],\n",
      "        [31.9086, 26.8110],\n",
      "        [25.2439, 30.1486],\n",
      "        [27.8658, 27.8272]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9691, 0.1032, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9532, 29.9251],\n",
      "        [31.9088, 26.8110],\n",
      "        [25.2440, 30.1485],\n",
      "        [27.8659, 27.8272]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9692, 0.1032, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9532, 29.9251],\n",
      "        [31.9087, 26.8112],\n",
      "        [25.2439, 30.1486],\n",
      "        [27.8658, 27.8273]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9692, 0.1032, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9533, 29.9251],\n",
      "        [31.9090, 26.8112],\n",
      "        [25.2441, 30.1486],\n",
      "        [27.8659, 27.8273]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9692, 0.1032, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9532, 29.9252],\n",
      "        [31.9088, 26.8114],\n",
      "        [25.2441, 30.1487],\n",
      "        [27.8659, 27.8273]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9692, 0.1032, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9533, 29.9252],\n",
      "        [31.9091, 26.8114],\n",
      "        [25.2442, 30.1487],\n",
      "        [27.8659, 27.8273]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9692, 0.1033, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9532, 29.9252],\n",
      "        [31.9089, 26.8116],\n",
      "        [25.2441, 30.1488],\n",
      "        [27.8659, 27.8274]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9692, 0.1033, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9533, 29.9252],\n",
      "        [31.9092, 26.8116],\n",
      "        [25.2443, 30.1488],\n",
      "        [27.8660, 27.8274]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9693, 0.1033, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9533, 29.9253],\n",
      "        [31.9090, 26.8118],\n",
      "        [25.2442, 30.1488],\n",
      "        [27.8660, 27.8274]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9693, 0.1033, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9534, 29.9253],\n",
      "        [31.9093, 26.8118],\n",
      "        [25.2444, 30.1488],\n",
      "        [27.8661, 27.8274]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9693, 0.1033, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9534, 29.9254],\n",
      "        [31.9092, 26.8121],\n",
      "        [25.2444, 30.1489],\n",
      "        [27.8660, 27.8275]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9693, 0.1033, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9534, 29.9254],\n",
      "        [31.9094, 26.8120],\n",
      "        [25.2445, 30.1489],\n",
      "        [27.8661, 27.8275]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9694, 0.1033, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9534, 29.9254],\n",
      "        [31.9093, 26.8123],\n",
      "        [25.2444, 30.1490],\n",
      "        [27.8661, 27.8276]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9694, 0.1033, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9535, 29.9254],\n",
      "        [31.9095, 26.8122],\n",
      "        [25.2446, 30.1490],\n",
      "        [27.8662, 27.8276]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9694, 0.1033, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9535, 29.9255],\n",
      "        [31.9094, 26.8125],\n",
      "        [25.2446, 30.1491],\n",
      "        [27.8662, 27.8276]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9694, 0.1033, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9535, 29.9255],\n",
      "        [31.9096, 26.8125],\n",
      "        [25.2447, 30.1490],\n",
      "        [27.8662, 27.8276]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9694, 0.1033, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9535, 29.9255],\n",
      "        [31.9095, 26.8127],\n",
      "        [25.2447, 30.1491],\n",
      "        [27.8662, 27.8277]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9694, 0.1033, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9536, 29.9255],\n",
      "        [31.9098, 26.8126],\n",
      "        [25.2448, 30.1491],\n",
      "        [27.8663, 27.8277]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9695, 0.1034, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9535, 29.9256],\n",
      "        [31.9096, 26.8129],\n",
      "        [25.2448, 30.1492],\n",
      "        [27.8663, 27.8277]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9695, 0.1034, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9536, 29.9256],\n",
      "        [31.9099, 26.8129],\n",
      "        [25.2449, 30.1492],\n",
      "        [27.8664, 27.8277]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9695, 0.1034, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9536, 29.9256],\n",
      "        [31.9097, 26.8131],\n",
      "        [25.2448, 30.1493],\n",
      "        [27.8663, 27.8278]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9695, 0.1034, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9537, 29.9256],\n",
      "        [31.9100, 26.8131],\n",
      "        [25.2450, 30.1492],\n",
      "        [27.8664, 27.8278]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9695, 0.1034, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9536, 29.9257],\n",
      "        [31.9099, 26.8133],\n",
      "        [25.2450, 30.1493],\n",
      "        [27.8664, 27.8279]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9695, 0.1034, 0.9611], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9537, 29.9257],\n",
      "        [31.9101, 26.8133],\n",
      "        [25.2451, 30.1493],\n",
      "        [27.8665, 27.8279]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9696, 0.1034, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9537, 29.9257],\n",
      "        [31.9100, 26.8135],\n",
      "        [25.2450, 30.1494],\n",
      "        [27.8664, 27.8279]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9696, 0.1034, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9538, 29.9257],\n",
      "        [31.9102, 26.8135],\n",
      "        [25.2452, 30.1494],\n",
      "        [27.8665, 27.8279]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9696, 0.1034, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9538, 29.9258],\n",
      "        [31.9101, 26.8137],\n",
      "        [25.2452, 30.1495],\n",
      "        [27.8665, 27.8280]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9696, 0.1034, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9538, 29.9258],\n",
      "        [31.9103, 26.8137],\n",
      "        [25.2453, 30.1495],\n",
      "        [27.8666, 27.8280]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9697, 0.1034, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9538, 29.9258],\n",
      "        [31.9102, 26.8139],\n",
      "        [25.2453, 30.1495],\n",
      "        [27.8665, 27.8280]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9697, 0.1034, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9539, 29.9258],\n",
      "        [31.9104, 26.8138],\n",
      "        [25.2454, 30.1495],\n",
      "        [27.8666, 27.8280]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9697, 0.1035, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9538, 29.9259],\n",
      "        [31.9103, 26.8141],\n",
      "        [25.2454, 30.1496],\n",
      "        [27.8666, 27.8281]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9697, 0.1035, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9539, 29.9259],\n",
      "        [31.9106, 26.8141],\n",
      "        [25.2455, 30.1496],\n",
      "        [27.8667, 27.8281]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9697, 0.1035, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9539, 29.9260],\n",
      "        [31.9104, 26.8143],\n",
      "        [25.2455, 30.1497],\n",
      "        [27.8666, 27.8282]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9697, 0.1035, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9540, 29.9259],\n",
      "        [31.9107, 26.8143],\n",
      "        [25.2456, 30.1496],\n",
      "        [27.8667, 27.8281]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9698, 0.1035, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9539, 29.9260],\n",
      "        [31.9105, 26.8145],\n",
      "        [25.2456, 30.1497],\n",
      "        [27.8667, 27.8282]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9698, 0.1035, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9540, 29.9260],\n",
      "        [31.9108, 26.8145],\n",
      "        [25.2457, 30.1497],\n",
      "        [27.8668, 27.8282]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9977, 0.9698, 0.1035, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9540, 29.9261],\n",
      "        [31.9107, 26.8147],\n",
      "        [25.2457, 30.1498],\n",
      "        [27.8668, 27.8283]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9977, 0.9698, 0.1035, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9541, 29.9261],\n",
      "        [31.9109, 26.8147],\n",
      "        [25.2458, 30.1498],\n",
      "        [27.8669, 27.8283]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9699, 0.1035, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9540, 29.9261],\n",
      "        [31.9108, 26.8149],\n",
      "        [25.2458, 30.1499],\n",
      "        [27.8668, 27.8283]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9699, 0.1035, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9541, 29.9261],\n",
      "        [31.9110, 26.8149],\n",
      "        [25.2459, 30.1499],\n",
      "        [27.8669, 27.8283]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9699, 0.1035, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9541, 29.9262],\n",
      "        [31.9109, 26.8151],\n",
      "        [25.2459, 30.1500],\n",
      "        [27.8669, 27.8284]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9699, 0.1035, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9542, 29.9262],\n",
      "        [31.9111, 26.8150],\n",
      "        [25.2460, 30.1499],\n",
      "        [27.8670, 27.8284]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9699, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9541, 29.9262],\n",
      "        [31.9110, 26.8153],\n",
      "        [25.2460, 30.1500],\n",
      "        [27.8669, 27.8284]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9699, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9542, 29.9262],\n",
      "        [31.9112, 26.8152],\n",
      "        [25.2461, 30.1500],\n",
      "        [27.8670, 27.8284]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9700, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9542, 29.9263],\n",
      "        [31.9111, 26.8155],\n",
      "        [25.2460, 30.1501],\n",
      "        [27.8670, 27.8285]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9700, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9543, 29.9263],\n",
      "        [31.9113, 26.8154],\n",
      "        [25.2462, 30.1501],\n",
      "        [27.8671, 27.8285]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9700, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9542, 29.9263],\n",
      "        [31.9112, 26.8157],\n",
      "        [25.2462, 30.1501],\n",
      "        [27.8670, 27.8286]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9700, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9543, 29.9263],\n",
      "        [31.9115, 26.8156],\n",
      "        [25.2463, 30.1501],\n",
      "        [27.8671, 27.8286]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9701, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9543, 29.9264],\n",
      "        [31.9113, 26.8159],\n",
      "        [25.2463, 30.1502],\n",
      "        [27.8671, 27.8286]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9701, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9544, 29.9264],\n",
      "        [31.9116, 26.8158],\n",
      "        [25.2464, 30.1502],\n",
      "        [27.8672, 27.8286]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9701, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9543, 29.9264],\n",
      "        [31.9114, 26.8160],\n",
      "        [25.2464, 30.1503],\n",
      "        [27.8671, 27.8287]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9701, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9544, 29.9264],\n",
      "        [31.9117, 26.8160],\n",
      "        [25.2465, 30.1503],\n",
      "        [27.8672, 27.8287]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9701, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9544, 29.9265],\n",
      "        [31.9115, 26.8162],\n",
      "        [25.2465, 30.1504],\n",
      "        [27.8672, 27.8287]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9701, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9545, 29.9265],\n",
      "        [31.9118, 26.8162],\n",
      "        [25.2466, 30.1503],\n",
      "        [27.8673, 27.8287]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9702, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9544, 29.9265],\n",
      "        [31.9116, 26.8164],\n",
      "        [25.2465, 30.1504],\n",
      "        [27.8672, 27.8288]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9702, 0.1036, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9545, 29.9265],\n",
      "        [31.9119, 26.8164],\n",
      "        [25.2467, 30.1504],\n",
      "        [27.8673, 27.8288]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9702, 0.1037, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9545, 29.9266],\n",
      "        [31.9118, 26.8166],\n",
      "        [25.2466, 30.1505],\n",
      "        [27.8673, 27.8288]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9702, 0.1037, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9545, 29.9266],\n",
      "        [31.9120, 26.8166],\n",
      "        [25.2468, 30.1505],\n",
      "        [27.8674, 27.8288]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9702, 0.1037, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9545, 29.9267],\n",
      "        [31.9119, 26.8168],\n",
      "        [25.2467, 30.1505],\n",
      "        [27.8673, 27.8289]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9702, 0.1037, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9546, 29.9267],\n",
      "        [31.9121, 26.8168],\n",
      "        [25.2469, 30.1505],\n",
      "        [27.8674, 27.8289]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9703, 0.1037, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9546, 29.9267],\n",
      "        [31.9120, 26.8170],\n",
      "        [25.2468, 30.1506],\n",
      "        [27.8674, 27.8290]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9703, 0.1037, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9547, 29.9267],\n",
      "        [31.9122, 26.8170],\n",
      "        [25.2470, 30.1506],\n",
      "        [27.8675, 27.8290]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9703, 0.1037, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9546, 29.9268],\n",
      "        [31.9121, 26.8172],\n",
      "        [25.2469, 30.1507],\n",
      "        [27.8674, 27.8290]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9703, 0.1037, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9547, 29.9268],\n",
      "        [31.9123, 26.8172],\n",
      "        [25.2471, 30.1507],\n",
      "        [27.8675, 27.8290]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9704, 0.1037, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9547, 29.9268],\n",
      "        [31.9122, 26.8174],\n",
      "        [25.2470, 30.1508],\n",
      "        [27.8675, 27.8291]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9704, 0.1037, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9547, 29.9268],\n",
      "        [31.9124, 26.8174],\n",
      "        [25.2472, 30.1507],\n",
      "        [27.8676, 27.8291]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9704, 0.1037, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9547, 29.9269],\n",
      "        [31.9123, 26.8176],\n",
      "        [25.2471, 30.1508],\n",
      "        [27.8676, 27.8291]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9704, 0.1037, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9548, 29.9269],\n",
      "        [31.9125, 26.8176],\n",
      "        [25.2473, 30.1508],\n",
      "        [27.8677, 27.8291]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9704, 0.1038, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9548, 29.9269],\n",
      "        [31.9124, 26.8178],\n",
      "        [25.2472, 30.1509],\n",
      "        [27.8676, 27.8292]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9704, 0.1038, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9548, 29.9269],\n",
      "        [31.9127, 26.8178],\n",
      "        [25.2474, 30.1509],\n",
      "        [27.8677, 27.8292]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9705, 0.1038, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9548, 29.9270],\n",
      "        [31.9125, 26.8180],\n",
      "        [25.2473, 30.1509],\n",
      "        [27.8677, 27.8292]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9705, 0.1038, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9549, 29.9270],\n",
      "        [31.9128, 26.8180],\n",
      "        [25.2475, 30.1509],\n",
      "        [27.8678, 27.8292]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9705, 0.1038, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9549, 29.9270],\n",
      "        [31.9126, 26.8182],\n",
      "        [25.2474, 30.1510],\n",
      "        [27.8677, 27.8293]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9705, 0.1038, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9549, 29.9270],\n",
      "        [31.9129, 26.8181],\n",
      "        [25.2476, 30.1510],\n",
      "        [27.8678, 27.8293]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9705, 0.1038, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9549, 29.9271],\n",
      "        [31.9128, 26.8184],\n",
      "        [25.2475, 30.1511],\n",
      "        [27.8678, 27.8294]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9705, 0.1038, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9550, 29.9271],\n",
      "        [31.9130, 26.8184],\n",
      "        [25.2477, 30.1511],\n",
      "        [27.8679, 27.8294]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9706, 0.1038, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9550, 29.9271],\n",
      "        [31.9129, 26.8185],\n",
      "        [25.2476, 30.1512],\n",
      "        [27.8678, 27.8294]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9706, 0.1038, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9550, 29.9271],\n",
      "        [31.9131, 26.8185],\n",
      "        [25.2478, 30.1511],\n",
      "        [27.8679, 27.8294]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9706, 0.1038, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9550, 29.9272],\n",
      "        [31.9130, 26.8187],\n",
      "        [25.2477, 30.1512],\n",
      "        [27.8679, 27.8295]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9706, 0.1038, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9551, 29.9272],\n",
      "        [31.9132, 26.8187],\n",
      "        [25.2479, 30.1512],\n",
      "        [27.8680, 27.8295]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9706, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9550, 29.9272],\n",
      "        [31.9131, 26.8189],\n",
      "        [25.2478, 30.1513],\n",
      "        [27.8679, 27.8295]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9706, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9551, 29.9272],\n",
      "        [31.9133, 26.8189],\n",
      "        [25.2480, 30.1512],\n",
      "        [27.8680, 27.8295]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9707, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9551, 29.9273],\n",
      "        [31.9132, 26.8191],\n",
      "        [25.2479, 30.1513],\n",
      "        [27.8680, 27.8296]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9707, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9552, 29.9273],\n",
      "        [31.9134, 26.8191],\n",
      "        [25.2481, 30.1513],\n",
      "        [27.8681, 27.8296]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9707, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9551, 29.9273],\n",
      "        [31.9133, 26.8193],\n",
      "        [25.2480, 30.1514],\n",
      "        [27.8680, 27.8296]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9707, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9552, 29.9273],\n",
      "        [31.9135, 26.8193],\n",
      "        [25.2482, 30.1514],\n",
      "        [27.8681, 27.8296]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9708, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9552, 29.9274],\n",
      "        [31.9134, 26.8195],\n",
      "        [25.2481, 30.1515],\n",
      "        [27.8681, 27.8297]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9708, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9553, 29.9274],\n",
      "        [31.9136, 26.8195],\n",
      "        [25.2482, 30.1515],\n",
      "        [27.8682, 27.8297]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9708, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9552, 29.9274],\n",
      "        [31.9135, 26.8197],\n",
      "        [25.2482, 30.1515],\n",
      "        [27.8681, 27.8297]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9708, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9553, 29.9274],\n",
      "        [31.9137, 26.8197],\n",
      "        [25.2483, 30.1515],\n",
      "        [27.8682, 27.8297]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9708, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9553, 29.9275],\n",
      "        [31.9136, 26.8199],\n",
      "        [25.2483, 30.1516],\n",
      "        [27.8682, 27.8298]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9708, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9553, 29.9275],\n",
      "        [31.9138, 26.8198],\n",
      "        [25.2484, 30.1516],\n",
      "        [27.8683, 27.8298]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9709, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9553, 29.9275],\n",
      "        [31.9137, 26.8200],\n",
      "        [25.2484, 30.1517],\n",
      "        [27.8682, 27.8299]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9709, 0.1039, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9554, 29.9275],\n",
      "        [31.9139, 26.8200],\n",
      "        [25.2485, 30.1516],\n",
      "        [27.8683, 27.8298]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9709, 0.1040, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9553, 29.9276],\n",
      "        [31.9138, 26.8202],\n",
      "        [25.2485, 30.1517],\n",
      "        [27.8683, 27.8299]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9709, 0.1040, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9554, 29.9276],\n",
      "        [31.9140, 26.8202],\n",
      "        [25.2486, 30.1517],\n",
      "        [27.8684, 27.8299]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9709, 0.1040, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9554, 29.9277],\n",
      "        [31.9139, 26.8204],\n",
      "        [25.2486, 30.1518],\n",
      "        [27.8683, 27.8300]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9709, 0.1040, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9555, 29.9277],\n",
      "        [31.9141, 26.8204],\n",
      "        [25.2487, 30.1518],\n",
      "        [27.8684, 27.8300]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9710, 0.1040, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9555, 29.9277],\n",
      "        [31.9140, 26.8206],\n",
      "        [25.2487, 30.1519],\n",
      "        [27.8684, 27.8300]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9710, 0.1040, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9555, 29.9277],\n",
      "        [31.9142, 26.8206],\n",
      "        [25.2488, 30.1518],\n",
      "        [27.8685, 27.8300]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9710, 0.1040, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9555, 29.9278],\n",
      "        [31.9141, 26.8208],\n",
      "        [25.2488, 30.1519],\n",
      "        [27.8685, 27.8301]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9710, 0.1040, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9556, 29.9278],\n",
      "        [31.9144, 26.8208],\n",
      "        [25.2489, 30.1519],\n",
      "        [27.8685, 27.8301]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9710, 0.1040, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9556, 29.9278],\n",
      "        [31.9142, 26.8210],\n",
      "        [25.2489, 30.1520],\n",
      "        [27.8685, 27.8302]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9710, 0.1040, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9556, 29.9278],\n",
      "        [31.9145, 26.8210],\n",
      "        [25.2490, 30.1520],\n",
      "        [27.8686, 27.8301]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9711, 0.1040, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9556, 29.9279],\n",
      "        [31.9143, 26.8212],\n",
      "        [25.2490, 30.1521],\n",
      "        [27.8686, 27.8302]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9711, 0.1040, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9557, 29.9279],\n",
      "        [31.9146, 26.8211],\n",
      "        [25.2491, 30.1520],\n",
      "        [27.8686, 27.8302]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9711, 0.1041, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9556, 29.9279],\n",
      "        [31.9144, 26.8213],\n",
      "        [25.2490, 30.1521],\n",
      "        [27.8686, 27.8303]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9711, 0.1041, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9557, 29.9279],\n",
      "        [31.9147, 26.8213],\n",
      "        [25.2492, 30.1521],\n",
      "        [27.8687, 27.8302]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9712, 0.1041, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9557, 29.9280],\n",
      "        [31.9145, 26.8215],\n",
      "        [25.2491, 30.1522],\n",
      "        [27.8686, 27.8303]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9712, 0.1041, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9557, 29.9280],\n",
      "        [31.9147, 26.8215],\n",
      "        [25.2493, 30.1521],\n",
      "        [27.8687, 27.8303]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9712, 0.1041, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9557, 29.9280],\n",
      "        [31.9146, 26.8217],\n",
      "        [25.2492, 30.1522],\n",
      "        [27.8687, 27.8304]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9712, 0.1041, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9558, 29.9280],\n",
      "        [31.9149, 26.8217],\n",
      "        [25.2494, 30.1522],\n",
      "        [27.8688, 27.8303]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9712, 0.1041, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9558, 29.9281],\n",
      "        [31.9147, 26.8219],\n",
      "        [25.2493, 30.1523],\n",
      "        [27.8687, 27.8304]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9712, 0.1041, 0.9612], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9558, 29.9281],\n",
      "        [31.9150, 26.8219],\n",
      "        [25.2495, 30.1523],\n",
      "        [27.8688, 27.8304]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9713, 0.1041, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9558, 29.9281],\n",
      "        [31.9148, 26.8221],\n",
      "        [25.2494, 30.1524],\n",
      "        [27.8688, 27.8305]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9713, 0.1041, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9559, 29.9281],\n",
      "        [31.9151, 26.8221],\n",
      "        [25.2496, 30.1523],\n",
      "        [27.8689, 27.8305]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9713, 0.1041, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9559, 29.9282],\n",
      "        [31.9149, 26.8222],\n",
      "        [25.2495, 30.1524],\n",
      "        [27.8688, 27.8305]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9713, 0.1041, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9559, 29.9282],\n",
      "        [31.9152, 26.8222],\n",
      "        [25.2497, 30.1524],\n",
      "        [27.8689, 27.8305]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9713, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9559, 29.9282],\n",
      "        [31.9150, 26.8224],\n",
      "        [25.2496, 30.1525],\n",
      "        [27.8689, 27.8306]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9713, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9560, 29.9282],\n",
      "        [31.9153, 26.8224],\n",
      "        [25.2498, 30.1525],\n",
      "        [27.8690, 27.8306]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9714, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9559, 29.9283],\n",
      "        [31.9151, 26.8226],\n",
      "        [25.2497, 30.1525],\n",
      "        [27.8689, 27.8306]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9714, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9560, 29.9283],\n",
      "        [31.9154, 26.8226],\n",
      "        [25.2498, 30.1525],\n",
      "        [27.8690, 27.8306]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9714, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9560, 29.9283],\n",
      "        [31.9152, 26.8228],\n",
      "        [25.2498, 30.1526],\n",
      "        [27.8690, 27.8307]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9714, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9561, 29.9283],\n",
      "        [31.9155, 26.8228],\n",
      "        [25.2499, 30.1526],\n",
      "        [27.8691, 27.8307]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9714, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9560, 29.9284],\n",
      "        [31.9153, 26.8230],\n",
      "        [25.2499, 30.1527],\n",
      "        [27.8690, 27.8307]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9714, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9561, 29.9284],\n",
      "        [31.9156, 26.8229],\n",
      "        [25.2500, 30.1527],\n",
      "        [27.8691, 27.8307]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9715, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9561, 29.9284],\n",
      "        [31.9154, 26.8231],\n",
      "        [25.2500, 30.1527],\n",
      "        [27.8691, 27.8308]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9715, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9562, 29.9284],\n",
      "        [31.9157, 26.8231],\n",
      "        [25.2501, 30.1527],\n",
      "        [27.8692, 27.8308]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9715, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9561, 29.9285],\n",
      "        [31.9156, 26.8233],\n",
      "        [25.2501, 30.1528],\n",
      "        [27.8691, 27.8309]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9715, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9562, 29.9285],\n",
      "        [31.9158, 26.8233],\n",
      "        [25.2502, 30.1528],\n",
      "        [27.8692, 27.8308]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9715, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9562, 29.9285],\n",
      "        [31.9157, 26.8235],\n",
      "        [25.2502, 30.1529],\n",
      "        [27.8692, 27.8309]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9715, 0.1042, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9563, 29.9285],\n",
      "        [31.9159, 26.8235],\n",
      "        [25.2503, 30.1529],\n",
      "        [27.8693, 27.8309]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9716, 0.1043, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9562, 29.9286],\n",
      "        [31.9158, 26.8237],\n",
      "        [25.2503, 30.1529],\n",
      "        [27.8693, 27.8310]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9716, 0.1043, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9563, 29.9286],\n",
      "        [31.9160, 26.8237],\n",
      "        [25.2504, 30.1529],\n",
      "        [27.8693, 27.8310]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9716, 0.1043, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9562, 29.9286],\n",
      "        [31.9158, 26.8239],\n",
      "        [25.2503, 30.1530],\n",
      "        [27.8693, 27.8310]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9716, 0.1043, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9563, 29.9286],\n",
      "        [31.9161, 26.8238],\n",
      "        [25.2505, 30.1530],\n",
      "        [27.8694, 27.8310]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9716, 0.1043, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9563, 29.9287],\n",
      "        [31.9160, 26.8240],\n",
      "        [25.2504, 30.1531],\n",
      "        [27.8693, 27.8311]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9716, 0.1043, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9564, 29.9287],\n",
      "        [31.9162, 26.8240],\n",
      "        [25.2506, 30.1530],\n",
      "        [27.8694, 27.8311]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9717, 0.1043, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9564, 29.9287],\n",
      "        [31.9161, 26.8242],\n",
      "        [25.2506, 30.1531],\n",
      "        [27.8694, 27.8311]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9717, 0.1043, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9564, 29.9287],\n",
      "        [31.9163, 26.8242],\n",
      "        [25.2507, 30.1531],\n",
      "        [27.8695, 27.8311]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9717, 0.1043, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9564, 29.9288],\n",
      "        [31.9162, 26.8244],\n",
      "        [25.2506, 30.1532],\n",
      "        [27.8695, 27.8312]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9717, 0.1043, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9565, 29.9288],\n",
      "        [31.9164, 26.8244],\n",
      "        [25.2508, 30.1532],\n",
      "        [27.8695, 27.8312]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9717, 0.1043, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9564, 29.9288],\n",
      "        [31.9163, 26.8246],\n",
      "        [25.2507, 30.1533],\n",
      "        [27.8695, 27.8312]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9717, 0.1043, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9565, 29.9288],\n",
      "        [31.9165, 26.8246],\n",
      "        [25.2509, 30.1532],\n",
      "        [27.8696, 27.8312]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9718, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9565, 29.9289],\n",
      "        [31.9164, 26.8248],\n",
      "        [25.2508, 30.1533],\n",
      "        [27.8696, 27.8313]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9718, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9566, 29.9289],\n",
      "        [31.9166, 26.8247],\n",
      "        [25.2510, 30.1533],\n",
      "        [27.8696, 27.8313]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9718, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9565, 29.9289],\n",
      "        [31.9165, 26.8249],\n",
      "        [25.2509, 30.1534],\n",
      "        [27.8696, 27.8313]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9718, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9566, 29.9289],\n",
      "        [31.9167, 26.8249],\n",
      "        [25.2511, 30.1533],\n",
      "        [27.8697, 27.8313]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9978, 0.9718, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9566, 29.9290],\n",
      "        [31.9166, 26.8251],\n",
      "        [25.2510, 30.1534],\n",
      "        [27.8696, 27.8314]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9978, 0.9718, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9566, 29.9290],\n",
      "        [31.9168, 26.8251],\n",
      "        [25.2512, 30.1534],\n",
      "        [27.8697, 27.8314]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9719, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9566, 29.9290],\n",
      "        [31.9166, 26.8253],\n",
      "        [25.2511, 30.1535],\n",
      "        [27.8697, 27.8314]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9719, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9567, 29.9290],\n",
      "        [31.9169, 26.8253],\n",
      "        [25.2512, 30.1535],\n",
      "        [27.8698, 27.8314]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9719, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9567, 29.9291],\n",
      "        [31.9167, 26.8254],\n",
      "        [25.2512, 30.1535],\n",
      "        [27.8697, 27.8315]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9719, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9567, 29.9291],\n",
      "        [31.9170, 26.8254],\n",
      "        [25.2513, 30.1535],\n",
      "        [27.8698, 27.8315]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9719, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9567, 29.9291],\n",
      "        [31.9168, 26.8256],\n",
      "        [25.2513, 30.1536],\n",
      "        [27.8698, 27.8315]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9719, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9568, 29.9291],\n",
      "        [31.9171, 26.8256],\n",
      "        [25.2514, 30.1536],\n",
      "        [27.8699, 27.8315]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9720, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9567, 29.9292],\n",
      "        [31.9169, 26.8258],\n",
      "        [25.2514, 30.1537],\n",
      "        [27.8698, 27.8316]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9720, 0.1044, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9568, 29.9292],\n",
      "        [31.9172, 26.8258],\n",
      "        [25.2515, 30.1537],\n",
      "        [27.8699, 27.8316]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9720, 0.1045, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9568, 29.9292],\n",
      "        [31.9171, 26.8260],\n",
      "        [25.2515, 30.1537],\n",
      "        [27.8699, 27.8317]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9720, 0.1045, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9569, 29.9292],\n",
      "        [31.9173, 26.8260],\n",
      "        [25.2516, 30.1537],\n",
      "        [27.8700, 27.8317]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9720, 0.1045, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9568, 29.9293],\n",
      "        [31.9172, 26.8262],\n",
      "        [25.2516, 30.1538],\n",
      "        [27.8699, 27.8317]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9720, 0.1045, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9569, 29.9293],\n",
      "        [31.9174, 26.8261],\n",
      "        [25.2517, 30.1538],\n",
      "        [27.8700, 27.8317]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9721, 0.1045, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9569, 29.9293],\n",
      "        [31.9172, 26.8263],\n",
      "        [25.2516, 30.1539],\n",
      "        [27.8700, 27.8318]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9721, 0.1045, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9569, 29.9293],\n",
      "        [31.9174, 26.8263],\n",
      "        [25.2518, 30.1538],\n",
      "        [27.8701, 27.8317]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9721, 0.1045, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9569, 29.9294],\n",
      "        [31.9173, 26.8265],\n",
      "        [25.2517, 30.1539],\n",
      "        [27.8700, 27.8318]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9721, 0.1045, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9570, 29.9294],\n",
      "        [31.9175, 26.8265],\n",
      "        [25.2519, 30.1539],\n",
      "        [27.8701, 27.8318]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9721, 0.1045, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9570, 29.9294],\n",
      "        [31.9174, 26.8267],\n",
      "        [25.2518, 30.1540],\n",
      "        [27.8701, 27.8319]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9721, 0.1045, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9570, 29.9294],\n",
      "        [31.9176, 26.8266],\n",
      "        [25.2520, 30.1540],\n",
      "        [27.8702, 27.8319]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9722, 0.1045, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9570, 29.9295],\n",
      "        [31.9175, 26.8268],\n",
      "        [25.2519, 30.1540],\n",
      "        [27.8701, 27.8319]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9722, 0.1045, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9571, 29.9295],\n",
      "        [31.9177, 26.8268],\n",
      "        [25.2521, 30.1540],\n",
      "        [27.8702, 27.8319]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9722, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9571, 29.9295],\n",
      "        [31.9176, 26.8270],\n",
      "        [25.2520, 30.1541],\n",
      "        [27.8702, 27.8320]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9722, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9571, 29.9295],\n",
      "        [31.9178, 26.8270],\n",
      "        [25.2522, 30.1541],\n",
      "        [27.8703, 27.8320]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9722, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9571, 29.9296],\n",
      "        [31.9177, 26.8272],\n",
      "        [25.2521, 30.1542],\n",
      "        [27.8702, 27.8320]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9722, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9572, 29.9296],\n",
      "        [31.9179, 26.8272],\n",
      "        [25.2523, 30.1542],\n",
      "        [27.8703, 27.8320]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9723, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9571, 29.9296],\n",
      "        [31.9178, 26.8273],\n",
      "        [25.2522, 30.1542],\n",
      "        [27.8703, 27.8321]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9723, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9572, 29.9296],\n",
      "        [31.9180, 26.8273],\n",
      "        [25.2523, 30.1542],\n",
      "        [27.8703, 27.8321]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9723, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9572, 29.9297],\n",
      "        [31.9179, 26.8275],\n",
      "        [25.2523, 30.1543],\n",
      "        [27.8703, 27.8321]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9723, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9573, 29.9297],\n",
      "        [31.9181, 26.8275],\n",
      "        [25.2524, 30.1543],\n",
      "        [27.8704, 27.8321]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9723, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9572, 29.9297],\n",
      "        [31.9180, 26.8277],\n",
      "        [25.2524, 30.1543],\n",
      "        [27.8704, 27.8322]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9723, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9573, 29.9297],\n",
      "        [31.9182, 26.8277],\n",
      "        [25.2525, 30.1543],\n",
      "        [27.8704, 27.8322]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9724, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9573, 29.9298],\n",
      "        [31.9181, 26.8278],\n",
      "        [25.2525, 30.1544],\n",
      "        [27.8704, 27.8322]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9724, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9573, 29.9298],\n",
      "        [31.9183, 26.8278],\n",
      "        [25.2526, 30.1544],\n",
      "        [27.8705, 27.8322]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9724, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9573, 29.9298],\n",
      "        [31.9182, 26.8280],\n",
      "        [25.2525, 30.1545],\n",
      "        [27.8705, 27.8323]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9724, 0.1046, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9574, 29.9298],\n",
      "        [31.9184, 26.8280],\n",
      "        [25.2527, 30.1544],\n",
      "        [27.8705, 27.8323]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9724, 0.1047, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9573, 29.9299],\n",
      "        [31.9183, 26.8282],\n",
      "        [25.2526, 30.1545],\n",
      "        [27.8705, 27.8323]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9724, 0.1047, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9574, 29.9299],\n",
      "        [31.9185, 26.8282],\n",
      "        [25.2528, 30.1545],\n",
      "        [27.8706, 27.8323]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9725, 0.1047, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9574, 29.9299],\n",
      "        [31.9184, 26.8284],\n",
      "        [25.2527, 30.1546],\n",
      "        [27.8706, 27.8324]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9725, 0.1047, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9575, 29.9299],\n",
      "        [31.9186, 26.8284],\n",
      "        [25.2529, 30.1546],\n",
      "        [27.8706, 27.8324]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9725, 0.1047, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9574, 29.9300],\n",
      "        [31.9185, 26.8285],\n",
      "        [25.2528, 30.1547],\n",
      "        [27.8706, 27.8324]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9725, 0.1047, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9575, 29.9300],\n",
      "        [31.9187, 26.8285],\n",
      "        [25.2530, 30.1546],\n",
      "        [27.8707, 27.8324]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9725, 0.1047, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9575, 29.9300],\n",
      "        [31.9186, 26.8287],\n",
      "        [25.2529, 30.1547],\n",
      "        [27.8706, 27.8325]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9725, 0.1047, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9575, 29.9300],\n",
      "        [31.9188, 26.8287],\n",
      "        [25.2530, 30.1547],\n",
      "        [27.8707, 27.8325]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9726, 0.1047, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9575, 29.9300],\n",
      "        [31.9187, 26.8289],\n",
      "        [25.2530, 30.1548],\n",
      "        [27.8707, 27.8325]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9726, 0.1047, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9576, 29.9300],\n",
      "        [31.9189, 26.8288],\n",
      "        [25.2531, 30.1547],\n",
      "        [27.8708, 27.8325]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9726, 0.1047, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9576, 29.9301],\n",
      "        [31.9188, 26.8290],\n",
      "        [25.2531, 30.1548],\n",
      "        [27.8707, 27.8326]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9726, 0.1047, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9576, 29.9301],\n",
      "        [31.9190, 26.8290],\n",
      "        [25.2532, 30.1548],\n",
      "        [27.8708, 27.8326]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9726, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9576, 29.9301],\n",
      "        [31.9189, 26.8292],\n",
      "        [25.2532, 30.1549],\n",
      "        [27.8708, 27.8326]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9726, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9577, 29.9301],\n",
      "        [31.9191, 26.8292],\n",
      "        [25.2533, 30.1549],\n",
      "        [27.8709, 27.8326]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9727, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9576, 29.9302],\n",
      "        [31.9189, 26.8294],\n",
      "        [25.2533, 30.1549],\n",
      "        [27.8708, 27.8327]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9727, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9577, 29.9302],\n",
      "        [31.9192, 26.8294],\n",
      "        [25.2534, 30.1549],\n",
      "        [27.8709, 27.8327]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9727, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9577, 29.9302],\n",
      "        [31.9191, 26.8295],\n",
      "        [25.2534, 30.1550],\n",
      "        [27.8709, 27.8328]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9727, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9578, 29.9302],\n",
      "        [31.9193, 26.8295],\n",
      "        [25.2535, 30.1550],\n",
      "        [27.8710, 27.8327]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9727, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9577, 29.9303],\n",
      "        [31.9191, 26.8297],\n",
      "        [25.2534, 30.1551],\n",
      "        [27.8709, 27.8328]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9727, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9578, 29.9303],\n",
      "        [31.9193, 26.8297],\n",
      "        [25.2536, 30.1550],\n",
      "        [27.8710, 27.8328]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9728, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9578, 29.9303],\n",
      "        [31.9192, 26.8299],\n",
      "        [25.2535, 30.1551],\n",
      "        [27.8710, 27.8328]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9728, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9578, 29.9303],\n",
      "        [31.9194, 26.8298],\n",
      "        [25.2537, 30.1551],\n",
      "        [27.8711, 27.8328]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9728, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9578, 29.9304],\n",
      "        [31.9193, 26.8300],\n",
      "        [25.2536, 30.1552],\n",
      "        [27.8710, 27.8329]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9728, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9579, 29.9304],\n",
      "        [31.9195, 26.8300],\n",
      "        [25.2538, 30.1552],\n",
      "        [27.8711, 27.8329]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9728, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9578, 29.9304],\n",
      "        [31.9194, 26.8302],\n",
      "        [25.2537, 30.1552],\n",
      "        [27.8711, 27.8330]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9728, 0.1048, 0.9613], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9579, 29.9304],\n",
      "        [31.9196, 26.8302],\n",
      "        [25.2539, 30.1552],\n",
      "        [27.8712, 27.8330]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9728, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9579, 29.9305],\n",
      "        [31.9195, 26.8304],\n",
      "        [25.2538, 30.1553],\n",
      "        [27.8711, 27.8330]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9728, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9580, 29.9305],\n",
      "        [31.9197, 26.8303],\n",
      "        [25.2539, 30.1553],\n",
      "        [27.8712, 27.8330]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9729, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9579, 29.9305],\n",
      "        [31.9196, 26.8305],\n",
      "        [25.2539, 30.1554],\n",
      "        [27.8712, 27.8331]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9729, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9580, 29.9305],\n",
      "        [31.9198, 26.8305],\n",
      "        [25.2540, 30.1553],\n",
      "        [27.8713, 27.8331]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9729, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9580, 29.9306],\n",
      "        [31.9197, 26.8307],\n",
      "        [25.2540, 30.1554],\n",
      "        [27.8712, 27.8331]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9729, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9580, 29.9306],\n",
      "        [31.9199, 26.8307],\n",
      "        [25.2541, 30.1554],\n",
      "        [27.8713, 27.8331]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9729, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9580, 29.9306],\n",
      "        [31.9198, 26.8309],\n",
      "        [25.2541, 30.1555],\n",
      "        [27.8713, 27.8332]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9729, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9581, 29.9306],\n",
      "        [31.9200, 26.8308],\n",
      "        [25.2542, 30.1555],\n",
      "        [27.8714, 27.8332]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9730, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9581, 29.9307],\n",
      "        [31.9199, 26.8310],\n",
      "        [25.2542, 30.1555],\n",
      "        [27.8713, 27.8332]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9730, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9581, 29.9307],\n",
      "        [31.9201, 26.8310],\n",
      "        [25.2543, 30.1555],\n",
      "        [27.8714, 27.8332]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9730, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9581, 29.9307],\n",
      "        [31.9200, 26.8312],\n",
      "        [25.2542, 30.1556],\n",
      "        [27.8714, 27.8333]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9730, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9582, 29.9307],\n",
      "        [31.9202, 26.8312],\n",
      "        [25.2544, 30.1556],\n",
      "        [27.8714, 27.8333]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9730, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9581, 29.9308],\n",
      "        [31.9200, 26.8313],\n",
      "        [25.2543, 30.1556],\n",
      "        [27.8714, 27.8333]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9730, 0.1049, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9582, 29.9308],\n",
      "        [31.9202, 26.8313],\n",
      "        [25.2545, 30.1556],\n",
      "        [27.8715, 27.8333]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9731, 0.1050, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9582, 29.9308],\n",
      "        [31.9201, 26.8315],\n",
      "        [25.2544, 30.1557],\n",
      "        [27.8714, 27.8334]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9731, 0.1050, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9582, 29.9308],\n",
      "        [31.9203, 26.8315],\n",
      "        [25.2546, 30.1557],\n",
      "        [27.8715, 27.8334]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9731, 0.1050, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9582, 29.9309],\n",
      "        [31.9202, 26.8317],\n",
      "        [25.2545, 30.1558],\n",
      "        [27.8715, 27.8334]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9731, 0.1050, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9583, 29.9309],\n",
      "        [31.9204, 26.8316],\n",
      "        [25.2546, 30.1557],\n",
      "        [27.8716, 27.8334]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9731, 0.1050, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9583, 29.9309],\n",
      "        [31.9203, 26.8318],\n",
      "        [25.2546, 30.1558],\n",
      "        [27.8715, 27.8335]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9731, 0.1050, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9583, 29.9309],\n",
      "        [31.9205, 26.8318],\n",
      "        [25.2547, 30.1558],\n",
      "        [27.8716, 27.8335]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9732, 0.1050, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9583, 29.9310],\n",
      "        [31.9204, 26.8320],\n",
      "        [25.2547, 30.1559],\n",
      "        [27.8716, 27.8335]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9732, 0.1050, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9584, 29.9310],\n",
      "        [31.9206, 26.8320],\n",
      "        [25.2548, 30.1559],\n",
      "        [27.8717, 27.8335]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9732, 0.1050, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9583, 29.9310],\n",
      "        [31.9205, 26.8321],\n",
      "        [25.2548, 30.1559],\n",
      "        [27.8716, 27.8336]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9732, 0.1050, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9584, 29.9310],\n",
      "        [31.9207, 26.8321],\n",
      "        [25.2549, 30.1559],\n",
      "        [27.8717, 27.8336]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9732, 0.1050, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9584, 29.9311],\n",
      "        [31.9206, 26.8323],\n",
      "        [25.2549, 30.1560],\n",
      "        [27.8717, 27.8336]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9732, 0.1050, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9584, 29.9310],\n",
      "        [31.9208, 26.8323],\n",
      "        [25.2550, 30.1560],\n",
      "        [27.8718, 27.8336]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9732, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9584, 29.9311],\n",
      "        [31.9207, 26.8325],\n",
      "        [25.2549, 30.1560],\n",
      "        [27.8717, 27.8337]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9732, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9585, 29.9311],\n",
      "        [31.9209, 26.8325],\n",
      "        [25.2551, 30.1560],\n",
      "        [27.8718, 27.8337]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9733, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9585, 29.9311],\n",
      "        [31.9208, 26.8326],\n",
      "        [25.2550, 30.1561],\n",
      "        [27.8718, 27.8337]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9733, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9585, 29.9311],\n",
      "        [31.9210, 26.8326],\n",
      "        [25.2552, 30.1561],\n",
      "        [27.8718, 27.8337]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9733, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9585, 29.9312],\n",
      "        [31.9209, 26.8328],\n",
      "        [25.2551, 30.1562],\n",
      "        [27.8718, 27.8338]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9733, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9586, 29.9312],\n",
      "        [31.9210, 26.8328],\n",
      "        [25.2552, 30.1561],\n",
      "        [27.8719, 27.8337]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9733, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9585, 29.9312],\n",
      "        [31.9210, 26.8329],\n",
      "        [25.2552, 30.1562],\n",
      "        [27.8719, 27.8338]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9733, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9586, 29.9312],\n",
      "        [31.9212, 26.8329],\n",
      "        [25.2553, 30.1562],\n",
      "        [27.8719, 27.8338]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9734, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9586, 29.9313],\n",
      "        [31.9210, 26.8331],\n",
      "        [25.2553, 30.1563],\n",
      "        [27.8719, 27.8339]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9734, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9586, 29.9313],\n",
      "        [31.9212, 26.8331],\n",
      "        [25.2554, 30.1563],\n",
      "        [27.8720, 27.8338]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9734, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9586, 29.9313],\n",
      "        [31.9211, 26.8333],\n",
      "        [25.2554, 30.1563],\n",
      "        [27.8719, 27.8339]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9734, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9587, 29.9313],\n",
      "        [31.9213, 26.8333],\n",
      "        [25.2555, 30.1563],\n",
      "        [27.8720, 27.8339]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9734, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9587, 29.9314],\n",
      "        [31.9212, 26.8334],\n",
      "        [25.2555, 30.1564],\n",
      "        [27.8720, 27.8340]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9734, 0.1051, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9587, 29.9314],\n",
      "        [31.9214, 26.8334],\n",
      "        [25.2556, 30.1564],\n",
      "        [27.8721, 27.8340]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9735, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9587, 29.9314],\n",
      "        [31.9213, 26.8336],\n",
      "        [25.2555, 30.1565],\n",
      "        [27.8720, 27.8340]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9735, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9588, 29.9314],\n",
      "        [31.9215, 26.8336],\n",
      "        [25.2557, 30.1564],\n",
      "        [27.8721, 27.8340]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9735, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9587, 29.9315],\n",
      "        [31.9214, 26.8337],\n",
      "        [25.2556, 30.1565],\n",
      "        [27.8721, 27.8341]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9735, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9588, 29.9315],\n",
      "        [31.9216, 26.8337],\n",
      "        [25.2558, 30.1565],\n",
      "        [27.8722, 27.8340]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9735, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9588, 29.9315],\n",
      "        [31.9215, 26.8339],\n",
      "        [25.2557, 30.1566],\n",
      "        [27.8721, 27.8341]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9735, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9588, 29.9315],\n",
      "        [31.9217, 26.8339],\n",
      "        [25.2558, 30.1565],\n",
      "        [27.8722, 27.8341]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9735, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9588, 29.9315],\n",
      "        [31.9216, 26.8340],\n",
      "        [25.2558, 30.1566],\n",
      "        [27.8722, 27.8341]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9735, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9589, 29.9316],\n",
      "        [31.9218, 26.8340],\n",
      "        [25.2559, 30.1566],\n",
      "        [27.8723, 27.8342]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9736, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9589, 29.9316],\n",
      "        [31.9217, 26.8342],\n",
      "        [25.2559, 30.1567],\n",
      "        [27.8722, 27.8342]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9736, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9589, 29.9316],\n",
      "        [31.9218, 26.8342],\n",
      "        [25.2560, 30.1567],\n",
      "        [27.8723, 27.8342]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9736, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9589, 29.9316],\n",
      "        [31.9217, 26.8343],\n",
      "        [25.2560, 30.1567],\n",
      "        [27.8722, 27.8342]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9736, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9590, 29.9317],\n",
      "        [31.9219, 26.8344],\n",
      "        [25.2561, 30.1567],\n",
      "        [27.8723, 27.8343]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9736, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9589, 29.9317],\n",
      "        [31.9218, 26.8345],\n",
      "        [25.2561, 30.1568],\n",
      "        [27.8723, 27.8343]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9736, 0.1052, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9590, 29.9317],\n",
      "        [31.9220, 26.8345],\n",
      "        [25.2562, 30.1568],\n",
      "        [27.8724, 27.8343]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9737, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9590, 29.9317],\n",
      "        [31.9219, 26.8347],\n",
      "        [25.2561, 30.1568],\n",
      "        [27.8723, 27.8343]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9737, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9591, 29.9317],\n",
      "        [31.9221, 26.8347],\n",
      "        [25.2563, 30.1568],\n",
      "        [27.8724, 27.8344]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9737, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9590, 29.9318],\n",
      "        [31.9220, 26.8348],\n",
      "        [25.2562, 30.1569],\n",
      "        [27.8724, 27.8344]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9737, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9591, 29.9318],\n",
      "        [31.9222, 26.8348],\n",
      "        [25.2564, 30.1569],\n",
      "        [27.8725, 27.8344]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9737, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9591, 29.9318],\n",
      "        [31.9221, 26.8350],\n",
      "        [25.2563, 30.1570],\n",
      "        [27.8724, 27.8344]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9737, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9591, 29.9318],\n",
      "        [31.9223, 26.8350],\n",
      "        [25.2564, 30.1569],\n",
      "        [27.8725, 27.8344]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9979, 0.9738, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9591, 29.9319],\n",
      "        [31.9222, 26.8351],\n",
      "        [25.2564, 30.1570],\n",
      "        [27.8725, 27.8345]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9979, 0.9738, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9592, 29.9319],\n",
      "        [31.9224, 26.8351],\n",
      "        [25.2565, 30.1570],\n",
      "        [27.8726, 27.8345]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9738, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9591, 29.9319],\n",
      "        [31.9223, 26.8353],\n",
      "        [25.2565, 30.1571],\n",
      "        [27.8725, 27.8345]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9738, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9592, 29.9319],\n",
      "        [31.9224, 26.8353],\n",
      "        [25.2566, 30.1570],\n",
      "        [27.8726, 27.8345]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9738, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9592, 29.9320],\n",
      "        [31.9223, 26.8354],\n",
      "        [25.2566, 30.1571],\n",
      "        [27.8726, 27.8346]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9738, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9592, 29.9320],\n",
      "        [31.9225, 26.8354],\n",
      "        [25.2567, 30.1571],\n",
      "        [27.8727, 27.8346]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9738, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9592, 29.9320],\n",
      "        [31.9224, 26.8356],\n",
      "        [25.2566, 30.1572],\n",
      "        [27.8726, 27.8346]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9738, 0.1053, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9593, 29.9320],\n",
      "        [31.9226, 26.8356],\n",
      "        [25.2568, 30.1572],\n",
      "        [27.8727, 27.8346]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9739, 0.1054, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9593, 29.9321],\n",
      "        [31.9225, 26.8358],\n",
      "        [25.2567, 30.1572],\n",
      "        [27.8727, 27.8347]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9739, 0.1054, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9593, 29.9321],\n",
      "        [31.9227, 26.8357],\n",
      "        [25.2569, 30.1572],\n",
      "        [27.8727, 27.8347]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9739, 0.1054, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9593, 29.9321],\n",
      "        [31.9226, 26.8359],\n",
      "        [25.2568, 30.1573],\n",
      "        [27.8727, 27.8347]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9739, 0.1054, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9594, 29.9321],\n",
      "        [31.9228, 26.8359],\n",
      "        [25.2570, 30.1573],\n",
      "        [27.8728, 27.8347]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9739, 0.1054, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9593, 29.9321],\n",
      "        [31.9227, 26.8360],\n",
      "        [25.2569, 30.1573],\n",
      "        [27.8727, 27.8348]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9739, 0.1054, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9594, 29.9321],\n",
      "        [31.9229, 26.8360],\n",
      "        [25.2570, 30.1573],\n",
      "        [27.8728, 27.8348]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9740, 0.1054, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9594, 29.9322],\n",
      "        [31.9228, 26.8362],\n",
      "        [25.2570, 30.1574],\n",
      "        [27.8728, 27.8348]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9740, 0.1054, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9594, 29.9322],\n",
      "        [31.9230, 26.8362],\n",
      "        [25.2571, 30.1574],\n",
      "        [27.8729, 27.8348]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9740, 0.1054, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9594, 29.9322],\n",
      "        [31.9228, 26.8363],\n",
      "        [25.2571, 30.1575],\n",
      "        [27.8728, 27.8349]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9740, 0.1054, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9595, 29.9322],\n",
      "        [31.9230, 26.8363],\n",
      "        [25.2572, 30.1574],\n",
      "        [27.8729, 27.8349]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9740, 0.1054, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9594, 29.9323],\n",
      "        [31.9229, 26.8365],\n",
      "        [25.2572, 30.1575],\n",
      "        [27.8729, 27.8349]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9740, 0.1054, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9595, 29.9323],\n",
      "        [31.9231, 26.8365],\n",
      "        [25.2573, 30.1575],\n",
      "        [27.8729, 27.8349]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9740, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9595, 29.9323],\n",
      "        [31.9230, 26.8367],\n",
      "        [25.2572, 30.1576],\n",
      "        [27.8729, 27.8350]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9740, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9596, 29.9323],\n",
      "        [31.9232, 26.8367],\n",
      "        [25.2574, 30.1576],\n",
      "        [27.8730, 27.8350]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9741, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9595, 29.9324],\n",
      "        [31.9231, 26.8368],\n",
      "        [25.2573, 30.1576],\n",
      "        [27.8730, 27.8350]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9741, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9596, 29.9324],\n",
      "        [31.9233, 26.8368],\n",
      "        [25.2575, 30.1576],\n",
      "        [27.8730, 27.8350]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9741, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9596, 29.9324],\n",
      "        [31.9232, 26.8370],\n",
      "        [25.2574, 30.1577],\n",
      "        [27.8730, 27.8351]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9741, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9596, 29.9324],\n",
      "        [31.9234, 26.8370],\n",
      "        [25.2576, 30.1577],\n",
      "        [27.8731, 27.8351]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9741, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9596, 29.9325],\n",
      "        [31.9233, 26.8371],\n",
      "        [25.2575, 30.1577],\n",
      "        [27.8731, 27.8351]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9741, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9597, 29.9325],\n",
      "        [31.9235, 26.8371],\n",
      "        [25.2576, 30.1577],\n",
      "        [27.8731, 27.8351]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9742, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9596, 29.9325],\n",
      "        [31.9234, 26.8373],\n",
      "        [25.2576, 30.1578],\n",
      "        [27.8731, 27.8352]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9742, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9597, 29.9325],\n",
      "        [31.9235, 26.8372],\n",
      "        [25.2577, 30.1578],\n",
      "        [27.8732, 27.8352]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9742, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9597, 29.9325],\n",
      "        [31.9234, 26.8374],\n",
      "        [25.2577, 30.1578],\n",
      "        [27.8731, 27.8352]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9742, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9597, 29.9325],\n",
      "        [31.9236, 26.8374],\n",
      "        [25.2578, 30.1578],\n",
      "        [27.8732, 27.8352]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9742, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9597, 29.9326],\n",
      "        [31.9235, 26.8376],\n",
      "        [25.2577, 30.1579],\n",
      "        [27.8732, 27.8353]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9742, 0.1055, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9598, 29.9326],\n",
      "        [31.9237, 26.8376],\n",
      "        [25.2579, 30.1579],\n",
      "        [27.8732, 27.8353]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9742, 0.1056, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9598, 29.9326],\n",
      "        [31.9236, 26.8377],\n",
      "        [25.2578, 30.1580],\n",
      "        [27.8732, 27.8353]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9742, 0.1056, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9598, 29.9326],\n",
      "        [31.9238, 26.8377],\n",
      "        [25.2580, 30.1579],\n",
      "        [27.8733, 27.8353]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9743, 0.1056, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9598, 29.9327],\n",
      "        [31.9237, 26.8379],\n",
      "        [25.2579, 30.1580],\n",
      "        [27.8733, 27.8354]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9743, 0.1056, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9599, 29.9327],\n",
      "        [31.9239, 26.8379],\n",
      "        [25.2581, 30.1580],\n",
      "        [27.8733, 27.8354]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9743, 0.1056, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9598, 29.9327],\n",
      "        [31.9238, 26.8380],\n",
      "        [25.2580, 30.1581],\n",
      "        [27.8733, 27.8354]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9743, 0.1056, 0.9614], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9599, 29.9327],\n",
      "        [31.9240, 26.8380],\n",
      "        [25.2581, 30.1580],\n",
      "        [27.8734, 27.8354]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9743, 0.1056, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9599, 29.9328],\n",
      "        [31.9239, 26.8382],\n",
      "        [25.2581, 30.1581],\n",
      "        [27.8734, 27.8355]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9743, 0.1056, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9599, 29.9328],\n",
      "        [31.9240, 26.8381],\n",
      "        [25.2582, 30.1581],\n",
      "        [27.8734, 27.8354]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9744, 0.1056, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9599, 29.9328],\n",
      "        [31.9240, 26.8383],\n",
      "        [25.2582, 30.1582],\n",
      "        [27.8734, 27.8355]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9744, 0.1056, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9600, 29.9328],\n",
      "        [31.9241, 26.8383],\n",
      "        [25.2583, 30.1582],\n",
      "        [27.8735, 27.8355]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9744, 0.1056, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9600, 29.9329],\n",
      "        [31.9240, 26.8385],\n",
      "        [25.2583, 30.1582],\n",
      "        [27.8734, 27.8356]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9744, 0.1056, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9600, 29.9329],\n",
      "        [31.9242, 26.8384],\n",
      "        [25.2584, 30.1582],\n",
      "        [27.8735, 27.8355]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9744, 0.1056, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9600, 29.9329],\n",
      "        [31.9241, 26.8386],\n",
      "        [25.2583, 30.1583],\n",
      "        [27.8735, 27.8356]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9744, 0.1056, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9600, 29.9329],\n",
      "        [31.9243, 26.8386],\n",
      "        [25.2585, 30.1583],\n",
      "        [27.8736, 27.8356]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9744, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9600, 29.9329],\n",
      "        [31.9242, 26.8387],\n",
      "        [25.2584, 30.1583],\n",
      "        [27.8735, 27.8356]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9744, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9601, 29.9329],\n",
      "        [31.9244, 26.8387],\n",
      "        [25.2585, 30.1583],\n",
      "        [27.8736, 27.8356]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9745, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9601, 29.9330],\n",
      "        [31.9243, 26.8389],\n",
      "        [25.2585, 30.1584],\n",
      "        [27.8736, 27.8357]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9745, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9601, 29.9330],\n",
      "        [31.9244, 26.8389],\n",
      "        [25.2586, 30.1584],\n",
      "        [27.8736, 27.8357]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9745, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9601, 29.9330],\n",
      "        [31.9243, 26.8391],\n",
      "        [25.2586, 30.1585],\n",
      "        [27.8736, 27.8357]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9745, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9602, 29.9330],\n",
      "        [31.9245, 26.8390],\n",
      "        [25.2587, 30.1584],\n",
      "        [27.8737, 27.8357]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9745, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9601, 29.9331],\n",
      "        [31.9244, 26.8392],\n",
      "        [25.2587, 30.1585],\n",
      "        [27.8736, 27.8358]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9745, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9602, 29.9331],\n",
      "        [31.9246, 26.8392],\n",
      "        [25.2588, 30.1585],\n",
      "        [27.8737, 27.8358]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9745, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9602, 29.9331],\n",
      "        [31.9245, 26.8393],\n",
      "        [25.2587, 30.1585],\n",
      "        [27.8737, 27.8358]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9745, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9602, 29.9331],\n",
      "        [31.9247, 26.8393],\n",
      "        [25.2589, 30.1585],\n",
      "        [27.8738, 27.8358]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9746, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9602, 29.9332],\n",
      "        [31.9246, 26.8395],\n",
      "        [25.2588, 30.1586],\n",
      "        [27.8737, 27.8359]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9746, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9603, 29.9332],\n",
      "        [31.9248, 26.8395],\n",
      "        [25.2590, 30.1586],\n",
      "        [27.8738, 27.8359]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9746, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9603, 29.9332],\n",
      "        [31.9247, 26.8396],\n",
      "        [25.2589, 30.1587],\n",
      "        [27.8738, 27.8359]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9746, 0.1057, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9603, 29.9332],\n",
      "        [31.9249, 26.8396],\n",
      "        [25.2590, 30.1586],\n",
      "        [27.8738, 27.8359]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9746, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9603, 29.9333],\n",
      "        [31.9248, 26.8398],\n",
      "        [25.2590, 30.1587],\n",
      "        [27.8738, 27.8360]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9746, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9603, 29.9332],\n",
      "        [31.9249, 26.8398],\n",
      "        [25.2591, 30.1587],\n",
      "        [27.8739, 27.8360]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9747, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9603, 29.9333],\n",
      "        [31.9248, 26.8399],\n",
      "        [25.2591, 30.1588],\n",
      "        [27.8739, 27.8360]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9747, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9604, 29.9333],\n",
      "        [31.9250, 26.8399],\n",
      "        [25.2592, 30.1587],\n",
      "        [27.8739, 27.8360]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9747, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9603, 29.9333],\n",
      "        [31.9249, 26.8401],\n",
      "        [25.2591, 30.1588],\n",
      "        [27.8739, 27.8361]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9747, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9604, 29.9333],\n",
      "        [31.9251, 26.8401],\n",
      "        [25.2593, 30.1588],\n",
      "        [27.8740, 27.8361]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9747, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9604, 29.9334],\n",
      "        [31.9250, 26.8402],\n",
      "        [25.2592, 30.1589],\n",
      "        [27.8739, 27.8361]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9747, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9605, 29.9334],\n",
      "        [31.9252, 26.8402],\n",
      "        [25.2594, 30.1589],\n",
      "        [27.8740, 27.8361]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9747, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9604, 29.9334],\n",
      "        [31.9251, 26.8404],\n",
      "        [25.2593, 30.1589],\n",
      "        [27.8740, 27.8362]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9747, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9605, 29.9334],\n",
      "        [31.9253, 26.8403],\n",
      "        [25.2594, 30.1589],\n",
      "        [27.8741, 27.8361]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9748, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9605, 29.9335],\n",
      "        [31.9252, 26.8405],\n",
      "        [25.2594, 30.1590],\n",
      "        [27.8740, 27.8362]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9748, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9605, 29.9335],\n",
      "        [31.9253, 26.8405],\n",
      "        [25.2595, 30.1590],\n",
      "        [27.8741, 27.8362]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9748, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9605, 29.9335],\n",
      "        [31.9252, 26.8407],\n",
      "        [25.2595, 30.1590],\n",
      "        [27.8741, 27.8363]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9748, 0.1058, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9606, 29.9335],\n",
      "        [31.9254, 26.8406],\n",
      "        [25.2596, 30.1590],\n",
      "        [27.8741, 27.8362]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9748, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9605, 29.9336],\n",
      "        [31.9253, 26.8408],\n",
      "        [25.2596, 30.1591],\n",
      "        [27.8741, 27.8363]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9748, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9606, 29.9336],\n",
      "        [31.9255, 26.8408],\n",
      "        [25.2597, 30.1591],\n",
      "        [27.8742, 27.8363]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9748, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9606, 29.9336],\n",
      "        [31.9254, 26.8409],\n",
      "        [25.2596, 30.1591],\n",
      "        [27.8741, 27.8363]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9748, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9606, 29.9336],\n",
      "        [31.9256, 26.8409],\n",
      "        [25.2598, 30.1591],\n",
      "        [27.8742, 27.8363]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9749, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9606, 29.9336],\n",
      "        [31.9255, 26.8411],\n",
      "        [25.2597, 30.1592],\n",
      "        [27.8742, 27.8364]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9749, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9607, 29.9336],\n",
      "        [31.9256, 26.8411],\n",
      "        [25.2599, 30.1592],\n",
      "        [27.8743, 27.8364]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9749, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9606, 29.9337],\n",
      "        [31.9255, 26.8412],\n",
      "        [25.2598, 30.1592],\n",
      "        [27.8742, 27.8364]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9749, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9607, 29.9337],\n",
      "        [31.9257, 26.8412],\n",
      "        [25.2599, 30.1592],\n",
      "        [27.8743, 27.8364]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9749, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9607, 29.9337],\n",
      "        [31.9256, 26.8414],\n",
      "        [25.2599, 30.1593],\n",
      "        [27.8743, 27.8365]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9749, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9607, 29.9337],\n",
      "        [31.9258, 26.8414],\n",
      "        [25.2600, 30.1593],\n",
      "        [27.8743, 27.8365]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9750, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9607, 29.9338],\n",
      "        [31.9257, 26.8415],\n",
      "        [25.2600, 30.1593],\n",
      "        [27.8743, 27.8365]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9750, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9608, 29.9338],\n",
      "        [31.9259, 26.8415],\n",
      "        [25.2601, 30.1593],\n",
      "        [27.8744, 27.8365]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9750, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9607, 29.9338],\n",
      "        [31.9258, 26.8416],\n",
      "        [25.2600, 30.1594],\n",
      "        [27.8743, 27.8366]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9750, 0.1059, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9608, 29.9338],\n",
      "        [31.9260, 26.8416],\n",
      "        [25.2602, 30.1594],\n",
      "        [27.8744, 27.8366]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9750, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9608, 29.9339],\n",
      "        [31.9259, 26.8418],\n",
      "        [25.2601, 30.1595],\n",
      "        [27.8744, 27.8366]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9750, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9608, 29.9339],\n",
      "        [31.9260, 26.8418],\n",
      "        [25.2603, 30.1594],\n",
      "        [27.8745, 27.8366]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9750, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9608, 29.9339],\n",
      "        [31.9260, 26.8419],\n",
      "        [25.2602, 30.1595],\n",
      "        [27.8744, 27.8367]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9750, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9609, 29.9339],\n",
      "        [31.9261, 26.8419],\n",
      "        [25.2603, 30.1595],\n",
      "        [27.8745, 27.8367]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9751, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9609, 29.9340],\n",
      "        [31.9260, 26.8421],\n",
      "        [25.2603, 30.1596],\n",
      "        [27.8745, 27.8367]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9751, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9609, 29.9339],\n",
      "        [31.9262, 26.8421],\n",
      "        [25.2604, 30.1595],\n",
      "        [27.8745, 27.8367]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9751, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9609, 29.9340],\n",
      "        [31.9261, 26.8422],\n",
      "        [25.2604, 30.1596],\n",
      "        [27.8745, 27.8368]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9751, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9609, 29.9340],\n",
      "        [31.9263, 26.8422],\n",
      "        [25.2605, 30.1596],\n",
      "        [27.8746, 27.8367]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9751, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9609, 29.9340],\n",
      "        [31.9262, 26.8424],\n",
      "        [25.2605, 30.1597],\n",
      "        [27.8746, 27.8368]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9751, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9610, 29.9340],\n",
      "        [31.9263, 26.8423],\n",
      "        [25.2606, 30.1596],\n",
      "        [27.8746, 27.8368]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9751, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9610, 29.9341],\n",
      "        [31.9263, 26.8425],\n",
      "        [25.2605, 30.1597],\n",
      "        [27.8746, 27.8368]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9751, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9610, 29.9341],\n",
      "        [31.9264, 26.8425],\n",
      "        [25.2606, 30.1597],\n",
      "        [27.8747, 27.8368]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9752, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9610, 29.9341],\n",
      "        [31.9263, 26.8426],\n",
      "        [25.2606, 30.1598],\n",
      "        [27.8746, 27.8369]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9752, 0.1060, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9611, 29.9341],\n",
      "        [31.9265, 26.8426],\n",
      "        [25.2607, 30.1597],\n",
      "        [27.8747, 27.8369]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9752, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9610, 29.9342],\n",
      "        [31.9264, 26.8428],\n",
      "        [25.2607, 30.1598],\n",
      "        [27.8747, 27.8369]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9752, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9611, 29.9342],\n",
      "        [31.9266, 26.8428],\n",
      "        [25.2608, 30.1598],\n",
      "        [27.8748, 27.8369]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9752, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9611, 29.9342],\n",
      "        [31.9265, 26.8429],\n",
      "        [25.2608, 30.1599],\n",
      "        [27.8747, 27.8370]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9752, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9611, 29.9342],\n",
      "        [31.9267, 26.8429],\n",
      "        [25.2609, 30.1598],\n",
      "        [27.8748, 27.8370]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9752, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9611, 29.9343],\n",
      "        [31.9266, 26.8431],\n",
      "        [25.2609, 30.1599],\n",
      "        [27.8748, 27.8370]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9752, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9612, 29.9342],\n",
      "        [31.9267, 26.8430],\n",
      "        [25.2610, 30.1599],\n",
      "        [27.8748, 27.8370]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9753, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9612, 29.9343],\n",
      "        [31.9266, 26.8432],\n",
      "        [25.2609, 30.1600],\n",
      "        [27.8748, 27.8371]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9753, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9612, 29.9343],\n",
      "        [31.9268, 26.8432],\n",
      "        [25.2611, 30.1600],\n",
      "        [27.8749, 27.8371]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9753, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9612, 29.9343],\n",
      "        [31.9267, 26.8433],\n",
      "        [25.2610, 30.1600],\n",
      "        [27.8749, 27.8371]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9753, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9612, 29.9343],\n",
      "        [31.9269, 26.8433],\n",
      "        [25.2611, 30.1600],\n",
      "        [27.8749, 27.8371]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9753, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9612, 29.9344],\n",
      "        [31.9268, 26.8435],\n",
      "        [25.2611, 30.1601],\n",
      "        [27.8749, 27.8372]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9753, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9613, 29.9344],\n",
      "        [31.9270, 26.8435],\n",
      "        [25.2612, 30.1600],\n",
      "        [27.8749, 27.8371]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9753, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9613, 29.9344],\n",
      "        [31.9269, 26.8436],\n",
      "        [25.2612, 30.1601],\n",
      "        [27.8749, 27.8372]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9753, 0.1061, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9613, 29.9344],\n",
      "        [31.9270, 26.8436],\n",
      "        [25.2613, 30.1601],\n",
      "        [27.8750, 27.8372]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9754, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9613, 29.9345],\n",
      "        [31.9269, 26.8437],\n",
      "        [25.2612, 30.1602],\n",
      "        [27.8750, 27.8372]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9754, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9613, 29.9344],\n",
      "        [31.9271, 26.8437],\n",
      "        [25.2614, 30.1601],\n",
      "        [27.8750, 27.8372]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9754, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9613, 29.9345],\n",
      "        [31.9270, 26.8439],\n",
      "        [25.2613, 30.1602],\n",
      "        [27.8750, 27.8373]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9754, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9614, 29.9345],\n",
      "        [31.9272, 26.8439],\n",
      "        [25.2614, 30.1602],\n",
      "        [27.8751, 27.8373]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9754, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9614, 29.9345],\n",
      "        [31.9271, 26.8440],\n",
      "        [25.2614, 30.1603],\n",
      "        [27.8750, 27.8373]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9754, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9614, 29.9345],\n",
      "        [31.9273, 26.8440],\n",
      "        [25.2615, 30.1603],\n",
      "        [27.8751, 27.8373]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9754, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9614, 29.9346],\n",
      "        [31.9272, 26.8442],\n",
      "        [25.2615, 30.1603],\n",
      "        [27.8751, 27.8374]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9754, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9614, 29.9346],\n",
      "        [31.9273, 26.8441],\n",
      "        [25.2616, 30.1603],\n",
      "        [27.8751, 27.8374]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9755, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9614, 29.9346],\n",
      "        [31.9273, 26.8443],\n",
      "        [25.2616, 30.1604],\n",
      "        [27.8751, 27.8374]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9755, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9615, 29.9346],\n",
      "        [31.9274, 26.8443],\n",
      "        [25.2617, 30.1604],\n",
      "        [27.8752, 27.8374]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9755, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9615, 29.9347],\n",
      "        [31.9273, 26.8444],\n",
      "        [25.2616, 30.1604],\n",
      "        [27.8752, 27.8375]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9755, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9615, 29.9347],\n",
      "        [31.9275, 26.8444],\n",
      "        [25.2618, 30.1604],\n",
      "        [27.8752, 27.8375]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9755, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9615, 29.9347],\n",
      "        [31.9274, 26.8446],\n",
      "        [25.2617, 30.1605],\n",
      "        [27.8752, 27.8375]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9755, 0.1062, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9616, 29.9347],\n",
      "        [31.9276, 26.8446],\n",
      "        [25.2619, 30.1605],\n",
      "        [27.8753, 27.8375]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9755, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9615, 29.9348],\n",
      "        [31.9275, 26.8447],\n",
      "        [25.2618, 30.1605],\n",
      "        [27.8752, 27.8376]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9755, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9616, 29.9347],\n",
      "        [31.9276, 26.8447],\n",
      "        [25.2619, 30.1605],\n",
      "        [27.8753, 27.8376]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9980, 0.9756, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9616, 29.9348],\n",
      "        [31.9275, 26.8448],\n",
      "        [25.2619, 30.1606],\n",
      "        [27.8753, 27.8376]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9980, 0.9756, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9616, 29.9348],\n",
      "        [31.9277, 26.8448],\n",
      "        [25.2620, 30.1606],\n",
      "        [27.8754, 27.8376]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9756, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9616, 29.9348],\n",
      "        [31.9276, 26.8450],\n",
      "        [25.2620, 30.1606],\n",
      "        [27.8753, 27.8376]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9756, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9617, 29.9348],\n",
      "        [31.9278, 26.8450],\n",
      "        [25.2621, 30.1606],\n",
      "        [27.8754, 27.8376]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9756, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9616, 29.9349],\n",
      "        [31.9277, 26.8451],\n",
      "        [25.2620, 30.1607],\n",
      "        [27.8754, 27.8377]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9756, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9617, 29.9349],\n",
      "        [31.9279, 26.8451],\n",
      "        [25.2622, 30.1607],\n",
      "        [27.8754, 27.8377]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9757, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9617, 29.9349],\n",
      "        [31.9278, 26.8452],\n",
      "        [25.2621, 30.1607],\n",
      "        [27.8754, 27.8377]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9757, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9617, 29.9349],\n",
      "        [31.9279, 26.8453],\n",
      "        [25.2622, 30.1607],\n",
      "        [27.8755, 27.8377]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9757, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9617, 29.9350],\n",
      "        [31.9278, 26.8454],\n",
      "        [25.2622, 30.1608],\n",
      "        [27.8754, 27.8378]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9757, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9618, 29.9350],\n",
      "        [31.9280, 26.8454],\n",
      "        [25.2623, 30.1608],\n",
      "        [27.8755, 27.8378]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9757, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9618, 29.9350],\n",
      "        [31.9279, 26.8455],\n",
      "        [25.2623, 30.1608],\n",
      "        [27.8755, 27.8378]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9757, 0.1063, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9618, 29.9350],\n",
      "        [31.9281, 26.8455],\n",
      "        [25.2624, 30.1608],\n",
      "        [27.8755, 27.8378]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9757, 0.1064, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9618, 29.9351],\n",
      "        [31.9280, 26.8457],\n",
      "        [25.2624, 30.1609],\n",
      "        [27.8755, 27.8379]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9757, 0.1064, 0.9615], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9618, 29.9350],\n",
      "        [31.9282, 26.8456],\n",
      "        [25.2625, 30.1609],\n",
      "        [27.8756, 27.8379]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9758, 0.1064, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9618, 29.9351],\n",
      "        [31.9281, 26.8458],\n",
      "        [25.2624, 30.1609],\n",
      "        [27.8756, 27.8379]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9758, 0.1064, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9619, 29.9351],\n",
      "        [31.9282, 26.8458],\n",
      "        [25.2626, 30.1609],\n",
      "        [27.8756, 27.8379]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9758, 0.1064, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9619, 29.9351],\n",
      "        [31.9281, 26.8459],\n",
      "        [25.2625, 30.1610],\n",
      "        [27.8756, 27.8380]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9758, 0.1064, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9619, 29.9351],\n",
      "        [31.9283, 26.8459],\n",
      "        [25.2626, 30.1610],\n",
      "        [27.8757, 27.8379]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9758, 0.1064, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9619, 29.9352],\n",
      "        [31.9282, 26.8461],\n",
      "        [25.2626, 30.1610],\n",
      "        [27.8756, 27.8380]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9758, 0.1064, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9619, 29.9352],\n",
      "        [31.9284, 26.8461],\n",
      "        [25.2627, 30.1610],\n",
      "        [27.8757, 27.8380]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9758, 0.1064, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9619, 29.9352],\n",
      "        [31.9283, 26.8462],\n",
      "        [25.2627, 30.1611],\n",
      "        [27.8757, 27.8380]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9758, 0.1064, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9620, 29.9352],\n",
      "        [31.9285, 26.8462],\n",
      "        [25.2628, 30.1611],\n",
      "        [27.8757, 27.8380]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9758, 0.1064, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9619, 29.9352],\n",
      "        [31.9284, 26.8463],\n",
      "        [25.2627, 30.1611],\n",
      "        [27.8757, 27.8381]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9758, 0.1064, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9620, 29.9352],\n",
      "        [31.9285, 26.8463],\n",
      "        [25.2629, 30.1611],\n",
      "        [27.8758, 27.8381]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9759, 0.1064, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9620, 29.9353],\n",
      "        [31.9284, 26.8465],\n",
      "        [25.2628, 30.1612],\n",
      "        [27.8757, 27.8381]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9759, 0.1064, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9620, 29.9353],\n",
      "        [31.9286, 26.8464],\n",
      "        [25.2629, 30.1612],\n",
      "        [27.8758, 27.8381]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9759, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9620, 29.9353],\n",
      "        [31.9285, 26.8466],\n",
      "        [25.2629, 30.1612],\n",
      "        [27.8758, 27.8382]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9759, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9621, 29.9353],\n",
      "        [31.9287, 26.8466],\n",
      "        [25.2630, 30.1612],\n",
      "        [27.8759, 27.8382]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9759, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9621, 29.9354],\n",
      "        [31.9286, 26.8467],\n",
      "        [25.2630, 30.1613],\n",
      "        [27.8758, 27.8382]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9759, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9621, 29.9354],\n",
      "        [31.9288, 26.8467],\n",
      "        [25.2631, 30.1613],\n",
      "        [27.8759, 27.8382]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9759, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9621, 29.9354],\n",
      "        [31.9287, 26.8469],\n",
      "        [25.2631, 30.1613],\n",
      "        [27.8759, 27.8383]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9759, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9622, 29.9354],\n",
      "        [31.9288, 26.8469],\n",
      "        [25.2632, 30.1613],\n",
      "        [27.8759, 27.8383]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9760, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9621, 29.9355],\n",
      "        [31.9287, 26.8470],\n",
      "        [25.2631, 30.1614],\n",
      "        [27.8759, 27.8383]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9760, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9622, 29.9355],\n",
      "        [31.9289, 26.8470],\n",
      "        [25.2633, 30.1614],\n",
      "        [27.8760, 27.8383]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9760, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9622, 29.9355],\n",
      "        [31.9288, 26.8471],\n",
      "        [25.2632, 30.1614],\n",
      "        [27.8759, 27.8384]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9760, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9622, 29.9355],\n",
      "        [31.9290, 26.8471],\n",
      "        [25.2633, 30.1614],\n",
      "        [27.8760, 27.8384]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9760, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9622, 29.9355],\n",
      "        [31.9289, 26.8473],\n",
      "        [25.2633, 30.1615],\n",
      "        [27.8760, 27.8384]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9760, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9622, 29.9355],\n",
      "        [31.9290, 26.8472],\n",
      "        [25.2634, 30.1615],\n",
      "        [27.8760, 27.8384]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9760, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9622, 29.9356],\n",
      "        [31.9289, 26.8474],\n",
      "        [25.2634, 30.1615],\n",
      "        [27.8760, 27.8384]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9760, 0.1065, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9623, 29.9356],\n",
      "        [31.9291, 26.8474],\n",
      "        [25.2635, 30.1615],\n",
      "        [27.8761, 27.8384]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9761, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9622, 29.9356],\n",
      "        [31.9290, 26.8475],\n",
      "        [25.2634, 30.1616],\n",
      "        [27.8761, 27.8385]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9761, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9623, 29.9356],\n",
      "        [31.9292, 26.8475],\n",
      "        [25.2636, 30.1616],\n",
      "        [27.8761, 27.8385]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9761, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9623, 29.9357],\n",
      "        [31.9291, 26.8476],\n",
      "        [25.2635, 30.1616],\n",
      "        [27.8761, 27.8385]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9761, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9623, 29.9357],\n",
      "        [31.9292, 26.8476],\n",
      "        [25.2636, 30.1616],\n",
      "        [27.8762, 27.8385]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9761, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9623, 29.9357],\n",
      "        [31.9292, 26.8478],\n",
      "        [25.2636, 30.1617],\n",
      "        [27.8761, 27.8386]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9761, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9624, 29.9357],\n",
      "        [31.9293, 26.8478],\n",
      "        [25.2637, 30.1617],\n",
      "        [27.8762, 27.8386]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9761, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9623, 29.9357],\n",
      "        [31.9292, 26.8479],\n",
      "        [25.2637, 30.1617],\n",
      "        [27.8762, 27.8386]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9761, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9624, 29.9357],\n",
      "        [31.9294, 26.8479],\n",
      "        [25.2638, 30.1617],\n",
      "        [27.8762, 27.8386]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9762, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9624, 29.9358],\n",
      "        [31.9293, 26.8480],\n",
      "        [25.2638, 30.1618],\n",
      "        [27.8762, 27.8387]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9762, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9624, 29.9358],\n",
      "        [31.9295, 26.8480],\n",
      "        [25.2639, 30.1618],\n",
      "        [27.8763, 27.8386]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9762, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9624, 29.9358],\n",
      "        [31.9294, 26.8482],\n",
      "        [25.2638, 30.1618],\n",
      "        [27.8763, 27.8387]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9762, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9625, 29.9358],\n",
      "        [31.9295, 26.8482],\n",
      "        [25.2640, 30.1618],\n",
      "        [27.8763, 27.8387]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9762, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9625, 29.9359],\n",
      "        [31.9294, 26.8483],\n",
      "        [25.2639, 30.1619],\n",
      "        [27.8763, 27.8387]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9762, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9625, 29.9359],\n",
      "        [31.9296, 26.8483],\n",
      "        [25.2640, 30.1619],\n",
      "        [27.8764, 27.8387]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9762, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9625, 29.9359],\n",
      "        [31.9295, 26.8484],\n",
      "        [25.2640, 30.1619],\n",
      "        [27.8763, 27.8388]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9762, 0.1066, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9625, 29.9359],\n",
      "        [31.9297, 26.8484],\n",
      "        [25.2641, 30.1619],\n",
      "        [27.8764, 27.8388]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9763, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9625, 29.9359],\n",
      "        [31.9296, 26.8486],\n",
      "        [25.2640, 30.1620],\n",
      "        [27.8764, 27.8388]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9763, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9626, 29.9359],\n",
      "        [31.9297, 26.8485],\n",
      "        [25.2642, 30.1619],\n",
      "        [27.8764, 27.8388]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9763, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9625, 29.9360],\n",
      "        [31.9296, 26.8487],\n",
      "        [25.2641, 30.1620],\n",
      "        [27.8764, 27.8389]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9763, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9626, 29.9360],\n",
      "        [31.9298, 26.8487],\n",
      "        [25.2642, 30.1620],\n",
      "        [27.8765, 27.8389]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9763, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9626, 29.9360],\n",
      "        [31.9297, 26.8488],\n",
      "        [25.2642, 30.1621],\n",
      "        [27.8764, 27.8389]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9763, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9626, 29.9360],\n",
      "        [31.9299, 26.8488],\n",
      "        [25.2643, 30.1620],\n",
      "        [27.8765, 27.8389]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9763, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9626, 29.9361],\n",
      "        [31.9298, 26.8490],\n",
      "        [25.2643, 30.1621],\n",
      "        [27.8765, 27.8390]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9763, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9627, 29.9360],\n",
      "        [31.9299, 26.8489],\n",
      "        [25.2644, 30.1621],\n",
      "        [27.8765, 27.8389]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9764, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9627, 29.9361],\n",
      "        [31.9299, 26.8491],\n",
      "        [25.2643, 30.1622],\n",
      "        [27.8765, 27.8390]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9764, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9627, 29.9361],\n",
      "        [31.9300, 26.8491],\n",
      "        [25.2645, 30.1622],\n",
      "        [27.8766, 27.8390]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9764, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9627, 29.9361],\n",
      "        [31.9299, 26.8492],\n",
      "        [25.2644, 30.1622],\n",
      "        [27.8765, 27.8390]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9764, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9627, 29.9361],\n",
      "        [31.9301, 26.8492],\n",
      "        [25.2646, 30.1622],\n",
      "        [27.8766, 27.8390]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9764, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9627, 29.9362],\n",
      "        [31.9300, 26.8493],\n",
      "        [25.2645, 30.1623],\n",
      "        [27.8766, 27.8391]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9764, 0.1067, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9628, 29.9362],\n",
      "        [31.9302, 26.8493],\n",
      "        [25.2646, 30.1622],\n",
      "        [27.8767, 27.8391]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9764, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9628, 29.9362],\n",
      "        [31.9301, 26.8495],\n",
      "        [25.2646, 30.1623],\n",
      "        [27.8766, 27.8391]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9764, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9628, 29.9362],\n",
      "        [31.9302, 26.8494],\n",
      "        [25.2647, 30.1623],\n",
      "        [27.8767, 27.8391]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9765, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9628, 29.9363],\n",
      "        [31.9302, 26.8496],\n",
      "        [25.2647, 30.1624],\n",
      "        [27.8767, 27.8392]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9765, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9629, 29.9363],\n",
      "        [31.9303, 26.8496],\n",
      "        [25.2648, 30.1623],\n",
      "        [27.8767, 27.8392]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9765, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9628, 29.9363],\n",
      "        [31.9302, 26.8497],\n",
      "        [25.2647, 30.1624],\n",
      "        [27.8767, 27.8392]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9765, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9629, 29.9363],\n",
      "        [31.9304, 26.8497],\n",
      "        [25.2648, 30.1624],\n",
      "        [27.8768, 27.8392]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9765, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9628, 29.9363],\n",
      "        [31.9303, 26.8498],\n",
      "        [25.2648, 30.1625],\n",
      "        [27.8767, 27.8392]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9765, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9629, 29.9363],\n",
      "        [31.9304, 26.8498],\n",
      "        [25.2649, 30.1624],\n",
      "        [27.8768, 27.8392]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9765, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9629, 29.9364],\n",
      "        [31.9304, 26.8500],\n",
      "        [25.2649, 30.1625],\n",
      "        [27.8768, 27.8393]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9765, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9629, 29.9364],\n",
      "        [31.9305, 26.8500],\n",
      "        [25.2650, 30.1625],\n",
      "        [27.8768, 27.8393]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9765, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9629, 29.9364],\n",
      "        [31.9304, 26.8501],\n",
      "        [25.2650, 30.1625],\n",
      "        [27.8768, 27.8393]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9765, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9630, 29.9364],\n",
      "        [31.9306, 26.8501],\n",
      "        [25.2651, 30.1625],\n",
      "        [27.8769, 27.8393]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9766, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9629, 29.9365],\n",
      "        [31.9305, 26.8502],\n",
      "        [25.2650, 30.1626],\n",
      "        [27.8769, 27.8394]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9766, 0.1068, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9630, 29.9364],\n",
      "        [31.9306, 26.8502],\n",
      "        [25.2652, 30.1626],\n",
      "        [27.8769, 27.8394]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9766, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9630, 29.9365],\n",
      "        [31.9306, 26.8503],\n",
      "        [25.2651, 30.1626],\n",
      "        [27.8769, 27.8394]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9766, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9630, 29.9365],\n",
      "        [31.9307, 26.8503],\n",
      "        [25.2652, 30.1626],\n",
      "        [27.8770, 27.8394]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9766, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9630, 29.9365],\n",
      "        [31.9306, 26.8505],\n",
      "        [25.2652, 30.1627],\n",
      "        [27.8769, 27.8395]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9766, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9631, 29.9365],\n",
      "        [31.9308, 26.8505],\n",
      "        [25.2653, 30.1627],\n",
      "        [27.8770, 27.8395]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9766, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9631, 29.9366],\n",
      "        [31.9307, 26.8506],\n",
      "        [25.2653, 30.1628],\n",
      "        [27.8770, 27.8395]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9766, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9631, 29.9366],\n",
      "        [31.9309, 26.8506],\n",
      "        [25.2654, 30.1627],\n",
      "        [27.8770, 27.8395]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9767, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9631, 29.9366],\n",
      "        [31.9308, 26.8507],\n",
      "        [25.2653, 30.1628],\n",
      "        [27.8770, 27.8395]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9767, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9632, 29.9366],\n",
      "        [31.9309, 26.8507],\n",
      "        [25.2655, 30.1628],\n",
      "        [27.8771, 27.8395]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9767, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9631, 29.9367],\n",
      "        [31.9308, 26.8509],\n",
      "        [25.2654, 30.1628],\n",
      "        [27.8770, 27.8396]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9767, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9632, 29.9367],\n",
      "        [31.9310, 26.8508],\n",
      "        [25.2655, 30.1628],\n",
      "        [27.8771, 27.8396]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9767, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9632, 29.9367],\n",
      "        [31.9309, 26.8510],\n",
      "        [25.2655, 30.1629],\n",
      "        [27.8771, 27.8396]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9767, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9632, 29.9367],\n",
      "        [31.9311, 26.8510],\n",
      "        [25.2656, 30.1629],\n",
      "        [27.8771, 27.8396]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9767, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9632, 29.9367],\n",
      "        [31.9310, 26.8511],\n",
      "        [25.2656, 30.1629],\n",
      "        [27.8771, 27.8396]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9767, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9632, 29.9367],\n",
      "        [31.9311, 26.8511],\n",
      "        [25.2657, 30.1629],\n",
      "        [27.8772, 27.8396]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9768, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9632, 29.9368],\n",
      "        [31.9310, 26.8512],\n",
      "        [25.2656, 30.1630],\n",
      "        [27.8771, 27.8397]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9768, 0.1069, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9633, 29.9367],\n",
      "        [31.9312, 26.8512],\n",
      "        [25.2657, 30.1630],\n",
      "        [27.8772, 27.8397]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9768, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9632, 29.9368],\n",
      "        [31.9311, 26.8513],\n",
      "        [25.2657, 30.1630],\n",
      "        [27.8772, 27.8397]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9768, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9633, 29.9368],\n",
      "        [31.9313, 26.8513],\n",
      "        [25.2658, 30.1630],\n",
      "        [27.8772, 27.8397]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9768, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9633, 29.9368],\n",
      "        [31.9312, 26.8515],\n",
      "        [25.2658, 30.1631],\n",
      "        [27.8772, 27.8398]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9768, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9633, 29.9368],\n",
      "        [31.9313, 26.8515],\n",
      "        [25.2659, 30.1631],\n",
      "        [27.8773, 27.8398]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9768, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9633, 29.9369],\n",
      "        [31.9312, 26.8516],\n",
      "        [25.2659, 30.1631],\n",
      "        [27.8772, 27.8398]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9768, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9634, 29.9369],\n",
      "        [31.9314, 26.8516],\n",
      "        [25.2660, 30.1631],\n",
      "        [27.8773, 27.8398]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9768, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9633, 29.9369],\n",
      "        [31.9313, 26.8517],\n",
      "        [25.2659, 30.1632],\n",
      "        [27.8773, 27.8399]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9768, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9634, 29.9369],\n",
      "        [31.9315, 26.8517],\n",
      "        [25.2661, 30.1632],\n",
      "        [27.8774, 27.8399]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9769, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9634, 29.9370],\n",
      "        [31.9314, 26.8518],\n",
      "        [25.2660, 30.1632],\n",
      "        [27.8773, 27.8399]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9769, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9634, 29.9370],\n",
      "        [31.9315, 26.8518],\n",
      "        [25.2661, 30.1632],\n",
      "        [27.8774, 27.8399]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9769, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9634, 29.9370],\n",
      "        [31.9314, 26.8520],\n",
      "        [25.2661, 30.1633],\n",
      "        [27.8774, 27.8400]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9769, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9635, 29.9370],\n",
      "        [31.9316, 26.8520],\n",
      "        [25.2662, 30.1632],\n",
      "        [27.8774, 27.8400]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9769, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9634, 29.9370],\n",
      "        [31.9315, 26.8521],\n",
      "        [25.2662, 30.1633],\n",
      "        [27.8774, 27.8400]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9769, 0.1070, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9635, 29.9370],\n",
      "        [31.9317, 26.8521],\n",
      "        [25.2663, 30.1633],\n",
      "        [27.8775, 27.8400]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9769, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9635, 29.9371],\n",
      "        [31.9316, 26.8522],\n",
      "        [25.2662, 30.1634],\n",
      "        [27.8774, 27.8400]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9769, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9635, 29.9371],\n",
      "        [31.9317, 26.8522],\n",
      "        [25.2663, 30.1633],\n",
      "        [27.8775, 27.8400]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9770, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9635, 29.9371],\n",
      "        [31.9316, 26.8523],\n",
      "        [25.2663, 30.1634],\n",
      "        [27.8775, 27.8401]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9770, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9635, 29.9371],\n",
      "        [31.9318, 26.8523],\n",
      "        [25.2664, 30.1634],\n",
      "        [27.8775, 27.8401]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9770, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9635, 29.9372],\n",
      "        [31.9317, 26.8525],\n",
      "        [25.2664, 30.1634],\n",
      "        [27.8775, 27.8401]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9770, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9636, 29.9372],\n",
      "        [31.9319, 26.8525],\n",
      "        [25.2665, 30.1634],\n",
      "        [27.8776, 27.8401]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9770, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9636, 29.9372],\n",
      "        [31.9318, 26.8526],\n",
      "        [25.2665, 30.1635],\n",
      "        [27.8775, 27.8401]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9770, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9636, 29.9372],\n",
      "        [31.9319, 26.8526],\n",
      "        [25.2666, 30.1635],\n",
      "        [27.8776, 27.8401]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9770, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9636, 29.9372],\n",
      "        [31.9319, 26.8527],\n",
      "        [25.2665, 30.1635],\n",
      "        [27.8776, 27.8402]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9770, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9636, 29.9372],\n",
      "        [31.9320, 26.8527],\n",
      "        [25.2666, 30.1635],\n",
      "        [27.8776, 27.8402]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9770, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9636, 29.9373],\n",
      "        [31.9319, 26.8528],\n",
      "        [25.2666, 30.1636],\n",
      "        [27.8776, 27.8402]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9770, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9637, 29.9373],\n",
      "        [31.9321, 26.8528],\n",
      "        [25.2667, 30.1636],\n",
      "        [27.8777, 27.8402]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9771, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9636, 29.9373],\n",
      "        [31.9320, 26.8529],\n",
      "        [25.2667, 30.1636],\n",
      "        [27.8776, 27.8403]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9771, 0.1071, 0.9616], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9637, 29.9373],\n",
      "        [31.9321, 26.8529],\n",
      "        [25.2668, 30.1636],\n",
      "        [27.8777, 27.8403]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9771, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9637, 29.9374],\n",
      "        [31.9321, 26.8531],\n",
      "        [25.2668, 30.1637],\n",
      "        [27.8777, 27.8403]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9771, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9638, 29.9374],\n",
      "        [31.9322, 26.8531],\n",
      "        [25.2669, 30.1637],\n",
      "        [27.8778, 27.8403]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9771, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9637, 29.9374],\n",
      "        [31.9321, 26.8532],\n",
      "        [25.2668, 30.1637],\n",
      "        [27.8777, 27.8404]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9771, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9638, 29.9374],\n",
      "        [31.9323, 26.8532],\n",
      "        [25.2669, 30.1637],\n",
      "        [27.8778, 27.8404]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9771, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9637, 29.9374],\n",
      "        [31.9322, 26.8533],\n",
      "        [25.2669, 30.1638],\n",
      "        [27.8778, 27.8404]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9771, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9638, 29.9374],\n",
      "        [31.9323, 26.8533],\n",
      "        [25.2670, 30.1638],\n",
      "        [27.8778, 27.8404]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9772, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9638, 29.9375],\n",
      "        [31.9323, 26.8534],\n",
      "        [25.2670, 30.1638],\n",
      "        [27.8778, 27.8404]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9772, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9638, 29.9375],\n",
      "        [31.9324, 26.8534],\n",
      "        [25.2671, 30.1638],\n",
      "        [27.8779, 27.8404]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9772, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9638, 29.9375],\n",
      "        [31.9323, 26.8535],\n",
      "        [25.2670, 30.1639],\n",
      "        [27.8778, 27.8405]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9772, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9639, 29.9375],\n",
      "        [31.9325, 26.8535],\n",
      "        [25.2672, 30.1638],\n",
      "        [27.8779, 27.8405]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9772, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9638, 29.9375],\n",
      "        [31.9324, 26.8537],\n",
      "        [25.2671, 30.1639],\n",
      "        [27.8778, 27.8405]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9772, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9639, 29.9375],\n",
      "        [31.9325, 26.8537],\n",
      "        [25.2672, 30.1639],\n",
      "        [27.8779, 27.8405]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9772, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9639, 29.9376],\n",
      "        [31.9324, 26.8538],\n",
      "        [25.2672, 30.1640],\n",
      "        [27.8779, 27.8406]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9772, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9639, 29.9376],\n",
      "        [31.9326, 26.8538],\n",
      "        [25.2673, 30.1639],\n",
      "        [27.8780, 27.8406]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9772, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9639, 29.9376],\n",
      "        [31.9325, 26.8539],\n",
      "        [25.2673, 30.1640],\n",
      "        [27.8779, 27.8406]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9772, 0.1072, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9640, 29.9376],\n",
      "        [31.9326, 26.8539],\n",
      "        [25.2674, 30.1640],\n",
      "        [27.8780, 27.8406]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9773, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9639, 29.9377],\n",
      "        [31.9326, 26.8540],\n",
      "        [25.2673, 30.1640],\n",
      "        [27.8780, 27.8406]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9773, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9640, 29.9377],\n",
      "        [31.9327, 26.8540],\n",
      "        [25.2675, 30.1640],\n",
      "        [27.8780, 27.8406]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9773, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9640, 29.9377],\n",
      "        [31.9326, 26.8542],\n",
      "        [25.2674, 30.1641],\n",
      "        [27.8780, 27.8407]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9773, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9640, 29.9377],\n",
      "        [31.9328, 26.8541],\n",
      "        [25.2675, 30.1641],\n",
      "        [27.8781, 27.8407]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9981, 0.9773, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9640, 29.9377],\n",
      "        [31.9327, 26.8543],\n",
      "        [25.2675, 30.1641],\n",
      "        [27.8780, 27.8407]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9981, 0.9773, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9641, 29.9377],\n",
      "        [31.9329, 26.8543],\n",
      "        [25.2676, 30.1641],\n",
      "        [27.8781, 27.8407]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9773, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9640, 29.9378],\n",
      "        [31.9328, 26.8544],\n",
      "        [25.2676, 30.1642],\n",
      "        [27.8781, 27.8408]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9773, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9641, 29.9378],\n",
      "        [31.9329, 26.8544],\n",
      "        [25.2677, 30.1642],\n",
      "        [27.8781, 27.8408]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9774, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9641, 29.9378],\n",
      "        [31.9328, 26.8545],\n",
      "        [25.2676, 30.1642],\n",
      "        [27.8781, 27.8408]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9774, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9641, 29.9378],\n",
      "        [31.9330, 26.8545],\n",
      "        [25.2677, 30.1642],\n",
      "        [27.8782, 27.8408]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9774, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9641, 29.9378],\n",
      "        [31.9329, 26.8546],\n",
      "        [25.2677, 30.1643],\n",
      "        [27.8782, 27.8408]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9774, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9642, 29.9378],\n",
      "        [31.9331, 26.8546],\n",
      "        [25.2678, 30.1643],\n",
      "        [27.8782, 27.8409]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9774, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9641, 29.9379],\n",
      "        [31.9330, 26.8547],\n",
      "        [25.2678, 30.1643],\n",
      "        [27.8782, 27.8409]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9774, 0.1073, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9642, 29.9379],\n",
      "        [31.9331, 26.8547],\n",
      "        [25.2679, 30.1643],\n",
      "        [27.8782, 27.8409]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9774, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9641, 29.9379],\n",
      "        [31.9330, 26.8549],\n",
      "        [25.2678, 30.1644],\n",
      "        [27.8782, 27.8409]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9774, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9642, 29.9379],\n",
      "        [31.9332, 26.8549],\n",
      "        [25.2680, 30.1644],\n",
      "        [27.8783, 27.8409]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9774, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9642, 29.9379],\n",
      "        [31.9331, 26.8550],\n",
      "        [25.2679, 30.1644],\n",
      "        [27.8782, 27.8410]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9774, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9642, 29.9379],\n",
      "        [31.9332, 26.8550],\n",
      "        [25.2680, 30.1644],\n",
      "        [27.8783, 27.8409]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9775, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9642, 29.9380],\n",
      "        [31.9331, 26.8551],\n",
      "        [25.2680, 30.1645],\n",
      "        [27.8783, 27.8410]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9775, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9643, 29.9380],\n",
      "        [31.9333, 26.8551],\n",
      "        [25.2681, 30.1644],\n",
      "        [27.8784, 27.8410]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9775, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9642, 29.9380],\n",
      "        [31.9332, 26.8552],\n",
      "        [25.2681, 30.1645],\n",
      "        [27.8783, 27.8410]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9775, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9643, 29.9380],\n",
      "        [31.9334, 26.8552],\n",
      "        [25.2682, 30.1645],\n",
      "        [27.8784, 27.8410]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9775, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9643, 29.9381],\n",
      "        [31.9333, 26.8553],\n",
      "        [25.2681, 30.1645],\n",
      "        [27.8784, 27.8411]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9775, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9643, 29.9381],\n",
      "        [31.9334, 26.8553],\n",
      "        [25.2682, 30.1645],\n",
      "        [27.8784, 27.8411]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9775, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9643, 29.9381],\n",
      "        [31.9334, 26.8555],\n",
      "        [25.2682, 30.1646],\n",
      "        [27.8784, 27.8411]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9775, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9643, 29.9381],\n",
      "        [31.9335, 26.8554],\n",
      "        [25.2683, 30.1646],\n",
      "        [27.8785, 27.8411]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9776, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9643, 29.9381],\n",
      "        [31.9334, 26.8556],\n",
      "        [25.2683, 30.1646],\n",
      "        [27.8784, 27.8412]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9776, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9644, 29.9381],\n",
      "        [31.9335, 26.8556],\n",
      "        [25.2684, 30.1646],\n",
      "        [27.8785, 27.8412]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9776, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9644, 29.9382],\n",
      "        [31.9335, 26.8557],\n",
      "        [25.2684, 30.1647],\n",
      "        [27.8785, 27.8412]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9776, 0.1074, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9644, 29.9382],\n",
      "        [31.9336, 26.8557],\n",
      "        [25.2685, 30.1647],\n",
      "        [27.8785, 27.8412]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9776, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9644, 29.9382],\n",
      "        [31.9335, 26.8558],\n",
      "        [25.2684, 30.1647],\n",
      "        [27.8785, 27.8412]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9776, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9644, 29.9382],\n",
      "        [31.9337, 26.8558],\n",
      "        [25.2685, 30.1647],\n",
      "        [27.8786, 27.8412]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9776, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9644, 29.9383],\n",
      "        [31.9336, 26.8559],\n",
      "        [25.2685, 30.1648],\n",
      "        [27.8785, 27.8413]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9776, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9645, 29.9383],\n",
      "        [31.9337, 26.8559],\n",
      "        [25.2686, 30.1648],\n",
      "        [27.8786, 27.8413]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9776, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9645, 29.9383],\n",
      "        [31.9337, 26.8560],\n",
      "        [25.2686, 30.1648],\n",
      "        [27.8786, 27.8413]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9776, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9645, 29.9383],\n",
      "        [31.9338, 26.8560],\n",
      "        [25.2687, 30.1648],\n",
      "        [27.8786, 27.8413]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9777, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9645, 29.9383],\n",
      "        [31.9337, 26.8561],\n",
      "        [25.2686, 30.1649],\n",
      "        [27.8786, 27.8413]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9777, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9645, 29.9383],\n",
      "        [31.9339, 26.8561],\n",
      "        [25.2687, 30.1648],\n",
      "        [27.8787, 27.8413]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9777, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9645, 29.9384],\n",
      "        [31.9338, 26.8563],\n",
      "        [25.2687, 30.1649],\n",
      "        [27.8786, 27.8414]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9777, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9646, 29.9384],\n",
      "        [31.9339, 26.8563],\n",
      "        [25.2688, 30.1649],\n",
      "        [27.8787, 27.8414]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9777, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9645, 29.9384],\n",
      "        [31.9339, 26.8564],\n",
      "        [25.2688, 30.1650],\n",
      "        [27.8787, 27.8414]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9777, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9646, 29.9384],\n",
      "        [31.9340, 26.8564],\n",
      "        [25.2689, 30.1649],\n",
      "        [27.8787, 27.8414]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9777, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9646, 29.9384],\n",
      "        [31.9339, 26.8565],\n",
      "        [25.2688, 30.1650],\n",
      "        [27.8787, 27.8415]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9777, 0.1075, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9646, 29.9384],\n",
      "        [31.9341, 26.8565],\n",
      "        [25.2690, 30.1650],\n",
      "        [27.8788, 27.8415]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9777, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9646, 29.9385],\n",
      "        [31.9340, 26.8566],\n",
      "        [25.2689, 30.1651],\n",
      "        [27.8787, 27.8415]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9777, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9647, 29.9385],\n",
      "        [31.9341, 26.8566],\n",
      "        [25.2690, 30.1650],\n",
      "        [27.8788, 27.8415]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9778, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9646, 29.9385],\n",
      "        [31.9340, 26.8567],\n",
      "        [25.2690, 30.1651],\n",
      "        [27.8788, 27.8416]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9778, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9647, 29.9385],\n",
      "        [31.9342, 26.8567],\n",
      "        [25.2691, 30.1651],\n",
      "        [27.8788, 27.8415]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9778, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9647, 29.9386],\n",
      "        [31.9341, 26.8568],\n",
      "        [25.2691, 30.1651],\n",
      "        [27.8788, 27.8416]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9778, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9647, 29.9385],\n",
      "        [31.9342, 26.8568],\n",
      "        [25.2692, 30.1651],\n",
      "        [27.8789, 27.8416]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9778, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9647, 29.9386],\n",
      "        [31.9342, 26.8570],\n",
      "        [25.2691, 30.1652],\n",
      "        [27.8788, 27.8416]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9778, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9648, 29.9386],\n",
      "        [31.9343, 26.8570],\n",
      "        [25.2693, 30.1652],\n",
      "        [27.8789, 27.8416]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9778, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9647, 29.9386],\n",
      "        [31.9342, 26.8571],\n",
      "        [25.2692, 30.1652],\n",
      "        [27.8789, 27.8417]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9778, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9648, 29.9386],\n",
      "        [31.9344, 26.8571],\n",
      "        [25.2693, 30.1652],\n",
      "        [27.8789, 27.8417]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9778, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9648, 29.9387],\n",
      "        [31.9343, 26.8572],\n",
      "        [25.2693, 30.1653],\n",
      "        [27.8789, 27.8417]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9778, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9648, 29.9387],\n",
      "        [31.9344, 26.8572],\n",
      "        [25.2694, 30.1653],\n",
      "        [27.8790, 27.8417]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9779, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9648, 29.9387],\n",
      "        [31.9344, 26.8573],\n",
      "        [25.2694, 30.1653],\n",
      "        [27.8789, 27.8417]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9779, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9648, 29.9387],\n",
      "        [31.9345, 26.8573],\n",
      "        [25.2695, 30.1653],\n",
      "        [27.8790, 27.8417]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9779, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9648, 29.9387],\n",
      "        [31.9344, 26.8574],\n",
      "        [25.2694, 30.1653],\n",
      "        [27.8790, 27.8418]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9779, 0.1076, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9649, 29.9387],\n",
      "        [31.9346, 26.8574],\n",
      "        [25.2695, 30.1653],\n",
      "        [27.8790, 27.8418]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9779, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9648, 29.9388],\n",
      "        [31.9345, 26.8575],\n",
      "        [25.2695, 30.1654],\n",
      "        [27.8790, 27.8418]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9779, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9649, 29.9388],\n",
      "        [31.9346, 26.8575],\n",
      "        [25.2696, 30.1654],\n",
      "        [27.8791, 27.8418]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9779, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9649, 29.9388],\n",
      "        [31.9345, 26.8576],\n",
      "        [25.2696, 30.1654],\n",
      "        [27.8790, 27.8419]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9779, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9649, 29.9388],\n",
      "        [31.9347, 26.8576],\n",
      "        [25.2697, 30.1654],\n",
      "        [27.8791, 27.8419]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9780, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9649, 29.9388],\n",
      "        [31.9346, 26.8578],\n",
      "        [25.2696, 30.1655],\n",
      "        [27.8791, 27.8419]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9780, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9650, 29.9388],\n",
      "        [31.9347, 26.8577],\n",
      "        [25.2697, 30.1655],\n",
      "        [27.8791, 27.8419]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9780, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9649, 29.9389],\n",
      "        [31.9347, 26.8579],\n",
      "        [25.2697, 30.1655],\n",
      "        [27.8791, 27.8419]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9780, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9650, 29.9389],\n",
      "        [31.9348, 26.8579],\n",
      "        [25.2698, 30.1655],\n",
      "        [27.8792, 27.8419]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9780, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9650, 29.9389],\n",
      "        [31.9347, 26.8580],\n",
      "        [25.2698, 30.1656],\n",
      "        [27.8792, 27.8420]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9780, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9650, 29.9389],\n",
      "        [31.9349, 26.8580],\n",
      "        [25.2699, 30.1656],\n",
      "        [27.8792, 27.8420]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9780, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9650, 29.9390],\n",
      "        [31.9348, 26.8581],\n",
      "        [25.2698, 30.1656],\n",
      "        [27.8792, 27.8420]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9780, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9650, 29.9390],\n",
      "        [31.9349, 26.8581],\n",
      "        [25.2700, 30.1656],\n",
      "        [27.8792, 27.8420]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9780, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9650, 29.9390],\n",
      "        [31.9348, 26.8582],\n",
      "        [25.2699, 30.1657],\n",
      "        [27.8792, 27.8421]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9780, 0.1077, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9651, 29.9390],\n",
      "        [31.9350, 26.8582],\n",
      "        [25.2700, 30.1656],\n",
      "        [27.8793, 27.8421]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9781, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9650, 29.9390],\n",
      "        [31.9349, 26.8583],\n",
      "        [25.2700, 30.1657],\n",
      "        [27.8792, 27.8421]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9781, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9651, 29.9390],\n",
      "        [31.9350, 26.8583],\n",
      "        [25.2701, 30.1657],\n",
      "        [27.8793, 27.8421]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9781, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9651, 29.9391],\n",
      "        [31.9350, 26.8584],\n",
      "        [25.2701, 30.1658],\n",
      "        [27.8793, 27.8421]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9781, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9651, 29.9391],\n",
      "        [31.9351, 26.8584],\n",
      "        [25.2702, 30.1657],\n",
      "        [27.8794, 27.8421]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9781, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9651, 29.9391],\n",
      "        [31.9350, 26.8586],\n",
      "        [25.2701, 30.1658],\n",
      "        [27.8793, 27.8422]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9781, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9652, 29.9391],\n",
      "        [31.9352, 26.8585],\n",
      "        [25.2702, 30.1658],\n",
      "        [27.8794, 27.8422]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9781, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9651, 29.9391],\n",
      "        [31.9351, 26.8586],\n",
      "        [25.2702, 30.1658],\n",
      "        [27.8793, 27.8422]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9781, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9652, 29.9391],\n",
      "        [31.9352, 26.8586],\n",
      "        [25.2703, 30.1658],\n",
      "        [27.8794, 27.8422]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9781, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9651, 29.9392],\n",
      "        [31.9351, 26.8588],\n",
      "        [25.2703, 30.1659],\n",
      "        [27.8794, 27.8422]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9781, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9652, 29.9392],\n",
      "        [31.9353, 26.8588],\n",
      "        [25.2704, 30.1659],\n",
      "        [27.8794, 27.8422]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9782, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9652, 29.9392],\n",
      "        [31.9352, 26.8589],\n",
      "        [25.2703, 30.1659],\n",
      "        [27.8794, 27.8423]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9782, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9652, 29.9392],\n",
      "        [31.9353, 26.8589],\n",
      "        [25.2704, 30.1659],\n",
      "        [27.8795, 27.8423]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9782, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9652, 29.9392],\n",
      "        [31.9353, 26.8590],\n",
      "        [25.2704, 30.1660],\n",
      "        [27.8794, 27.8423]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9782, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9653, 29.9392],\n",
      "        [31.9354, 26.8590],\n",
      "        [25.2705, 30.1660],\n",
      "        [27.8795, 27.8423]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9782, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9652, 29.9393],\n",
      "        [31.9353, 26.8591],\n",
      "        [25.2705, 30.1660],\n",
      "        [27.8795, 27.8424]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9782, 0.1078, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9653, 29.9393],\n",
      "        [31.9354, 26.8591],\n",
      "        [25.2706, 30.1660],\n",
      "        [27.8795, 27.8424]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9782, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9653, 29.9393],\n",
      "        [31.9354, 26.8592],\n",
      "        [25.2705, 30.1660],\n",
      "        [27.8795, 27.8424]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9782, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9653, 29.9393],\n",
      "        [31.9355, 26.8592],\n",
      "        [25.2707, 30.1660],\n",
      "        [27.8796, 27.8424]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9782, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9653, 29.9393],\n",
      "        [31.9354, 26.8593],\n",
      "        [25.2706, 30.1661],\n",
      "        [27.8795, 27.8424]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9782, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9654, 29.9393],\n",
      "        [31.9356, 26.8593],\n",
      "        [25.2707, 30.1661],\n",
      "        [27.8796, 27.8424]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9783, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9653, 29.9394],\n",
      "        [31.9355, 26.8594],\n",
      "        [25.2707, 30.1661],\n",
      "        [27.8796, 27.8425]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9783, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9654, 29.9394],\n",
      "        [31.9356, 26.8594],\n",
      "        [25.2708, 30.1661],\n",
      "        [27.8796, 27.8425]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9783, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9654, 29.9394],\n",
      "        [31.9356, 26.8595],\n",
      "        [25.2707, 30.1662],\n",
      "        [27.8796, 27.8425]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9783, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9654, 29.9394],\n",
      "        [31.9357, 26.8595],\n",
      "        [25.2709, 30.1662],\n",
      "        [27.8797, 27.8425]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9783, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9654, 29.9395],\n",
      "        [31.9356, 26.8597],\n",
      "        [25.2708, 30.1662],\n",
      "        [27.8796, 27.8425]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9783, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9655, 29.9395],\n",
      "        [31.9358, 26.8597],\n",
      "        [25.2709, 30.1662],\n",
      "        [27.8797, 27.8426]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9783, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9654, 29.9395],\n",
      "        [31.9357, 26.8598],\n",
      "        [25.2709, 30.1663],\n",
      "        [27.8797, 27.8426]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9783, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9655, 29.9395],\n",
      "        [31.9358, 26.8598],\n",
      "        [25.2710, 30.1663],\n",
      "        [27.8797, 27.8426]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9783, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9654, 29.9395],\n",
      "        [31.9357, 26.8599],\n",
      "        [25.2710, 30.1663],\n",
      "        [27.8797, 27.8426]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9783, 0.1079, 0.9617], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9655, 29.9395],\n",
      "        [31.9359, 26.8599],\n",
      "        [25.2711, 30.1663],\n",
      "        [27.8798, 27.8426]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9784, 0.1079, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9655, 29.9396],\n",
      "        [31.9358, 26.8600],\n",
      "        [25.2710, 30.1663],\n",
      "        [27.8797, 27.8427]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9784, 0.1079, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9655, 29.9396],\n",
      "        [31.9359, 26.8600],\n",
      "        [25.2711, 30.1663],\n",
      "        [27.8798, 27.8427]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9784, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9655, 29.9396],\n",
      "        [31.9359, 26.8601],\n",
      "        [25.2711, 30.1664],\n",
      "        [27.8798, 27.8427]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9784, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9656, 29.9396],\n",
      "        [31.9360, 26.8601],\n",
      "        [25.2712, 30.1664],\n",
      "        [27.8798, 27.8427]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9784, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9655, 29.9396],\n",
      "        [31.9359, 26.8602],\n",
      "        [25.2712, 30.1664],\n",
      "        [27.8798, 27.8427]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9784, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9656, 29.9396],\n",
      "        [31.9360, 26.8602],\n",
      "        [25.2713, 30.1664],\n",
      "        [27.8799, 27.8427]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9784, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9656, 29.9397],\n",
      "        [31.9360, 26.8603],\n",
      "        [25.2712, 30.1665],\n",
      "        [27.8798, 27.8428]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9784, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9656, 29.9397],\n",
      "        [31.9361, 26.8603],\n",
      "        [25.2713, 30.1665],\n",
      "        [27.8799, 27.8428]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9784, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9656, 29.9397],\n",
      "        [31.9360, 26.8604],\n",
      "        [25.2713, 30.1665],\n",
      "        [27.8799, 27.8428]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9784, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9656, 29.9397],\n",
      "        [31.9362, 26.8604],\n",
      "        [25.2714, 30.1665],\n",
      "        [27.8799, 27.8428]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9785, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9656, 29.9397],\n",
      "        [31.9361, 26.8605],\n",
      "        [25.2714, 30.1666],\n",
      "        [27.8799, 27.8429]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9785, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9657, 29.9397],\n",
      "        [31.9362, 26.8605],\n",
      "        [25.2715, 30.1666],\n",
      "        [27.8800, 27.8429]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9785, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9657, 29.9398],\n",
      "        [31.9362, 26.8606],\n",
      "        [25.2714, 30.1666],\n",
      "        [27.8799, 27.8429]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9785, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9657, 29.9398],\n",
      "        [31.9363, 26.8606],\n",
      "        [25.2716, 30.1666],\n",
      "        [27.8800, 27.8429]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9785, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9657, 29.9398],\n",
      "        [31.9362, 26.8607],\n",
      "        [25.2715, 30.1666],\n",
      "        [27.8800, 27.8429]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9785, 0.1080, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9657, 29.9398],\n",
      "        [31.9363, 26.8607],\n",
      "        [25.2716, 30.1666],\n",
      "        [27.8800, 27.8429]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9785, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9657, 29.9398],\n",
      "        [31.9363, 26.8609],\n",
      "        [25.2716, 30.1667],\n",
      "        [27.8800, 27.8430]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9785, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9658, 29.9398],\n",
      "        [31.9364, 26.8608],\n",
      "        [25.2717, 30.1667],\n",
      "        [27.8801, 27.8430]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9785, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9657, 29.9399],\n",
      "        [31.9363, 26.8610],\n",
      "        [25.2716, 30.1667],\n",
      "        [27.8800, 27.8430]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9785, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9658, 29.9399],\n",
      "        [31.9365, 26.8610],\n",
      "        [25.2718, 30.1667],\n",
      "        [27.8801, 27.8430]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9786, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9658, 29.9399],\n",
      "        [31.9364, 26.8611],\n",
      "        [25.2717, 30.1668],\n",
      "        [27.8801, 27.8430]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9786, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9658, 29.9399],\n",
      "        [31.9365, 26.8611],\n",
      "        [25.2718, 30.1668],\n",
      "        [27.8801, 27.8430]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9786, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9658, 29.9399],\n",
      "        [31.9364, 26.8612],\n",
      "        [25.2718, 30.1668],\n",
      "        [27.8801, 27.8431]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9786, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9658, 29.9399],\n",
      "        [31.9366, 26.8612],\n",
      "        [25.2719, 30.1668],\n",
      "        [27.8802, 27.8431]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9786, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9658, 29.9400],\n",
      "        [31.9365, 26.8613],\n",
      "        [25.2718, 30.1669],\n",
      "        [27.8801, 27.8431]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9786, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9659, 29.9400],\n",
      "        [31.9366, 26.8613],\n",
      "        [25.2720, 30.1668],\n",
      "        [27.8802, 27.8431]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9786, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9658, 29.9400],\n",
      "        [31.9366, 26.8614],\n",
      "        [25.2719, 30.1669],\n",
      "        [27.8802, 27.8431]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9786, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9659, 29.9400],\n",
      "        [31.9367, 26.8614],\n",
      "        [25.2720, 30.1669],\n",
      "        [27.8802, 27.8431]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9786, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9659, 29.9400],\n",
      "        [31.9366, 26.8615],\n",
      "        [25.2720, 30.1669],\n",
      "        [27.8802, 27.8432]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9786, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9659, 29.9400],\n",
      "        [31.9367, 26.8615],\n",
      "        [25.2721, 30.1669],\n",
      "        [27.8802, 27.8432]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9786, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9659, 29.9401],\n",
      "        [31.9367, 26.8616],\n",
      "        [25.2720, 30.1670],\n",
      "        [27.8802, 27.8432]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9786, 0.1081, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9659, 29.9401],\n",
      "        [31.9368, 26.8616],\n",
      "        [25.2722, 30.1670],\n",
      "        [27.8803, 27.8432]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9787, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9659, 29.9401],\n",
      "        [31.9367, 26.8617],\n",
      "        [25.2721, 30.1670],\n",
      "        [27.8803, 27.8433]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9787, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9660, 29.9401],\n",
      "        [31.9369, 26.8617],\n",
      "        [25.2722, 30.1670],\n",
      "        [27.8803, 27.8432]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9787, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9660, 29.9402],\n",
      "        [31.9368, 26.8618],\n",
      "        [25.2722, 30.1671],\n",
      "        [27.8803, 27.8433]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9787, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9660, 29.9402],\n",
      "        [31.9369, 26.8618],\n",
      "        [25.2723, 30.1671],\n",
      "        [27.8803, 27.8433]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9787, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9660, 29.9402],\n",
      "        [31.9368, 26.8619],\n",
      "        [25.2723, 30.1671],\n",
      "        [27.8803, 27.8433]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9787, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9660, 29.9402],\n",
      "        [31.9370, 26.8619],\n",
      "        [25.2724, 30.1671],\n",
      "        [27.8804, 27.8433]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9787, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9660, 29.9402],\n",
      "        [31.9369, 26.8620],\n",
      "        [25.2723, 30.1672],\n",
      "        [27.8804, 27.8434]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9787, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9661, 29.9402],\n",
      "        [31.9370, 26.8620],\n",
      "        [25.2724, 30.1671],\n",
      "        [27.8804, 27.8434]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9787, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9661, 29.9403],\n",
      "        [31.9370, 26.8622],\n",
      "        [25.2724, 30.1672],\n",
      "        [27.8804, 27.8434]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9787, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9661, 29.9403],\n",
      "        [31.9371, 26.8621],\n",
      "        [25.2725, 30.1672],\n",
      "        [27.8804, 27.8434]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9788, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9661, 29.9403],\n",
      "        [31.9370, 26.8623],\n",
      "        [25.2725, 30.1672],\n",
      "        [27.8804, 27.8435]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9788, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9661, 29.9403],\n",
      "        [31.9372, 26.8623],\n",
      "        [25.2726, 30.1672],\n",
      "        [27.8805, 27.8435]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9788, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9661, 29.9403],\n",
      "        [31.9371, 26.8624],\n",
      "        [25.2725, 30.1673],\n",
      "        [27.8804, 27.8435]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9788, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9661, 29.9403],\n",
      "        [31.9372, 26.8624],\n",
      "        [25.2726, 30.1673],\n",
      "        [27.8805, 27.8435]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9788, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9661, 29.9404],\n",
      "        [31.9371, 26.8624],\n",
      "        [25.2726, 30.1673],\n",
      "        [27.8805, 27.8435]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9788, 0.1082, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9662, 29.9403],\n",
      "        [31.9372, 26.8624],\n",
      "        [25.2727, 30.1673],\n",
      "        [27.8805, 27.8435]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9788, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9661, 29.9404],\n",
      "        [31.9372, 26.8626],\n",
      "        [25.2727, 30.1674],\n",
      "        [27.8805, 27.8435]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9788, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9662, 29.9404],\n",
      "        [31.9373, 26.8625],\n",
      "        [25.2728, 30.1673],\n",
      "        [27.8806, 27.8435]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9788, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9662, 29.9404],\n",
      "        [31.9372, 26.8627],\n",
      "        [25.2727, 30.1674],\n",
      "        [27.8805, 27.8436]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9788, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9662, 29.9404],\n",
      "        [31.9374, 26.8627],\n",
      "        [25.2728, 30.1674],\n",
      "        [27.8806, 27.8436]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9789, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9662, 29.9405],\n",
      "        [31.9373, 26.8628],\n",
      "        [25.2728, 30.1674],\n",
      "        [27.8806, 27.8436]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9789, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9663, 29.9405],\n",
      "        [31.9374, 26.8628],\n",
      "        [25.2729, 30.1674],\n",
      "        [27.8806, 27.8436]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9789, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9662, 29.9405],\n",
      "        [31.9374, 26.8629],\n",
      "        [25.2729, 30.1675],\n",
      "        [27.8806, 27.8437]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9789, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9663, 29.9405],\n",
      "        [31.9375, 26.8629],\n",
      "        [25.2730, 30.1675],\n",
      "        [27.8807, 27.8437]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9789, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9663, 29.9405],\n",
      "        [31.9374, 26.8630],\n",
      "        [25.2729, 30.1675],\n",
      "        [27.8806, 27.8437]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9789, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9663, 29.9405],\n",
      "        [31.9375, 26.8630],\n",
      "        [25.2730, 30.1675],\n",
      "        [27.8807, 27.8437]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9789, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9663, 29.9406],\n",
      "        [31.9375, 26.8631],\n",
      "        [25.2730, 30.1676],\n",
      "        [27.8807, 27.8437]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9789, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9663, 29.9406],\n",
      "        [31.9376, 26.8631],\n",
      "        [25.2731, 30.1676],\n",
      "        [27.8807, 27.8437]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9789, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9663, 29.9406],\n",
      "        [31.9375, 26.8632],\n",
      "        [25.2731, 30.1676],\n",
      "        [27.8807, 27.8438]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9789, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9664, 29.9406],\n",
      "        [31.9377, 26.8632],\n",
      "        [25.2732, 30.1676],\n",
      "        [27.8808, 27.8438]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9790, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9664, 29.9406],\n",
      "        [31.9376, 26.8633],\n",
      "        [25.2731, 30.1677],\n",
      "        [27.8807, 27.8438]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9790, 0.1083, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9664, 29.9406],\n",
      "        [31.9377, 26.8633],\n",
      "        [25.2733, 30.1676],\n",
      "        [27.8808, 27.8438]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9982, 0.9790, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9664, 29.9407],\n",
      "        [31.9376, 26.8634],\n",
      "        [25.2732, 30.1677],\n",
      "        [27.8808, 27.8439]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9982, 0.9790, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9664, 29.9407],\n",
      "        [31.9378, 26.8634],\n",
      "        [25.2733, 30.1677],\n",
      "        [27.8808, 27.8438]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9790, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9664, 29.9407],\n",
      "        [31.9377, 26.8635],\n",
      "        [25.2733, 30.1677],\n",
      "        [27.8808, 27.8439]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9790, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9665, 29.9407],\n",
      "        [31.9378, 26.8635],\n",
      "        [25.2734, 30.1677],\n",
      "        [27.8809, 27.8439]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9790, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9664, 29.9407],\n",
      "        [31.9378, 26.8636],\n",
      "        [25.2733, 30.1678],\n",
      "        [27.8808, 27.8439]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9790, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9665, 29.9407],\n",
      "        [31.9379, 26.8636],\n",
      "        [25.2735, 30.1678],\n",
      "        [27.8809, 27.8439]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9790, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9665, 29.9408],\n",
      "        [31.9378, 26.8637],\n",
      "        [25.2734, 30.1678],\n",
      "        [27.8809, 27.8440]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9790, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9665, 29.9408],\n",
      "        [31.9379, 26.8637],\n",
      "        [25.2735, 30.1678],\n",
      "        [27.8809, 27.8439]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9790, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9665, 29.9408],\n",
      "        [31.9379, 26.8638],\n",
      "        [25.2735, 30.1679],\n",
      "        [27.8809, 27.8440]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9790, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9665, 29.9408],\n",
      "        [31.9380, 26.8638],\n",
      "        [25.2736, 30.1678],\n",
      "        [27.8809, 27.8440]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9791, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9665, 29.9408],\n",
      "        [31.9379, 26.8639],\n",
      "        [25.2735, 30.1679],\n",
      "        [27.8809, 27.8440]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9791, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9665, 29.9408],\n",
      "        [31.9380, 26.8639],\n",
      "        [25.2736, 30.1679],\n",
      "        [27.8810, 27.8440]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9791, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9665, 29.9409],\n",
      "        [31.9380, 26.8640],\n",
      "        [25.2736, 30.1679],\n",
      "        [27.8810, 27.8441]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9791, 0.1084, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9666, 29.9409],\n",
      "        [31.9381, 26.8640],\n",
      "        [25.2737, 30.1679],\n",
      "        [27.8810, 27.8441]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9791, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9666, 29.9409],\n",
      "        [31.9380, 26.8641],\n",
      "        [25.2737, 30.1680],\n",
      "        [27.8810, 27.8441]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9791, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9666, 29.9409],\n",
      "        [31.9382, 26.8641],\n",
      "        [25.2738, 30.1680],\n",
      "        [27.8810, 27.8441]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9791, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9666, 29.9409],\n",
      "        [31.9381, 26.8642],\n",
      "        [25.2737, 30.1680],\n",
      "        [27.8810, 27.8441]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9791, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9666, 29.9409],\n",
      "        [31.9382, 26.8642],\n",
      "        [25.2739, 30.1680],\n",
      "        [27.8811, 27.8441]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9791, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9666, 29.9410],\n",
      "        [31.9381, 26.8643],\n",
      "        [25.2738, 30.1681],\n",
      "        [27.8811, 27.8442]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9791, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9667, 29.9410],\n",
      "        [31.9383, 26.8643],\n",
      "        [25.2739, 30.1680],\n",
      "        [27.8811, 27.8442]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9792, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9666, 29.9410],\n",
      "        [31.9382, 26.8644],\n",
      "        [25.2739, 30.1681],\n",
      "        [27.8811, 27.8442]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9792, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9667, 29.9410],\n",
      "        [31.9383, 26.8644],\n",
      "        [25.2740, 30.1681],\n",
      "        [27.8811, 27.8442]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9792, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9667, 29.9411],\n",
      "        [31.9383, 26.8646],\n",
      "        [25.2740, 30.1682],\n",
      "        [27.8811, 27.8442]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9792, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9667, 29.9411],\n",
      "        [31.9384, 26.8645],\n",
      "        [25.2741, 30.1681],\n",
      "        [27.8812, 27.8442]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9792, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9667, 29.9411],\n",
      "        [31.9383, 26.8646],\n",
      "        [25.2740, 30.1682],\n",
      "        [27.8811, 27.8443]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9792, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9668, 29.9411],\n",
      "        [31.9384, 26.8646],\n",
      "        [25.2741, 30.1682],\n",
      "        [27.8812, 27.8443]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9792, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9667, 29.9411],\n",
      "        [31.9384, 26.8648],\n",
      "        [25.2741, 30.1682],\n",
      "        [27.8812, 27.8443]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9792, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9668, 29.9411],\n",
      "        [31.9385, 26.8647],\n",
      "        [25.2742, 30.1682],\n",
      "        [27.8812, 27.8443]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9792, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9668, 29.9412],\n",
      "        [31.9384, 26.8648],\n",
      "        [25.2741, 30.1683],\n",
      "        [27.8812, 27.8444]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9792, 0.1085, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9668, 29.9412],\n",
      "        [31.9386, 26.8648],\n",
      "        [25.2743, 30.1682],\n",
      "        [27.8813, 27.8443]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9793, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9668, 29.9412],\n",
      "        [31.9385, 26.8650],\n",
      "        [25.2742, 30.1683],\n",
      "        [27.8812, 27.8444]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9793, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9668, 29.9412],\n",
      "        [31.9386, 26.8649],\n",
      "        [25.2743, 30.1683],\n",
      "        [27.8813, 27.8444]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9793, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9668, 29.9412],\n",
      "        [31.9385, 26.8650],\n",
      "        [25.2743, 30.1683],\n",
      "        [27.8813, 27.8444]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9793, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9668, 29.9412],\n",
      "        [31.9386, 26.8650],\n",
      "        [25.2744, 30.1683],\n",
      "        [27.8813, 27.8444]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9793, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9668, 29.9412],\n",
      "        [31.9386, 26.8651],\n",
      "        [25.2743, 30.1684],\n",
      "        [27.8813, 27.8444]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9793, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9669, 29.9412],\n",
      "        [31.9387, 26.8651],\n",
      "        [25.2744, 30.1684],\n",
      "        [27.8813, 27.8444]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9793, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9668, 29.9413],\n",
      "        [31.9386, 26.8652],\n",
      "        [25.2744, 30.1684],\n",
      "        [27.8813, 27.8445]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9793, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9669, 29.9413],\n",
      "        [31.9387, 26.8652],\n",
      "        [25.2745, 30.1684],\n",
      "        [27.8814, 27.8445]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9793, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9669, 29.9413],\n",
      "        [31.9387, 26.8653],\n",
      "        [25.2745, 30.1685],\n",
      "        [27.8813, 27.8445]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9793, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9669, 29.9413],\n",
      "        [31.9388, 26.8653],\n",
      "        [25.2746, 30.1684],\n",
      "        [27.8814, 27.8445]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9793, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9669, 29.9413],\n",
      "        [31.9387, 26.8654],\n",
      "        [25.2745, 30.1685],\n",
      "        [27.8814, 27.8446]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9793, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9669, 29.9413],\n",
      "        [31.9389, 26.8654],\n",
      "        [25.2746, 30.1685],\n",
      "        [27.8814, 27.8445]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9794, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9669, 29.9414],\n",
      "        [31.9388, 26.8656],\n",
      "        [25.2746, 30.1685],\n",
      "        [27.8814, 27.8446]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9794, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9670, 29.9414],\n",
      "        [31.9389, 26.8655],\n",
      "        [25.2747, 30.1685],\n",
      "        [27.8815, 27.8446]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9794, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9670, 29.9414],\n",
      "        [31.9388, 26.8657],\n",
      "        [25.2747, 30.1686],\n",
      "        [27.8814, 27.8446]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9794, 0.1086, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9670, 29.9414],\n",
      "        [31.9390, 26.8657],\n",
      "        [25.2748, 30.1686],\n",
      "        [27.8815, 27.8446]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9794, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9670, 29.9414],\n",
      "        [31.9389, 26.8658],\n",
      "        [25.2747, 30.1686],\n",
      "        [27.8815, 27.8447]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9794, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9670, 29.9414],\n",
      "        [31.9390, 26.8657],\n",
      "        [25.2748, 30.1686],\n",
      "        [27.8815, 27.8447]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9794, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9670, 29.9415],\n",
      "        [31.9390, 26.8659],\n",
      "        [25.2748, 30.1687],\n",
      "        [27.8815, 27.8447]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9794, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9671, 29.9415],\n",
      "        [31.9391, 26.8658],\n",
      "        [25.2749, 30.1686],\n",
      "        [27.8816, 27.8447]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9794, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9670, 29.9415],\n",
      "        [31.9390, 26.8660],\n",
      "        [25.2749, 30.1687],\n",
      "        [27.8815, 27.8447]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9794, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9671, 29.9415],\n",
      "        [31.9391, 26.8660],\n",
      "        [25.2750, 30.1687],\n",
      "        [27.8816, 27.8447]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9794, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9671, 29.9416],\n",
      "        [31.9391, 26.8661],\n",
      "        [25.2749, 30.1687],\n",
      "        [27.8816, 27.8448]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9794, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9671, 29.9416],\n",
      "        [31.9392, 26.8661],\n",
      "        [25.2750, 30.1687],\n",
      "        [27.8816, 27.8448]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9795, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9671, 29.9416],\n",
      "        [31.9391, 26.8662],\n",
      "        [25.2750, 30.1688],\n",
      "        [27.8816, 27.8448]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9795, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9671, 29.9416],\n",
      "        [31.9392, 26.8662],\n",
      "        [25.2751, 30.1688],\n",
      "        [27.8817, 27.8448]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9795, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9671, 29.9416],\n",
      "        [31.9392, 26.8663],\n",
      "        [25.2751, 30.1688],\n",
      "        [27.8816, 27.8449]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9795, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9672, 29.9416],\n",
      "        [31.9393, 26.8662],\n",
      "        [25.2752, 30.1688],\n",
      "        [27.8817, 27.8448]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9795, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9671, 29.9416],\n",
      "        [31.9392, 26.8664],\n",
      "        [25.2751, 30.1689],\n",
      "        [27.8817, 27.8449]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9795, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9672, 29.9416],\n",
      "        [31.9393, 26.8663],\n",
      "        [25.2752, 30.1688],\n",
      "        [27.8817, 27.8449]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9795, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9672, 29.9417],\n",
      "        [31.9393, 26.8664],\n",
      "        [25.2752, 30.1689],\n",
      "        [27.8817, 27.8449]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9795, 0.1087, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9672, 29.9417],\n",
      "        [31.9394, 26.8664],\n",
      "        [25.2753, 30.1689],\n",
      "        [27.8817, 27.8449]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9795, 0.1088, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9672, 29.9417],\n",
      "        [31.9393, 26.8666],\n",
      "        [25.2753, 30.1689],\n",
      "        [27.8817, 27.8449]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9795, 0.1088, 0.9618], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9672, 29.9417],\n",
      "        [31.9394, 26.8665],\n",
      "        [25.2754, 30.1689],\n",
      "        [27.8818, 27.8449]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9796, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9672, 29.9417],\n",
      "        [31.9394, 26.8667],\n",
      "        [25.2753, 30.1690],\n",
      "        [27.8817, 27.8450]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9796, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9673, 29.9417],\n",
      "        [31.9395, 26.8666],\n",
      "        [25.2754, 30.1689],\n",
      "        [27.8818, 27.8450]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9796, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9672, 29.9418],\n",
      "        [31.9394, 26.8667],\n",
      "        [25.2754, 30.1690],\n",
      "        [27.8818, 27.8450]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9796, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9673, 29.9418],\n",
      "        [31.9396, 26.8667],\n",
      "        [25.2755, 30.1690],\n",
      "        [27.8818, 27.8450]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9796, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9673, 29.9418],\n",
      "        [31.9395, 26.8668],\n",
      "        [25.2754, 30.1691],\n",
      "        [27.8818, 27.8450]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9796, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9673, 29.9418],\n",
      "        [31.9396, 26.8668],\n",
      "        [25.2756, 30.1690],\n",
      "        [27.8819, 27.8450]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9796, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9673, 29.9418],\n",
      "        [31.9395, 26.8669],\n",
      "        [25.2755, 30.1691],\n",
      "        [27.8818, 27.8451]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9796, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9674, 29.9418],\n",
      "        [31.9397, 26.8669],\n",
      "        [25.2756, 30.1691],\n",
      "        [27.8819, 27.8451]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9796, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9673, 29.9419],\n",
      "        [31.9396, 26.8671],\n",
      "        [25.2756, 30.1691],\n",
      "        [27.8819, 27.8451]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9796, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9674, 29.9419],\n",
      "        [31.9397, 26.8671],\n",
      "        [25.2757, 30.1691],\n",
      "        [27.8819, 27.8451]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9796, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9674, 29.9419],\n",
      "        [31.9396, 26.8671],\n",
      "        [25.2757, 30.1692],\n",
      "        [27.8819, 27.8452]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9796, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9674, 29.9419],\n",
      "        [31.9398, 26.8671],\n",
      "        [25.2758, 30.1692],\n",
      "        [27.8820, 27.8451]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9797, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9674, 29.9419],\n",
      "        [31.9397, 26.8672],\n",
      "        [25.2757, 30.1692],\n",
      "        [27.8819, 27.8452]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9797, 0.1088, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9674, 29.9419],\n",
      "        [31.9398, 26.8672],\n",
      "        [25.2758, 30.1692],\n",
      "        [27.8820, 27.8452]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9797, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9674, 29.9420],\n",
      "        [31.9397, 26.8673],\n",
      "        [25.2758, 30.1693],\n",
      "        [27.8820, 27.8452]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9797, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9675, 29.9420],\n",
      "        [31.9399, 26.8673],\n",
      "        [25.2759, 30.1692],\n",
      "        [27.8820, 27.8452]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9797, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9674, 29.9420],\n",
      "        [31.9398, 26.8674],\n",
      "        [25.2758, 30.1693],\n",
      "        [27.8820, 27.8453]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9797, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9675, 29.9420],\n",
      "        [31.9399, 26.8674],\n",
      "        [25.2759, 30.1693],\n",
      "        [27.8820, 27.8453]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9797, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9675, 29.9420],\n",
      "        [31.9399, 26.8675],\n",
      "        [25.2759, 30.1693],\n",
      "        [27.8820, 27.8453]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9797, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9675, 29.9420],\n",
      "        [31.9400, 26.8675],\n",
      "        [25.2760, 30.1693],\n",
      "        [27.8821, 27.8453]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9797, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9675, 29.9421],\n",
      "        [31.9399, 26.8676],\n",
      "        [25.2760, 30.1694],\n",
      "        [27.8820, 27.8453]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9797, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9675, 29.9421],\n",
      "        [31.9400, 26.8676],\n",
      "        [25.2761, 30.1693],\n",
      "        [27.8821, 27.8453]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9797, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9675, 29.9421],\n",
      "        [31.9400, 26.8677],\n",
      "        [25.2760, 30.1694],\n",
      "        [27.8821, 27.8454]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9797, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9675, 29.9421],\n",
      "        [31.9401, 26.8677],\n",
      "        [25.2761, 30.1694],\n",
      "        [27.8821, 27.8454]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9798, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9675, 29.9421],\n",
      "        [31.9400, 26.8678],\n",
      "        [25.2761, 30.1694],\n",
      "        [27.8821, 27.8454]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9798, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9676, 29.9421],\n",
      "        [31.9401, 26.8678],\n",
      "        [25.2762, 30.1694],\n",
      "        [27.8822, 27.8454]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9798, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9675, 29.9422],\n",
      "        [31.9401, 26.8679],\n",
      "        [25.2762, 30.1695],\n",
      "        [27.8821, 27.8454]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9798, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9676, 29.9422],\n",
      "        [31.9402, 26.8679],\n",
      "        [25.2763, 30.1695],\n",
      "        [27.8822, 27.8454]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9798, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9676, 29.9422],\n",
      "        [31.9401, 26.8680],\n",
      "        [25.2762, 30.1695],\n",
      "        [27.8822, 27.8455]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9798, 0.1089, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9676, 29.9422],\n",
      "        [31.9402, 26.8680],\n",
      "        [25.2763, 30.1695],\n",
      "        [27.8822, 27.8454]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9798, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9676, 29.9422],\n",
      "        [31.9402, 26.8681],\n",
      "        [25.2763, 30.1696],\n",
      "        [27.8822, 27.8455]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9798, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9677, 29.9422],\n",
      "        [31.9403, 26.8681],\n",
      "        [25.2764, 30.1696],\n",
      "        [27.8822, 27.8455]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9798, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9676, 29.9423],\n",
      "        [31.9402, 26.8682],\n",
      "        [25.2764, 30.1696],\n",
      "        [27.8822, 27.8455]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9798, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9677, 29.9423],\n",
      "        [31.9403, 26.8682],\n",
      "        [25.2765, 30.1696],\n",
      "        [27.8823, 27.8455]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9799, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9677, 29.9423],\n",
      "        [31.9403, 26.8683],\n",
      "        [25.2764, 30.1697],\n",
      "        [27.8823, 27.8456]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9799, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9677, 29.9423],\n",
      "        [31.9404, 26.8683],\n",
      "        [25.2765, 30.1696],\n",
      "        [27.8823, 27.8456]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9799, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9677, 29.9423],\n",
      "        [31.9403, 26.8684],\n",
      "        [25.2765, 30.1697],\n",
      "        [27.8823, 27.8456]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9799, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9677, 29.9423],\n",
      "        [31.9404, 26.8684],\n",
      "        [25.2766, 30.1697],\n",
      "        [27.8823, 27.8456]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9799, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9677, 29.9424],\n",
      "        [31.9404, 26.8685],\n",
      "        [25.2766, 30.1697],\n",
      "        [27.8823, 27.8456]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9799, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9678, 29.9424],\n",
      "        [31.9405, 26.8685],\n",
      "        [25.2766, 30.1697],\n",
      "        [27.8824, 27.8456]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9799, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9677, 29.9424],\n",
      "        [31.9404, 26.8686],\n",
      "        [25.2766, 30.1698],\n",
      "        [27.8823, 27.8457]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9799, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9678, 29.9424],\n",
      "        [31.9406, 26.8686],\n",
      "        [25.2767, 30.1698],\n",
      "        [27.8824, 27.8457]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9799, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9678, 29.9424],\n",
      "        [31.9405, 26.8687],\n",
      "        [25.2767, 30.1698],\n",
      "        [27.8824, 27.8457]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9799, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9678, 29.9424],\n",
      "        [31.9406, 26.8687],\n",
      "        [25.2768, 30.1698],\n",
      "        [27.8824, 27.8457]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9799, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9678, 29.9425],\n",
      "        [31.9405, 26.8688],\n",
      "        [25.2768, 30.1698],\n",
      "        [27.8824, 27.8457]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9799, 0.1090, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9678, 29.9425],\n",
      "        [31.9407, 26.8688],\n",
      "        [25.2769, 30.1698],\n",
      "        [27.8825, 27.8457]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9800, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9678, 29.9425],\n",
      "        [31.9406, 26.8689],\n",
      "        [25.2768, 30.1699],\n",
      "        [27.8824, 27.8458]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9800, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9678, 29.9425],\n",
      "        [31.9407, 26.8689],\n",
      "        [25.2769, 30.1698],\n",
      "        [27.8825, 27.8458]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9800, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9678, 29.9425],\n",
      "        [31.9406, 26.8690],\n",
      "        [25.2769, 30.1699],\n",
      "        [27.8824, 27.8458]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9800, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9679, 29.9425],\n",
      "        [31.9407, 26.8690],\n",
      "        [25.2770, 30.1699],\n",
      "        [27.8825, 27.8458]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9800, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9678, 29.9425],\n",
      "        [31.9407, 26.8691],\n",
      "        [25.2769, 30.1699],\n",
      "        [27.8825, 27.8458]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9800, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9679, 29.9426],\n",
      "        [31.9408, 26.8691],\n",
      "        [25.2770, 30.1699],\n",
      "        [27.8825, 27.8458]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9800, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9679, 29.9426],\n",
      "        [31.9407, 26.8692],\n",
      "        [25.2770, 30.1700],\n",
      "        [27.8825, 27.8459]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9800, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9679, 29.9426],\n",
      "        [31.9408, 26.8692],\n",
      "        [25.2771, 30.1700],\n",
      "        [27.8826, 27.8459]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9800, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9679, 29.9426],\n",
      "        [31.9408, 26.8693],\n",
      "        [25.2771, 30.1700],\n",
      "        [27.8825, 27.8459]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9800, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9679, 29.9426],\n",
      "        [31.9409, 26.8693],\n",
      "        [25.2772, 30.1700],\n",
      "        [27.8826, 27.8459]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9800, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9679, 29.9426],\n",
      "        [31.9408, 26.8694],\n",
      "        [25.2771, 30.1701],\n",
      "        [27.8826, 27.8459]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9800, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9680, 29.9427],\n",
      "        [31.9409, 26.8694],\n",
      "        [25.2772, 30.1700],\n",
      "        [27.8826, 27.8459]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9801, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9680, 29.9427],\n",
      "        [31.9409, 26.8695],\n",
      "        [25.2772, 30.1701],\n",
      "        [27.8826, 27.8460]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9801, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9680, 29.9427],\n",
      "        [31.9410, 26.8695],\n",
      "        [25.2773, 30.1701],\n",
      "        [27.8827, 27.8460]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9801, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9680, 29.9427],\n",
      "        [31.9409, 26.8696],\n",
      "        [25.2773, 30.1701],\n",
      "        [27.8826, 27.8460]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9801, 0.1091, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9680, 29.9427],\n",
      "        [31.9410, 26.8696],\n",
      "        [25.2774, 30.1701],\n",
      "        [27.8827, 27.8460]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9801, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9680, 29.9427],\n",
      "        [31.9410, 26.8697],\n",
      "        [25.2773, 30.1702],\n",
      "        [27.8827, 27.8460]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9801, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9680, 29.9427],\n",
      "        [31.9411, 26.8696],\n",
      "        [25.2774, 30.1702],\n",
      "        [27.8827, 27.8460]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9801, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9680, 29.9428],\n",
      "        [31.9410, 26.8697],\n",
      "        [25.2774, 30.1702],\n",
      "        [27.8827, 27.8461]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9801, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9681, 29.9428],\n",
      "        [31.9411, 26.8697],\n",
      "        [25.2775, 30.1702],\n",
      "        [27.8827, 27.8461]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9801, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9680, 29.9428],\n",
      "        [31.9411, 26.8698],\n",
      "        [25.2774, 30.1702],\n",
      "        [27.8827, 27.8461]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9801, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9681, 29.9428],\n",
      "        [31.9412, 26.8698],\n",
      "        [25.2775, 30.1702],\n",
      "        [27.8828, 27.8461]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9801, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9681, 29.9429],\n",
      "        [31.9411, 26.8699],\n",
      "        [25.2775, 30.1703],\n",
      "        [27.8828, 27.8461]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9801, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9681, 29.9428],\n",
      "        [31.9412, 26.8699],\n",
      "        [25.2776, 30.1703],\n",
      "        [27.8828, 27.8461]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9802, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9681, 29.9429],\n",
      "        [31.9412, 26.8700],\n",
      "        [25.2776, 30.1703],\n",
      "        [27.8828, 27.8462]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9802, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9682, 29.9429],\n",
      "        [31.9413, 26.8700],\n",
      "        [25.2777, 30.1703],\n",
      "        [27.8828, 27.8462]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9802, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9681, 29.9429],\n",
      "        [31.9412, 26.8701],\n",
      "        [25.2776, 30.1704],\n",
      "        [27.8828, 27.8462]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9802, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9682, 29.9429],\n",
      "        [31.9413, 26.8701],\n",
      "        [25.2777, 30.1704],\n",
      "        [27.8829, 27.8462]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9802, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9682, 29.9430],\n",
      "        [31.9413, 26.8702],\n",
      "        [25.2777, 30.1704],\n",
      "        [27.8828, 27.8463]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9802, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9682, 29.9429],\n",
      "        [31.9414, 26.8702],\n",
      "        [25.2778, 30.1704],\n",
      "        [27.8829, 27.8462]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9802, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9682, 29.9430],\n",
      "        [31.9413, 26.8703],\n",
      "        [25.2778, 30.1704],\n",
      "        [27.8829, 27.8463]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9802, 0.1092, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9682, 29.9430],\n",
      "        [31.9414, 26.8703],\n",
      "        [25.2779, 30.1704],\n",
      "        [27.8829, 27.8463]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9802, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9682, 29.9430],\n",
      "        [31.9414, 26.8704],\n",
      "        [25.2778, 30.1705],\n",
      "        [27.8829, 27.8463]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9802, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9682, 29.9430],\n",
      "        [31.9415, 26.8704],\n",
      "        [25.2779, 30.1705],\n",
      "        [27.8829, 27.8463]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9802, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9682, 29.9430],\n",
      "        [31.9414, 26.8705],\n",
      "        [25.2779, 30.1705],\n",
      "        [27.8829, 27.8463]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9802, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9683, 29.9430],\n",
      "        [31.9415, 26.8705],\n",
      "        [25.2780, 30.1705],\n",
      "        [27.8830, 27.8463]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9803, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9683, 29.9431],\n",
      "        [31.9415, 26.8706],\n",
      "        [25.2779, 30.1706],\n",
      "        [27.8829, 27.8464]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9803, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9683, 29.9431],\n",
      "        [31.9416, 26.8706],\n",
      "        [25.2781, 30.1705],\n",
      "        [27.8830, 27.8464]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9803, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9683, 29.9431],\n",
      "        [31.9415, 26.8707],\n",
      "        [25.2780, 30.1706],\n",
      "        [27.8830, 27.8464]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9803, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9683, 29.9431],\n",
      "        [31.9416, 26.8707],\n",
      "        [25.2781, 30.1706],\n",
      "        [27.8830, 27.8464]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9803, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9683, 29.9431],\n",
      "        [31.9416, 26.8708],\n",
      "        [25.2781, 30.1706],\n",
      "        [27.8830, 27.8464]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9803, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9683, 29.9431],\n",
      "        [31.9417, 26.8708],\n",
      "        [25.2782, 30.1706],\n",
      "        [27.8830, 27.8464]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9803, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9683, 29.9431],\n",
      "        [31.9416, 26.8709],\n",
      "        [25.2781, 30.1707],\n",
      "        [27.8830, 27.8465]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9803, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9684, 29.9432],\n",
      "        [31.9417, 26.8709],\n",
      "        [25.2782, 30.1707],\n",
      "        [27.8831, 27.8465]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9803, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9684, 29.9432],\n",
      "        [31.9417, 26.8710],\n",
      "        [25.2782, 30.1707],\n",
      "        [27.8831, 27.8465]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9803, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9684, 29.9432],\n",
      "        [31.9418, 26.8710],\n",
      "        [25.2783, 30.1707],\n",
      "        [27.8831, 27.8465]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9803, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9684, 29.9432],\n",
      "        [31.9417, 26.8711],\n",
      "        [25.2783, 30.1707],\n",
      "        [27.8831, 27.8465]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9803, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9684, 29.9432],\n",
      "        [31.9418, 26.8710],\n",
      "        [25.2784, 30.1707],\n",
      "        [27.8831, 27.8465]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9804, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9684, 29.9432],\n",
      "        [31.9418, 26.8711],\n",
      "        [25.2783, 30.1708],\n",
      "        [27.8831, 27.8466]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9804, 0.1093, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9685, 29.9433],\n",
      "        [31.9419, 26.8711],\n",
      "        [25.2784, 30.1708],\n",
      "        [27.8832, 27.8466]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9804, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9684, 29.9433],\n",
      "        [31.9418, 26.8713],\n",
      "        [25.2784, 30.1708],\n",
      "        [27.8832, 27.8466]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9804, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9685, 29.9433],\n",
      "        [31.9419, 26.8712],\n",
      "        [25.2785, 30.1708],\n",
      "        [27.8832, 27.8466]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9804, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9684, 29.9433],\n",
      "        [31.9419, 26.8713],\n",
      "        [25.2784, 30.1709],\n",
      "        [27.8832, 27.8466]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9804, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9685, 29.9433],\n",
      "        [31.9420, 26.8713],\n",
      "        [25.2786, 30.1708],\n",
      "        [27.8832, 27.8466]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9804, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9685, 29.9434],\n",
      "        [31.9419, 26.8714],\n",
      "        [25.2785, 30.1709],\n",
      "        [27.8832, 27.8467]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9804, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9685, 29.9434],\n",
      "        [31.9420, 26.8714],\n",
      "        [25.2786, 30.1709],\n",
      "        [27.8833, 27.8467]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9804, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9685, 29.9434],\n",
      "        [31.9420, 26.8715],\n",
      "        [25.2786, 30.1709],\n",
      "        [27.8832, 27.8467]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9804, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9685, 29.9434],\n",
      "        [31.9421, 26.8715],\n",
      "        [25.2787, 30.1709],\n",
      "        [27.8833, 27.8467]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9804, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9685, 29.9434],\n",
      "        [31.9420, 26.8716],\n",
      "        [25.2786, 30.1710],\n",
      "        [27.8832, 27.8467]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9804, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9686, 29.9434],\n",
      "        [31.9421, 26.8716],\n",
      "        [25.2787, 30.1710],\n",
      "        [27.8833, 27.8467]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9805, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9685, 29.9434],\n",
      "        [31.9421, 26.8717],\n",
      "        [25.2787, 30.1710],\n",
      "        [27.8833, 27.8468]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9805, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9686, 29.9434],\n",
      "        [31.9422, 26.8717],\n",
      "        [25.2788, 30.1710],\n",
      "        [27.8833, 27.8468]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9805, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9686, 29.9435],\n",
      "        [31.9421, 26.8718],\n",
      "        [25.2788, 30.1710],\n",
      "        [27.8833, 27.8468]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9805, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9686, 29.9435],\n",
      "        [31.9422, 26.8718],\n",
      "        [25.2788, 30.1710],\n",
      "        [27.8834, 27.8468]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9805, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9686, 29.9435],\n",
      "        [31.9422, 26.8719],\n",
      "        [25.2788, 30.1711],\n",
      "        [27.8833, 27.8468]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9805, 0.1094, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9686, 29.9435],\n",
      "        [31.9423, 26.8719],\n",
      "        [25.2789, 30.1711],\n",
      "        [27.8834, 27.8468]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9805, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9686, 29.9435],\n",
      "        [31.9422, 26.8720],\n",
      "        [25.2789, 30.1711],\n",
      "        [27.8834, 27.8469]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9805, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9687, 29.9435],\n",
      "        [31.9423, 26.8720],\n",
      "        [25.2790, 30.1711],\n",
      "        [27.8834, 27.8469]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9805, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9686, 29.9436],\n",
      "        [31.9423, 26.8721],\n",
      "        [25.2789, 30.1712],\n",
      "        [27.8834, 27.8469]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9805, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9687, 29.9436],\n",
      "        [31.9424, 26.8721],\n",
      "        [25.2790, 30.1711],\n",
      "        [27.8834, 27.8469]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9805, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9687, 29.9436],\n",
      "        [31.9423, 26.8721],\n",
      "        [25.2790, 30.1712],\n",
      "        [27.8834, 27.8469]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9805, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9687, 29.9436],\n",
      "        [31.9424, 26.8722],\n",
      "        [25.2791, 30.1712],\n",
      "        [27.8835, 27.8469]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9806, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9687, 29.9436],\n",
      "        [31.9424, 26.8722],\n",
      "        [25.2791, 30.1712],\n",
      "        [27.8834, 27.8470]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9806, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9687, 29.9436],\n",
      "        [31.9425, 26.8722],\n",
      "        [25.2792, 30.1712],\n",
      "        [27.8835, 27.8470]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9806, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9687, 29.9437],\n",
      "        [31.9424, 26.8723],\n",
      "        [25.2791, 30.1713],\n",
      "        [27.8835, 27.8470]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9806, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9688, 29.9437],\n",
      "        [31.9425, 26.8723],\n",
      "        [25.2792, 30.1712],\n",
      "        [27.8835, 27.8470]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9983, 0.9806, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9687, 29.9437],\n",
      "        [31.9424, 26.8724],\n",
      "        [25.2792, 30.1713],\n",
      "        [27.8835, 27.8470]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9983, 0.9806, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9688, 29.9437],\n",
      "        [31.9426, 26.8724],\n",
      "        [25.2793, 30.1713],\n",
      "        [27.8836, 27.8470]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9806, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9688, 29.9437],\n",
      "        [31.9425, 26.8725],\n",
      "        [25.2793, 30.1713],\n",
      "        [27.8835, 27.8471]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9806, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9688, 29.9437],\n",
      "        [31.9426, 26.8725],\n",
      "        [25.2794, 30.1713],\n",
      "        [27.8836, 27.8471]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9806, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9688, 29.9437],\n",
      "        [31.9425, 26.8726],\n",
      "        [25.2793, 30.1714],\n",
      "        [27.8836, 27.8471]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9806, 0.1095, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9688, 29.9437],\n",
      "        [31.9427, 26.8726],\n",
      "        [25.2794, 30.1713],\n",
      "        [27.8836, 27.8471]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9806, 0.1096, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9688, 29.9438],\n",
      "        [31.9426, 26.8727],\n",
      "        [25.2794, 30.1714],\n",
      "        [27.8836, 27.8471]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9806, 0.1096, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9689, 29.9438],\n",
      "        [31.9427, 26.8727],\n",
      "        [25.2795, 30.1714],\n",
      "        [27.8837, 27.8471]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9806, 0.1096, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9688, 29.9438],\n",
      "        [31.9427, 26.8728],\n",
      "        [25.2794, 30.1714],\n",
      "        [27.8836, 27.8472]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9806, 0.1096, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9689, 29.9438],\n",
      "        [31.9427, 26.8728],\n",
      "        [25.2795, 30.1714],\n",
      "        [27.8837, 27.8472]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9807, 0.1096, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9688, 29.9438],\n",
      "        [31.9427, 26.8729],\n",
      "        [25.2795, 30.1715],\n",
      "        [27.8836, 27.8472]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9807, 0.1096, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9689, 29.9438],\n",
      "        [31.9428, 26.8729],\n",
      "        [25.2796, 30.1715],\n",
      "        [27.8837, 27.8472]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9807, 0.1096, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9689, 29.9439],\n",
      "        [31.9427, 26.8730],\n",
      "        [25.2796, 30.1715],\n",
      "        [27.8837, 27.8472]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9807, 0.1096, 0.9619], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9689, 29.9439],\n",
      "        [31.9428, 26.8729],\n",
      "        [25.2796, 30.1715],\n",
      "        [27.8837, 27.8472]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9807, 0.1096, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9689, 29.9439],\n",
      "        [31.9428, 26.8730],\n",
      "        [25.2796, 30.1715],\n",
      "        [27.8837, 27.8472]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9807, 0.1096, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9689, 29.9439],\n",
      "        [31.9429, 26.8730],\n",
      "        [25.2797, 30.1715],\n",
      "        [27.8837, 27.8472]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9807, 0.1096, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9689, 29.9439],\n",
      "        [31.9428, 26.8731],\n",
      "        [25.2797, 30.1716],\n",
      "        [27.8837, 27.8473]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9807, 0.1096, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9690, 29.9439],\n",
      "        [31.9429, 26.8731],\n",
      "        [25.2798, 30.1716],\n",
      "        [27.8838, 27.8473]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9807, 0.1096, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9689, 29.9440],\n",
      "        [31.9429, 26.8732],\n",
      "        [25.2797, 30.1716],\n",
      "        [27.8837, 27.8473]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9807, 0.1096, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9690, 29.9440],\n",
      "        [31.9430, 26.8732],\n",
      "        [25.2798, 30.1716],\n",
      "        [27.8838, 27.8473]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9807, 0.1096, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9690, 29.9440],\n",
      "        [31.9429, 26.8733],\n",
      "        [25.2798, 30.1717],\n",
      "        [27.8838, 27.8473]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9807, 0.1096, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9690, 29.9440],\n",
      "        [31.9430, 26.8733],\n",
      "        [25.2799, 30.1716],\n",
      "        [27.8838, 27.8473]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9808, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9690, 29.9440],\n",
      "        [31.9430, 26.8734],\n",
      "        [25.2799, 30.1717],\n",
      "        [27.8838, 27.8474]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9808, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9690, 29.9440],\n",
      "        [31.9431, 26.8734],\n",
      "        [25.2800, 30.1717],\n",
      "        [27.8839, 27.8474]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9808, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9690, 29.9440],\n",
      "        [31.9430, 26.8735],\n",
      "        [25.2799, 30.1717],\n",
      "        [27.8838, 27.8474]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9808, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9691, 29.9440],\n",
      "        [31.9431, 26.8735],\n",
      "        [25.2800, 30.1717],\n",
      "        [27.8839, 27.8474]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9808, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9690, 29.9441],\n",
      "        [31.9431, 26.8736],\n",
      "        [25.2800, 30.1718],\n",
      "        [27.8839, 27.8475]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9808, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9691, 29.9441],\n",
      "        [31.9432, 26.8736],\n",
      "        [25.2801, 30.1718],\n",
      "        [27.8839, 27.8474]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9808, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9691, 29.9441],\n",
      "        [31.9431, 26.8737],\n",
      "        [25.2800, 30.1718],\n",
      "        [27.8839, 27.8475]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9808, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9691, 29.9441],\n",
      "        [31.9432, 26.8737],\n",
      "        [25.2802, 30.1718],\n",
      "        [27.8839, 27.8475]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9808, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9691, 29.9442],\n",
      "        [31.9432, 26.8738],\n",
      "        [25.2801, 30.1718],\n",
      "        [27.8839, 27.8475]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9808, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9691, 29.9441],\n",
      "        [31.9433, 26.8738],\n",
      "        [25.2802, 30.1718],\n",
      "        [27.8840, 27.8475]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9808, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9691, 29.9442],\n",
      "        [31.9432, 26.8738],\n",
      "        [25.2802, 30.1719],\n",
      "        [27.8839, 27.8475]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9808, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9692, 29.9442],\n",
      "        [31.9433, 26.8738],\n",
      "        [25.2803, 30.1719],\n",
      "        [27.8840, 27.8475]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9809, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9691, 29.9442],\n",
      "        [31.9433, 26.8739],\n",
      "        [25.2802, 30.1719],\n",
      "        [27.8840, 27.8476]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9809, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9692, 29.9442],\n",
      "        [31.9434, 26.8739],\n",
      "        [25.2803, 30.1719],\n",
      "        [27.8840, 27.8476]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9809, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9692, 29.9442],\n",
      "        [31.9433, 26.8740],\n",
      "        [25.2803, 30.1720],\n",
      "        [27.8840, 27.8476]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9809, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9692, 29.9442],\n",
      "        [31.9434, 26.8740],\n",
      "        [25.2804, 30.1719],\n",
      "        [27.8840, 27.8476]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9809, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9692, 29.9443],\n",
      "        [31.9433, 26.8741],\n",
      "        [25.2803, 30.1720],\n",
      "        [27.8840, 27.8476]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9809, 0.1097, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9692, 29.9443],\n",
      "        [31.9435, 26.8741],\n",
      "        [25.2805, 30.1720],\n",
      "        [27.8841, 27.8476]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9809, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9692, 29.9443],\n",
      "        [31.9434, 26.8742],\n",
      "        [25.2804, 30.1720],\n",
      "        [27.8840, 27.8477]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9809, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9692, 29.9443],\n",
      "        [31.9435, 26.8742],\n",
      "        [25.2805, 30.1720],\n",
      "        [27.8841, 27.8477]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9809, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9692, 29.9443],\n",
      "        [31.9434, 26.8743],\n",
      "        [25.2805, 30.1720],\n",
      "        [27.8841, 27.8477]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9809, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9693, 29.9443],\n",
      "        [31.9435, 26.8743],\n",
      "        [25.2806, 30.1720],\n",
      "        [27.8841, 27.8477]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9809, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9692, 29.9444],\n",
      "        [31.9435, 26.8744],\n",
      "        [25.2805, 30.1721],\n",
      "        [27.8841, 27.8477]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9809, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9693, 29.9443],\n",
      "        [31.9436, 26.8744],\n",
      "        [25.2806, 30.1721],\n",
      "        [27.8841, 27.8477]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9809, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9693, 29.9444],\n",
      "        [31.9435, 26.8745],\n",
      "        [25.2806, 30.1721],\n",
      "        [27.8841, 27.8478]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9809, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9693, 29.9444],\n",
      "        [31.9436, 26.8745],\n",
      "        [25.2807, 30.1721],\n",
      "        [27.8842, 27.8478]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9810, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9693, 29.9444],\n",
      "        [31.9436, 26.8746],\n",
      "        [25.2807, 30.1722],\n",
      "        [27.8842, 27.8478]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9810, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9693, 29.9444],\n",
      "        [31.9437, 26.8745],\n",
      "        [25.2807, 30.1721],\n",
      "        [27.8842, 27.8478]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9810, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9693, 29.9444],\n",
      "        [31.9436, 26.8746],\n",
      "        [25.2807, 30.1722],\n",
      "        [27.8842, 27.8478]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9810, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9694, 29.9444],\n",
      "        [31.9437, 26.8746],\n",
      "        [25.2808, 30.1722],\n",
      "        [27.8842, 27.8478]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9810, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9693, 29.9445],\n",
      "        [31.9437, 26.8747],\n",
      "        [25.2808, 30.1722],\n",
      "        [27.8842, 27.8479]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9810, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9694, 29.9445],\n",
      "        [31.9438, 26.8747],\n",
      "        [25.2809, 30.1722],\n",
      "        [27.8843, 27.8479]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9810, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9694, 29.9445],\n",
      "        [31.9437, 26.8748],\n",
      "        [25.2808, 30.1723],\n",
      "        [27.8842, 27.8479]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9810, 0.1098, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9694, 29.9445],\n",
      "        [31.9438, 26.8748],\n",
      "        [25.2809, 30.1723],\n",
      "        [27.8843, 27.8479]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9810, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9694, 29.9445],\n",
      "        [31.9438, 26.8749],\n",
      "        [25.2809, 30.1723],\n",
      "        [27.8843, 27.8479]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9810, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9694, 29.9445],\n",
      "        [31.9439, 26.8749],\n",
      "        [25.2810, 30.1723],\n",
      "        [27.8843, 27.8479]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9810, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9694, 29.9446],\n",
      "        [31.9438, 26.8750],\n",
      "        [25.2810, 30.1723],\n",
      "        [27.8843, 27.8479]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9810, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9695, 29.9446],\n",
      "        [31.9439, 26.8750],\n",
      "        [25.2811, 30.1723],\n",
      "        [27.8843, 27.8480]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9811, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9694, 29.9446],\n",
      "        [31.9439, 26.8751],\n",
      "        [25.2810, 30.1724],\n",
      "        [27.8843, 27.8480]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9811, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9695, 29.9446],\n",
      "        [31.9440, 26.8751],\n",
      "        [25.2811, 30.1724],\n",
      "        [27.8844, 27.8480]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9811, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9694, 29.9446],\n",
      "        [31.9439, 26.8752],\n",
      "        [25.2811, 30.1724],\n",
      "        [27.8843, 27.8480]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9811, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9695, 29.9446],\n",
      "        [31.9440, 26.8752],\n",
      "        [25.2812, 30.1724],\n",
      "        [27.8844, 27.8480]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9811, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9695, 29.9447],\n",
      "        [31.9439, 26.8752],\n",
      "        [25.2811, 30.1725],\n",
      "        [27.8844, 27.8481]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9811, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9695, 29.9446],\n",
      "        [31.9441, 26.8752],\n",
      "        [25.2812, 30.1724],\n",
      "        [27.8844, 27.8480]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9811, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9695, 29.9447],\n",
      "        [31.9440, 26.8753],\n",
      "        [25.2812, 30.1725],\n",
      "        [27.8844, 27.8481]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9811, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9695, 29.9447],\n",
      "        [31.9441, 26.8753],\n",
      "        [25.2813, 30.1725],\n",
      "        [27.8844, 27.8481]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9811, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9695, 29.9447],\n",
      "        [31.9440, 26.8754],\n",
      "        [25.2813, 30.1725],\n",
      "        [27.8844, 27.8481]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9811, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9696, 29.9447],\n",
      "        [31.9441, 26.8754],\n",
      "        [25.2814, 30.1725],\n",
      "        [27.8845, 27.8481]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9811, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9695, 29.9447],\n",
      "        [31.9441, 26.8755],\n",
      "        [25.2813, 30.1725],\n",
      "        [27.8844, 27.8481]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9811, 0.1099, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9696, 29.9447],\n",
      "        [31.9442, 26.8755],\n",
      "        [25.2814, 30.1725],\n",
      "        [27.8845, 27.8481]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9811, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9696, 29.9448],\n",
      "        [31.9441, 26.8756],\n",
      "        [25.2814, 30.1726],\n",
      "        [27.8845, 27.8482]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9811, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9696, 29.9448],\n",
      "        [31.9442, 26.8756],\n",
      "        [25.2815, 30.1726],\n",
      "        [27.8845, 27.8482]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9696, 29.9448],\n",
      "        [31.9442, 26.8757],\n",
      "        [25.2814, 30.1726],\n",
      "        [27.8845, 27.8482]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9696, 29.9448],\n",
      "        [31.9443, 26.8757],\n",
      "        [25.2815, 30.1726],\n",
      "        [27.8846, 27.8482]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9696, 29.9448],\n",
      "        [31.9442, 26.8758],\n",
      "        [25.2815, 30.1727],\n",
      "        [27.8845, 27.8482]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9696, 29.9448],\n",
      "        [31.9443, 26.8757],\n",
      "        [25.2816, 30.1726],\n",
      "        [27.8846, 27.8482]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9696, 29.9448],\n",
      "        [31.9443, 26.8758],\n",
      "        [25.2815, 30.1727],\n",
      "        [27.8845, 27.8482]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9697, 29.9449],\n",
      "        [31.9444, 26.8758],\n",
      "        [25.2817, 30.1727],\n",
      "        [27.8846, 27.8483]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9696, 29.9449],\n",
      "        [31.9443, 26.8759],\n",
      "        [25.2816, 30.1727],\n",
      "        [27.8846, 27.8483]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9697, 29.9449],\n",
      "        [31.9444, 26.8759],\n",
      "        [25.2817, 30.1727],\n",
      "        [27.8846, 27.8483]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9697, 29.9449],\n",
      "        [31.9443, 26.8760],\n",
      "        [25.2817, 30.1728],\n",
      "        [27.8846, 27.8483]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9697, 29.9449],\n",
      "        [31.9444, 26.8760],\n",
      "        [25.2818, 30.1727],\n",
      "        [27.8846, 27.8483]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9697, 29.9449],\n",
      "        [31.9444, 26.8761],\n",
      "        [25.2817, 30.1728],\n",
      "        [27.8846, 27.8484]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9697, 29.9449],\n",
      "        [31.9445, 26.8761],\n",
      "        [25.2818, 30.1728],\n",
      "        [27.8847, 27.8483]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9697, 29.9450],\n",
      "        [31.9444, 26.8762],\n",
      "        [25.2818, 30.1728],\n",
      "        [27.8847, 27.8484]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9812, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9698, 29.9450],\n",
      "        [31.9445, 26.8762],\n",
      "        [25.2819, 30.1728],\n",
      "        [27.8847, 27.8484]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9813, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9697, 29.9450],\n",
      "        [31.9445, 26.8763],\n",
      "        [25.2819, 30.1729],\n",
      "        [27.8847, 27.8484]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9813, 0.1100, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9698, 29.9450],\n",
      "        [31.9446, 26.8763],\n",
      "        [25.2820, 30.1729],\n",
      "        [27.8847, 27.8484]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9813, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9698, 29.9450],\n",
      "        [31.9445, 26.8764],\n",
      "        [25.2819, 30.1729],\n",
      "        [27.8847, 27.8484]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9813, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9698, 29.9450],\n",
      "        [31.9446, 26.8763],\n",
      "        [25.2820, 30.1729],\n",
      "        [27.8848, 27.8484]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9813, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9698, 29.9451],\n",
      "        [31.9446, 26.8764],\n",
      "        [25.2820, 30.1729],\n",
      "        [27.8847, 27.8485]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9813, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9698, 29.9451],\n",
      "        [31.9447, 26.8764],\n",
      "        [25.2821, 30.1729],\n",
      "        [27.8848, 27.8485]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9813, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9698, 29.9451],\n",
      "        [31.9446, 26.8765],\n",
      "        [25.2820, 30.1730],\n",
      "        [27.8848, 27.8485]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9813, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9699, 29.9451],\n",
      "        [31.9447, 26.8765],\n",
      "        [25.2821, 30.1730],\n",
      "        [27.8848, 27.8485]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9813, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9698, 29.9451],\n",
      "        [31.9447, 26.8766],\n",
      "        [25.2821, 30.1730],\n",
      "        [27.8848, 27.8485]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9813, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9699, 29.9451],\n",
      "        [31.9448, 26.8766],\n",
      "        [25.2822, 30.1730],\n",
      "        [27.8848, 27.8485]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9813, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9699, 29.9452],\n",
      "        [31.9447, 26.8767],\n",
      "        [25.2822, 30.1730],\n",
      "        [27.8848, 27.8486]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9813, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9699, 29.9451],\n",
      "        [31.9448, 26.8767],\n",
      "        [25.2822, 30.1730],\n",
      "        [27.8849, 27.8486]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9814, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9699, 29.9452],\n",
      "        [31.9448, 26.8768],\n",
      "        [25.2822, 30.1731],\n",
      "        [27.8849, 27.8486]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9814, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9699, 29.9452],\n",
      "        [31.9449, 26.8768],\n",
      "        [25.2823, 30.1731],\n",
      "        [27.8849, 27.8486]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9814, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9699, 29.9452],\n",
      "        [31.9448, 26.8768],\n",
      "        [25.2823, 30.1731],\n",
      "        [27.8849, 27.8486]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9814, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9699, 29.9452],\n",
      "        [31.9449, 26.8768],\n",
      "        [25.2824, 30.1731],\n",
      "        [27.8849, 27.8486]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9814, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9699, 29.9452],\n",
      "        [31.9448, 26.8769],\n",
      "        [25.2823, 30.1731],\n",
      "        [27.8849, 27.8487]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9814, 0.1101, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9700, 29.9452],\n",
      "        [31.9449, 26.8769],\n",
      "        [25.2824, 30.1731],\n",
      "        [27.8849, 27.8486]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9814, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9699, 29.9453],\n",
      "        [31.9449, 26.8770],\n",
      "        [25.2824, 30.1732],\n",
      "        [27.8849, 27.8487]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9814, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9700, 29.9453],\n",
      "        [31.9450, 26.8770],\n",
      "        [25.2825, 30.1732],\n",
      "        [27.8850, 27.8487]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9814, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9700, 29.9453],\n",
      "        [31.9449, 26.8771],\n",
      "        [25.2824, 30.1732],\n",
      "        [27.8849, 27.8487]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9814, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9700, 29.9453],\n",
      "        [31.9450, 26.8771],\n",
      "        [25.2825, 30.1732],\n",
      "        [27.8850, 27.8487]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9814, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9700, 29.9453],\n",
      "        [31.9450, 26.8772],\n",
      "        [25.2825, 30.1732],\n",
      "        [27.8850, 27.8487]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9814, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9700, 29.9453],\n",
      "        [31.9451, 26.8772],\n",
      "        [25.2826, 30.1732],\n",
      "        [27.8850, 27.8488]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9814, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9700, 29.9454],\n",
      "        [31.9450, 26.8773],\n",
      "        [25.2826, 30.1733],\n",
      "        [27.8850, 27.8488]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9814, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9700, 29.9453],\n",
      "        [31.9451, 26.8773],\n",
      "        [25.2827, 30.1733],\n",
      "        [27.8850, 27.8488]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9815, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9700, 29.9454],\n",
      "        [31.9451, 26.8774],\n",
      "        [25.2826, 30.1733],\n",
      "        [27.8850, 27.8488]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9815, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9701, 29.9454],\n",
      "        [31.9452, 26.8774],\n",
      "        [25.2827, 30.1733],\n",
      "        [27.8851, 27.8488]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9815, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9701, 29.9454],\n",
      "        [31.9451, 26.8774],\n",
      "        [25.2827, 30.1734],\n",
      "        [27.8850, 27.8488]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9815, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9701, 29.9454],\n",
      "        [31.9452, 26.8775],\n",
      "        [25.2828, 30.1733],\n",
      "        [27.8851, 27.8489]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9815, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9701, 29.9454],\n",
      "        [31.9452, 26.8775],\n",
      "        [25.2827, 30.1734],\n",
      "        [27.8851, 27.8489]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9815, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9701, 29.9454],\n",
      "        [31.9452, 26.8775],\n",
      "        [25.2828, 30.1734],\n",
      "        [27.8851, 27.8489]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9815, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9701, 29.9455],\n",
      "        [31.9452, 26.8776],\n",
      "        [25.2828, 30.1734],\n",
      "        [27.8851, 27.8489]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9815, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9701, 29.9455],\n",
      "        [31.9453, 26.8776],\n",
      "        [25.2829, 30.1734],\n",
      "        [27.8851, 27.8489]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9815, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9701, 29.9455],\n",
      "        [31.9452, 26.8777],\n",
      "        [25.2829, 30.1734],\n",
      "        [27.8851, 27.8489]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9815, 0.1102, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9702, 29.9455],\n",
      "        [31.9453, 26.8777],\n",
      "        [25.2830, 30.1735],\n",
      "        [27.8852, 27.8489]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9815, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9701, 29.9455],\n",
      "        [31.9453, 26.8778],\n",
      "        [25.2829, 30.1735],\n",
      "        [27.8851, 27.8490]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9815, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9702, 29.9455],\n",
      "        [31.9454, 26.8778],\n",
      "        [25.2830, 30.1735],\n",
      "        [27.8852, 27.8490]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9815, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9702, 29.9456],\n",
      "        [31.9453, 26.8779],\n",
      "        [25.2830, 30.1735],\n",
      "        [27.8852, 27.8490]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9815, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9702, 29.9456],\n",
      "        [31.9454, 26.8779],\n",
      "        [25.2831, 30.1735],\n",
      "        [27.8852, 27.8490]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9816, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9702, 29.9456],\n",
      "        [31.9454, 26.8779],\n",
      "        [25.2830, 30.1736],\n",
      "        [27.8852, 27.8490]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9816, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9702, 29.9456],\n",
      "        [31.9455, 26.8779],\n",
      "        [25.2831, 30.1735],\n",
      "        [27.8853, 27.8490]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9816, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9702, 29.9456],\n",
      "        [31.9454, 26.8780],\n",
      "        [25.2831, 30.1736],\n",
      "        [27.8852, 27.8491]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9816, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9702, 29.9456],\n",
      "        [31.9455, 26.8780],\n",
      "        [25.2832, 30.1736],\n",
      "        [27.8853, 27.8491]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9816, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9702, 29.9456],\n",
      "        [31.9454, 26.8781],\n",
      "        [25.2832, 30.1736],\n",
      "        [27.8853, 27.8491]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9816, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9703, 29.9456],\n",
      "        [31.9456, 26.8781],\n",
      "        [25.2833, 30.1736],\n",
      "        [27.8853, 27.8491]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9816, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9702, 29.9457],\n",
      "        [31.9455, 26.8782],\n",
      "        [25.2832, 30.1736],\n",
      "        [27.8853, 27.8491]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9816, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9703, 29.9456],\n",
      "        [31.9456, 26.8782],\n",
      "        [25.2833, 30.1736],\n",
      "        [27.8853, 27.8491]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9816, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9703, 29.9457],\n",
      "        [31.9455, 26.8783],\n",
      "        [25.2833, 30.1737],\n",
      "        [27.8853, 27.8491]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9816, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9703, 29.9457],\n",
      "        [31.9456, 26.8783],\n",
      "        [25.2834, 30.1737],\n",
      "        [27.8853, 27.8491]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9816, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9703, 29.9457],\n",
      "        [31.9456, 26.8783],\n",
      "        [25.2833, 30.1737],\n",
      "        [27.8853, 27.8492]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9816, 0.1103, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9703, 29.9457],\n",
      "        [31.9457, 26.8784],\n",
      "        [25.2834, 30.1737],\n",
      "        [27.8854, 27.8492]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9816, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9703, 29.9458],\n",
      "        [31.9456, 26.8784],\n",
      "        [25.2834, 30.1738],\n",
      "        [27.8854, 27.8492]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9816, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9703, 29.9457],\n",
      "        [31.9457, 26.8784],\n",
      "        [25.2835, 30.1737],\n",
      "        [27.8854, 27.8492]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9703, 29.9458],\n",
      "        [31.9457, 26.8785],\n",
      "        [25.2834, 30.1738],\n",
      "        [27.8854, 27.8492]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9704, 29.9458],\n",
      "        [31.9458, 26.8785],\n",
      "        [25.2835, 30.1738],\n",
      "        [27.8854, 27.8492]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9703, 29.9458],\n",
      "        [31.9457, 26.8786],\n",
      "        [25.2835, 30.1738],\n",
      "        [27.8854, 27.8493]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9704, 29.9458],\n",
      "        [31.9458, 26.8786],\n",
      "        [25.2836, 30.1738],\n",
      "        [27.8854, 27.8493]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9704, 29.9458],\n",
      "        [31.9457, 26.8787],\n",
      "        [25.2836, 30.1739],\n",
      "        [27.8854, 27.8493]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9704, 29.9458],\n",
      "        [31.9458, 26.8787],\n",
      "        [25.2836, 30.1738],\n",
      "        [27.8855, 27.8493]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9704, 29.9459],\n",
      "        [31.9458, 26.8788],\n",
      "        [25.2836, 30.1739],\n",
      "        [27.8854, 27.8493]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9704, 29.9459],\n",
      "        [31.9459, 26.8788],\n",
      "        [25.2837, 30.1739],\n",
      "        [27.8855, 27.8493]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9704, 29.9459],\n",
      "        [31.9458, 26.8788],\n",
      "        [25.2837, 30.1739],\n",
      "        [27.8855, 27.8493]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9705, 29.9459],\n",
      "        [31.9459, 26.8788],\n",
      "        [25.2838, 30.1739],\n",
      "        [27.8855, 27.8494]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9704, 29.9459],\n",
      "        [31.9459, 26.8789],\n",
      "        [25.2837, 30.1740],\n",
      "        [27.8855, 27.8494]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9705, 29.9459],\n",
      "        [31.9460, 26.8789],\n",
      "        [25.2838, 30.1739],\n",
      "        [27.8855, 27.8494]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9705, 29.9460],\n",
      "        [31.9459, 26.8790],\n",
      "        [25.2838, 30.1740],\n",
      "        [27.8855, 27.8494]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9817, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9705, 29.9459],\n",
      "        [31.9460, 26.8790],\n",
      "        [25.2839, 30.1740],\n",
      "        [27.8856, 27.8494]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9818, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9705, 29.9460],\n",
      "        [31.9459, 26.8791],\n",
      "        [25.2838, 30.1740],\n",
      "        [27.8855, 27.8494]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9818, 0.1104, 0.9620], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9705, 29.9460],\n",
      "        [31.9461, 26.8791],\n",
      "        [25.2839, 30.1740],\n",
      "        [27.8856, 27.8495]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9818, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9705, 29.9460],\n",
      "        [31.9460, 26.8792],\n",
      "        [25.2839, 30.1741],\n",
      "        [27.8856, 27.8495]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9818, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9705, 29.9460],\n",
      "        [31.9461, 26.8792],\n",
      "        [25.2840, 30.1740],\n",
      "        [27.8856, 27.8495]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9818, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9705, 29.9460],\n",
      "        [31.9461, 26.8793],\n",
      "        [25.2840, 30.1741],\n",
      "        [27.8856, 27.8495]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9818, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9706, 29.9460],\n",
      "        [31.9462, 26.8792],\n",
      "        [25.2841, 30.1741],\n",
      "        [27.8857, 27.8495]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9818, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9706, 29.9461],\n",
      "        [31.9461, 26.8793],\n",
      "        [25.2840, 30.1741],\n",
      "        [27.8856, 27.8495]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9818, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9706, 29.9461],\n",
      "        [31.9462, 26.8793],\n",
      "        [25.2841, 30.1741],\n",
      "        [27.8857, 27.8495]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9818, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9706, 29.9461],\n",
      "        [31.9461, 26.8794],\n",
      "        [25.2841, 30.1742],\n",
      "        [27.8857, 27.8496]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9818, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9706, 29.9461],\n",
      "        [31.9462, 26.8794],\n",
      "        [25.2842, 30.1742],\n",
      "        [27.8857, 27.8496]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9818, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9706, 29.9461],\n",
      "        [31.9462, 26.8795],\n",
      "        [25.2841, 30.1742],\n",
      "        [27.8857, 27.8496]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9818, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9706, 29.9461],\n",
      "        [31.9463, 26.8795],\n",
      "        [25.2842, 30.1742],\n",
      "        [27.8857, 27.8496]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9818, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9706, 29.9461],\n",
      "        [31.9462, 26.8796],\n",
      "        [25.2842, 30.1742],\n",
      "        [27.8857, 27.8496]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9818, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9706, 29.9461],\n",
      "        [31.9463, 26.8796],\n",
      "        [25.2843, 30.1742],\n",
      "        [27.8857, 27.8496]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9819, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9706, 29.9462],\n",
      "        [31.9462, 26.8796],\n",
      "        [25.2842, 30.1743],\n",
      "        [27.8857, 27.8496]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9819, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9707, 29.9462],\n",
      "        [31.9464, 26.8796],\n",
      "        [25.2843, 30.1742],\n",
      "        [27.8858, 27.8497]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9819, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9707, 29.9462],\n",
      "        [31.9463, 26.8797],\n",
      "        [25.2843, 30.1743],\n",
      "        [27.8858, 27.8497]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9819, 0.1105, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9707, 29.9462],\n",
      "        [31.9464, 26.8797],\n",
      "        [25.2844, 30.1743],\n",
      "        [27.8858, 27.8497]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9819, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9707, 29.9462],\n",
      "        [31.9463, 26.8798],\n",
      "        [25.2844, 30.1743],\n",
      "        [27.8858, 27.8497]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9819, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9707, 29.9462],\n",
      "        [31.9464, 26.8798],\n",
      "        [25.2845, 30.1743],\n",
      "        [27.8858, 27.8497]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9819, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9707, 29.9462],\n",
      "        [31.9464, 26.8799],\n",
      "        [25.2844, 30.1744],\n",
      "        [27.8858, 27.8497]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9819, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9707, 29.9463],\n",
      "        [31.9465, 26.8799],\n",
      "        [25.2845, 30.1743],\n",
      "        [27.8858, 27.8497]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9819, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9707, 29.9463],\n",
      "        [31.9464, 26.8800],\n",
      "        [25.2845, 30.1744],\n",
      "        [27.8858, 27.8498]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9819, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9708, 29.9463],\n",
      "        [31.9465, 26.8800],\n",
      "        [25.2846, 30.1744],\n",
      "        [27.8859, 27.8498]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9819, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9707, 29.9463],\n",
      "        [31.9465, 26.8800],\n",
      "        [25.2845, 30.1744],\n",
      "        [27.8859, 27.8498]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9819, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9708, 29.9463],\n",
      "        [31.9466, 26.8800],\n",
      "        [25.2846, 30.1744],\n",
      "        [27.8859, 27.8498]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9819, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9707, 29.9463],\n",
      "        [31.9465, 26.8801],\n",
      "        [25.2846, 30.1745],\n",
      "        [27.8859, 27.8498]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9819, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9708, 29.9463],\n",
      "        [31.9466, 26.8801],\n",
      "        [25.2847, 30.1744],\n",
      "        [27.8859, 27.8498]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9820, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9708, 29.9464],\n",
      "        [31.9465, 26.8802],\n",
      "        [25.2847, 30.1745],\n",
      "        [27.8859, 27.8499]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9820, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9708, 29.9464],\n",
      "        [31.9467, 26.8802],\n",
      "        [25.2848, 30.1745],\n",
      "        [27.8860, 27.8499]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9820, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9708, 29.9464],\n",
      "        [31.9466, 26.8803],\n",
      "        [25.2847, 30.1745],\n",
      "        [27.8859, 27.8499]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9820, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9708, 29.9464],\n",
      "        [31.9467, 26.8803],\n",
      "        [25.2848, 30.1745],\n",
      "        [27.8860, 27.8499]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9820, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9708, 29.9464],\n",
      "        [31.9466, 26.8804],\n",
      "        [25.2848, 30.1746],\n",
      "        [27.8860, 27.8499]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9820, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9709, 29.9464],\n",
      "        [31.9467, 26.8804],\n",
      "        [25.2849, 30.1745],\n",
      "        [27.8860, 27.8499]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9820, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9708, 29.9464],\n",
      "        [31.9467, 26.8804],\n",
      "        [25.2848, 30.1746],\n",
      "        [27.8860, 27.8499]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9820, 0.1106, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9709, 29.9465],\n",
      "        [31.9468, 26.8804],\n",
      "        [25.2849, 30.1746],\n",
      "        [27.8860, 27.8500]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9820, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9709, 29.9465],\n",
      "        [31.9467, 26.8805],\n",
      "        [25.2849, 30.1746],\n",
      "        [27.8860, 27.8500]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9820, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9709, 29.9465],\n",
      "        [31.9468, 26.8805],\n",
      "        [25.2850, 30.1746],\n",
      "        [27.8861, 27.8500]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9820, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9709, 29.9465],\n",
      "        [31.9468, 26.8806],\n",
      "        [25.2849, 30.1747],\n",
      "        [27.8860, 27.8500]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9820, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9709, 29.9465],\n",
      "        [31.9469, 26.8806],\n",
      "        [25.2850, 30.1746],\n",
      "        [27.8861, 27.8500]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9820, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9709, 29.9465],\n",
      "        [31.9468, 26.8807],\n",
      "        [25.2850, 30.1747],\n",
      "        [27.8860, 27.8500]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9820, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9709, 29.9465],\n",
      "        [31.9469, 26.8807],\n",
      "        [25.2851, 30.1747],\n",
      "        [27.8861, 27.8500]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9820, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9709, 29.9466],\n",
      "        [31.9468, 26.8808],\n",
      "        [25.2850, 30.1747],\n",
      "        [27.8861, 27.8501]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9820, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9710, 29.9466],\n",
      "        [31.9469, 26.8808],\n",
      "        [25.2851, 30.1747],\n",
      "        [27.8861, 27.8501]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9821, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9710, 29.9466],\n",
      "        [31.9469, 26.8808],\n",
      "        [25.2851, 30.1748],\n",
      "        [27.8861, 27.8501]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9821, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9710, 29.9466],\n",
      "        [31.9470, 26.8808],\n",
      "        [25.2852, 30.1747],\n",
      "        [27.8861, 27.8501]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9821, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9710, 29.9466],\n",
      "        [31.9469, 26.8809],\n",
      "        [25.2852, 30.1748],\n",
      "        [27.8861, 27.8501]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9821, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9710, 29.9466],\n",
      "        [31.9470, 26.8809],\n",
      "        [25.2852, 30.1748],\n",
      "        [27.8862, 27.8501]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9821, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9710, 29.9466],\n",
      "        [31.9470, 26.8810],\n",
      "        [25.2852, 30.1748],\n",
      "        [27.8861, 27.8501]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9821, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9710, 29.9466],\n",
      "        [31.9470, 26.8810],\n",
      "        [25.2853, 30.1748],\n",
      "        [27.8862, 27.8501]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9821, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9710, 29.9467],\n",
      "        [31.9470, 26.8811],\n",
      "        [25.2853, 30.1748],\n",
      "        [27.8862, 27.8502]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9821, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9710, 29.9467],\n",
      "        [31.9471, 26.8811],\n",
      "        [25.2854, 30.1748],\n",
      "        [27.8862, 27.8502]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9984, 0.9821, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9710, 29.9467],\n",
      "        [31.9470, 26.8811],\n",
      "        [25.2853, 30.1749],\n",
      "        [27.8862, 27.8502]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9984, 0.9821, 0.1107, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9711, 29.9467],\n",
      "        [31.9471, 26.8811],\n",
      "        [25.2854, 30.1749],\n",
      "        [27.8862, 27.8502]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9821, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9710, 29.9467],\n",
      "        [31.9471, 26.8812],\n",
      "        [25.2854, 30.1749],\n",
      "        [27.8862, 27.8502]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9821, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9711, 29.9467],\n",
      "        [31.9472, 26.8812],\n",
      "        [25.2855, 30.1749],\n",
      "        [27.8863, 27.8502]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9821, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9711, 29.9468],\n",
      "        [31.9471, 26.8813],\n",
      "        [25.2855, 30.1750],\n",
      "        [27.8862, 27.8503]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9821, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9711, 29.9467],\n",
      "        [31.9472, 26.8813],\n",
      "        [25.2855, 30.1749],\n",
      "        [27.8863, 27.8503]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9822, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9711, 29.9468],\n",
      "        [31.9472, 26.8814],\n",
      "        [25.2855, 30.1750],\n",
      "        [27.8863, 27.8503]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9822, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9711, 29.9468],\n",
      "        [31.9473, 26.8814],\n",
      "        [25.2856, 30.1750],\n",
      "        [27.8863, 27.8503]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9822, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9711, 29.9468],\n",
      "        [31.9472, 26.8815],\n",
      "        [25.2856, 30.1750],\n",
      "        [27.8863, 27.8503]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9822, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9712, 29.9468],\n",
      "        [31.9473, 26.8815],\n",
      "        [25.2857, 30.1750],\n",
      "        [27.8863, 27.8503]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9822, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9711, 29.9468],\n",
      "        [31.9472, 26.8815],\n",
      "        [25.2856, 30.1750],\n",
      "        [27.8863, 27.8503]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9822, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9712, 29.9468],\n",
      "        [31.9473, 26.8815],\n",
      "        [25.2857, 30.1750],\n",
      "        [27.8864, 27.8504]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9822, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9712, 29.9469],\n",
      "        [31.9473, 26.8816],\n",
      "        [25.2857, 30.1751],\n",
      "        [27.8863, 27.8504]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9822, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9712, 29.9469],\n",
      "        [31.9474, 26.8816],\n",
      "        [25.2858, 30.1751],\n",
      "        [27.8864, 27.8504]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9822, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9712, 29.9469],\n",
      "        [31.9473, 26.8817],\n",
      "        [25.2857, 30.1751],\n",
      "        [27.8864, 27.8504]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9822, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9712, 29.9469],\n",
      "        [31.9474, 26.8817],\n",
      "        [25.2858, 30.1751],\n",
      "        [27.8864, 27.8504]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9822, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9712, 29.9469],\n",
      "        [31.9474, 26.8818],\n",
      "        [25.2858, 30.1752],\n",
      "        [27.8864, 27.8505]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9822, 0.1108, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9712, 29.9469],\n",
      "        [31.9475, 26.8818],\n",
      "        [25.2859, 30.1751],\n",
      "        [27.8864, 27.8504]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9822, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9712, 29.9469],\n",
      "        [31.9474, 26.8818],\n",
      "        [25.2858, 30.1752],\n",
      "        [27.8864, 27.8505]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9822, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9713, 29.9470],\n",
      "        [31.9475, 26.8818],\n",
      "        [25.2859, 30.1752],\n",
      "        [27.8865, 27.8505]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9822, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9712, 29.9470],\n",
      "        [31.9474, 26.8819],\n",
      "        [25.2859, 30.1752],\n",
      "        [27.8864, 27.8505]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9822, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9713, 29.9470],\n",
      "        [31.9475, 26.8819],\n",
      "        [25.2860, 30.1752],\n",
      "        [27.8865, 27.8505]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9713, 29.9470],\n",
      "        [31.9475, 26.8820],\n",
      "        [25.2860, 30.1752],\n",
      "        [27.8865, 27.8505]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9713, 29.9470],\n",
      "        [31.9476, 26.8820],\n",
      "        [25.2860, 30.1752],\n",
      "        [27.8865, 27.8505]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9713, 29.9470],\n",
      "        [31.9475, 26.8821],\n",
      "        [25.2860, 30.1753],\n",
      "        [27.8865, 27.8506]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9713, 29.9470],\n",
      "        [31.9476, 26.8821],\n",
      "        [25.2861, 30.1753],\n",
      "        [27.8865, 27.8506]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9713, 29.9471],\n",
      "        [31.9476, 26.8822],\n",
      "        [25.2861, 30.1753],\n",
      "        [27.8865, 27.8506]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9713, 29.9471],\n",
      "        [31.9477, 26.8822],\n",
      "        [25.2862, 30.1753],\n",
      "        [27.8866, 27.8506]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9713, 29.9471],\n",
      "        [31.9476, 26.8822],\n",
      "        [25.2861, 30.1753],\n",
      "        [27.8865, 27.8506]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9713, 29.9471],\n",
      "        [31.9477, 26.8822],\n",
      "        [25.2862, 30.1753],\n",
      "        [27.8866, 27.8506]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9713, 29.9471],\n",
      "        [31.9476, 26.8823],\n",
      "        [25.2862, 30.1754],\n",
      "        [27.8865, 27.8506]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9714, 29.9471],\n",
      "        [31.9477, 26.8823],\n",
      "        [25.2863, 30.1754],\n",
      "        [27.8866, 27.8506]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9713, 29.9471],\n",
      "        [31.9477, 26.8824],\n",
      "        [25.2862, 30.1754],\n",
      "        [27.8866, 27.8507]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9714, 29.9471],\n",
      "        [31.9478, 26.8824],\n",
      "        [25.2863, 30.1754],\n",
      "        [27.8866, 27.8507]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9714, 29.9472],\n",
      "        [31.9477, 26.8825],\n",
      "        [25.2863, 30.1754],\n",
      "        [27.8866, 27.8507]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9823, 0.1109, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9714, 29.9472],\n",
      "        [31.9478, 26.8825],\n",
      "        [25.2864, 30.1754],\n",
      "        [27.8866, 27.8507]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9714, 29.9472],\n",
      "        [31.9478, 26.8825],\n",
      "        [25.2863, 30.1755],\n",
      "        [27.8866, 27.8507]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9714, 29.9472],\n",
      "        [31.9479, 26.8825],\n",
      "        [25.2864, 30.1754],\n",
      "        [27.8867, 27.8507]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9714, 29.9472],\n",
      "        [31.9478, 26.8826],\n",
      "        [25.2864, 30.1755],\n",
      "        [27.8867, 27.8508]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9714, 29.9472],\n",
      "        [31.9479, 26.8826],\n",
      "        [25.2865, 30.1755],\n",
      "        [27.8867, 27.8507]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9714, 29.9472],\n",
      "        [31.9478, 26.8827],\n",
      "        [25.2865, 30.1755],\n",
      "        [27.8867, 27.8508]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9715, 29.9472],\n",
      "        [31.9479, 26.8827],\n",
      "        [25.2865, 30.1755],\n",
      "        [27.8867, 27.8508]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9714, 29.9473],\n",
      "        [31.9479, 26.8828],\n",
      "        [25.2865, 30.1756],\n",
      "        [27.8867, 27.8508]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9715, 29.9473],\n",
      "        [31.9480, 26.8828],\n",
      "        [25.2866, 30.1756],\n",
      "        [27.8867, 27.8508]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9715, 29.9473],\n",
      "        [31.9479, 26.8828],\n",
      "        [25.2866, 30.1756],\n",
      "        [27.8867, 27.8508]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9715, 29.9473],\n",
      "        [31.9480, 26.8828],\n",
      "        [25.2867, 30.1756],\n",
      "        [27.8868, 27.8508]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9715, 29.9473],\n",
      "        [31.9480, 26.8829],\n",
      "        [25.2866, 30.1756],\n",
      "        [27.8867, 27.8509]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9715, 29.9473],\n",
      "        [31.9480, 26.8829],\n",
      "        [25.2867, 30.1756],\n",
      "        [27.8868, 27.8509]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9715, 29.9474],\n",
      "        [31.9480, 26.8830],\n",
      "        [25.2867, 30.1757],\n",
      "        [27.8868, 27.8509]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9715, 29.9473],\n",
      "        [31.9481, 26.8830],\n",
      "        [25.2868, 30.1756],\n",
      "        [27.8868, 27.8509]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9715, 29.9474],\n",
      "        [31.9480, 26.8831],\n",
      "        [25.2867, 30.1757],\n",
      "        [27.8868, 27.8509]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9824, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9716, 29.9474],\n",
      "        [31.9481, 26.8831],\n",
      "        [25.2868, 30.1757],\n",
      "        [27.8868, 27.8509]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9825, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9716, 29.9474],\n",
      "        [31.9481, 26.8831],\n",
      "        [25.2868, 30.1757],\n",
      "        [27.8868, 27.8510]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9825, 0.1110, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9716, 29.9474],\n",
      "        [31.9482, 26.8831],\n",
      "        [25.2869, 30.1757],\n",
      "        [27.8869, 27.8510]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9825, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9716, 29.9474],\n",
      "        [31.9481, 26.8832],\n",
      "        [25.2868, 30.1758],\n",
      "        [27.8868, 27.8510]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9825, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9716, 29.9474],\n",
      "        [31.9482, 26.8832],\n",
      "        [25.2869, 30.1757],\n",
      "        [27.8869, 27.8510]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9825, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9716, 29.9475],\n",
      "        [31.9482, 26.8833],\n",
      "        [25.2869, 30.1758],\n",
      "        [27.8869, 27.8510]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9825, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9716, 29.9475],\n",
      "        [31.9483, 26.8833],\n",
      "        [25.2870, 30.1758],\n",
      "        [27.8869, 27.8510]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9825, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9716, 29.9475],\n",
      "        [31.9482, 26.8834],\n",
      "        [25.2870, 30.1758],\n",
      "        [27.8869, 27.8510]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9825, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9717, 29.9475],\n",
      "        [31.9483, 26.8834],\n",
      "        [25.2871, 30.1758],\n",
      "        [27.8869, 27.8510]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9825, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9716, 29.9475],\n",
      "        [31.9482, 26.8834],\n",
      "        [25.2870, 30.1758],\n",
      "        [27.8869, 27.8511]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9825, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9717, 29.9475],\n",
      "        [31.9483, 26.8834],\n",
      "        [25.2871, 30.1758],\n",
      "        [27.8870, 27.8511]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9825, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9717, 29.9475],\n",
      "        [31.9483, 26.8835],\n",
      "        [25.2871, 30.1759],\n",
      "        [27.8869, 27.8511]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9825, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9717, 29.9476],\n",
      "        [31.9484, 26.8835],\n",
      "        [25.2872, 30.1759],\n",
      "        [27.8870, 27.8511]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9825, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9717, 29.9476],\n",
      "        [31.9483, 26.8836],\n",
      "        [25.2871, 30.1759],\n",
      "        [27.8869, 27.8511]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9825, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9717, 29.9475],\n",
      "        [31.9484, 26.8836],\n",
      "        [25.2872, 30.1759],\n",
      "        [27.8870, 27.8511]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9826, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9717, 29.9476],\n",
      "        [31.9484, 26.8837],\n",
      "        [25.2872, 30.1759],\n",
      "        [27.8870, 27.8511]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9826, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9717, 29.9476],\n",
      "        [31.9484, 26.8837],\n",
      "        [25.2873, 30.1759],\n",
      "        [27.8870, 27.8511]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9826, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9717, 29.9476],\n",
      "        [31.9484, 26.8837],\n",
      "        [25.2872, 30.1760],\n",
      "        [27.8870, 27.8512]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9826, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9717, 29.9476],\n",
      "        [31.9485, 26.8837],\n",
      "        [25.2873, 30.1760],\n",
      "        [27.8870, 27.8512]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9826, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9717, 29.9476],\n",
      "        [31.9484, 26.8838],\n",
      "        [25.2873, 30.1760],\n",
      "        [27.8870, 27.8512]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9826, 0.1111, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9718, 29.9476],\n",
      "        [31.9485, 26.8838],\n",
      "        [25.2874, 30.1760],\n",
      "        [27.8871, 27.8512]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9826, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9717, 29.9477],\n",
      "        [31.9485, 26.8839],\n",
      "        [25.2873, 30.1760],\n",
      "        [27.8870, 27.8512]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9826, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9718, 29.9477],\n",
      "        [31.9486, 26.8839],\n",
      "        [25.2874, 30.1760],\n",
      "        [27.8871, 27.8512]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9826, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9718, 29.9477],\n",
      "        [31.9485, 26.8840],\n",
      "        [25.2874, 30.1761],\n",
      "        [27.8871, 27.8513]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9826, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9718, 29.9477],\n",
      "        [31.9486, 26.8840],\n",
      "        [25.2875, 30.1760],\n",
      "        [27.8871, 27.8513]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9826, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9718, 29.9477],\n",
      "        [31.9485, 26.8840],\n",
      "        [25.2875, 30.1761],\n",
      "        [27.8871, 27.8513]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9826, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9718, 29.9477],\n",
      "        [31.9486, 26.8840],\n",
      "        [25.2875, 30.1761],\n",
      "        [27.8871, 27.8513]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9826, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9718, 29.9477],\n",
      "        [31.9486, 26.8841],\n",
      "        [25.2875, 30.1761],\n",
      "        [27.8871, 27.8513]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9826, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9719, 29.9478],\n",
      "        [31.9487, 26.8841],\n",
      "        [25.2876, 30.1761],\n",
      "        [27.8872, 27.8513]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9826, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9718, 29.9478],\n",
      "        [31.9486, 26.8842],\n",
      "        [25.2876, 30.1762],\n",
      "        [27.8871, 27.8513]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9826, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9719, 29.9478],\n",
      "        [31.9487, 26.8842],\n",
      "        [25.2877, 30.1761],\n",
      "        [27.8872, 27.8513]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9827, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9719, 29.9478],\n",
      "        [31.9487, 26.8843],\n",
      "        [25.2876, 30.1762],\n",
      "        [27.8872, 27.8514]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9827, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9719, 29.9478],\n",
      "        [31.9487, 26.8842],\n",
      "        [25.2877, 30.1762],\n",
      "        [27.8872, 27.8514]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9827, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9719, 29.9478],\n",
      "        [31.9487, 26.8843],\n",
      "        [25.2877, 30.1762],\n",
      "        [27.8872, 27.8514]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9827, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9719, 29.9478],\n",
      "        [31.9488, 26.8843],\n",
      "        [25.2878, 30.1762],\n",
      "        [27.8872, 27.8514]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9827, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9719, 29.9479],\n",
      "        [31.9487, 26.8844],\n",
      "        [25.2877, 30.1763],\n",
      "        [27.8872, 27.8514]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9827, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9719, 29.9479],\n",
      "        [31.9488, 26.8844],\n",
      "        [25.2878, 30.1762],\n",
      "        [27.8872, 27.8514]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9827, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9719, 29.9479],\n",
      "        [31.9488, 26.8845],\n",
      "        [25.2878, 30.1763],\n",
      "        [27.8872, 27.8515]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9827, 0.1112, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9719, 29.9479],\n",
      "        [31.9489, 26.8845],\n",
      "        [25.2879, 30.1763],\n",
      "        [27.8873, 27.8514]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9827, 0.1113, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9719, 29.9479],\n",
      "        [31.9488, 26.8846],\n",
      "        [25.2878, 30.1763],\n",
      "        [27.8873, 27.8515]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9827, 0.1113, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9720, 29.9479],\n",
      "        [31.9489, 26.8845],\n",
      "        [25.2879, 30.1763],\n",
      "        [27.8873, 27.8515]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9827, 0.1113, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9719, 29.9479],\n",
      "        [31.9488, 26.8846],\n",
      "        [25.2879, 30.1763],\n",
      "        [27.8873, 27.8515]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9827, 0.1113, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9720, 29.9479],\n",
      "        [31.9489, 26.8846],\n",
      "        [25.2880, 30.1763],\n",
      "        [27.8873, 27.8515]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9827, 0.1113, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9720, 29.9480],\n",
      "        [31.9489, 26.8847],\n",
      "        [25.2879, 30.1764],\n",
      "        [27.8873, 27.8515]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9827, 0.1113, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9720, 29.9480],\n",
      "        [31.9490, 26.8847],\n",
      "        [25.2880, 30.1764],\n",
      "        [27.8873, 27.8515]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9827, 0.1113, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9720, 29.9480],\n",
      "        [31.9489, 26.8848],\n",
      "        [25.2880, 30.1764],\n",
      "        [27.8873, 27.8516]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9827, 0.1113, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9720, 29.9480],\n",
      "        [31.9490, 26.8848],\n",
      "        [25.2881, 30.1764],\n",
      "        [27.8874, 27.8516]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9828, 0.1113, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9720, 29.9480],\n",
      "        [31.9490, 26.8848],\n",
      "        [25.2881, 30.1764],\n",
      "        [27.8873, 27.8516]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9828, 0.1113, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9721, 29.9480],\n",
      "        [31.9491, 26.8849],\n",
      "        [25.2882, 30.1764],\n",
      "        [27.8874, 27.8516]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9828, 0.1113, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9720, 29.9480],\n",
      "        [31.9490, 26.8849],\n",
      "        [25.2881, 30.1765],\n",
      "        [27.8874, 27.8516]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9828, 0.1113, 0.9621], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9720, 29.9480],\n",
      "        [31.9491, 26.8849],\n",
      "        [25.2882, 30.1764],\n",
      "        [27.8874, 27.8516]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9828, 0.1113, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9720, 29.9480],\n",
      "        [31.9490, 26.8850],\n",
      "        [25.2882, 30.1765],\n",
      "        [27.8874, 27.8516]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9828, 0.1113, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9721, 29.9481],\n",
      "        [31.9491, 26.8850],\n",
      "        [25.2883, 30.1765],\n",
      "        [27.8874, 27.8516]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9828, 0.1113, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9721, 29.9481],\n",
      "        [31.9491, 26.8851],\n",
      "        [25.2882, 30.1765],\n",
      "        [27.8874, 27.8517]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9828, 0.1113, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9721, 29.9481],\n",
      "        [31.9492, 26.8851],\n",
      "        [25.2883, 30.1765],\n",
      "        [27.8875, 27.8517]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9828, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9721, 29.9481],\n",
      "        [31.9491, 26.8851],\n",
      "        [25.2883, 30.1766],\n",
      "        [27.8874, 27.8517]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9828, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9721, 29.9481],\n",
      "        [31.9492, 26.8851],\n",
      "        [25.2884, 30.1765],\n",
      "        [27.8875, 27.8517]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9828, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9721, 29.9481],\n",
      "        [31.9491, 26.8852],\n",
      "        [25.2883, 30.1766],\n",
      "        [27.8875, 27.8517]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9828, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9721, 29.9481],\n",
      "        [31.9492, 26.8852],\n",
      "        [25.2884, 30.1766],\n",
      "        [27.8875, 27.8517]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9828, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9721, 29.9482],\n",
      "        [31.9492, 26.8853],\n",
      "        [25.2884, 30.1766],\n",
      "        [27.8875, 27.8518]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9828, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9722, 29.9482],\n",
      "        [31.9493, 26.8853],\n",
      "        [25.2885, 30.1766],\n",
      "        [27.8875, 27.8518]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9828, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9721, 29.9482],\n",
      "        [31.9492, 26.8853],\n",
      "        [25.2884, 30.1767],\n",
      "        [27.8875, 27.8518]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9828, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9722, 29.9482],\n",
      "        [31.9493, 26.8854],\n",
      "        [25.2885, 30.1766],\n",
      "        [27.8876, 27.8518]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9829, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9722, 29.9482],\n",
      "        [31.9493, 26.8854],\n",
      "        [25.2885, 30.1767],\n",
      "        [27.8875, 27.8518]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9829, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9722, 29.9482],\n",
      "        [31.9494, 26.8854],\n",
      "        [25.2886, 30.1767],\n",
      "        [27.8876, 27.8518]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9829, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9722, 29.9482],\n",
      "        [31.9493, 26.8855],\n",
      "        [25.2886, 30.1767],\n",
      "        [27.8876, 27.8518]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9829, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9722, 29.9482],\n",
      "        [31.9494, 26.8855],\n",
      "        [25.2886, 30.1767],\n",
      "        [27.8876, 27.8518]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9829, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9722, 29.9483],\n",
      "        [31.9493, 26.8856],\n",
      "        [25.2886, 30.1767],\n",
      "        [27.8876, 27.8519]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9829, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9722, 29.9483],\n",
      "        [31.9494, 26.8856],\n",
      "        [25.2887, 30.1767],\n",
      "        [27.8876, 27.8519]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9829, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9722, 29.9483],\n",
      "        [31.9494, 26.8856],\n",
      "        [25.2887, 30.1768],\n",
      "        [27.8876, 27.8519]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9829, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9723, 29.9483],\n",
      "        [31.9495, 26.8856],\n",
      "        [25.2888, 30.1768],\n",
      "        [27.8876, 27.8519]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9829, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9722, 29.9483],\n",
      "        [31.9494, 26.8857],\n",
      "        [25.2887, 30.1768],\n",
      "        [27.8876, 27.8519]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9829, 0.1114, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9723, 29.9483],\n",
      "        [31.9495, 26.8857],\n",
      "        [25.2888, 30.1768],\n",
      "        [27.8877, 27.8519]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9829, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9723, 29.9484],\n",
      "        [31.9495, 26.8858],\n",
      "        [25.2888, 30.1768],\n",
      "        [27.8876, 27.8520]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9829, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9723, 29.9483],\n",
      "        [31.9495, 26.8858],\n",
      "        [25.2888, 30.1768],\n",
      "        [27.8877, 27.8519]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9829, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9723, 29.9484],\n",
      "        [31.9495, 26.8859],\n",
      "        [25.2888, 30.1769],\n",
      "        [27.8877, 27.8520]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9829, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9723, 29.9484],\n",
      "        [31.9496, 26.8858],\n",
      "        [25.2889, 30.1769],\n",
      "        [27.8877, 27.8520]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9829, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9723, 29.9484],\n",
      "        [31.9495, 26.8859],\n",
      "        [25.2889, 30.1769],\n",
      "        [27.8877, 27.8520]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9829, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9723, 29.9484],\n",
      "        [31.9496, 26.8859],\n",
      "        [25.2890, 30.1769],\n",
      "        [27.8877, 27.8520]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9830, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9723, 29.9484],\n",
      "        [31.9496, 26.8860],\n",
      "        [25.2889, 30.1769],\n",
      "        [27.8877, 27.8520]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9830, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9723, 29.9484],\n",
      "        [31.9496, 26.8860],\n",
      "        [25.2890, 30.1769],\n",
      "        [27.8877, 27.8520]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9830, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9723, 29.9485],\n",
      "        [31.9496, 26.8861],\n",
      "        [25.2890, 30.1770],\n",
      "        [27.8877, 27.8521]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9830, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9724, 29.9484],\n",
      "        [31.9497, 26.8861],\n",
      "        [25.2891, 30.1769],\n",
      "        [27.8878, 27.8520]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9830, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9724, 29.9485],\n",
      "        [31.9496, 26.8862],\n",
      "        [25.2890, 30.1770],\n",
      "        [27.8878, 27.8521]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9830, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9724, 29.9485],\n",
      "        [31.9497, 26.8861],\n",
      "        [25.2891, 30.1770],\n",
      "        [27.8878, 27.8521]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9830, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9724, 29.9485],\n",
      "        [31.9497, 26.8862],\n",
      "        [25.2891, 30.1770],\n",
      "        [27.8878, 27.8521]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9830, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9724, 29.9485],\n",
      "        [31.9498, 26.8862],\n",
      "        [25.2892, 30.1770],\n",
      "        [27.8878, 27.8521]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9830, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9724, 29.9485],\n",
      "        [31.9497, 26.8863],\n",
      "        [25.2892, 30.1771],\n",
      "        [27.8878, 27.8521]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9830, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9724, 29.9485],\n",
      "        [31.9498, 26.8863],\n",
      "        [25.2892, 30.1770],\n",
      "        [27.8878, 27.8521]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9830, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9724, 29.9485],\n",
      "        [31.9497, 26.8863],\n",
      "        [25.2892, 30.1771],\n",
      "        [27.8878, 27.8522]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9830, 0.1115, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9724, 29.9485],\n",
      "        [31.9498, 26.8863],\n",
      "        [25.2893, 30.1771],\n",
      "        [27.8878, 27.8521]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9830, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9724, 29.9486],\n",
      "        [31.9498, 26.8864],\n",
      "        [25.2892, 30.1771],\n",
      "        [27.8878, 27.8522]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9830, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9724, 29.9486],\n",
      "        [31.9499, 26.8864],\n",
      "        [25.2893, 30.1771],\n",
      "        [27.8879, 27.8522]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9830, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9724, 29.9486],\n",
      "        [31.9498, 26.8865],\n",
      "        [25.2893, 30.1771],\n",
      "        [27.8879, 27.8522]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9830, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9725, 29.9486],\n",
      "        [31.9499, 26.8865],\n",
      "        [25.2894, 30.1771],\n",
      "        [27.8879, 27.8522]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9725, 29.9486],\n",
      "        [31.9499, 26.8866],\n",
      "        [25.2894, 30.1772],\n",
      "        [27.8879, 27.8522]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9725, 29.9486],\n",
      "        [31.9499, 26.8866],\n",
      "        [25.2894, 30.1772],\n",
      "        [27.8879, 27.8522]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9725, 29.9487],\n",
      "        [31.9499, 26.8866],\n",
      "        [25.2894, 30.1772],\n",
      "        [27.8879, 27.8523]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9725, 29.9486],\n",
      "        [31.9500, 26.8866],\n",
      "        [25.2895, 30.1772],\n",
      "        [27.8879, 27.8523]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9725, 29.9487],\n",
      "        [31.9499, 26.8867],\n",
      "        [25.2895, 30.1772],\n",
      "        [27.8879, 27.8523]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9725, 29.9487],\n",
      "        [31.9500, 26.8867],\n",
      "        [25.2895, 30.1772],\n",
      "        [27.8880, 27.8523]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9725, 29.9487],\n",
      "        [31.9500, 26.8868],\n",
      "        [25.2895, 30.1773],\n",
      "        [27.8880, 27.8523]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9726, 29.9487],\n",
      "        [31.9501, 26.8868],\n",
      "        [25.2896, 30.1773],\n",
      "        [27.8880, 27.8523]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9725, 29.9487],\n",
      "        [31.9500, 26.8868],\n",
      "        [25.2896, 30.1773],\n",
      "        [27.8880, 27.8523]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9726, 29.9487],\n",
      "        [31.9501, 26.8869],\n",
      "        [25.2897, 30.1773],\n",
      "        [27.8880, 27.8524]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9726, 29.9488],\n",
      "        [31.9500, 26.8869],\n",
      "        [25.2896, 30.1773],\n",
      "        [27.8880, 27.8524]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9726, 29.9488],\n",
      "        [31.9501, 26.8869],\n",
      "        [25.2897, 30.1773],\n",
      "        [27.8880, 27.8524]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9726, 29.9488],\n",
      "        [31.9501, 26.8870],\n",
      "        [25.2897, 30.1774],\n",
      "        [27.8880, 27.8524]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9831, 0.1116, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9726, 29.9488],\n",
      "        [31.9502, 26.8870],\n",
      "        [25.2898, 30.1773],\n",
      "        [27.8881, 27.8524]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9831, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9726, 29.9488],\n",
      "        [31.9501, 26.8871],\n",
      "        [25.2897, 30.1774],\n",
      "        [27.8880, 27.8524]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9831, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9726, 29.9488],\n",
      "        [31.9502, 26.8871],\n",
      "        [25.2898, 30.1774],\n",
      "        [27.8881, 27.8524]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9831, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9726, 29.9488],\n",
      "        [31.9502, 26.8871],\n",
      "        [25.2898, 30.1774],\n",
      "        [27.8881, 27.8525]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9831, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9727, 29.9488],\n",
      "        [31.9502, 26.8871],\n",
      "        [25.2899, 30.1774],\n",
      "        [27.8881, 27.8525]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9726, 29.9489],\n",
      "        [31.9502, 26.8872],\n",
      "        [25.2898, 30.1774],\n",
      "        [27.8881, 27.8525]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9727, 29.9489],\n",
      "        [31.9503, 26.8872],\n",
      "        [25.2899, 30.1774],\n",
      "        [27.8881, 27.8525]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9727, 29.9489],\n",
      "        [31.9502, 26.8873],\n",
      "        [25.2899, 30.1775],\n",
      "        [27.8881, 27.8525]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9727, 29.9489],\n",
      "        [31.9503, 26.8873],\n",
      "        [25.2900, 30.1775],\n",
      "        [27.8882, 27.8525]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9727, 29.9489],\n",
      "        [31.9503, 26.8873],\n",
      "        [25.2899, 30.1775],\n",
      "        [27.8881, 27.8525]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9727, 29.9489],\n",
      "        [31.9504, 26.8873],\n",
      "        [25.2900, 30.1775],\n",
      "        [27.8882, 27.8525]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9727, 29.9489],\n",
      "        [31.9503, 26.8874],\n",
      "        [25.2900, 30.1775],\n",
      "        [27.8882, 27.8526]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9727, 29.9489],\n",
      "        [31.9504, 26.8874],\n",
      "        [25.2901, 30.1775],\n",
      "        [27.8882, 27.8526]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9727, 29.9490],\n",
      "        [31.9503, 26.8875],\n",
      "        [25.2901, 30.1776],\n",
      "        [27.8882, 27.8526]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9727, 29.9490],\n",
      "        [31.9504, 26.8875],\n",
      "        [25.2901, 30.1776],\n",
      "        [27.8882, 27.8526]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9727, 29.9490],\n",
      "        [31.9504, 26.8876],\n",
      "        [25.2901, 30.1776],\n",
      "        [27.8882, 27.8526]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9728, 29.9490],\n",
      "        [31.9505, 26.8876],\n",
      "        [25.2902, 30.1776],\n",
      "        [27.8882, 27.8526]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9727, 29.9490],\n",
      "        [31.9504, 26.8876],\n",
      "        [25.2902, 30.1776],\n",
      "        [27.8882, 27.8526]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9832, 0.1117, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9728, 29.9490],\n",
      "        [31.9505, 26.8876],\n",
      "        [25.2902, 30.1776],\n",
      "        [27.8883, 27.8526]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9832, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9728, 29.9490],\n",
      "        [31.9504, 26.8877],\n",
      "        [25.2902, 30.1777],\n",
      "        [27.8882, 27.8527]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9832, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9728, 29.9490],\n",
      "        [31.9505, 26.8877],\n",
      "        [25.2903, 30.1776],\n",
      "        [27.8883, 27.8527]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9728, 29.9491],\n",
      "        [31.9505, 26.8878],\n",
      "        [25.2903, 30.1777],\n",
      "        [27.8883, 27.8527]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9728, 29.9490],\n",
      "        [31.9505, 26.8877],\n",
      "        [25.2903, 30.1777],\n",
      "        [27.8883, 27.8527]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9728, 29.9491],\n",
      "        [31.9505, 26.8878],\n",
      "        [25.2903, 30.1777],\n",
      "        [27.8883, 27.8527]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9728, 29.9491],\n",
      "        [31.9506, 26.8878],\n",
      "        [25.2904, 30.1777],\n",
      "        [27.8883, 27.8527]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9728, 29.9491],\n",
      "        [31.9505, 26.8879],\n",
      "        [25.2904, 30.1777],\n",
      "        [27.8883, 27.8528]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9728, 29.9491],\n",
      "        [31.9506, 26.8879],\n",
      "        [25.2904, 30.1777],\n",
      "        [27.8883, 27.8527]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9728, 29.9491],\n",
      "        [31.9506, 26.8880],\n",
      "        [25.2904, 30.1778],\n",
      "        [27.8883, 27.8528]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9728, 29.9491],\n",
      "        [31.9506, 26.8880],\n",
      "        [25.2905, 30.1777],\n",
      "        [27.8884, 27.8528]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9728, 29.9492],\n",
      "        [31.9506, 26.8880],\n",
      "        [25.2905, 30.1778],\n",
      "        [27.8883, 27.8528]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9729, 29.9491],\n",
      "        [31.9507, 26.8880],\n",
      "        [25.2906, 30.1778],\n",
      "        [27.8884, 27.8528]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9729, 29.9492],\n",
      "        [31.9506, 26.8881],\n",
      "        [25.2905, 30.1778],\n",
      "        [27.8884, 27.8528]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9729, 29.9492],\n",
      "        [31.9507, 26.8881],\n",
      "        [25.2906, 30.1778],\n",
      "        [27.8884, 27.8528]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9729, 29.9492],\n",
      "        [31.9507, 26.8882],\n",
      "        [25.2906, 30.1779],\n",
      "        [27.8884, 27.8528]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9729, 29.9492],\n",
      "        [31.9508, 26.8882],\n",
      "        [25.2907, 30.1778],\n",
      "        [27.8884, 27.8528]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9729, 29.9492],\n",
      "        [31.9507, 26.8882],\n",
      "        [25.2906, 30.1779],\n",
      "        [27.8884, 27.8529]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9833, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9729, 29.9492],\n",
      "        [31.9508, 26.8882],\n",
      "        [25.2907, 30.1779],\n",
      "        [27.8884, 27.8529]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9834, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9729, 29.9492],\n",
      "        [31.9507, 26.8883],\n",
      "        [25.2907, 30.1779],\n",
      "        [27.8884, 27.8529]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9834, 0.1118, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9730, 29.9493],\n",
      "        [31.9508, 26.8883],\n",
      "        [25.2908, 30.1779],\n",
      "        [27.8885, 27.8529]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9729, 29.9493],\n",
      "        [31.9508, 26.8884],\n",
      "        [25.2907, 30.1779],\n",
      "        [27.8884, 27.8529]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9730, 29.9493],\n",
      "        [31.9509, 26.8884],\n",
      "        [25.2908, 30.1779],\n",
      "        [27.8885, 27.8529]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9730, 29.9493],\n",
      "        [31.9508, 26.8884],\n",
      "        [25.2908, 30.1780],\n",
      "        [27.8885, 27.8530]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9730, 29.9493],\n",
      "        [31.9509, 26.8884],\n",
      "        [25.2909, 30.1780],\n",
      "        [27.8885, 27.8530]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9730, 29.9493],\n",
      "        [31.9509, 26.8885],\n",
      "        [25.2908, 30.1780],\n",
      "        [27.8885, 27.8530]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9730, 29.9493],\n",
      "        [31.9509, 26.8885],\n",
      "        [25.2909, 30.1780],\n",
      "        [27.8885, 27.8530]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9730, 29.9494],\n",
      "        [31.9509, 26.8886],\n",
      "        [25.2909, 30.1780],\n",
      "        [27.8885, 27.8530]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9730, 29.9494],\n",
      "        [31.9510, 26.8886],\n",
      "        [25.2910, 30.1780],\n",
      "        [27.8886, 27.8530]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9730, 29.9494],\n",
      "        [31.9509, 26.8887],\n",
      "        [25.2910, 30.1781],\n",
      "        [27.8885, 27.8530]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9730, 29.9494],\n",
      "        [31.9510, 26.8886],\n",
      "        [25.2910, 30.1780],\n",
      "        [27.8886, 27.8530]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9730, 29.9494],\n",
      "        [31.9510, 26.8887],\n",
      "        [25.2910, 30.1781],\n",
      "        [27.8886, 27.8531]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9731, 29.9494],\n",
      "        [31.9510, 26.8887],\n",
      "        [25.2911, 30.1781],\n",
      "        [27.8886, 27.8531]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9731, 29.9494],\n",
      "        [31.9510, 26.8888],\n",
      "        [25.2911, 30.1781],\n",
      "        [27.8886, 27.8531]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9731, 29.9494],\n",
      "        [31.9511, 26.8888],\n",
      "        [25.2911, 30.1781],\n",
      "        [27.8886, 27.8531]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9731, 29.9495],\n",
      "        [31.9510, 26.8889],\n",
      "        [25.2911, 30.1781],\n",
      "        [27.8886, 27.8531]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9834, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9731, 29.9495],\n",
      "        [31.9511, 26.8889],\n",
      "        [25.2912, 30.1781],\n",
      "        [27.8887, 27.8531]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9835, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9731, 29.9495],\n",
      "        [31.9511, 26.8889],\n",
      "        [25.2912, 30.1782],\n",
      "        [27.8886, 27.8531]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9835, 0.1119, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9731, 29.9495],\n",
      "        [31.9512, 26.8889],\n",
      "        [25.2912, 30.1782],\n",
      "        [27.8887, 27.8531]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9731, 29.9495],\n",
      "        [31.9511, 26.8890],\n",
      "        [25.2912, 30.1782],\n",
      "        [27.8887, 27.8532]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9732, 29.9495],\n",
      "        [31.9512, 26.8890],\n",
      "        [25.2913, 30.1782],\n",
      "        [27.8887, 27.8532]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9731, 29.9495],\n",
      "        [31.9512, 26.8891],\n",
      "        [25.2913, 30.1782],\n",
      "        [27.8887, 27.8532]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9731, 29.9495],\n",
      "        [31.9512, 26.8890],\n",
      "        [25.2913, 30.1782],\n",
      "        [27.8887, 27.8532]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9731, 29.9495],\n",
      "        [31.9512, 26.8891],\n",
      "        [25.2913, 30.1783],\n",
      "        [27.8887, 27.8532]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9732, 29.9495],\n",
      "        [31.9513, 26.8891],\n",
      "        [25.2914, 30.1782],\n",
      "        [27.8887, 27.8532]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9732, 29.9496],\n",
      "        [31.9512, 26.8892],\n",
      "        [25.2914, 30.1783],\n",
      "        [27.8887, 27.8532]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9732, 29.9496],\n",
      "        [31.9513, 26.8892],\n",
      "        [25.2914, 30.1783],\n",
      "        [27.8887, 27.8532]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9732, 29.9496],\n",
      "        [31.9513, 26.8893],\n",
      "        [25.2914, 30.1783],\n",
      "        [27.8887, 27.8533]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9732, 29.9496],\n",
      "        [31.9513, 26.8892],\n",
      "        [25.2915, 30.1783],\n",
      "        [27.8888, 27.8533]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9732, 29.9496],\n",
      "        [31.9513, 26.8893],\n",
      "        [25.2915, 30.1783],\n",
      "        [27.8888, 27.8533]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9732, 29.9496],\n",
      "        [31.9514, 26.8893],\n",
      "        [25.2915, 30.1783],\n",
      "        [27.8888, 27.8533]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9732, 29.9496],\n",
      "        [31.9513, 26.8894],\n",
      "        [25.2915, 30.1784],\n",
      "        [27.8888, 27.8533]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9732, 29.9496],\n",
      "        [31.9514, 26.8894],\n",
      "        [25.2916, 30.1784],\n",
      "        [27.8888, 27.8533]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9732, 29.9497],\n",
      "        [31.9514, 26.8895],\n",
      "        [25.2916, 30.1784],\n",
      "        [27.8888, 27.8533]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9835, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9733, 29.9497],\n",
      "        [31.9514, 26.8895],\n",
      "        [25.2917, 30.1784],\n",
      "        [27.8888, 27.8533]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9836, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9732, 29.9497],\n",
      "        [31.9514, 26.8895],\n",
      "        [25.2916, 30.1784],\n",
      "        [27.8888, 27.8534]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9836, 0.1120, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9733, 29.9497],\n",
      "        [31.9515, 26.8895],\n",
      "        [25.2917, 30.1784],\n",
      "        [27.8888, 27.8534]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9732, 29.9497],\n",
      "        [31.9514, 26.8896],\n",
      "        [25.2917, 30.1785],\n",
      "        [27.8888, 27.8534]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9733, 29.9497],\n",
      "        [31.9515, 26.8896],\n",
      "        [25.2918, 30.1785],\n",
      "        [27.8889, 27.8534]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9733, 29.9498],\n",
      "        [31.9515, 26.8897],\n",
      "        [25.2917, 30.1785],\n",
      "        [27.8889, 27.8534]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9733, 29.9497],\n",
      "        [31.9515, 26.8897],\n",
      "        [25.2918, 30.1785],\n",
      "        [27.8889, 27.8534]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9985, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9733, 29.9498],\n",
      "        [31.9515, 26.8897],\n",
      "        [25.2918, 30.1785],\n",
      "        [27.8889, 27.8534]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9985, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9733, 29.9498],\n",
      "        [31.9516, 26.8897],\n",
      "        [25.2919, 30.1785],\n",
      "        [27.8889, 27.8534]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9733, 29.9498],\n",
      "        [31.9515, 26.8898],\n",
      "        [25.2918, 30.1785],\n",
      "        [27.8889, 27.8535]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9734, 29.9498],\n",
      "        [31.9516, 26.8898],\n",
      "        [25.2919, 30.1785],\n",
      "        [27.8889, 27.8535]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9733, 29.9498],\n",
      "        [31.9516, 26.8899],\n",
      "        [25.2919, 30.1786],\n",
      "        [27.8889, 27.8535]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9734, 29.9498],\n",
      "        [31.9516, 26.8899],\n",
      "        [25.2920, 30.1786],\n",
      "        [27.8890, 27.8535]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9734, 29.9498],\n",
      "        [31.9516, 26.8899],\n",
      "        [25.2919, 30.1786],\n",
      "        [27.8889, 27.8535]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9734, 29.9498],\n",
      "        [31.9517, 26.8899],\n",
      "        [25.2920, 30.1786],\n",
      "        [27.8890, 27.8535]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9734, 29.9499],\n",
      "        [31.9516, 26.8900],\n",
      "        [25.2920, 30.1786],\n",
      "        [27.8890, 27.8535]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9836, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9734, 29.9499],\n",
      "        [31.9517, 26.8900],\n",
      "        [25.2921, 30.1786],\n",
      "        [27.8890, 27.8535]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9837, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9734, 29.9499],\n",
      "        [31.9517, 26.8901],\n",
      "        [25.2921, 30.1787],\n",
      "        [27.8890, 27.8536]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9837, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9734, 29.9499],\n",
      "        [31.9517, 26.8901],\n",
      "        [25.2921, 30.1786],\n",
      "        [27.8890, 27.8536]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9837, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9734, 29.9499],\n",
      "        [31.9517, 26.8901],\n",
      "        [25.2921, 30.1787],\n",
      "        [27.8890, 27.8536]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9837, 0.1121, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9734, 29.9499],\n",
      "        [31.9518, 26.8901],\n",
      "        [25.2922, 30.1787],\n",
      "        [27.8890, 27.8536]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9734, 29.9499],\n",
      "        [31.9517, 26.8902],\n",
      "        [25.2922, 30.1787],\n",
      "        [27.8890, 27.8536]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9734, 29.9499],\n",
      "        [31.9518, 26.8902],\n",
      "        [25.2922, 30.1787],\n",
      "        [27.8891, 27.8536]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9734, 29.9500],\n",
      "        [31.9518, 26.8903],\n",
      "        [25.2922, 30.1787],\n",
      "        [27.8890, 27.8536]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9735, 29.9500],\n",
      "        [31.9519, 26.8903],\n",
      "        [25.2923, 30.1787],\n",
      "        [27.8891, 27.8537]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9735, 29.9500],\n",
      "        [31.9518, 26.8903],\n",
      "        [25.2923, 30.1788],\n",
      "        [27.8891, 27.8537]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9735, 29.9500],\n",
      "        [31.9519, 26.8903],\n",
      "        [25.2923, 30.1788],\n",
      "        [27.8891, 27.8537]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9735, 29.9500],\n",
      "        [31.9518, 26.8904],\n",
      "        [25.2923, 30.1788],\n",
      "        [27.8891, 27.8537]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9735, 29.9500],\n",
      "        [31.9519, 26.8904],\n",
      "        [25.2924, 30.1788],\n",
      "        [27.8891, 27.8537]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9735, 29.9500],\n",
      "        [31.9519, 26.8905],\n",
      "        [25.2924, 30.1788],\n",
      "        [27.8891, 27.8537]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9735, 29.9500],\n",
      "        [31.9519, 26.8904],\n",
      "        [25.2924, 30.1788],\n",
      "        [27.8891, 27.8537]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9735, 29.9501],\n",
      "        [31.9519, 26.8905],\n",
      "        [25.2924, 30.1789],\n",
      "        [27.8891, 27.8537]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9622], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9735, 29.9500],\n",
      "        [31.9520, 26.8905],\n",
      "        [25.2925, 30.1788],\n",
      "        [27.8892, 27.8537]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9735, 29.9501],\n",
      "        [31.9519, 26.8906],\n",
      "        [25.2925, 30.1789],\n",
      "        [27.8891, 27.8538]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9837, 0.1122, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9736, 29.9501],\n",
      "        [31.9520, 26.8906],\n",
      "        [25.2925, 30.1789],\n",
      "        [27.8892, 27.8538]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9838, 0.1122, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9735, 29.9501],\n",
      "        [31.9520, 26.8906],\n",
      "        [25.2925, 30.1789],\n",
      "        [27.8892, 27.8538]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9838, 0.1122, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9736, 29.9501],\n",
      "        [31.9520, 26.8906],\n",
      "        [25.2926, 30.1789],\n",
      "        [27.8892, 27.8538]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9838, 0.1122, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9736, 29.9501],\n",
      "        [31.9520, 26.8907],\n",
      "        [25.2926, 30.1789],\n",
      "        [27.8892, 27.8538]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9838, 0.1122, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9736, 29.9501],\n",
      "        [31.9521, 26.8907],\n",
      "        [25.2926, 30.1789],\n",
      "        [27.8892, 27.8538]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9736, 29.9502],\n",
      "        [31.9520, 26.8908],\n",
      "        [25.2926, 30.1790],\n",
      "        [27.8892, 27.8539]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9736, 29.9501],\n",
      "        [31.9521, 26.8908],\n",
      "        [25.2927, 30.1790],\n",
      "        [27.8892, 27.8538]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9736, 29.9502],\n",
      "        [31.9521, 26.8909],\n",
      "        [25.2927, 30.1790],\n",
      "        [27.8892, 27.8539]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9736, 29.9502],\n",
      "        [31.9521, 26.8908],\n",
      "        [25.2927, 30.1790],\n",
      "        [27.8893, 27.8539]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9736, 29.9502],\n",
      "        [31.9521, 26.8909],\n",
      "        [25.2927, 30.1790],\n",
      "        [27.8893, 27.8539]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9736, 29.9502],\n",
      "        [31.9522, 26.8909],\n",
      "        [25.2928, 30.1790],\n",
      "        [27.8893, 27.8539]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9736, 29.9502],\n",
      "        [31.9521, 26.8910],\n",
      "        [25.2928, 30.1791],\n",
      "        [27.8893, 27.8539]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9737, 29.9502],\n",
      "        [31.9522, 26.8910],\n",
      "        [25.2928, 30.1791],\n",
      "        [27.8893, 27.8539]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9736, 29.9502],\n",
      "        [31.9522, 26.8910],\n",
      "        [25.2928, 30.1791],\n",
      "        [27.8893, 27.8539]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9737, 29.9503],\n",
      "        [31.9522, 26.8910],\n",
      "        [25.2929, 30.1791],\n",
      "        [27.8893, 27.8539]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9737, 29.9503],\n",
      "        [31.9522, 26.8911],\n",
      "        [25.2929, 30.1791],\n",
      "        [27.8893, 27.8540]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9737, 29.9503],\n",
      "        [31.9523, 26.8911],\n",
      "        [25.2929, 30.1791],\n",
      "        [27.8893, 27.8540]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9737, 29.9503],\n",
      "        [31.9522, 26.8912],\n",
      "        [25.2929, 30.1791],\n",
      "        [27.8893, 27.8540]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9838, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9737, 29.9503],\n",
      "        [31.9523, 26.8912],\n",
      "        [25.2930, 30.1791],\n",
      "        [27.8894, 27.8540]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9839, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9737, 29.9503],\n",
      "        [31.9523, 26.8912],\n",
      "        [25.2930, 30.1792],\n",
      "        [27.8894, 27.8540]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9839, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9737, 29.9503],\n",
      "        [31.9523, 26.8912],\n",
      "        [25.2931, 30.1792],\n",
      "        [27.8894, 27.8540]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9839, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9737, 29.9503],\n",
      "        [31.9523, 26.8913],\n",
      "        [25.2930, 30.1792],\n",
      "        [27.8894, 27.8540]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9839, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9738, 29.9503],\n",
      "        [31.9524, 26.8913],\n",
      "        [25.2931, 30.1792],\n",
      "        [27.8894, 27.8541]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9839, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9737, 29.9504],\n",
      "        [31.9523, 26.8914],\n",
      "        [25.2931, 30.1792],\n",
      "        [27.8894, 27.8541]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9839, 0.1123, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9738, 29.9504],\n",
      "        [31.9524, 26.8914],\n",
      "        [25.2932, 30.1792],\n",
      "        [27.8894, 27.8541]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9839, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9738, 29.9504],\n",
      "        [31.9524, 26.8914],\n",
      "        [25.2931, 30.1793],\n",
      "        [27.8894, 27.8541]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9839, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9738, 29.9504],\n",
      "        [31.9524, 26.8914],\n",
      "        [25.2932, 30.1793],\n",
      "        [27.8895, 27.8541]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9839, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9738, 29.9504],\n",
      "        [31.9524, 26.8915],\n",
      "        [25.2932, 30.1793],\n",
      "        [27.8894, 27.8541]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9839, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9738, 29.9504],\n",
      "        [31.9525, 26.8915],\n",
      "        [25.2933, 30.1793],\n",
      "        [27.8895, 27.8541]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9839, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9738, 29.9504],\n",
      "        [31.9524, 26.8916],\n",
      "        [25.2932, 30.1793],\n",
      "        [27.8895, 27.8542]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9839, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9738, 29.9504],\n",
      "        [31.9525, 26.8916],\n",
      "        [25.2933, 30.1793],\n",
      "        [27.8895, 27.8542]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9839, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9738, 29.9505],\n",
      "        [31.9525, 26.8916],\n",
      "        [25.2933, 30.1793],\n",
      "        [27.8895, 27.8542]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9839, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9738, 29.9505],\n",
      "        [31.9525, 26.8916],\n",
      "        [25.2934, 30.1793],\n",
      "        [27.8895, 27.8542]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9839, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9738, 29.9505],\n",
      "        [31.9525, 26.8917],\n",
      "        [25.2933, 30.1794],\n",
      "        [27.8895, 27.8542]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9839, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9738, 29.9505],\n",
      "        [31.9526, 26.8917],\n",
      "        [25.2934, 30.1794],\n",
      "        [27.8895, 27.8542]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9839, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9738, 29.9505],\n",
      "        [31.9525, 26.8918],\n",
      "        [25.2934, 30.1794],\n",
      "        [27.8895, 27.8542]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9839, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9739, 29.9505],\n",
      "        [31.9526, 26.8918],\n",
      "        [25.2935, 30.1794],\n",
      "        [27.8896, 27.8542]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9840, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9739, 29.9505],\n",
      "        [31.9526, 26.8918],\n",
      "        [25.2934, 30.1794],\n",
      "        [27.8896, 27.8543]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9840, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9739, 29.9505],\n",
      "        [31.9527, 26.8918],\n",
      "        [25.2935, 30.1794],\n",
      "        [27.8896, 27.8543]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9840, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9739, 29.9506],\n",
      "        [31.9526, 26.8919],\n",
      "        [25.2935, 30.1795],\n",
      "        [27.8896, 27.8543]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9840, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9739, 29.9506],\n",
      "        [31.9527, 26.8919],\n",
      "        [25.2935, 30.1794],\n",
      "        [27.8896, 27.8543]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9840, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9739, 29.9506],\n",
      "        [31.9526, 26.8919],\n",
      "        [25.2935, 30.1795],\n",
      "        [27.8896, 27.8543]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9840, 0.1124, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9739, 29.9506],\n",
      "        [31.9527, 26.8919],\n",
      "        [25.2936, 30.1795],\n",
      "        [27.8896, 27.8543]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9739, 29.9506],\n",
      "        [31.9527, 26.8920],\n",
      "        [25.2936, 30.1795],\n",
      "        [27.8896, 27.8543]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9739, 29.9506],\n",
      "        [31.9527, 26.8920],\n",
      "        [25.2936, 30.1795],\n",
      "        [27.8896, 27.8543]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9739, 29.9506],\n",
      "        [31.9527, 26.8921],\n",
      "        [25.2936, 30.1795],\n",
      "        [27.8896, 27.8543]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9739, 29.9506],\n",
      "        [31.9528, 26.8921],\n",
      "        [25.2937, 30.1795],\n",
      "        [27.8897, 27.8543]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9739, 29.9506],\n",
      "        [31.9527, 26.8921],\n",
      "        [25.2937, 30.1795],\n",
      "        [27.8896, 27.8544]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9740, 29.9506],\n",
      "        [31.9528, 26.8921],\n",
      "        [25.2938, 30.1795],\n",
      "        [27.8897, 27.8544]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9739, 29.9507],\n",
      "        [31.9528, 26.8922],\n",
      "        [25.2937, 30.1796],\n",
      "        [27.8897, 27.8544]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9740, 29.9507],\n",
      "        [31.9528, 26.8922],\n",
      "        [25.2938, 30.1796],\n",
      "        [27.8897, 27.8544]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9740, 29.9507],\n",
      "        [31.9528, 26.8923],\n",
      "        [25.2938, 30.1796],\n",
      "        [27.8897, 27.8544]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9740, 29.9507],\n",
      "        [31.9529, 26.8923],\n",
      "        [25.2939, 30.1796],\n",
      "        [27.8897, 27.8544]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9740, 29.9507],\n",
      "        [31.9528, 26.8923],\n",
      "        [25.2938, 30.1796],\n",
      "        [27.8897, 27.8544]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9740, 29.9507],\n",
      "        [31.9529, 26.8923],\n",
      "        [25.2939, 30.1796],\n",
      "        [27.8897, 27.8544]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9740, 29.9507],\n",
      "        [31.9529, 26.8924],\n",
      "        [25.2939, 30.1797],\n",
      "        [27.8897, 27.8545]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9840, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9740, 29.9507],\n",
      "        [31.9529, 26.8924],\n",
      "        [25.2940, 30.1797],\n",
      "        [27.8898, 27.8545]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9841, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9740, 29.9508],\n",
      "        [31.9529, 26.8925],\n",
      "        [25.2939, 30.1797],\n",
      "        [27.8897, 27.8545]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9841, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9740, 29.9508],\n",
      "        [31.9530, 26.8924],\n",
      "        [25.2940, 30.1797],\n",
      "        [27.8898, 27.8545]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9841, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9740, 29.9508],\n",
      "        [31.9529, 26.8925],\n",
      "        [25.2940, 30.1797],\n",
      "        [27.8898, 27.8545]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9841, 0.1125, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9741, 29.9508],\n",
      "        [31.9530, 26.8925],\n",
      "        [25.2941, 30.1797],\n",
      "        [27.8898, 27.8545]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9741, 29.9508],\n",
      "        [31.9530, 26.8926],\n",
      "        [25.2940, 30.1798],\n",
      "        [27.8898, 27.8545]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9741, 29.9508],\n",
      "        [31.9530, 26.8926],\n",
      "        [25.2941, 30.1797],\n",
      "        [27.8898, 27.8545]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9741, 29.9508],\n",
      "        [31.9530, 26.8926],\n",
      "        [25.2941, 30.1798],\n",
      "        [27.8898, 27.8546]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9741, 29.9508],\n",
      "        [31.9531, 26.8926],\n",
      "        [25.2942, 30.1798],\n",
      "        [27.8898, 27.8546]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9741, 29.9509],\n",
      "        [31.9530, 26.8927],\n",
      "        [25.2941, 30.1798],\n",
      "        [27.8898, 27.8546]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9741, 29.9509],\n",
      "        [31.9531, 26.8927],\n",
      "        [25.2942, 30.1798],\n",
      "        [27.8899, 27.8546]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9741, 29.9509],\n",
      "        [31.9531, 26.8928],\n",
      "        [25.2942, 30.1798],\n",
      "        [27.8898, 27.8546]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9741, 29.9509],\n",
      "        [31.9531, 26.8928],\n",
      "        [25.2943, 30.1798],\n",
      "        [27.8899, 27.8546]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9741, 29.9509],\n",
      "        [31.9531, 26.8928],\n",
      "        [25.2942, 30.1799],\n",
      "        [27.8899, 27.8546]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9742, 29.9509],\n",
      "        [31.9532, 26.8928],\n",
      "        [25.2943, 30.1799],\n",
      "        [27.8899, 27.8547]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9741, 29.9509],\n",
      "        [31.9531, 26.8929],\n",
      "        [25.2943, 30.1799],\n",
      "        [27.8899, 27.8547]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9742, 29.9509],\n",
      "        [31.9532, 26.8929],\n",
      "        [25.2944, 30.1799],\n",
      "        [27.8899, 27.8547]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9742, 29.9510],\n",
      "        [31.9532, 26.8930],\n",
      "        [25.2943, 30.1799],\n",
      "        [27.8899, 27.8547]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9841, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9742, 29.9510],\n",
      "        [31.9532, 26.8930],\n",
      "        [25.2944, 30.1799],\n",
      "        [27.8900, 27.8547]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9842, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9742, 29.9510],\n",
      "        [31.9532, 26.8930],\n",
      "        [25.2944, 30.1800],\n",
      "        [27.8899, 27.8547]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9842, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9742, 29.9510],\n",
      "        [31.9533, 26.8930],\n",
      "        [25.2945, 30.1799],\n",
      "        [27.8900, 27.8547]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9842, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9742, 29.9510],\n",
      "        [31.9532, 26.8931],\n",
      "        [25.2944, 30.1800],\n",
      "        [27.8899, 27.8547]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9842, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9742, 29.9510],\n",
      "        [31.9533, 26.8931],\n",
      "        [25.2945, 30.1800],\n",
      "        [27.8900, 27.8547]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9842, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9742, 29.9510],\n",
      "        [31.9532, 26.8932],\n",
      "        [25.2945, 30.1800],\n",
      "        [27.8900, 27.8548]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9842, 0.1126, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9742, 29.9510],\n",
      "        [31.9533, 26.8931],\n",
      "        [25.2946, 30.1800],\n",
      "        [27.8900, 27.8548]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9742, 29.9511],\n",
      "        [31.9533, 26.8932],\n",
      "        [25.2945, 30.1800],\n",
      "        [27.8900, 27.8548]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9743, 29.9511],\n",
      "        [31.9534, 26.8932],\n",
      "        [25.2946, 30.1800],\n",
      "        [27.8900, 27.8548]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9742, 29.9511],\n",
      "        [31.9533, 26.8933],\n",
      "        [25.2946, 30.1801],\n",
      "        [27.8900, 27.8548]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9743, 29.9511],\n",
      "        [31.9534, 26.8933],\n",
      "        [25.2947, 30.1800],\n",
      "        [27.8900, 27.8548]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9742, 29.9511],\n",
      "        [31.9533, 26.8933],\n",
      "        [25.2946, 30.1801],\n",
      "        [27.8900, 27.8548]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9743, 29.9511],\n",
      "        [31.9534, 26.8933],\n",
      "        [25.2947, 30.1801],\n",
      "        [27.8901, 27.8548]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9743, 29.9511],\n",
      "        [31.9534, 26.8934],\n",
      "        [25.2947, 30.1801],\n",
      "        [27.8900, 27.8549]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9743, 29.9511],\n",
      "        [31.9534, 26.8934],\n",
      "        [25.2948, 30.1801],\n",
      "        [27.8901, 27.8549]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9743, 29.9511],\n",
      "        [31.9534, 26.8935],\n",
      "        [25.2947, 30.1801],\n",
      "        [27.8901, 27.8549]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9743, 29.9511],\n",
      "        [31.9535, 26.8934],\n",
      "        [25.2948, 30.1801],\n",
      "        [27.8901, 27.8549]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9743, 29.9512],\n",
      "        [31.9534, 26.8935],\n",
      "        [25.2948, 30.1802],\n",
      "        [27.8901, 27.8549]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9743, 29.9511],\n",
      "        [31.9535, 26.8935],\n",
      "        [25.2949, 30.1801],\n",
      "        [27.8901, 27.8549]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9743, 29.9512],\n",
      "        [31.9535, 26.8936],\n",
      "        [25.2948, 30.1802],\n",
      "        [27.8901, 27.8549]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9842, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9743, 29.9512],\n",
      "        [31.9535, 26.8936],\n",
      "        [25.2949, 30.1802],\n",
      "        [27.8901, 27.8549]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9843, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9743, 29.9512],\n",
      "        [31.9535, 26.8936],\n",
      "        [25.2949, 30.1802],\n",
      "        [27.8901, 27.8549]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9843, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9744, 29.9512],\n",
      "        [31.9536, 26.8936],\n",
      "        [25.2950, 30.1802],\n",
      "        [27.8902, 27.8550]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9843, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9743, 29.9512],\n",
      "        [31.9535, 26.8937],\n",
      "        [25.2949, 30.1802],\n",
      "        [27.8901, 27.8550]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9843, 0.1127, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9744, 29.9512],\n",
      "        [31.9536, 26.8937],\n",
      "        [25.2950, 30.1802],\n",
      "        [27.8902, 27.8550]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9744, 29.9513],\n",
      "        [31.9536, 26.8938],\n",
      "        [25.2950, 30.1803],\n",
      "        [27.8902, 27.8550]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9744, 29.9513],\n",
      "        [31.9536, 26.8938],\n",
      "        [25.2951, 30.1803],\n",
      "        [27.8902, 27.8550]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9744, 29.9513],\n",
      "        [31.9536, 26.8938],\n",
      "        [25.2950, 30.1803],\n",
      "        [27.8902, 27.8550]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9744, 29.9513],\n",
      "        [31.9537, 26.8938],\n",
      "        [25.2951, 30.1803],\n",
      "        [27.8902, 27.8550]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9744, 29.9513],\n",
      "        [31.9536, 26.8939],\n",
      "        [25.2951, 30.1803],\n",
      "        [27.8902, 27.8550]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9744, 29.9513],\n",
      "        [31.9537, 26.8939],\n",
      "        [25.2952, 30.1803],\n",
      "        [27.8902, 27.8550]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9744, 29.9513],\n",
      "        [31.9537, 26.8940],\n",
      "        [25.2951, 30.1804],\n",
      "        [27.8902, 27.8551]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9745, 29.9513],\n",
      "        [31.9537, 26.8940],\n",
      "        [25.2952, 30.1803],\n",
      "        [27.8903, 27.8551]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9744, 29.9513],\n",
      "        [31.9537, 26.8940],\n",
      "        [25.2952, 30.1804],\n",
      "        [27.8902, 27.8551]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9745, 29.9513],\n",
      "        [31.9538, 26.8940],\n",
      "        [25.2953, 30.1804],\n",
      "        [27.8903, 27.8551]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9744, 29.9514],\n",
      "        [31.9537, 26.8941],\n",
      "        [25.2952, 30.1804],\n",
      "        [27.8903, 27.8551]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9745, 29.9514],\n",
      "        [31.9538, 26.8941],\n",
      "        [25.2953, 30.1804],\n",
      "        [27.8903, 27.8551]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9745, 29.9514],\n",
      "        [31.9538, 26.8941],\n",
      "        [25.2953, 30.1804],\n",
      "        [27.8903, 27.8552]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9843, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9745, 29.9514],\n",
      "        [31.9538, 26.8941],\n",
      "        [25.2954, 30.1804],\n",
      "        [27.8903, 27.8552]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9844, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9745, 29.9514],\n",
      "        [31.9538, 26.8942],\n",
      "        [25.2953, 30.1805],\n",
      "        [27.8903, 27.8552]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9844, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9745, 29.9514],\n",
      "        [31.9539, 26.8942],\n",
      "        [25.2954, 30.1805],\n",
      "        [27.8903, 27.8552]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9844, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9745, 29.9514],\n",
      "        [31.9538, 26.8943],\n",
      "        [25.2954, 30.1805],\n",
      "        [27.8903, 27.8552]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9844, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9745, 29.9514],\n",
      "        [31.9539, 26.8943],\n",
      "        [25.2955, 30.1805],\n",
      "        [27.8903, 27.8552]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9844, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9745, 29.9515],\n",
      "        [31.9538, 26.8943],\n",
      "        [25.2954, 30.1805],\n",
      "        [27.8903, 27.8552]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9844, 0.1128, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9746, 29.9515],\n",
      "        [31.9539, 26.8943],\n",
      "        [25.2955, 30.1805],\n",
      "        [27.8904, 27.8552]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9745, 29.9515],\n",
      "        [31.9539, 26.8944],\n",
      "        [25.2955, 30.1805],\n",
      "        [27.8904, 27.8553]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9746, 29.9515],\n",
      "        [31.9540, 26.8944],\n",
      "        [25.2956, 30.1805],\n",
      "        [27.8904, 27.8552]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9746, 29.9515],\n",
      "        [31.9539, 26.8945],\n",
      "        [25.2955, 30.1806],\n",
      "        [27.8904, 27.8553]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9746, 29.9515],\n",
      "        [31.9540, 26.8944],\n",
      "        [25.2956, 30.1806],\n",
      "        [27.8904, 27.8553]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9746, 29.9515],\n",
      "        [31.9539, 26.8945],\n",
      "        [25.2956, 30.1806],\n",
      "        [27.8904, 27.8553]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9746, 29.9515],\n",
      "        [31.9540, 26.8945],\n",
      "        [25.2957, 30.1806],\n",
      "        [27.8904, 27.8553]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9746, 29.9516],\n",
      "        [31.9540, 26.8946],\n",
      "        [25.2956, 30.1806],\n",
      "        [27.8904, 27.8553]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9746, 29.9516],\n",
      "        [31.9540, 26.8946],\n",
      "        [25.2957, 30.1806],\n",
      "        [27.8905, 27.8553]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9746, 29.9516],\n",
      "        [31.9540, 26.8946],\n",
      "        [25.2957, 30.1807],\n",
      "        [27.8904, 27.8554]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9746, 29.9516],\n",
      "        [31.9541, 26.8946],\n",
      "        [25.2958, 30.1806],\n",
      "        [27.8905, 27.8553]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9746, 29.9516],\n",
      "        [31.9540, 26.8947],\n",
      "        [25.2957, 30.1807],\n",
      "        [27.8905, 27.8554]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9747, 29.9516],\n",
      "        [31.9541, 26.8947],\n",
      "        [25.2958, 30.1807],\n",
      "        [27.8905, 27.8554]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9746, 29.9516],\n",
      "        [31.9540, 26.8947],\n",
      "        [25.2958, 30.1807],\n",
      "        [27.8905, 27.8554]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9844, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9746, 29.9516],\n",
      "        [31.9541, 26.8947],\n",
      "        [25.2958, 30.1807],\n",
      "        [27.8905, 27.8554]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9845, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9746, 29.9516],\n",
      "        [31.9541, 26.8948],\n",
      "        [25.2958, 30.1807],\n",
      "        [27.8905, 27.8554]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9845, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9747, 29.9516],\n",
      "        [31.9542, 26.8948],\n",
      "        [25.2959, 30.1807],\n",
      "        [27.8905, 27.8554]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9845, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9746, 29.9516],\n",
      "        [31.9541, 26.8949],\n",
      "        [25.2959, 30.1807],\n",
      "        [27.8905, 27.8554]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9845, 0.1129, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9747, 29.9517],\n",
      "        [31.9542, 26.8949],\n",
      "        [25.2959, 30.1807],\n",
      "        [27.8905, 27.8554]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9747, 29.9517],\n",
      "        [31.9542, 26.8949],\n",
      "        [25.2959, 30.1808],\n",
      "        [27.8905, 27.8555]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9747, 29.9517],\n",
      "        [31.9542, 26.8949],\n",
      "        [25.2960, 30.1808],\n",
      "        [27.8906, 27.8554]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9747, 29.9517],\n",
      "        [31.9542, 26.8950],\n",
      "        [25.2960, 30.1808],\n",
      "        [27.8905, 27.8555]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9747, 29.9517],\n",
      "        [31.9543, 26.8950],\n",
      "        [25.2960, 30.1808],\n",
      "        [27.8906, 27.8555]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9747, 29.9517],\n",
      "        [31.9542, 26.8950],\n",
      "        [25.2960, 30.1808],\n",
      "        [27.8906, 27.8555]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9747, 29.9517],\n",
      "        [31.9543, 26.8950],\n",
      "        [25.2961, 30.1808],\n",
      "        [27.8906, 27.8555]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9747, 29.9518],\n",
      "        [31.9542, 26.8951],\n",
      "        [25.2961, 30.1809],\n",
      "        [27.8906, 27.8555]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9748, 29.9518],\n",
      "        [31.9543, 26.8951],\n",
      "        [25.2961, 30.1809],\n",
      "        [27.8906, 27.8555]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9747, 29.9518],\n",
      "        [31.9543, 26.8952],\n",
      "        [25.2961, 30.1809],\n",
      "        [27.8906, 27.8556]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9748, 29.9518],\n",
      "        [31.9543, 26.8952],\n",
      "        [25.2962, 30.1809],\n",
      "        [27.8906, 27.8556]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9747, 29.9518],\n",
      "        [31.9543, 26.8952],\n",
      "        [25.2962, 30.1809],\n",
      "        [27.8906, 27.8556]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9748, 29.9518],\n",
      "        [31.9544, 26.8952],\n",
      "        [25.2962, 30.1809],\n",
      "        [27.8907, 27.8556]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9748, 29.9518],\n",
      "        [31.9543, 26.8953],\n",
      "        [25.2962, 30.1809],\n",
      "        [27.8907, 27.8556]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9748, 29.9518],\n",
      "        [31.9544, 26.8953],\n",
      "        [25.2963, 30.1809],\n",
      "        [27.8907, 27.8556]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9748, 29.9518],\n",
      "        [31.9544, 26.8954],\n",
      "        [25.2963, 30.1810],\n",
      "        [27.8907, 27.8556]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9845, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9748, 29.9518],\n",
      "        [31.9544, 26.8954],\n",
      "        [25.2963, 30.1810],\n",
      "        [27.8907, 27.8556]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9846, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9748, 29.9519],\n",
      "        [31.9544, 26.8954],\n",
      "        [25.2963, 30.1810],\n",
      "        [27.8907, 27.8557]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9846, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9748, 29.9519],\n",
      "        [31.9545, 26.8954],\n",
      "        [25.2964, 30.1810],\n",
      "        [27.8907, 27.8556]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9846, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9748, 29.9519],\n",
      "        [31.9544, 26.8955],\n",
      "        [25.2964, 30.1810],\n",
      "        [27.8907, 27.8557]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9846, 0.1130, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9749, 29.9519],\n",
      "        [31.9545, 26.8955],\n",
      "        [25.2964, 30.1810],\n",
      "        [27.8907, 27.8557]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9748, 29.9519],\n",
      "        [31.9545, 26.8955],\n",
      "        [25.2964, 30.1810],\n",
      "        [27.8907, 27.8557]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9749, 29.9519],\n",
      "        [31.9545, 26.8955],\n",
      "        [25.2965, 30.1810],\n",
      "        [27.8908, 27.8557]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9749, 29.9519],\n",
      "        [31.9545, 26.8956],\n",
      "        [25.2965, 30.1811],\n",
      "        [27.8907, 27.8557]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9749, 29.9519],\n",
      "        [31.9546, 26.8956],\n",
      "        [25.2966, 30.1811],\n",
      "        [27.8908, 27.8557]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9749, 29.9520],\n",
      "        [31.9545, 26.8957],\n",
      "        [25.2965, 30.1811],\n",
      "        [27.8908, 27.8557]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9749, 29.9520],\n",
      "        [31.9546, 26.8957],\n",
      "        [25.2966, 30.1811],\n",
      "        [27.8908, 27.8557]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9749, 29.9520],\n",
      "        [31.9545, 26.8957],\n",
      "        [25.2966, 30.1811],\n",
      "        [27.8908, 27.8558]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9749, 29.9520],\n",
      "        [31.9546, 26.8957],\n",
      "        [25.2966, 30.1811],\n",
      "        [27.8908, 27.8558]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9749, 29.9520],\n",
      "        [31.9546, 26.8958],\n",
      "        [25.2966, 30.1812],\n",
      "        [27.8908, 27.8558]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9749, 29.9520],\n",
      "        [31.9547, 26.8958],\n",
      "        [25.2967, 30.1811],\n",
      "        [27.8908, 27.8558]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9749, 29.9520],\n",
      "        [31.9546, 26.8958],\n",
      "        [25.2967, 30.1812],\n",
      "        [27.8908, 27.8558]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9749, 29.9520],\n",
      "        [31.9547, 26.8958],\n",
      "        [25.2967, 30.1812],\n",
      "        [27.8909, 27.8558]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9749, 29.9521],\n",
      "        [31.9547, 26.8959],\n",
      "        [25.2967, 30.1812],\n",
      "        [27.8908, 27.8558]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9623], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9750, 29.9520],\n",
      "        [31.9547, 26.8959],\n",
      "        [25.2968, 30.1812],\n",
      "        [27.8909, 27.8558]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9749, 29.9521],\n",
      "        [31.9547, 26.8960],\n",
      "        [25.2968, 30.1812],\n",
      "        [27.8909, 27.8559]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9846, 0.1131, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9750, 29.9521],\n",
      "        [31.9548, 26.8960],\n",
      "        [25.2968, 30.1812],\n",
      "        [27.8909, 27.8559]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9847, 0.1131, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9750, 29.9521],\n",
      "        [31.9547, 26.8960],\n",
      "        [25.2968, 30.1812],\n",
      "        [27.8909, 27.8559]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9847, 0.1131, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9750, 29.9521],\n",
      "        [31.9548, 26.8960],\n",
      "        [25.2969, 30.1812],\n",
      "        [27.8909, 27.8559]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9750, 29.9521],\n",
      "        [31.9547, 26.8961],\n",
      "        [25.2969, 30.1813],\n",
      "        [27.8909, 27.8559]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9750, 29.9521],\n",
      "        [31.9548, 26.8961],\n",
      "        [25.2969, 30.1813],\n",
      "        [27.8909, 27.8559]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9750, 29.9521],\n",
      "        [31.9548, 26.8961],\n",
      "        [25.2969, 30.1813],\n",
      "        [27.8909, 27.8559]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9750, 29.9521],\n",
      "        [31.9548, 26.8961],\n",
      "        [25.2970, 30.1813],\n",
      "        [27.8910, 27.8559]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9750, 29.9521],\n",
      "        [31.9548, 26.8962],\n",
      "        [25.2969, 30.1813],\n",
      "        [27.8909, 27.8559]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9750, 29.9522],\n",
      "        [31.9549, 26.8962],\n",
      "        [25.2970, 30.1813],\n",
      "        [27.8910, 27.8559]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9750, 29.9522],\n",
      "        [31.9548, 26.8962],\n",
      "        [25.2970, 30.1813],\n",
      "        [27.8909, 27.8560]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9750, 29.9522],\n",
      "        [31.9549, 26.8962],\n",
      "        [25.2971, 30.1813],\n",
      "        [27.8910, 27.8560]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9750, 29.9522],\n",
      "        [31.9548, 26.8963],\n",
      "        [25.2970, 30.1814],\n",
      "        [27.8910, 27.8560]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9751, 29.9522],\n",
      "        [31.9549, 26.8963],\n",
      "        [25.2971, 30.1814],\n",
      "        [27.8910, 27.8560]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9750, 29.9522],\n",
      "        [31.9549, 26.8964],\n",
      "        [25.2971, 30.1814],\n",
      "        [27.8910, 27.8560]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9751, 29.9522],\n",
      "        [31.9549, 26.8964],\n",
      "        [25.2972, 30.1814],\n",
      "        [27.8910, 27.8560]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9751, 29.9522],\n",
      "        [31.9549, 26.8964],\n",
      "        [25.2971, 30.1814],\n",
      "        [27.8910, 27.8560]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9751, 29.9522],\n",
      "        [31.9550, 26.8964],\n",
      "        [25.2972, 30.1814],\n",
      "        [27.8910, 27.8560]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9751, 29.9523],\n",
      "        [31.9549, 26.8965],\n",
      "        [25.2972, 30.1815],\n",
      "        [27.8910, 27.8561]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9751, 29.9523],\n",
      "        [31.9550, 26.8965],\n",
      "        [25.2973, 30.1814],\n",
      "        [27.8911, 27.8561]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9751, 29.9523],\n",
      "        [31.9550, 26.8965],\n",
      "        [25.2972, 30.1815],\n",
      "        [27.8910, 27.8561]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9847, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9751, 29.9523],\n",
      "        [31.9550, 26.8965],\n",
      "        [25.2973, 30.1815],\n",
      "        [27.8911, 27.8561]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9848, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9751, 29.9523],\n",
      "        [31.9550, 26.8966],\n",
      "        [25.2973, 30.1815],\n",
      "        [27.8911, 27.8561]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9848, 0.1132, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9751, 29.9523],\n",
      "        [31.9551, 26.8966],\n",
      "        [25.2974, 30.1815],\n",
      "        [27.8911, 27.8561]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9751, 29.9523],\n",
      "        [31.9550, 26.8966],\n",
      "        [25.2973, 30.1815],\n",
      "        [27.8911, 27.8561]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9752, 29.9523],\n",
      "        [31.9551, 26.8966],\n",
      "        [25.2974, 30.1815],\n",
      "        [27.8911, 27.8561]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9751, 29.9524],\n",
      "        [31.9551, 26.8967],\n",
      "        [25.2974, 30.1816],\n",
      "        [27.8911, 27.8562]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9752, 29.9524],\n",
      "        [31.9551, 26.8967],\n",
      "        [25.2975, 30.1815],\n",
      "        [27.8911, 27.8562]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9751, 29.9524],\n",
      "        [31.9551, 26.8968],\n",
      "        [25.2974, 30.1816],\n",
      "        [27.8911, 27.8562]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9752, 29.9524],\n",
      "        [31.9552, 26.8968],\n",
      "        [25.2975, 30.1816],\n",
      "        [27.8911, 27.8562]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9752, 29.9524],\n",
      "        [31.9551, 26.8968],\n",
      "        [25.2975, 30.1816],\n",
      "        [27.8911, 27.8562]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9752, 29.9524],\n",
      "        [31.9552, 26.8968],\n",
      "        [25.2976, 30.1816],\n",
      "        [27.8912, 27.8562]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9752, 29.9524],\n",
      "        [31.9551, 26.8969],\n",
      "        [25.2975, 30.1816],\n",
      "        [27.8911, 27.8562]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9752, 29.9524],\n",
      "        [31.9552, 26.8969],\n",
      "        [25.2976, 30.1816],\n",
      "        [27.8912, 27.8562]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9752, 29.9524],\n",
      "        [31.9552, 26.8969],\n",
      "        [25.2976, 30.1817],\n",
      "        [27.8912, 27.8563]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9752, 29.9524],\n",
      "        [31.9553, 26.8970],\n",
      "        [25.2977, 30.1817],\n",
      "        [27.8912, 27.8563]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9752, 29.9525],\n",
      "        [31.9552, 26.8970],\n",
      "        [25.2976, 30.1817],\n",
      "        [27.8912, 27.8563]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9753, 29.9525],\n",
      "        [31.9553, 26.8970],\n",
      "        [25.2977, 30.1817],\n",
      "        [27.8912, 27.8563]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9752, 29.9525],\n",
      "        [31.9552, 26.8971],\n",
      "        [25.2977, 30.1817],\n",
      "        [27.8912, 27.8563]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9753, 29.9525],\n",
      "        [31.9553, 26.8971],\n",
      "        [25.2977, 30.1817],\n",
      "        [27.8912, 27.8563]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9753, 29.9525],\n",
      "        [31.9553, 26.8971],\n",
      "        [25.2977, 30.1817],\n",
      "        [27.8912, 27.8563]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9848, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9753, 29.9525],\n",
      "        [31.9553, 26.8971],\n",
      "        [25.2978, 30.1817],\n",
      "        [27.8913, 27.8563]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9849, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9753, 29.9525],\n",
      "        [31.9553, 26.8972],\n",
      "        [25.2978, 30.1818],\n",
      "        [27.8913, 27.8564]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9849, 0.1133, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9753, 29.9525],\n",
      "        [31.9554, 26.8972],\n",
      "        [25.2978, 30.1818],\n",
      "        [27.8913, 27.8563]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9753, 29.9525],\n",
      "        [31.9553, 26.8972],\n",
      "        [25.2978, 30.1818],\n",
      "        [27.8913, 27.8564]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9753, 29.9525],\n",
      "        [31.9554, 26.8972],\n",
      "        [25.2979, 30.1818],\n",
      "        [27.8913, 27.8564]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9753, 29.9526],\n",
      "        [31.9554, 26.8973],\n",
      "        [25.2979, 30.1818],\n",
      "        [27.8913, 27.8564]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9753, 29.9526],\n",
      "        [31.9554, 26.8973],\n",
      "        [25.2979, 30.1818],\n",
      "        [27.8913, 27.8564]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9753, 29.9526],\n",
      "        [31.9554, 26.8974],\n",
      "        [25.2979, 30.1818],\n",
      "        [27.8913, 27.8564]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9754, 29.9526],\n",
      "        [31.9555, 26.8974],\n",
      "        [25.2980, 30.1818],\n",
      "        [27.8913, 27.8564]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9753, 29.9526],\n",
      "        [31.9554, 26.8974],\n",
      "        [25.2980, 30.1819],\n",
      "        [27.8913, 27.8564]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9754, 29.9526],\n",
      "        [31.9555, 26.8974],\n",
      "        [25.2980, 30.1819],\n",
      "        [27.8914, 27.8564]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9754, 29.9526],\n",
      "        [31.9554, 26.8975],\n",
      "        [25.2980, 30.1819],\n",
      "        [27.8913, 27.8565]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9754, 29.9526],\n",
      "        [31.9555, 26.8975],\n",
      "        [25.2981, 30.1819],\n",
      "        [27.8914, 27.8565]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9754, 29.9527],\n",
      "        [31.9555, 26.8975],\n",
      "        [25.2981, 30.1819],\n",
      "        [27.8914, 27.8565]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9754, 29.9527],\n",
      "        [31.9555, 26.8975],\n",
      "        [25.2981, 30.1819],\n",
      "        [27.8914, 27.8565]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9754, 29.9527],\n",
      "        [31.9555, 26.8976],\n",
      "        [25.2981, 30.1819],\n",
      "        [27.8914, 27.8565]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9754, 29.9527],\n",
      "        [31.9556, 26.8976],\n",
      "        [25.2982, 30.1819],\n",
      "        [27.8914, 27.8565]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9754, 29.9527],\n",
      "        [31.9555, 26.8976],\n",
      "        [25.2981, 30.1820],\n",
      "        [27.8914, 27.8565]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9754, 29.9527],\n",
      "        [31.9556, 26.8976],\n",
      "        [25.2982, 30.1820],\n",
      "        [27.8914, 27.8565]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9754, 29.9527],\n",
      "        [31.9556, 26.8977],\n",
      "        [25.2982, 30.1820],\n",
      "        [27.8914, 27.8565]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9849, 0.1134, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9754, 29.9527],\n",
      "        [31.9556, 26.8977],\n",
      "        [25.2983, 30.1820],\n",
      "        [27.8914, 27.8565]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9754, 29.9527],\n",
      "        [31.9556, 26.8977],\n",
      "        [25.2982, 30.1820],\n",
      "        [27.8914, 27.8566]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9754, 29.9527],\n",
      "        [31.9556, 26.8977],\n",
      "        [25.2983, 30.1820],\n",
      "        [27.8915, 27.8566]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9754, 29.9528],\n",
      "        [31.9556, 26.8978],\n",
      "        [25.2983, 30.1820],\n",
      "        [27.8914, 27.8566]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9755, 29.9528],\n",
      "        [31.9557, 26.8978],\n",
      "        [25.2984, 30.1820],\n",
      "        [27.8915, 27.8566]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9754, 29.9528],\n",
      "        [31.9556, 26.8979],\n",
      "        [25.2983, 30.1821],\n",
      "        [27.8915, 27.8566]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9755, 29.9528],\n",
      "        [31.9557, 26.8979],\n",
      "        [25.2984, 30.1821],\n",
      "        [27.8915, 27.8566]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9755, 29.9528],\n",
      "        [31.9557, 26.8979],\n",
      "        [25.2984, 30.1821],\n",
      "        [27.8915, 27.8566]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9755, 29.9528],\n",
      "        [31.9557, 26.8979],\n",
      "        [25.2985, 30.1821],\n",
      "        [27.8915, 27.8566]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9755, 29.9528],\n",
      "        [31.9557, 26.8980],\n",
      "        [25.2984, 30.1821],\n",
      "        [27.8915, 27.8567]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9755, 29.9528],\n",
      "        [31.9558, 26.8980],\n",
      "        [25.2985, 30.1821],\n",
      "        [27.8915, 27.8567]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9755, 29.9528],\n",
      "        [31.9557, 26.8980],\n",
      "        [25.2985, 30.1821],\n",
      "        [27.8915, 27.8567]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9755, 29.9528],\n",
      "        [31.9558, 26.8980],\n",
      "        [25.2986, 30.1821],\n",
      "        [27.8916, 27.8567]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9755, 29.9529],\n",
      "        [31.9557, 26.8981],\n",
      "        [25.2985, 30.1822],\n",
      "        [27.8915, 27.8567]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9755, 29.9529],\n",
      "        [31.9558, 26.8981],\n",
      "        [25.2986, 30.1821],\n",
      "        [27.8916, 27.8567]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9755, 29.9529],\n",
      "        [31.9558, 26.8981],\n",
      "        [25.2986, 30.1822],\n",
      "        [27.8916, 27.8567]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9986, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9756, 29.9529],\n",
      "        [31.9559, 26.8982],\n",
      "        [25.2987, 30.1822],\n",
      "        [27.8916, 27.8567]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9755, 29.9529],\n",
      "        [31.9558, 26.8982],\n",
      "        [25.2986, 30.1822],\n",
      "        [27.8916, 27.8567]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9756, 29.9529],\n",
      "        [31.9559, 26.8982],\n",
      "        [25.2987, 30.1822],\n",
      "        [27.8916, 27.8567]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9756, 29.9529],\n",
      "        [31.9558, 26.8983],\n",
      "        [25.2987, 30.1822],\n",
      "        [27.8916, 27.8568]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9850, 0.1135, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9756, 29.9529],\n",
      "        [31.9559, 26.8983],\n",
      "        [25.2987, 30.1822],\n",
      "        [27.8916, 27.8568]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9850, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9756, 29.9529],\n",
      "        [31.9559, 26.8983],\n",
      "        [25.2987, 30.1823],\n",
      "        [27.8916, 27.8568]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9850, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9756, 29.9530],\n",
      "        [31.9559, 26.8983],\n",
      "        [25.2988, 30.1823],\n",
      "        [27.8916, 27.8568]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9756, 29.9530],\n",
      "        [31.9559, 26.8984],\n",
      "        [25.2988, 30.1823],\n",
      "        [27.8916, 27.8568]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9756, 29.9530],\n",
      "        [31.9560, 26.8984],\n",
      "        [25.2988, 30.1823],\n",
      "        [27.8917, 27.8568]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9756, 29.9530],\n",
      "        [31.9559, 26.8984],\n",
      "        [25.2988, 30.1823],\n",
      "        [27.8916, 27.8568]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9756, 29.9530],\n",
      "        [31.9560, 26.8984],\n",
      "        [25.2989, 30.1823],\n",
      "        [27.8917, 27.8568]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9756, 29.9530],\n",
      "        [31.9560, 26.8985],\n",
      "        [25.2989, 30.1823],\n",
      "        [27.8917, 27.8569]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9756, 29.9530],\n",
      "        [31.9560, 26.8985],\n",
      "        [25.2989, 30.1823],\n",
      "        [27.8917, 27.8569]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9756, 29.9530],\n",
      "        [31.9560, 26.8985],\n",
      "        [25.2989, 30.1824],\n",
      "        [27.8917, 27.8569]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9757, 29.9530],\n",
      "        [31.9561, 26.8985],\n",
      "        [25.2990, 30.1824],\n",
      "        [27.8917, 27.8569]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9757, 29.9531],\n",
      "        [31.9560, 26.8986],\n",
      "        [25.2990, 30.1824],\n",
      "        [27.8917, 27.8569]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9757, 29.9531],\n",
      "        [31.9561, 26.8986],\n",
      "        [25.2990, 30.1824],\n",
      "        [27.8917, 27.8569]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9757, 29.9531],\n",
      "        [31.9561, 26.8987],\n",
      "        [25.2990, 30.1824],\n",
      "        [27.8917, 27.8569]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9757, 29.9531],\n",
      "        [31.9561, 26.8987],\n",
      "        [25.2991, 30.1824],\n",
      "        [27.8918, 27.8569]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9757, 29.9531],\n",
      "        [31.9561, 26.8987],\n",
      "        [25.2990, 30.1824],\n",
      "        [27.8917, 27.8570]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9757, 29.9531],\n",
      "        [31.9561, 26.8987],\n",
      "        [25.2991, 30.1824],\n",
      "        [27.8918, 27.8570]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9757, 29.9531],\n",
      "        [31.9561, 26.8988],\n",
      "        [25.2991, 30.1825],\n",
      "        [27.8917, 27.8570]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9757, 29.9531],\n",
      "        [31.9562, 26.8988],\n",
      "        [25.2992, 30.1825],\n",
      "        [27.8918, 27.8570]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9757, 29.9531],\n",
      "        [31.9561, 26.8988],\n",
      "        [25.2991, 30.1825],\n",
      "        [27.8918, 27.8570]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9851, 0.1136, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9757, 29.9531],\n",
      "        [31.9562, 26.8988],\n",
      "        [25.2992, 30.1825],\n",
      "        [27.8918, 27.8570]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9851, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9757, 29.9532],\n",
      "        [31.9562, 26.8989],\n",
      "        [25.2992, 30.1825],\n",
      "        [27.8918, 27.8570]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9851, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9757, 29.9532],\n",
      "        [31.9562, 26.8989],\n",
      "        [25.2993, 30.1825],\n",
      "        [27.8918, 27.8570]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9757, 29.9532],\n",
      "        [31.9562, 26.8989],\n",
      "        [25.2992, 30.1826],\n",
      "        [27.8918, 27.8570]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9758, 29.9532],\n",
      "        [31.9563, 26.8989],\n",
      "        [25.2993, 30.1825],\n",
      "        [27.8918, 27.8570]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9758, 29.9532],\n",
      "        [31.9562, 26.8990],\n",
      "        [25.2993, 30.1826],\n",
      "        [27.8918, 27.8571]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9758, 29.9532],\n",
      "        [31.9563, 26.8990],\n",
      "        [25.2994, 30.1826],\n",
      "        [27.8919, 27.8571]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9758, 29.9532],\n",
      "        [31.9562, 26.8991],\n",
      "        [25.2993, 30.1826],\n",
      "        [27.8919, 27.8571]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9758, 29.9532],\n",
      "        [31.9563, 26.8990],\n",
      "        [25.2994, 30.1826],\n",
      "        [27.8919, 27.8571]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9758, 29.9532],\n",
      "        [31.9563, 26.8991],\n",
      "        [25.2994, 30.1826],\n",
      "        [27.8919, 27.8571]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9758, 29.9532],\n",
      "        [31.9563, 26.8991],\n",
      "        [25.2994, 30.1826],\n",
      "        [27.8919, 27.8571]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9758, 29.9533],\n",
      "        [31.9563, 26.8992],\n",
      "        [25.2994, 30.1826],\n",
      "        [27.8919, 27.8571]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9758, 29.9533],\n",
      "        [31.9564, 26.8991],\n",
      "        [25.2995, 30.1826],\n",
      "        [27.8919, 27.8571]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9758, 29.9533],\n",
      "        [31.9563, 26.8992],\n",
      "        [25.2995, 30.1827],\n",
      "        [27.8919, 27.8571]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9758, 29.9533],\n",
      "        [31.9564, 26.8992],\n",
      "        [25.2995, 30.1827],\n",
      "        [27.8919, 27.8571]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9758, 29.9533],\n",
      "        [31.9563, 26.8993],\n",
      "        [25.2995, 30.1827],\n",
      "        [27.8919, 27.8572]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9758, 29.9533],\n",
      "        [31.9564, 26.8993],\n",
      "        [25.2996, 30.1827],\n",
      "        [27.8919, 27.8572]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9758, 29.9533],\n",
      "        [31.9564, 26.8993],\n",
      "        [25.2996, 30.1827],\n",
      "        [27.8919, 27.8572]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9759, 29.9533],\n",
      "        [31.9564, 26.8993],\n",
      "        [25.2996, 30.1827],\n",
      "        [27.8920, 27.8572]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9759, 29.9534],\n",
      "        [31.9564, 26.8994],\n",
      "        [25.2996, 30.1827],\n",
      "        [27.8920, 27.8572]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9852, 0.1137, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9759, 29.9534],\n",
      "        [31.9565, 26.8994],\n",
      "        [25.2997, 30.1827],\n",
      "        [27.8920, 27.8572]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9852, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9759, 29.9534],\n",
      "        [31.9564, 26.8994],\n",
      "        [25.2996, 30.1828],\n",
      "        [27.8920, 27.8572]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9852, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9759, 29.9534],\n",
      "        [31.9565, 26.8994],\n",
      "        [25.2997, 30.1828],\n",
      "        [27.8920, 27.8572]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9852, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9759, 29.9534],\n",
      "        [31.9565, 26.8995],\n",
      "        [25.2997, 30.1828],\n",
      "        [27.8920, 27.8573]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9852, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9759, 29.9534],\n",
      "        [31.9565, 26.8995],\n",
      "        [25.2998, 30.1828],\n",
      "        [27.8920, 27.8573]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9759, 29.9534],\n",
      "        [31.9565, 26.8995],\n",
      "        [25.2997, 30.1828],\n",
      "        [27.8920, 27.8573]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9759, 29.9534],\n",
      "        [31.9566, 26.8995],\n",
      "        [25.2998, 30.1828],\n",
      "        [27.8920, 27.8573]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9759, 29.9534],\n",
      "        [31.9565, 26.8996],\n",
      "        [25.2998, 30.1828],\n",
      "        [27.8920, 27.8573]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9759, 29.9534],\n",
      "        [31.9566, 26.8996],\n",
      "        [25.2999, 30.1828],\n",
      "        [27.8921, 27.8573]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9759, 29.9534],\n",
      "        [31.9565, 26.8996],\n",
      "        [25.2998, 30.1829],\n",
      "        [27.8920, 27.8573]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9759, 29.9534],\n",
      "        [31.9566, 26.8996],\n",
      "        [25.2999, 30.1828],\n",
      "        [27.8921, 27.8573]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9759, 29.9535],\n",
      "        [31.9566, 26.8997],\n",
      "        [25.2999, 30.1829],\n",
      "        [27.8921, 27.8574]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9760, 29.9535],\n",
      "        [31.9566, 26.8997],\n",
      "        [25.3000, 30.1829],\n",
      "        [27.8921, 27.8573]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9760, 29.9535],\n",
      "        [31.9566, 26.8998],\n",
      "        [25.2999, 30.1829],\n",
      "        [27.8921, 27.8574]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9760, 29.9535],\n",
      "        [31.9567, 26.8998],\n",
      "        [25.3000, 30.1829],\n",
      "        [27.8921, 27.8574]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9760, 29.9535],\n",
      "        [31.9566, 26.8998],\n",
      "        [25.3000, 30.1829],\n",
      "        [27.8921, 27.8574]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9760, 29.9535],\n",
      "        [31.9567, 26.8998],\n",
      "        [25.3000, 30.1829],\n",
      "        [27.8921, 27.8574]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9760, 29.9536],\n",
      "        [31.9567, 26.8999],\n",
      "        [25.3000, 30.1830],\n",
      "        [27.8921, 27.8574]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9853, 0.1138, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9760, 29.9535],\n",
      "        [31.9567, 26.8999],\n",
      "        [25.3001, 30.1830],\n",
      "        [27.8921, 27.8574]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9853, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9760, 29.9536],\n",
      "        [31.9567, 26.8999],\n",
      "        [25.3001, 30.1830],\n",
      "        [27.8921, 27.8574]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9853, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9760, 29.9536],\n",
      "        [31.9568, 26.8999],\n",
      "        [25.3001, 30.1830],\n",
      "        [27.8922, 27.8574]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9853, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9760, 29.9536],\n",
      "        [31.9567, 26.9000],\n",
      "        [25.3001, 30.1830],\n",
      "        [27.8922, 27.8575]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9853, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9760, 29.9536],\n",
      "        [31.9568, 26.9000],\n",
      "        [25.3002, 30.1830],\n",
      "        [27.8922, 27.8575]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9853, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9760, 29.9536],\n",
      "        [31.9567, 26.9000],\n",
      "        [25.3002, 30.1830],\n",
      "        [27.8922, 27.8575]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9853, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9761, 29.9536],\n",
      "        [31.9568, 26.9000],\n",
      "        [25.3002, 30.1830],\n",
      "        [27.8922, 27.8575]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9853, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9760, 29.9536],\n",
      "        [31.9568, 26.9001],\n",
      "        [25.3002, 30.1831],\n",
      "        [27.8922, 27.8575]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9853, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9761, 29.9536],\n",
      "        [31.9568, 26.9001],\n",
      "        [25.3003, 30.1831],\n",
      "        [27.8922, 27.8575]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9854, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9761, 29.9537],\n",
      "        [31.9568, 26.9002],\n",
      "        [25.3003, 30.1831],\n",
      "        [27.8922, 27.8575]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9854, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9761, 29.9537],\n",
      "        [31.9569, 26.9002],\n",
      "        [25.3003, 30.1831],\n",
      "        [27.8922, 27.8575]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9854, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9761, 29.9537],\n",
      "        [31.9568, 26.9002],\n",
      "        [25.3003, 30.1831],\n",
      "        [27.8922, 27.8575]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9854, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9761, 29.9537],\n",
      "        [31.9569, 26.9002],\n",
      "        [25.3004, 30.1831],\n",
      "        [27.8923, 27.8575]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9854, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9761, 29.9537],\n",
      "        [31.9569, 26.9003],\n",
      "        [25.3004, 30.1831],\n",
      "        [27.8922, 27.8576]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9854, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9761, 29.9537],\n",
      "        [31.9569, 26.9003],\n",
      "        [25.3004, 30.1831],\n",
      "        [27.8923, 27.8576]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9854, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9761, 29.9537],\n",
      "        [31.9569, 26.9003],\n",
      "        [25.3004, 30.1832],\n",
      "        [27.8923, 27.8576]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9854, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9761, 29.9537],\n",
      "        [31.9569, 26.9003],\n",
      "        [25.3005, 30.1831],\n",
      "        [27.8923, 27.8576]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9854, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9761, 29.9537],\n",
      "        [31.9569, 26.9004],\n",
      "        [25.3004, 30.1832],\n",
      "        [27.8923, 27.8576]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9854, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9761, 29.9537],\n",
      "        [31.9570, 26.9004],\n",
      "        [25.3005, 30.1832],\n",
      "        [27.8923, 27.8576]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9854, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9761, 29.9538],\n",
      "        [31.9569, 26.9004],\n",
      "        [25.3005, 30.1832],\n",
      "        [27.8923, 27.8576]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9854, 0.1139, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9762, 29.9538],\n",
      "        [31.9570, 26.9004],\n",
      "        [25.3006, 30.1832],\n",
      "        [27.8923, 27.8576]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9854, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9761, 29.9538],\n",
      "        [31.9570, 26.9005],\n",
      "        [25.3005, 30.1832],\n",
      "        [27.8923, 27.8577]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9854, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9762, 29.9538],\n",
      "        [31.9570, 26.9005],\n",
      "        [25.3006, 30.1832],\n",
      "        [27.8923, 27.8577]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9854, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9761, 29.9538],\n",
      "        [31.9570, 26.9005],\n",
      "        [25.3006, 30.1832],\n",
      "        [27.8923, 27.8577]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9854, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9762, 29.9538],\n",
      "        [31.9570, 26.9005],\n",
      "        [25.3006, 30.1832],\n",
      "        [27.8924, 27.8577]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9854, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9762, 29.9538],\n",
      "        [31.9570, 26.9006],\n",
      "        [25.3006, 30.1833],\n",
      "        [27.8923, 27.8577]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9854, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9762, 29.9538],\n",
      "        [31.9571, 26.9006],\n",
      "        [25.3007, 30.1833],\n",
      "        [27.8924, 27.8577]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9854, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9762, 29.9538],\n",
      "        [31.9570, 26.9006],\n",
      "        [25.3007, 30.1833],\n",
      "        [27.8923, 27.8577]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9854, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9762, 29.9538],\n",
      "        [31.9571, 26.9006],\n",
      "        [25.3007, 30.1833],\n",
      "        [27.8924, 27.8577]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9854, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9762, 29.9538],\n",
      "        [31.9571, 26.9007],\n",
      "        [25.3007, 30.1833],\n",
      "        [27.8924, 27.8577]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9854, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9762, 29.9538],\n",
      "        [31.9571, 26.9007],\n",
      "        [25.3008, 30.1833],\n",
      "        [27.8924, 27.8577]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9855, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9762, 29.9539],\n",
      "        [31.9571, 26.9007],\n",
      "        [25.3008, 30.1834],\n",
      "        [27.8924, 27.8578]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9855, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9762, 29.9539],\n",
      "        [31.9571, 26.9007],\n",
      "        [25.3008, 30.1833],\n",
      "        [27.8924, 27.8577]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9855, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9762, 29.9539],\n",
      "        [31.9571, 26.9008],\n",
      "        [25.3008, 30.1834],\n",
      "        [27.8924, 27.8578]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9855, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9762, 29.9539],\n",
      "        [31.9572, 26.9008],\n",
      "        [25.3009, 30.1834],\n",
      "        [27.8924, 27.8578]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9855, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9762, 29.9539],\n",
      "        [31.9572, 26.9009],\n",
      "        [25.3009, 30.1834],\n",
      "        [27.8924, 27.8578]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9855, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9763, 29.9539],\n",
      "        [31.9572, 26.9009],\n",
      "        [25.3009, 30.1834],\n",
      "        [27.8925, 27.8578]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9855, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9762, 29.9539],\n",
      "        [31.9572, 26.9009],\n",
      "        [25.3009, 30.1834],\n",
      "        [27.8924, 27.8578]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9855, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9763, 29.9539],\n",
      "        [31.9572, 26.9009],\n",
      "        [25.3010, 30.1834],\n",
      "        [27.8925, 27.8578]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9855, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9763, 29.9539],\n",
      "        [31.9572, 26.9010],\n",
      "        [25.3010, 30.1834],\n",
      "        [27.8925, 27.8578]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9855, 0.1140, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9763, 29.9539],\n",
      "        [31.9573, 26.9010],\n",
      "        [25.3010, 30.1834],\n",
      "        [27.8925, 27.8578]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9763, 29.9540],\n",
      "        [31.9572, 26.9010],\n",
      "        [25.3010, 30.1835],\n",
      "        [27.8925, 27.8579]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9763, 29.9540],\n",
      "        [31.9573, 26.9010],\n",
      "        [25.3011, 30.1835],\n",
      "        [27.8925, 27.8579]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9763, 29.9540],\n",
      "        [31.9573, 26.9011],\n",
      "        [25.3010, 30.1835],\n",
      "        [27.8925, 27.8579]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9624], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9763, 29.9540],\n",
      "        [31.9573, 26.9011],\n",
      "        [25.3011, 30.1835],\n",
      "        [27.8925, 27.8579]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9763, 29.9540],\n",
      "        [31.9573, 26.9011],\n",
      "        [25.3011, 30.1835],\n",
      "        [27.8925, 27.8579]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9763, 29.9540],\n",
      "        [31.9574, 26.9011],\n",
      "        [25.3012, 30.1835],\n",
      "        [27.8926, 27.8579]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9763, 29.9540],\n",
      "        [31.9573, 26.9012],\n",
      "        [25.3011, 30.1835],\n",
      "        [27.8925, 27.8579]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9763, 29.9540],\n",
      "        [31.9574, 26.9012],\n",
      "        [25.3012, 30.1835],\n",
      "        [27.8926, 27.8579]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9763, 29.9541],\n",
      "        [31.9573, 26.9012],\n",
      "        [25.3012, 30.1836],\n",
      "        [27.8925, 27.8580]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9764, 29.9541],\n",
      "        [31.9574, 26.9012],\n",
      "        [25.3013, 30.1836],\n",
      "        [27.8926, 27.8580]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9764, 29.9541],\n",
      "        [31.9574, 26.9013],\n",
      "        [25.3012, 30.1836],\n",
      "        [27.8926, 27.8580]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9764, 29.9541],\n",
      "        [31.9574, 26.9013],\n",
      "        [25.3013, 30.1836],\n",
      "        [27.8926, 27.8580]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9764, 29.9541],\n",
      "        [31.9574, 26.9013],\n",
      "        [25.3013, 30.1836],\n",
      "        [27.8926, 27.8580]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9855, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9764, 29.9541],\n",
      "        [31.9575, 26.9013],\n",
      "        [25.3013, 30.1836],\n",
      "        [27.8926, 27.8580]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9856, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9764, 29.9541],\n",
      "        [31.9574, 26.9014],\n",
      "        [25.3013, 30.1836],\n",
      "        [27.8926, 27.8580]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9856, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9764, 29.9541],\n",
      "        [31.9575, 26.9014],\n",
      "        [25.3014, 30.1836],\n",
      "        [27.8926, 27.8580]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9856, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9764, 29.9541],\n",
      "        [31.9575, 26.9014],\n",
      "        [25.3014, 30.1837],\n",
      "        [27.8926, 27.8580]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9856, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9764, 29.9541],\n",
      "        [31.9575, 26.9014],\n",
      "        [25.3014, 30.1837],\n",
      "        [27.8927, 27.8580]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9856, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9764, 29.9542],\n",
      "        [31.9575, 26.9015],\n",
      "        [25.3014, 30.1837],\n",
      "        [27.8926, 27.8581]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9856, 0.1141, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9764, 29.9542],\n",
      "        [31.9575, 26.9015],\n",
      "        [25.3015, 30.1837],\n",
      "        [27.8927, 27.8581]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9764, 29.9542],\n",
      "        [31.9575, 26.9015],\n",
      "        [25.3015, 30.1837],\n",
      "        [27.8927, 27.8581]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9765, 29.9542],\n",
      "        [31.9576, 26.9015],\n",
      "        [25.3015, 30.1837],\n",
      "        [27.8927, 27.8581]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9764, 29.9542],\n",
      "        [31.9575, 26.9016],\n",
      "        [25.3015, 30.1837],\n",
      "        [27.8927, 27.8581]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9765, 29.9542],\n",
      "        [31.9576, 26.9016],\n",
      "        [25.3016, 30.1837],\n",
      "        [27.8927, 27.8581]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9765, 29.9542],\n",
      "        [31.9576, 26.9017],\n",
      "        [25.3015, 30.1838],\n",
      "        [27.8927, 27.8581]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9765, 29.9542],\n",
      "        [31.9576, 26.9017],\n",
      "        [25.3016, 30.1837],\n",
      "        [27.8927, 27.8581]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9765, 29.9542],\n",
      "        [31.9576, 26.9017],\n",
      "        [25.3016, 30.1838],\n",
      "        [27.8927, 27.8582]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9765, 29.9542],\n",
      "        [31.9576, 26.9017],\n",
      "        [25.3017, 30.1838],\n",
      "        [27.8927, 27.8581]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9765, 29.9543],\n",
      "        [31.9576, 26.9018],\n",
      "        [25.3016, 30.1838],\n",
      "        [27.8927, 27.8582]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9765, 29.9543],\n",
      "        [31.9577, 26.9018],\n",
      "        [25.3017, 30.1838],\n",
      "        [27.8928, 27.8582]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9765, 29.9543],\n",
      "        [31.9576, 26.9018],\n",
      "        [25.3017, 30.1838],\n",
      "        [27.8927, 27.8582]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9765, 29.9543],\n",
      "        [31.9577, 26.9018],\n",
      "        [25.3018, 30.1838],\n",
      "        [27.8928, 27.8582]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9765, 29.9543],\n",
      "        [31.9577, 26.9019],\n",
      "        [25.3017, 30.1839],\n",
      "        [27.8928, 27.8582]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9765, 29.9543],\n",
      "        [31.9577, 26.9019],\n",
      "        [25.3018, 30.1838],\n",
      "        [27.8928, 27.8582]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9765, 29.9543],\n",
      "        [31.9577, 26.9019],\n",
      "        [25.3018, 30.1839],\n",
      "        [27.8928, 27.8582]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9856, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9766, 29.9543],\n",
      "        [31.9577, 26.9019],\n",
      "        [25.3018, 30.1839],\n",
      "        [27.8928, 27.8582]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9857, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9765, 29.9543],\n",
      "        [31.9577, 26.9020],\n",
      "        [25.3018, 30.1839],\n",
      "        [27.8928, 27.8583]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9857, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9766, 29.9543],\n",
      "        [31.9578, 26.9020],\n",
      "        [25.3019, 30.1839],\n",
      "        [27.8928, 27.8583]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9857, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9765, 29.9544],\n",
      "        [31.9577, 26.9020],\n",
      "        [25.3019, 30.1839],\n",
      "        [27.8928, 27.8583]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9857, 0.1142, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9766, 29.9544],\n",
      "        [31.9578, 26.9020],\n",
      "        [25.3019, 30.1839],\n",
      "        [27.8928, 27.8583]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9765, 29.9544],\n",
      "        [31.9578, 26.9021],\n",
      "        [25.3019, 30.1839],\n",
      "        [27.8928, 27.8583]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9766, 29.9544],\n",
      "        [31.9578, 26.9021],\n",
      "        [25.3020, 30.1839],\n",
      "        [27.8928, 27.8583]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9766, 29.9544],\n",
      "        [31.9578, 26.9021],\n",
      "        [25.3019, 30.1840],\n",
      "        [27.8928, 27.8583]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9766, 29.9544],\n",
      "        [31.9578, 26.9021],\n",
      "        [25.3020, 30.1839],\n",
      "        [27.8929, 27.8583]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9766, 29.9544],\n",
      "        [31.9578, 26.9022],\n",
      "        [25.3020, 30.1840],\n",
      "        [27.8929, 27.8583]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9766, 29.9544],\n",
      "        [31.9579, 26.9022],\n",
      "        [25.3021, 30.1840],\n",
      "        [27.8929, 27.8583]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9766, 29.9544],\n",
      "        [31.9578, 26.9022],\n",
      "        [25.3020, 30.1840],\n",
      "        [27.8929, 27.8583]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9766, 29.9544],\n",
      "        [31.9579, 26.9022],\n",
      "        [25.3021, 30.1840],\n",
      "        [27.8929, 27.8583]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9766, 29.9544],\n",
      "        [31.9579, 26.9023],\n",
      "        [25.3021, 30.1840],\n",
      "        [27.8929, 27.8584]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9766, 29.9544],\n",
      "        [31.9579, 26.9023],\n",
      "        [25.3022, 30.1840],\n",
      "        [27.8929, 27.8584]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9766, 29.9545],\n",
      "        [31.9579, 26.9023],\n",
      "        [25.3021, 30.1841],\n",
      "        [27.8929, 27.8584]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9767, 29.9545],\n",
      "        [31.9580, 26.9023],\n",
      "        [25.3022, 30.1841],\n",
      "        [27.8929, 27.8584]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9766, 29.9545],\n",
      "        [31.9579, 26.9024],\n",
      "        [25.3022, 30.1841],\n",
      "        [27.8929, 27.8584]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9767, 29.9545],\n",
      "        [31.9580, 26.9024],\n",
      "        [25.3022, 30.1841],\n",
      "        [27.8929, 27.8584]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9766, 29.9545],\n",
      "        [31.9579, 26.9024],\n",
      "        [25.3022, 30.1841],\n",
      "        [27.8929, 27.8584]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9767, 29.9545],\n",
      "        [31.9580, 26.9024],\n",
      "        [25.3023, 30.1841],\n",
      "        [27.8930, 27.8584]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9767, 29.9545],\n",
      "        [31.9580, 26.9025],\n",
      "        [25.3023, 30.1841],\n",
      "        [27.8930, 27.8585]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9857, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9767, 29.9545],\n",
      "        [31.9580, 26.9025],\n",
      "        [25.3023, 30.1841],\n",
      "        [27.8930, 27.8585]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9858, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9767, 29.9546],\n",
      "        [31.9580, 26.9025],\n",
      "        [25.3023, 30.1842],\n",
      "        [27.8930, 27.8585]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9858, 0.1143, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9767, 29.9545],\n",
      "        [31.9580, 26.9025],\n",
      "        [25.3024, 30.1841],\n",
      "        [27.8930, 27.8585]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9767, 29.9546],\n",
      "        [31.9580, 26.9026],\n",
      "        [25.3023, 30.1842],\n",
      "        [27.8930, 27.8585]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9767, 29.9546],\n",
      "        [31.9581, 26.9026],\n",
      "        [25.3024, 30.1842],\n",
      "        [27.8930, 27.8585]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9767, 29.9546],\n",
      "        [31.9580, 26.9026],\n",
      "        [25.3024, 30.1842],\n",
      "        [27.8930, 27.8585]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9767, 29.9546],\n",
      "        [31.9581, 26.9026],\n",
      "        [25.3025, 30.1842],\n",
      "        [27.8930, 27.8585]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9767, 29.9546],\n",
      "        [31.9581, 26.9027],\n",
      "        [25.3025, 30.1842],\n",
      "        [27.8930, 27.8585]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9768, 29.9546],\n",
      "        [31.9581, 26.9027],\n",
      "        [25.3025, 30.1842],\n",
      "        [27.8931, 27.8585]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9767, 29.9546],\n",
      "        [31.9581, 26.9027],\n",
      "        [25.3025, 30.1842],\n",
      "        [27.8930, 27.8586]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9768, 29.9546],\n",
      "        [31.9582, 26.9027],\n",
      "        [25.3026, 30.1842],\n",
      "        [27.8931, 27.8586]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9768, 29.9547],\n",
      "        [31.9581, 26.9028],\n",
      "        [25.3025, 30.1843],\n",
      "        [27.8931, 27.8586]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9768, 29.9547],\n",
      "        [31.9582, 26.9028],\n",
      "        [25.3026, 30.1843],\n",
      "        [27.8931, 27.8586]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9768, 29.9547],\n",
      "        [31.9582, 26.9029],\n",
      "        [25.3026, 30.1843],\n",
      "        [27.8931, 27.8586]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9768, 29.9547],\n",
      "        [31.9582, 26.9028],\n",
      "        [25.3027, 30.1843],\n",
      "        [27.8931, 27.8586]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9768, 29.9547],\n",
      "        [31.9582, 26.9029],\n",
      "        [25.3026, 30.1843],\n",
      "        [27.8931, 27.8586]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9768, 29.9547],\n",
      "        [31.9582, 26.9029],\n",
      "        [25.3027, 30.1843],\n",
      "        [27.8931, 27.8586]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9768, 29.9547],\n",
      "        [31.9582, 26.9029],\n",
      "        [25.3027, 30.1843],\n",
      "        [27.8931, 27.8586]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9768, 29.9547],\n",
      "        [31.9583, 26.9029],\n",
      "        [25.3028, 30.1843],\n",
      "        [27.8931, 27.8586]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9768, 29.9547],\n",
      "        [31.9582, 26.9030],\n",
      "        [25.3027, 30.1844],\n",
      "        [27.8931, 27.8587]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9768, 29.9547],\n",
      "        [31.9583, 26.9030],\n",
      "        [25.3028, 30.1844],\n",
      "        [27.8932, 27.8587]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9768, 29.9548],\n",
      "        [31.9583, 26.9031],\n",
      "        [25.3028, 30.1844],\n",
      "        [27.8931, 27.8587]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9769, 29.9548],\n",
      "        [31.9583, 26.9031],\n",
      "        [25.3028, 30.1844],\n",
      "        [27.8932, 27.8587]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9768, 29.9548],\n",
      "        [31.9583, 26.9031],\n",
      "        [25.3028, 30.1844],\n",
      "        [27.8932, 27.8587]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9858, 0.1144, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9769, 29.9548],\n",
      "        [31.9583, 26.9031],\n",
      "        [25.3029, 30.1844],\n",
      "        [27.8932, 27.8587]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9769, 29.9548],\n",
      "        [31.9583, 26.9032],\n",
      "        [25.3029, 30.1844],\n",
      "        [27.8932, 27.8587]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9769, 29.9548],\n",
      "        [31.9584, 26.9032],\n",
      "        [25.3029, 30.1844],\n",
      "        [27.8932, 27.8587]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9769, 29.9548],\n",
      "        [31.9583, 26.9032],\n",
      "        [25.3029, 30.1845],\n",
      "        [27.8932, 27.8588]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9769, 29.9548],\n",
      "        [31.9584, 26.9032],\n",
      "        [25.3030, 30.1845],\n",
      "        [27.8932, 27.8588]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9769, 29.9548],\n",
      "        [31.9584, 26.9033],\n",
      "        [25.3029, 30.1845],\n",
      "        [27.8932, 27.8588]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9769, 29.9548],\n",
      "        [31.9584, 26.9033],\n",
      "        [25.3030, 30.1845],\n",
      "        [27.8932, 27.8588]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9769, 29.9549],\n",
      "        [31.9584, 26.9033],\n",
      "        [25.3030, 30.1845],\n",
      "        [27.8932, 27.8588]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9769, 29.9549],\n",
      "        [31.9585, 26.9033],\n",
      "        [25.3031, 30.1845],\n",
      "        [27.8933, 27.8588]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9769, 29.9549],\n",
      "        [31.9584, 26.9034],\n",
      "        [25.3030, 30.1845],\n",
      "        [27.8933, 27.8588]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9769, 29.9549],\n",
      "        [31.9585, 26.9034],\n",
      "        [25.3031, 30.1845],\n",
      "        [27.8933, 27.8588]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9769, 29.9549],\n",
      "        [31.9584, 26.9034],\n",
      "        [25.3031, 30.1845],\n",
      "        [27.8933, 27.8588]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9769, 29.9549],\n",
      "        [31.9585, 26.9034],\n",
      "        [25.3032, 30.1845],\n",
      "        [27.8933, 27.8588]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9769, 29.9549],\n",
      "        [31.9585, 26.9035],\n",
      "        [25.3031, 30.1846],\n",
      "        [27.8933, 27.8589]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9769, 29.9549],\n",
      "        [31.9585, 26.9034],\n",
      "        [25.3032, 30.1845],\n",
      "        [27.8933, 27.8588]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9769, 29.9549],\n",
      "        [31.9585, 26.9035],\n",
      "        [25.3032, 30.1846],\n",
      "        [27.8933, 27.8589]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9770, 29.9549],\n",
      "        [31.9585, 26.9035],\n",
      "        [25.3032, 30.1846],\n",
      "        [27.8933, 27.8589]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9769, 29.9549],\n",
      "        [31.9585, 26.9036],\n",
      "        [25.3032, 30.1846],\n",
      "        [27.8933, 27.8589]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9770, 29.9549],\n",
      "        [31.9586, 26.9036],\n",
      "        [25.3033, 30.1846],\n",
      "        [27.8933, 27.8589]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9770, 29.9550],\n",
      "        [31.9585, 26.9036],\n",
      "        [25.3032, 30.1846],\n",
      "        [27.8933, 27.8589]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9859, 0.1145, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9770, 29.9549],\n",
      "        [31.9586, 26.9036],\n",
      "        [25.3033, 30.1846],\n",
      "        [27.8933, 27.8589]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9859, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9770, 29.9550],\n",
      "        [31.9586, 26.9037],\n",
      "        [25.3033, 30.1847],\n",
      "        [27.8933, 27.8589]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9859, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9770, 29.9550],\n",
      "        [31.9586, 26.9037],\n",
      "        [25.3034, 30.1846],\n",
      "        [27.8934, 27.8589]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9859, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9770, 29.9550],\n",
      "        [31.9586, 26.9037],\n",
      "        [25.3033, 30.1847],\n",
      "        [27.8934, 27.8590]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9859, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9770, 29.9550],\n",
      "        [31.9586, 26.9037],\n",
      "        [25.3034, 30.1847],\n",
      "        [27.8934, 27.8590]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9770, 29.9550],\n",
      "        [31.9586, 26.9038],\n",
      "        [25.3034, 30.1847],\n",
      "        [27.8934, 27.8590]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9770, 29.9550],\n",
      "        [31.9587, 26.9038],\n",
      "        [25.3035, 30.1847],\n",
      "        [27.8934, 27.8590]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9770, 29.9550],\n",
      "        [31.9586, 26.9038],\n",
      "        [25.3034, 30.1847],\n",
      "        [27.8934, 27.8590]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9770, 29.9550],\n",
      "        [31.9587, 26.9038],\n",
      "        [25.3035, 30.1847],\n",
      "        [27.8934, 27.8590]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9770, 29.9551],\n",
      "        [31.9587, 26.9039],\n",
      "        [25.3035, 30.1847],\n",
      "        [27.8934, 27.8590]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9771, 29.9551],\n",
      "        [31.9587, 26.9039],\n",
      "        [25.3035, 30.1847],\n",
      "        [27.8934, 27.8590]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9771, 29.9551],\n",
      "        [31.9587, 26.9039],\n",
      "        [25.3035, 30.1848],\n",
      "        [27.8934, 27.8590]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9771, 29.9551],\n",
      "        [31.9587, 26.9039],\n",
      "        [25.3036, 30.1848],\n",
      "        [27.8934, 27.8590]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9771, 29.9551],\n",
      "        [31.9587, 26.9040],\n",
      "        [25.3036, 30.1848],\n",
      "        [27.8934, 27.8591]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9771, 29.9551],\n",
      "        [31.9588, 26.9040],\n",
      "        [25.3036, 30.1848],\n",
      "        [27.8935, 27.8591]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9771, 29.9551],\n",
      "        [31.9587, 26.9040],\n",
      "        [25.3036, 30.1848],\n",
      "        [27.8934, 27.8591]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9771, 29.9551],\n",
      "        [31.9588, 26.9040],\n",
      "        [25.3037, 30.1848],\n",
      "        [27.8935, 27.8591]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9771, 29.9551],\n",
      "        [31.9588, 26.9041],\n",
      "        [25.3036, 30.1848],\n",
      "        [27.8935, 27.8591]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9771, 29.9551],\n",
      "        [31.9588, 26.9041],\n",
      "        [25.3037, 30.1848],\n",
      "        [27.8935, 27.8591]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9771, 29.9552],\n",
      "        [31.9588, 26.9041],\n",
      "        [25.3037, 30.1849],\n",
      "        [27.8935, 27.8591]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9860, 0.1146, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9771, 29.9552],\n",
      "        [31.9588, 26.9041],\n",
      "        [25.3038, 30.1849],\n",
      "        [27.8935, 27.8591]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9860, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9771, 29.9552],\n",
      "        [31.9588, 26.9042],\n",
      "        [25.3037, 30.1849],\n",
      "        [27.8935, 27.8591]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9860, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9771, 29.9552],\n",
      "        [31.9589, 26.9042],\n",
      "        [25.3038, 30.1849],\n",
      "        [27.8935, 27.8591]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9860, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9771, 29.9552],\n",
      "        [31.9588, 26.9042],\n",
      "        [25.3038, 30.1849],\n",
      "        [27.8935, 27.8592]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9860, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9771, 29.9552],\n",
      "        [31.9589, 26.9042],\n",
      "        [25.3039, 30.1849],\n",
      "        [27.8935, 27.8592]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9860, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9771, 29.9552],\n",
      "        [31.9589, 26.9043],\n",
      "        [25.3038, 30.1849],\n",
      "        [27.8935, 27.8592]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9860, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9772, 29.9552],\n",
      "        [31.9589, 26.9043],\n",
      "        [25.3039, 30.1849],\n",
      "        [27.8936, 27.8592]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9860, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9772, 29.9552],\n",
      "        [31.9589, 26.9043],\n",
      "        [25.3039, 30.1850],\n",
      "        [27.8936, 27.8592]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9860, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9772, 29.9552],\n",
      "        [31.9590, 26.9043],\n",
      "        [25.3039, 30.1849],\n",
      "        [27.8936, 27.8592]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9861, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9772, 29.9553],\n",
      "        [31.9589, 26.9044],\n",
      "        [25.3039, 30.1850],\n",
      "        [27.8936, 27.8592]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9861, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9772, 29.9553],\n",
      "        [31.9590, 26.9044],\n",
      "        [25.3040, 30.1850],\n",
      "        [27.8936, 27.8592]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9861, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9772, 29.9553],\n",
      "        [31.9589, 26.9044],\n",
      "        [25.3040, 30.1850],\n",
      "        [27.8936, 27.8592]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9861, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9772, 29.9553],\n",
      "        [31.9590, 26.9044],\n",
      "        [25.3040, 30.1850],\n",
      "        [27.8936, 27.8592]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9861, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9772, 29.9553],\n",
      "        [31.9590, 26.9045],\n",
      "        [25.3040, 30.1850],\n",
      "        [27.8936, 27.8593]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9861, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9772, 29.9553],\n",
      "        [31.9590, 26.9045],\n",
      "        [25.3041, 30.1850],\n",
      "        [27.8936, 27.8593]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9861, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9772, 29.9553],\n",
      "        [31.9590, 26.9045],\n",
      "        [25.3041, 30.1850],\n",
      "        [27.8936, 27.8593]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9861, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9772, 29.9553],\n",
      "        [31.9590, 26.9045],\n",
      "        [25.3041, 30.1850],\n",
      "        [27.8936, 27.8593]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9861, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9772, 29.9553],\n",
      "        [31.9590, 26.9046],\n",
      "        [25.3041, 30.1851],\n",
      "        [27.8936, 27.8593]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9861, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9772, 29.9553],\n",
      "        [31.9591, 26.9046],\n",
      "        [25.3042, 30.1851],\n",
      "        [27.8937, 27.8593]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9861, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9772, 29.9554],\n",
      "        [31.9590, 26.9046],\n",
      "        [25.3041, 30.1851],\n",
      "        [27.8937, 27.8593]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9861, 0.1147, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9773, 29.9554],\n",
      "        [31.9591, 26.9046],\n",
      "        [25.3042, 30.1851],\n",
      "        [27.8937, 27.8593]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9861, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9772, 29.9554],\n",
      "        [31.9591, 26.9047],\n",
      "        [25.3042, 30.1851],\n",
      "        [27.8937, 27.8593]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9861, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9773, 29.9554],\n",
      "        [31.9591, 26.9047],\n",
      "        [25.3043, 30.1851],\n",
      "        [27.8937, 27.8593]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9861, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9773, 29.9554],\n",
      "        [31.9591, 26.9047],\n",
      "        [25.3042, 30.1851],\n",
      "        [27.8937, 27.8594]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9861, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9773, 29.9554],\n",
      "        [31.9592, 26.9047],\n",
      "        [25.3043, 30.1851],\n",
      "        [27.8937, 27.8594]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9861, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9773, 29.9554],\n",
      "        [31.9591, 26.9048],\n",
      "        [25.3043, 30.1852],\n",
      "        [27.8937, 27.8594]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9861, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9773, 29.9554],\n",
      "        [31.9592, 26.9048],\n",
      "        [25.3043, 30.1852],\n",
      "        [27.8937, 27.8594]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9861, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9773, 29.9554],\n",
      "        [31.9591, 26.9048],\n",
      "        [25.3043, 30.1852],\n",
      "        [27.8937, 27.8594]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9861, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9773, 29.9554],\n",
      "        [31.9592, 26.9048],\n",
      "        [25.3044, 30.1852],\n",
      "        [27.8937, 27.8594]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9861, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9773, 29.9555],\n",
      "        [31.9592, 26.9049],\n",
      "        [25.3044, 30.1852],\n",
      "        [27.8937, 27.8594]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9861, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9773, 29.9555],\n",
      "        [31.9592, 26.9049],\n",
      "        [25.3044, 30.1852],\n",
      "        [27.8938, 27.8594]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9861, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9773, 29.9555],\n",
      "        [31.9592, 26.9049],\n",
      "        [25.3044, 30.1852],\n",
      "        [27.8937, 27.8594]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9861, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9773, 29.9555],\n",
      "        [31.9592, 26.9049],\n",
      "        [25.3045, 30.1852],\n",
      "        [27.8938, 27.8594]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9862, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9773, 29.9555],\n",
      "        [31.9592, 26.9050],\n",
      "        [25.3045, 30.1853],\n",
      "        [27.8938, 27.8595]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9862, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9774, 29.9555],\n",
      "        [31.9593, 26.9050],\n",
      "        [25.3045, 30.1852],\n",
      "        [27.8938, 27.8595]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9862, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9773, 29.9555],\n",
      "        [31.9592, 26.9050],\n",
      "        [25.3045, 30.1853],\n",
      "        [27.8938, 27.8595]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9862, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9774, 29.9555],\n",
      "        [31.9593, 26.9050],\n",
      "        [25.3046, 30.1853],\n",
      "        [27.8938, 27.8595]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9862, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9773, 29.9555],\n",
      "        [31.9593, 26.9051],\n",
      "        [25.3045, 30.1853],\n",
      "        [27.8938, 27.8595]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9862, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9774, 29.9555],\n",
      "        [31.9593, 26.9051],\n",
      "        [25.3046, 30.1853],\n",
      "        [27.8938, 27.8595]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9862, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9774, 29.9555],\n",
      "        [31.9593, 26.9051],\n",
      "        [25.3046, 30.1853],\n",
      "        [27.8938, 27.8595]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9862, 0.1148, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9774, 29.9555],\n",
      "        [31.9593, 26.9051],\n",
      "        [25.3046, 30.1853],\n",
      "        [27.8938, 27.8595]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9774, 29.9556],\n",
      "        [31.9593, 26.9051],\n",
      "        [25.3046, 30.1853],\n",
      "        [27.8938, 27.8595]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9774, 29.9556],\n",
      "        [31.9594, 26.9051],\n",
      "        [25.3047, 30.1853],\n",
      "        [27.8938, 27.8595]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9774, 29.9556],\n",
      "        [31.9593, 26.9052],\n",
      "        [25.3047, 30.1854],\n",
      "        [27.8938, 27.8596]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9774, 29.9556],\n",
      "        [31.9594, 26.9052],\n",
      "        [25.3047, 30.1853],\n",
      "        [27.8939, 27.8596]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9774, 29.9556],\n",
      "        [31.9594, 26.9053],\n",
      "        [25.3047, 30.1854],\n",
      "        [27.8939, 27.8596]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9774, 29.9556],\n",
      "        [31.9594, 26.9052],\n",
      "        [25.3048, 30.1854],\n",
      "        [27.8939, 27.8596]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9774, 29.9556],\n",
      "        [31.9594, 26.9053],\n",
      "        [25.3048, 30.1854],\n",
      "        [27.8939, 27.8596]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9774, 29.9556],\n",
      "        [31.9594, 26.9053],\n",
      "        [25.3048, 30.1854],\n",
      "        [27.8939, 27.8596]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9774, 29.9556],\n",
      "        [31.9594, 26.9053],\n",
      "        [25.3048, 30.1854],\n",
      "        [27.8939, 27.8596]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9774, 29.9556],\n",
      "        [31.9594, 26.9053],\n",
      "        [25.3049, 30.1854],\n",
      "        [27.8939, 27.8596]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9774, 29.9556],\n",
      "        [31.9594, 26.9054],\n",
      "        [25.3048, 30.1854],\n",
      "        [27.8939, 27.8596]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9775, 29.9556],\n",
      "        [31.9595, 26.9054],\n",
      "        [25.3049, 30.1854],\n",
      "        [27.8939, 27.8596]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9775, 29.9557],\n",
      "        [31.9594, 26.9054],\n",
      "        [25.3049, 30.1855],\n",
      "        [27.8939, 27.8597]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9775, 29.9557],\n",
      "        [31.9595, 26.9054],\n",
      "        [25.3049, 30.1855],\n",
      "        [27.8939, 27.8597]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9775, 29.9557],\n",
      "        [31.9595, 26.9055],\n",
      "        [25.3049, 30.1855],\n",
      "        [27.8939, 27.8597]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9775, 29.9557],\n",
      "        [31.9595, 26.9055],\n",
      "        [25.3050, 30.1855],\n",
      "        [27.8940, 27.8597]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9775, 29.9557],\n",
      "        [31.9595, 26.9055],\n",
      "        [25.3050, 30.1855],\n",
      "        [27.8939, 27.8597]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9862, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9775, 29.9557],\n",
      "        [31.9596, 26.9055],\n",
      "        [25.3050, 30.1855],\n",
      "        [27.8940, 27.8597]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9863, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9775, 29.9557],\n",
      "        [31.9595, 26.9056],\n",
      "        [25.3050, 30.1855],\n",
      "        [27.8940, 27.8597]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9863, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9775, 29.9557],\n",
      "        [31.9596, 26.9056],\n",
      "        [25.3051, 30.1855],\n",
      "        [27.8940, 27.8597]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9863, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9775, 29.9557],\n",
      "        [31.9595, 26.9056],\n",
      "        [25.3051, 30.1856],\n",
      "        [27.8940, 27.8597]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9863, 0.1149, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9775, 29.9557],\n",
      "        [31.9596, 26.9056],\n",
      "        [25.3051, 30.1855],\n",
      "        [27.8940, 27.8597]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9775, 29.9558],\n",
      "        [31.9596, 26.9057],\n",
      "        [25.3051, 30.1856],\n",
      "        [27.8940, 27.8598]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9775, 29.9558],\n",
      "        [31.9596, 26.9057],\n",
      "        [25.3052, 30.1856],\n",
      "        [27.8940, 27.8598]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9775, 29.9558],\n",
      "        [31.9596, 26.9057],\n",
      "        [25.3052, 30.1856],\n",
      "        [27.8940, 27.8598]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9776, 29.9558],\n",
      "        [31.9597, 26.9057],\n",
      "        [25.3052, 30.1856],\n",
      "        [27.8940, 27.8598]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9775, 29.9558],\n",
      "        [31.9596, 26.9058],\n",
      "        [25.3052, 30.1856],\n",
      "        [27.8940, 27.8598]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9776, 29.9558],\n",
      "        [31.9597, 26.9058],\n",
      "        [25.3053, 30.1856],\n",
      "        [27.8941, 27.8598]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9775, 29.9558],\n",
      "        [31.9596, 26.9058],\n",
      "        [25.3052, 30.1856],\n",
      "        [27.8940, 27.8598]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9776, 29.9558],\n",
      "        [31.9597, 26.9058],\n",
      "        [25.3053, 30.1856],\n",
      "        [27.8941, 27.8598]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9776, 29.9558],\n",
      "        [31.9597, 26.9059],\n",
      "        [25.3053, 30.1857],\n",
      "        [27.8941, 27.8598]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9776, 29.9558],\n",
      "        [31.9597, 26.9059],\n",
      "        [25.3053, 30.1857],\n",
      "        [27.8941, 27.8598]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9776, 29.9559],\n",
      "        [31.9597, 26.9059],\n",
      "        [25.3053, 30.1857],\n",
      "        [27.8941, 27.8599]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9776, 29.9559],\n",
      "        [31.9597, 26.9059],\n",
      "        [25.3054, 30.1857],\n",
      "        [27.8941, 27.8599]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9776, 29.9559],\n",
      "        [31.9597, 26.9060],\n",
      "        [25.3054, 30.1857],\n",
      "        [27.8941, 27.8599]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9625], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9776, 29.9559],\n",
      "        [31.9598, 26.9060],\n",
      "        [25.3054, 30.1857],\n",
      "        [27.8941, 27.8599]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9776, 29.9559],\n",
      "        [31.9597, 26.9060],\n",
      "        [25.3054, 30.1857],\n",
      "        [27.8941, 27.8599]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9776, 29.9559],\n",
      "        [31.9598, 26.9060],\n",
      "        [25.3055, 30.1857],\n",
      "        [27.8941, 27.8599]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9776, 29.9559],\n",
      "        [31.9598, 26.9061],\n",
      "        [25.3055, 30.1858],\n",
      "        [27.8941, 27.8599]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9777, 29.9559],\n",
      "        [31.9598, 26.9061],\n",
      "        [25.3055, 30.1858],\n",
      "        [27.8942, 27.8599]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9776, 29.9559],\n",
      "        [31.9598, 26.9061],\n",
      "        [25.3055, 30.1858],\n",
      "        [27.8941, 27.8599]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9863, 0.1150, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9776, 29.9559],\n",
      "        [31.9598, 26.9061],\n",
      "        [25.3056, 30.1858],\n",
      "        [27.8942, 27.8599]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9776, 29.9560],\n",
      "        [31.9598, 26.9062],\n",
      "        [25.3055, 30.1858],\n",
      "        [27.8941, 27.8600]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9777, 29.9560],\n",
      "        [31.9599, 26.9062],\n",
      "        [25.3056, 30.1858],\n",
      "        [27.8942, 27.8600]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9777, 29.9560],\n",
      "        [31.9598, 26.9062],\n",
      "        [25.3056, 30.1858],\n",
      "        [27.8942, 27.8600]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9777, 29.9560],\n",
      "        [31.9599, 26.9062],\n",
      "        [25.3057, 30.1858],\n",
      "        [27.8942, 27.8600]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9777, 29.9560],\n",
      "        [31.9599, 26.9063],\n",
      "        [25.3056, 30.1858],\n",
      "        [27.8942, 27.8600]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9777, 29.9560],\n",
      "        [31.9599, 26.9063],\n",
      "        [25.3057, 30.1858],\n",
      "        [27.8942, 27.8600]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9777, 29.9560],\n",
      "        [31.9599, 26.9063],\n",
      "        [25.3057, 30.1859],\n",
      "        [27.8942, 27.8600]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9777, 29.9560],\n",
      "        [31.9600, 26.9063],\n",
      "        [25.3057, 30.1859],\n",
      "        [27.8942, 27.8600]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9987, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9777, 29.9560],\n",
      "        [31.9599, 26.9064],\n",
      "        [25.3057, 30.1859],\n",
      "        [27.8942, 27.8600]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9987, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9777, 29.9560],\n",
      "        [31.9600, 26.9064],\n",
      "        [25.3058, 30.1859],\n",
      "        [27.8942, 27.8600]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9777, 29.9561],\n",
      "        [31.9599, 26.9064],\n",
      "        [25.3058, 30.1859],\n",
      "        [27.8942, 27.8601]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9777, 29.9561],\n",
      "        [31.9600, 26.9064],\n",
      "        [25.3058, 30.1859],\n",
      "        [27.8943, 27.8601]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9777, 29.9561],\n",
      "        [31.9600, 26.9065],\n",
      "        [25.3058, 30.1859],\n",
      "        [27.8942, 27.8601]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9777, 29.9561],\n",
      "        [31.9600, 26.9065],\n",
      "        [25.3059, 30.1859],\n",
      "        [27.8943, 27.8601]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9777, 29.9561],\n",
      "        [31.9600, 26.9065],\n",
      "        [25.3058, 30.1859],\n",
      "        [27.8942, 27.8601]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9777, 29.9561],\n",
      "        [31.9600, 26.9065],\n",
      "        [25.3059, 30.1859],\n",
      "        [27.8943, 27.8601]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9777, 29.9561],\n",
      "        [31.9600, 26.9065],\n",
      "        [25.3059, 30.1860],\n",
      "        [27.8943, 27.8601]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9778, 29.9561],\n",
      "        [31.9601, 26.9065],\n",
      "        [25.3059, 30.1860],\n",
      "        [27.8943, 27.8601]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9777, 29.9561],\n",
      "        [31.9600, 26.9066],\n",
      "        [25.3059, 30.1860],\n",
      "        [27.8943, 27.8601]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9778, 29.9561],\n",
      "        [31.9601, 26.9066],\n",
      "        [25.3060, 30.1860],\n",
      "        [27.8943, 27.8601]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9778, 29.9561],\n",
      "        [31.9601, 26.9067],\n",
      "        [25.3060, 30.1860],\n",
      "        [27.8943, 27.8602]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9864, 0.1151, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9778, 29.9561],\n",
      "        [31.9601, 26.9066],\n",
      "        [25.3060, 30.1860],\n",
      "        [27.8943, 27.8601]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9864, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9778, 29.9562],\n",
      "        [31.9601, 26.9067],\n",
      "        [25.3060, 30.1860],\n",
      "        [27.8943, 27.8602]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9864, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9778, 29.9562],\n",
      "        [31.9601, 26.9067],\n",
      "        [25.3061, 30.1860],\n",
      "        [27.8944, 27.8602]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9864, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9778, 29.9562],\n",
      "        [31.9601, 26.9067],\n",
      "        [25.3061, 30.1861],\n",
      "        [27.8943, 27.8602]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9864, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9778, 29.9562],\n",
      "        [31.9602, 26.9067],\n",
      "        [25.3061, 30.1861],\n",
      "        [27.8944, 27.8602]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9778, 29.9562],\n",
      "        [31.9601, 26.9068],\n",
      "        [25.3061, 30.1861],\n",
      "        [27.8943, 27.8602]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9778, 29.9562],\n",
      "        [31.9602, 26.9068],\n",
      "        [25.3062, 30.1861],\n",
      "        [27.8944, 27.8602]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9778, 29.9562],\n",
      "        [31.9601, 26.9068],\n",
      "        [25.3061, 30.1861],\n",
      "        [27.8944, 27.8602]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9778, 29.9562],\n",
      "        [31.9602, 26.9068],\n",
      "        [25.3062, 30.1861],\n",
      "        [27.8944, 27.8602]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9778, 29.9562],\n",
      "        [31.9602, 26.9069],\n",
      "        [25.3062, 30.1861],\n",
      "        [27.8944, 27.8602]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9779, 29.9562],\n",
      "        [31.9602, 26.9069],\n",
      "        [25.3062, 30.1861],\n",
      "        [27.8944, 27.8602]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9778, 29.9563],\n",
      "        [31.9602, 26.9069],\n",
      "        [25.3062, 30.1861],\n",
      "        [27.8944, 27.8603]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9779, 29.9562],\n",
      "        [31.9602, 26.9069],\n",
      "        [25.3063, 30.1861],\n",
      "        [27.8944, 27.8603]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9779, 29.9563],\n",
      "        [31.9602, 26.9070],\n",
      "        [25.3063, 30.1862],\n",
      "        [27.8944, 27.8603]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9779, 29.9563],\n",
      "        [31.9603, 26.9070],\n",
      "        [25.3063, 30.1862],\n",
      "        [27.8944, 27.8603]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9779, 29.9563],\n",
      "        [31.9602, 26.9070],\n",
      "        [25.3063, 30.1862],\n",
      "        [27.8944, 27.8603]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9779, 29.9563],\n",
      "        [31.9603, 26.9070],\n",
      "        [25.3064, 30.1862],\n",
      "        [27.8945, 27.8603]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9779, 29.9563],\n",
      "        [31.9603, 26.9071],\n",
      "        [25.3064, 30.1862],\n",
      "        [27.8945, 27.8603]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9779, 29.9563],\n",
      "        [31.9603, 26.9071],\n",
      "        [25.3064, 30.1862],\n",
      "        [27.8945, 27.8603]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9779, 29.9563],\n",
      "        [31.9603, 26.9071],\n",
      "        [25.3064, 30.1862],\n",
      "        [27.8945, 27.8603]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9865, 0.1152, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9779, 29.9563],\n",
      "        [31.9603, 26.9071],\n",
      "        [25.3065, 30.1862],\n",
      "        [27.8945, 27.8603]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9865, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9779, 29.9563],\n",
      "        [31.9603, 26.9072],\n",
      "        [25.3064, 30.1863],\n",
      "        [27.8945, 27.8604]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9865, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9779, 29.9563],\n",
      "        [31.9604, 26.9072],\n",
      "        [25.3065, 30.1862],\n",
      "        [27.8945, 27.8604]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9865, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9779, 29.9564],\n",
      "        [31.9603, 26.9072],\n",
      "        [25.3065, 30.1863],\n",
      "        [27.8945, 27.8604]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9865, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9779, 29.9564],\n",
      "        [31.9604, 26.9072],\n",
      "        [25.3065, 30.1863],\n",
      "        [27.8945, 27.8604]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9865, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9779, 29.9564],\n",
      "        [31.9604, 26.9073],\n",
      "        [25.3065, 30.1863],\n",
      "        [27.8945, 27.8604]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9865, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9780, 29.9564],\n",
      "        [31.9604, 26.9073],\n",
      "        [25.3066, 30.1863],\n",
      "        [27.8945, 27.8604]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9865, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9779, 29.9564],\n",
      "        [31.9604, 26.9073],\n",
      "        [25.3066, 30.1863],\n",
      "        [27.8945, 27.8604]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9865, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9780, 29.9564],\n",
      "        [31.9604, 26.9073],\n",
      "        [25.3066, 30.1863],\n",
      "        [27.8946, 27.8604]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9865, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9780, 29.9564],\n",
      "        [31.9604, 26.9074],\n",
      "        [25.3066, 30.1863],\n",
      "        [27.8945, 27.8604]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9865, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9780, 29.9564],\n",
      "        [31.9605, 26.9074],\n",
      "        [25.3067, 30.1863],\n",
      "        [27.8946, 27.8605]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9866, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9780, 29.9564],\n",
      "        [31.9604, 26.9074],\n",
      "        [25.3067, 30.1864],\n",
      "        [27.8946, 27.8605]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9866, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9780, 29.9564],\n",
      "        [31.9605, 26.9074],\n",
      "        [25.3067, 30.1864],\n",
      "        [27.8946, 27.8605]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9866, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9780, 29.9565],\n",
      "        [31.9605, 26.9075],\n",
      "        [25.3067, 30.1864],\n",
      "        [27.8946, 27.8605]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9866, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9780, 29.9565],\n",
      "        [31.9605, 26.9074],\n",
      "        [25.3068, 30.1864],\n",
      "        [27.8946, 27.8605]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9866, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9780, 29.9565],\n",
      "        [31.9605, 26.9075],\n",
      "        [25.3067, 30.1864],\n",
      "        [27.8946, 27.8605]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9866, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9780, 29.9565],\n",
      "        [31.9605, 26.9075],\n",
      "        [25.3068, 30.1864],\n",
      "        [27.8946, 27.8605]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9866, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9780, 29.9565],\n",
      "        [31.9605, 26.9075],\n",
      "        [25.3068, 30.1864],\n",
      "        [27.8946, 27.8605]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9866, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9780, 29.9565],\n",
      "        [31.9605, 26.9075],\n",
      "        [25.3068, 30.1864],\n",
      "        [27.8946, 27.8605]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9866, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9780, 29.9565],\n",
      "        [31.9605, 26.9076],\n",
      "        [25.3068, 30.1864],\n",
      "        [27.8946, 27.8605]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9866, 0.1153, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9780, 29.9565],\n",
      "        [31.9606, 26.9076],\n",
      "        [25.3069, 30.1864],\n",
      "        [27.8946, 27.8605]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9780, 29.9565],\n",
      "        [31.9605, 26.9076],\n",
      "        [25.3069, 30.1865],\n",
      "        [27.8946, 27.8606]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9781, 29.9565],\n",
      "        [31.9606, 26.9076],\n",
      "        [25.3069, 30.1865],\n",
      "        [27.8947, 27.8606]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9780, 29.9565],\n",
      "        [31.9606, 26.9077],\n",
      "        [25.3069, 30.1865],\n",
      "        [27.8946, 27.8606]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9781, 29.9565],\n",
      "        [31.9606, 26.9077],\n",
      "        [25.3070, 30.1865],\n",
      "        [27.8947, 27.8606]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9781, 29.9566],\n",
      "        [31.9606, 26.9077],\n",
      "        [25.3070, 30.1865],\n",
      "        [27.8947, 27.8606]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9781, 29.9566],\n",
      "        [31.9606, 26.9077],\n",
      "        [25.3070, 30.1865],\n",
      "        [27.8947, 27.8606]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9781, 29.9566],\n",
      "        [31.9606, 26.9078],\n",
      "        [25.3070, 30.1865],\n",
      "        [27.8947, 27.8606]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9781, 29.9566],\n",
      "        [31.9607, 26.9078],\n",
      "        [25.3071, 30.1865],\n",
      "        [27.8947, 27.8606]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9781, 29.9566],\n",
      "        [31.9606, 26.9078],\n",
      "        [25.3070, 30.1866],\n",
      "        [27.8947, 27.8606]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9781, 29.9566],\n",
      "        [31.9607, 26.9078],\n",
      "        [25.3071, 30.1866],\n",
      "        [27.8947, 27.8606]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9781, 29.9566],\n",
      "        [31.9607, 26.9079],\n",
      "        [25.3071, 30.1866],\n",
      "        [27.8947, 27.8607]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9781, 29.9566],\n",
      "        [31.9607, 26.9079],\n",
      "        [25.3071, 30.1866],\n",
      "        [27.8947, 27.8607]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9781, 29.9566],\n",
      "        [31.9607, 26.9079],\n",
      "        [25.3071, 30.1866],\n",
      "        [27.8947, 27.8607]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9781, 29.9566],\n",
      "        [31.9607, 26.9079],\n",
      "        [25.3072, 30.1866],\n",
      "        [27.8948, 27.8607]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9781, 29.9567],\n",
      "        [31.9607, 26.9080],\n",
      "        [25.3072, 30.1866],\n",
      "        [27.8947, 27.8607]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9866, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9782, 29.9567],\n",
      "        [31.9608, 26.9080],\n",
      "        [25.3072, 30.1866],\n",
      "        [27.8948, 27.8607]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9781, 29.9567],\n",
      "        [31.9607, 26.9080],\n",
      "        [25.3072, 30.1866],\n",
      "        [27.8947, 27.8607]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9782, 29.9567],\n",
      "        [31.9608, 26.9080],\n",
      "        [25.3073, 30.1866],\n",
      "        [27.8948, 27.8607]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9781, 29.9567],\n",
      "        [31.9607, 26.9080],\n",
      "        [25.3072, 30.1866],\n",
      "        [27.8948, 27.8607]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9781, 29.9567],\n",
      "        [31.9608, 26.9080],\n",
      "        [25.3073, 30.1866],\n",
      "        [27.8948, 27.8607]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9781, 29.9567],\n",
      "        [31.9608, 26.9081],\n",
      "        [25.3073, 30.1867],\n",
      "        [27.8948, 27.8607]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1154, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9782, 29.9567],\n",
      "        [31.9608, 26.9081],\n",
      "        [25.3073, 30.1867],\n",
      "        [27.8948, 27.8607]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9781, 29.9567],\n",
      "        [31.9608, 26.9081],\n",
      "        [25.3073, 30.1867],\n",
      "        [27.8948, 27.8608]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9782, 29.9567],\n",
      "        [31.9608, 26.9081],\n",
      "        [25.3074, 30.1867],\n",
      "        [27.8948, 27.8608]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9782, 29.9567],\n",
      "        [31.9608, 26.9082],\n",
      "        [25.3074, 30.1867],\n",
      "        [27.8948, 27.8608]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9782, 29.9567],\n",
      "        [31.9609, 26.9082],\n",
      "        [25.3074, 30.1867],\n",
      "        [27.8948, 27.8608]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9782, 29.9568],\n",
      "        [31.9608, 26.9082],\n",
      "        [25.3074, 30.1867],\n",
      "        [27.8948, 27.8608]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9782, 29.9568],\n",
      "        [31.9609, 26.9082],\n",
      "        [25.3075, 30.1867],\n",
      "        [27.8948, 27.8608]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9782, 29.9568],\n",
      "        [31.9609, 26.9083],\n",
      "        [25.3075, 30.1868],\n",
      "        [27.8948, 27.8608]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9782, 29.9568],\n",
      "        [31.9609, 26.9083],\n",
      "        [25.3075, 30.1868],\n",
      "        [27.8949, 27.8608]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9782, 29.9568],\n",
      "        [31.9609, 26.9083],\n",
      "        [25.3075, 30.1868],\n",
      "        [27.8948, 27.8608]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9782, 29.9568],\n",
      "        [31.9609, 26.9083],\n",
      "        [25.3076, 30.1868],\n",
      "        [27.8949, 27.8608]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9782, 29.9568],\n",
      "        [31.9609, 26.9084],\n",
      "        [25.3075, 30.1868],\n",
      "        [27.8949, 27.8609]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9782, 29.9568],\n",
      "        [31.9610, 26.9084],\n",
      "        [25.3076, 30.1868],\n",
      "        [27.8949, 27.8609]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9782, 29.9568],\n",
      "        [31.9609, 26.9084],\n",
      "        [25.3076, 30.1868],\n",
      "        [27.8949, 27.8609]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9783, 29.9568],\n",
      "        [31.9610, 26.9084],\n",
      "        [25.3076, 30.1868],\n",
      "        [27.8949, 27.8609]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9782, 29.9569],\n",
      "        [31.9610, 26.9085],\n",
      "        [25.3076, 30.1868],\n",
      "        [27.8949, 27.8609]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9783, 29.9569],\n",
      "        [31.9610, 26.9085],\n",
      "        [25.3077, 30.1868],\n",
      "        [27.8949, 27.8609]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9782, 29.9569],\n",
      "        [31.9610, 26.9085],\n",
      "        [25.3077, 30.1869],\n",
      "        [27.8949, 27.8609]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9783, 29.9569],\n",
      "        [31.9610, 26.9085],\n",
      "        [25.3077, 30.1868],\n",
      "        [27.8949, 27.8609]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9783, 29.9569],\n",
      "        [31.9610, 26.9085],\n",
      "        [25.3077, 30.1869],\n",
      "        [27.8949, 27.8609]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9783, 29.9569],\n",
      "        [31.9610, 26.9085],\n",
      "        [25.3078, 30.1869],\n",
      "        [27.8949, 27.8609]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9783, 29.9569],\n",
      "        [31.9610, 26.9086],\n",
      "        [25.3077, 30.1869],\n",
      "        [27.8949, 27.8609]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9867, 0.1155, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9783, 29.9569],\n",
      "        [31.9611, 26.9086],\n",
      "        [25.3078, 30.1869],\n",
      "        [27.8950, 27.8609]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9783, 29.9569],\n",
      "        [31.9610, 26.9086],\n",
      "        [25.3078, 30.1869],\n",
      "        [27.8950, 27.8610]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9783, 29.9569],\n",
      "        [31.9611, 26.9086],\n",
      "        [25.3079, 30.1869],\n",
      "        [27.8950, 27.8610]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9783, 29.9569],\n",
      "        [31.9611, 26.9087],\n",
      "        [25.3078, 30.1869],\n",
      "        [27.8950, 27.8610]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9783, 29.9569],\n",
      "        [31.9611, 26.9087],\n",
      "        [25.3079, 30.1869],\n",
      "        [27.8950, 27.8610]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9783, 29.9569],\n",
      "        [31.9611, 26.9087],\n",
      "        [25.3079, 30.1870],\n",
      "        [27.8950, 27.8610]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9783, 29.9569],\n",
      "        [31.9611, 26.9087],\n",
      "        [25.3079, 30.1870],\n",
      "        [27.8950, 27.8610]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9783, 29.9570],\n",
      "        [31.9611, 26.9088],\n",
      "        [25.3079, 30.1870],\n",
      "        [27.8950, 27.8610]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9783, 29.9570],\n",
      "        [31.9612, 26.9088],\n",
      "        [25.3080, 30.1870],\n",
      "        [27.8950, 27.8610]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9783, 29.9570],\n",
      "        [31.9611, 26.9088],\n",
      "        [25.3080, 30.1870],\n",
      "        [27.8950, 27.8610]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9784, 29.9570],\n",
      "        [31.9612, 26.9088],\n",
      "        [25.3080, 30.1870],\n",
      "        [27.8951, 27.8611]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9784, 29.9570],\n",
      "        [31.9612, 26.9089],\n",
      "        [25.3080, 30.1870],\n",
      "        [27.8950, 27.8611]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9784, 29.9570],\n",
      "        [31.9612, 26.9089],\n",
      "        [25.3081, 30.1870],\n",
      "        [27.8951, 27.8611]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9784, 29.9570],\n",
      "        [31.9612, 26.9089],\n",
      "        [25.3081, 30.1871],\n",
      "        [27.8951, 27.8611]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9784, 29.9570],\n",
      "        [31.9612, 26.9089],\n",
      "        [25.3081, 30.1870],\n",
      "        [27.8951, 27.8611]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9784, 29.9571],\n",
      "        [31.9612, 26.9090],\n",
      "        [25.3081, 30.1871],\n",
      "        [27.8951, 27.8611]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9784, 29.9571],\n",
      "        [31.9613, 26.9090],\n",
      "        [25.3082, 30.1871],\n",
      "        [27.8951, 27.8611]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9784, 29.9571],\n",
      "        [31.9612, 26.9090],\n",
      "        [25.3081, 30.1871],\n",
      "        [27.8951, 27.8611]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9784, 29.9571],\n",
      "        [31.9613, 26.9090],\n",
      "        [25.3082, 30.1871],\n",
      "        [27.8951, 27.8611]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9784, 29.9571],\n",
      "        [31.9613, 26.9091],\n",
      "        [25.3082, 30.1871],\n",
      "        [27.8951, 27.8611]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9868, 0.1156, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9784, 29.9571],\n",
      "        [31.9613, 26.9090],\n",
      "        [25.3082, 30.1871],\n",
      "        [27.8951, 27.8611]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9868, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9784, 29.9571],\n",
      "        [31.9613, 26.9091],\n",
      "        [25.3082, 30.1871],\n",
      "        [27.8951, 27.8612]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9868, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9785, 29.9571],\n",
      "        [31.9613, 26.9091],\n",
      "        [25.3083, 30.1871],\n",
      "        [27.8951, 27.8612]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9868, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9784, 29.9571],\n",
      "        [31.9613, 26.9091],\n",
      "        [25.3083, 30.1872],\n",
      "        [27.8951, 27.8612]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9868, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9785, 29.9571],\n",
      "        [31.9613, 26.9091],\n",
      "        [25.3083, 30.1872],\n",
      "        [27.8952, 27.8612]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9868, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9784, 29.9571],\n",
      "        [31.9613, 26.9092],\n",
      "        [25.3083, 30.1872],\n",
      "        [27.8951, 27.8612]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9868, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9785, 29.9571],\n",
      "        [31.9614, 26.9092],\n",
      "        [25.3084, 30.1872],\n",
      "        [27.8952, 27.8612]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9784, 29.9571],\n",
      "        [31.9613, 26.9092],\n",
      "        [25.3083, 30.1872],\n",
      "        [27.8951, 27.8612]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9785, 29.9571],\n",
      "        [31.9614, 26.9092],\n",
      "        [25.3084, 30.1872],\n",
      "        [27.8952, 27.8612]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9785, 29.9572],\n",
      "        [31.9614, 26.9093],\n",
      "        [25.3084, 30.1872],\n",
      "        [27.8952, 27.8612]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9785, 29.9572],\n",
      "        [31.9614, 26.9093],\n",
      "        [25.3085, 30.1872],\n",
      "        [27.8952, 27.8612]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9785, 29.9572],\n",
      "        [31.9614, 26.9093],\n",
      "        [25.3084, 30.1872],\n",
      "        [27.8952, 27.8613]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9785, 29.9572],\n",
      "        [31.9614, 26.9093],\n",
      "        [25.3085, 30.1872],\n",
      "        [27.8952, 27.8613]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9785, 29.9572],\n",
      "        [31.9614, 26.9094],\n",
      "        [25.3085, 30.1873],\n",
      "        [27.8952, 27.8613]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9785, 29.9572],\n",
      "        [31.9615, 26.9094],\n",
      "        [25.3085, 30.1873],\n",
      "        [27.8952, 27.8613]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9785, 29.9572],\n",
      "        [31.9614, 26.9094],\n",
      "        [25.3085, 30.1873],\n",
      "        [27.8952, 27.8613]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9785, 29.9572],\n",
      "        [31.9615, 26.9094],\n",
      "        [25.3086, 30.1873],\n",
      "        [27.8952, 27.8613]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9785, 29.9572],\n",
      "        [31.9614, 26.9095],\n",
      "        [25.3085, 30.1873],\n",
      "        [27.8952, 27.8613]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9785, 29.9572],\n",
      "        [31.9615, 26.9094],\n",
      "        [25.3086, 30.1873],\n",
      "        [27.8953, 27.8613]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9785, 29.9573],\n",
      "        [31.9615, 26.9095],\n",
      "        [25.3086, 30.1873],\n",
      "        [27.8952, 27.8613]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9785, 29.9573],\n",
      "        [31.9615, 26.9095],\n",
      "        [25.3087, 30.1873],\n",
      "        [27.8953, 27.8613]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9785, 29.9573],\n",
      "        [31.9615, 26.9095],\n",
      "        [25.3086, 30.1874],\n",
      "        [27.8953, 27.8614]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1157, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9786, 29.9573],\n",
      "        [31.9615, 26.9095],\n",
      "        [25.3087, 30.1873],\n",
      "        [27.8953, 27.8613]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9785, 29.9573],\n",
      "        [31.9615, 26.9096],\n",
      "        [25.3087, 30.1873],\n",
      "        [27.8953, 27.8613]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9786, 29.9573],\n",
      "        [31.9615, 26.9096],\n",
      "        [25.3087, 30.1873],\n",
      "        [27.8953, 27.8613]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9785, 29.9573],\n",
      "        [31.9615, 26.9096],\n",
      "        [25.3087, 30.1874],\n",
      "        [27.8953, 27.8614]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9786, 29.9573],\n",
      "        [31.9616, 26.9096],\n",
      "        [25.3088, 30.1874],\n",
      "        [27.8953, 27.8614]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9786, 29.9573],\n",
      "        [31.9615, 26.9097],\n",
      "        [25.3087, 30.1874],\n",
      "        [27.8953, 27.8614]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9786, 29.9573],\n",
      "        [31.9616, 26.9097],\n",
      "        [25.3088, 30.1874],\n",
      "        [27.8953, 27.8614]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9786, 29.9573],\n",
      "        [31.9616, 26.9097],\n",
      "        [25.3088, 30.1874],\n",
      "        [27.8953, 27.8614]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9786, 29.9573],\n",
      "        [31.9616, 26.9097],\n",
      "        [25.3088, 30.1874],\n",
      "        [27.8953, 27.8614]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9786, 29.9574],\n",
      "        [31.9616, 26.9098],\n",
      "        [25.3088, 30.1874],\n",
      "        [27.8953, 27.8614]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9786, 29.9573],\n",
      "        [31.9616, 26.9098],\n",
      "        [25.3089, 30.1874],\n",
      "        [27.8953, 27.8614]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9869, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9786, 29.9574],\n",
      "        [31.9616, 26.9098],\n",
      "        [25.3089, 30.1875],\n",
      "        [27.8953, 27.8614]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9869, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9786, 29.9574],\n",
      "        [31.9617, 26.9098],\n",
      "        [25.3089, 30.1875],\n",
      "        [27.8954, 27.8615]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9786, 29.9574],\n",
      "        [31.9616, 26.9098],\n",
      "        [25.3089, 30.1875],\n",
      "        [27.8953, 27.8615]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9786, 29.9574],\n",
      "        [31.9617, 26.9098],\n",
      "        [25.3090, 30.1875],\n",
      "        [27.8954, 27.8615]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9786, 29.9574],\n",
      "        [31.9617, 26.9099],\n",
      "        [25.3090, 30.1875],\n",
      "        [27.8954, 27.8615]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9786, 29.9574],\n",
      "        [31.9617, 26.9099],\n",
      "        [25.3090, 30.1875],\n",
      "        [27.8954, 27.8615]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9786, 29.9574],\n",
      "        [31.9617, 26.9099],\n",
      "        [25.3090, 30.1875],\n",
      "        [27.8954, 27.8615]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9786, 29.9574],\n",
      "        [31.9617, 26.9099],\n",
      "        [25.3091, 30.1875],\n",
      "        [27.8954, 27.8615]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9786, 29.9574],\n",
      "        [31.9617, 26.9100],\n",
      "        [25.3090, 30.1875],\n",
      "        [27.8954, 27.8615]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1158, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9787, 29.9574],\n",
      "        [31.9617, 26.9100],\n",
      "        [25.3091, 30.1875],\n",
      "        [27.8954, 27.8615]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9787, 29.9575],\n",
      "        [31.9617, 26.9100],\n",
      "        [25.3091, 30.1876],\n",
      "        [27.8954, 27.8615]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9787, 29.9575],\n",
      "        [31.9618, 26.9100],\n",
      "        [25.3091, 30.1875],\n",
      "        [27.8954, 27.8615]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9787, 29.9575],\n",
      "        [31.9617, 26.9101],\n",
      "        [25.3091, 30.1876],\n",
      "        [27.8954, 27.8616]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9787, 29.9575],\n",
      "        [31.9618, 26.9101],\n",
      "        [25.3092, 30.1876],\n",
      "        [27.8954, 27.8616]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9787, 29.9575],\n",
      "        [31.9618, 26.9101],\n",
      "        [25.3092, 30.1876],\n",
      "        [27.8954, 27.8616]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9787, 29.9575],\n",
      "        [31.9618, 26.9101],\n",
      "        [25.3092, 30.1876],\n",
      "        [27.8955, 27.8616]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9787, 29.9575],\n",
      "        [31.9618, 26.9102],\n",
      "        [25.3092, 30.1876],\n",
      "        [27.8955, 27.8616]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9787, 29.9575],\n",
      "        [31.9618, 26.9102],\n",
      "        [25.3093, 30.1876],\n",
      "        [27.8955, 27.8616]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9787, 29.9575],\n",
      "        [31.9618, 26.9102],\n",
      "        [25.3092, 30.1876],\n",
      "        [27.8955, 27.8616]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9787, 29.9575],\n",
      "        [31.9619, 26.9102],\n",
      "        [25.3093, 30.1876],\n",
      "        [27.8955, 27.8616]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9787, 29.9576],\n",
      "        [31.9618, 26.9102],\n",
      "        [25.3093, 30.1877],\n",
      "        [27.8955, 27.8616]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9787, 29.9576],\n",
      "        [31.9619, 26.9102],\n",
      "        [25.3094, 30.1877],\n",
      "        [27.8955, 27.8616]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9787, 29.9576],\n",
      "        [31.9618, 26.9103],\n",
      "        [25.3093, 30.1877],\n",
      "        [27.8955, 27.8617]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9788, 29.9576],\n",
      "        [31.9619, 26.9103],\n",
      "        [25.3094, 30.1877],\n",
      "        [27.8955, 27.8617]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9787, 29.9576],\n",
      "        [31.9619, 26.9103],\n",
      "        [25.3094, 30.1877],\n",
      "        [27.8955, 27.8617]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9788, 29.9576],\n",
      "        [31.9619, 26.9103],\n",
      "        [25.3094, 30.1877],\n",
      "        [27.8955, 27.8617]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9787, 29.9576],\n",
      "        [31.9619, 26.9104],\n",
      "        [25.3094, 30.1877],\n",
      "        [27.8955, 27.8617]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9788, 29.9576],\n",
      "        [31.9620, 26.9104],\n",
      "        [25.3095, 30.1877],\n",
      "        [27.8955, 27.8617]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9788, 29.9576],\n",
      "        [31.9619, 26.9104],\n",
      "        [25.3095, 30.1878],\n",
      "        [27.8955, 27.8617]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9870, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9788, 29.9576],\n",
      "        [31.9620, 26.9104],\n",
      "        [25.3095, 30.1877],\n",
      "        [27.8956, 27.8617]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9788, 29.9576],\n",
      "        [31.9619, 26.9105],\n",
      "        [25.3095, 30.1878],\n",
      "        [27.8956, 27.8617]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1159, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9788, 29.9576],\n",
      "        [31.9620, 26.9105],\n",
      "        [25.3096, 30.1878],\n",
      "        [27.8956, 27.8617]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9788, 29.9577],\n",
      "        [31.9620, 26.9105],\n",
      "        [25.3095, 30.1878],\n",
      "        [27.8956, 27.8618]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9788, 29.9577],\n",
      "        [31.9620, 26.9105],\n",
      "        [25.3096, 30.1878],\n",
      "        [27.8956, 27.8617]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9788, 29.9577],\n",
      "        [31.9620, 26.9105],\n",
      "        [25.3096, 30.1878],\n",
      "        [27.8956, 27.8618]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9788, 29.9577],\n",
      "        [31.9620, 26.9105],\n",
      "        [25.3096, 30.1878],\n",
      "        [27.8956, 27.8618]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9788, 29.9577],\n",
      "        [31.9620, 26.9106],\n",
      "        [25.3096, 30.1878],\n",
      "        [27.8956, 27.8618]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9788, 29.9577],\n",
      "        [31.9621, 26.9106],\n",
      "        [25.3097, 30.1878],\n",
      "        [27.8956, 27.8618]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9788, 29.9577],\n",
      "        [31.9620, 26.9106],\n",
      "        [25.3097, 30.1879],\n",
      "        [27.8956, 27.8618]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9788, 29.9577],\n",
      "        [31.9621, 26.9106],\n",
      "        [25.3097, 30.1879],\n",
      "        [27.8956, 27.8618]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9788, 29.9577],\n",
      "        [31.9620, 26.9107],\n",
      "        [25.3097, 30.1879],\n",
      "        [27.8956, 27.8618]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9626], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9788, 29.9577],\n",
      "        [31.9621, 26.9107],\n",
      "        [25.3098, 30.1879],\n",
      "        [27.8956, 27.8618]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9788, 29.9577],\n",
      "        [31.9621, 26.9107],\n",
      "        [25.3097, 30.1879],\n",
      "        [27.8956, 27.8618]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9789, 29.9577],\n",
      "        [31.9621, 26.9107],\n",
      "        [25.3098, 30.1879],\n",
      "        [27.8957, 27.8618]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9789, 29.9578],\n",
      "        [31.9621, 26.9108],\n",
      "        [25.3098, 30.1879],\n",
      "        [27.8957, 27.8619]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9789, 29.9578],\n",
      "        [31.9621, 26.9108],\n",
      "        [25.3099, 30.1879],\n",
      "        [27.8957, 27.8619]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9789, 29.9578],\n",
      "        [31.9621, 26.9108],\n",
      "        [25.3098, 30.1879],\n",
      "        [27.8957, 27.8619]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9789, 29.9578],\n",
      "        [31.9622, 26.9108],\n",
      "        [25.3099, 30.1879],\n",
      "        [27.8957, 27.8619]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9789, 29.9578],\n",
      "        [31.9621, 26.9109],\n",
      "        [25.3099, 30.1880],\n",
      "        [27.8957, 27.8619]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9789, 29.9578],\n",
      "        [31.9622, 26.9108],\n",
      "        [25.3099, 30.1879],\n",
      "        [27.8957, 27.8619]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9789, 29.9578],\n",
      "        [31.9622, 26.9109],\n",
      "        [25.3099, 30.1880],\n",
      "        [27.8957, 27.8619]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9789, 29.9578],\n",
      "        [31.9622, 26.9109],\n",
      "        [25.3100, 30.1880],\n",
      "        [27.8957, 27.8619]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9789, 29.9578],\n",
      "        [31.9622, 26.9109],\n",
      "        [25.3100, 30.1880],\n",
      "        [27.8957, 27.8619]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1160, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9789, 29.9578],\n",
      "        [31.9622, 26.9109],\n",
      "        [25.3100, 30.1880],\n",
      "        [27.8957, 27.8619]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9789, 29.9578],\n",
      "        [31.9622, 26.9110],\n",
      "        [25.3100, 30.1880],\n",
      "        [27.8957, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9789, 29.9578],\n",
      "        [31.9622, 26.9110],\n",
      "        [25.3101, 30.1880],\n",
      "        [27.8958, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9871, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9789, 29.9579],\n",
      "        [31.9622, 26.9110],\n",
      "        [25.3100, 30.1880],\n",
      "        [27.8957, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9871, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9789, 29.9579],\n",
      "        [31.9623, 26.9110],\n",
      "        [25.3101, 30.1880],\n",
      "        [27.8958, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9789, 29.9579],\n",
      "        [31.9622, 26.9111],\n",
      "        [25.3101, 30.1881],\n",
      "        [27.8958, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9790, 29.9579],\n",
      "        [31.9623, 26.9111],\n",
      "        [25.3101, 30.1880],\n",
      "        [27.8958, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9790, 29.9579],\n",
      "        [31.9623, 26.9111],\n",
      "        [25.3101, 30.1881],\n",
      "        [27.8958, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9789, 29.9579],\n",
      "        [31.9623, 26.9111],\n",
      "        [25.3102, 30.1880],\n",
      "        [27.8958, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9789, 29.9579],\n",
      "        [31.9623, 26.9111],\n",
      "        [25.3101, 30.1881],\n",
      "        [27.8958, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9790, 29.9579],\n",
      "        [31.9623, 26.9111],\n",
      "        [25.3102, 30.1881],\n",
      "        [27.8958, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9790, 29.9579],\n",
      "        [31.9623, 26.9112],\n",
      "        [25.3102, 30.1881],\n",
      "        [27.8958, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9790, 29.9579],\n",
      "        [31.9623, 26.9112],\n",
      "        [25.3102, 30.1881],\n",
      "        [27.8958, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9790, 29.9579],\n",
      "        [31.9623, 26.9112],\n",
      "        [25.3102, 30.1881],\n",
      "        [27.8958, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9790, 29.9579],\n",
      "        [31.9624, 26.9112],\n",
      "        [25.3103, 30.1881],\n",
      "        [27.8958, 27.8620]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9790, 29.9580],\n",
      "        [31.9623, 26.9113],\n",
      "        [25.3103, 30.1881],\n",
      "        [27.8958, 27.8621]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9790, 29.9579],\n",
      "        [31.9624, 26.9113],\n",
      "        [25.3103, 30.1881],\n",
      "        [27.8958, 27.8621]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9790, 29.9580],\n",
      "        [31.9623, 26.9113],\n",
      "        [25.3103, 30.1882],\n",
      "        [27.8958, 27.8621]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9790, 29.9580],\n",
      "        [31.9624, 26.9113],\n",
      "        [25.3104, 30.1881],\n",
      "        [27.8959, 27.8621]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9790, 29.9580],\n",
      "        [31.9624, 26.9114],\n",
      "        [25.3103, 30.1882],\n",
      "        [27.8958, 27.8621]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9790, 29.9580],\n",
      "        [31.9624, 26.9114],\n",
      "        [25.3104, 30.1882],\n",
      "        [27.8959, 27.8621]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9790, 29.9580],\n",
      "        [31.9624, 26.9114],\n",
      "        [25.3104, 30.1882],\n",
      "        [27.8959, 27.8621]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1161, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9790, 29.9580],\n",
      "        [31.9625, 26.9114],\n",
      "        [25.3105, 30.1882],\n",
      "        [27.8959, 27.8621]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9790, 29.9580],\n",
      "        [31.9624, 26.9114],\n",
      "        [25.3104, 30.1882],\n",
      "        [27.8959, 27.8621]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9791, 29.9580],\n",
      "        [31.9625, 26.9114],\n",
      "        [25.3105, 30.1882],\n",
      "        [27.8959, 27.8621]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9790, 29.9580],\n",
      "        [31.9624, 26.9115],\n",
      "        [25.3105, 30.1882],\n",
      "        [27.8959, 27.8622]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9791, 29.9580],\n",
      "        [31.9625, 26.9115],\n",
      "        [25.3105, 30.1882],\n",
      "        [27.8959, 27.8622]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9791, 29.9581],\n",
      "        [31.9625, 26.9115],\n",
      "        [25.3105, 30.1883],\n",
      "        [27.8959, 27.8622]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9791, 29.9581],\n",
      "        [31.9625, 26.9115],\n",
      "        [25.3106, 30.1883],\n",
      "        [27.8959, 27.8622]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9791, 29.9581],\n",
      "        [31.9625, 26.9116],\n",
      "        [25.3106, 30.1883],\n",
      "        [27.8959, 27.8622]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9791, 29.9581],\n",
      "        [31.9625, 26.9116],\n",
      "        [25.3106, 30.1883],\n",
      "        [27.8959, 27.8622]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9791, 29.9581],\n",
      "        [31.9625, 26.9116],\n",
      "        [25.3106, 30.1883],\n",
      "        [27.8959, 27.8622]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9791, 29.9581],\n",
      "        [31.9626, 26.9116],\n",
      "        [25.3107, 30.1883],\n",
      "        [27.8960, 27.8622]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9872, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9791, 29.9581],\n",
      "        [31.9625, 26.9117],\n",
      "        [25.3106, 30.1883],\n",
      "        [27.8960, 27.8622]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9872, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9791, 29.9581],\n",
      "        [31.9626, 26.9117],\n",
      "        [25.3107, 30.1883],\n",
      "        [27.8960, 27.8622]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9791, 29.9581],\n",
      "        [31.9626, 26.9117],\n",
      "        [25.3107, 30.1884],\n",
      "        [27.8960, 27.8623]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9791, 29.9581],\n",
      "        [31.9626, 26.9117],\n",
      "        [25.3107, 30.1883],\n",
      "        [27.8960, 27.8622]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9791, 29.9581],\n",
      "        [31.9626, 26.9117],\n",
      "        [25.3107, 30.1884],\n",
      "        [27.8960, 27.8623]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9791, 29.9581],\n",
      "        [31.9626, 26.9117],\n",
      "        [25.3108, 30.1884],\n",
      "        [27.8960, 27.8623]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9791, 29.9582],\n",
      "        [31.9626, 26.9118],\n",
      "        [25.3108, 30.1884],\n",
      "        [27.8960, 27.8623]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9791, 29.9582],\n",
      "        [31.9626, 26.9118],\n",
      "        [25.3108, 30.1884],\n",
      "        [27.8960, 27.8623]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9791, 29.9582],\n",
      "        [31.9626, 26.9118],\n",
      "        [25.3108, 30.1884],\n",
      "        [27.8960, 27.8623]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9792, 29.9582],\n",
      "        [31.9627, 26.9118],\n",
      "        [25.3109, 30.1884],\n",
      "        [27.8960, 27.8623]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9791, 29.9582],\n",
      "        [31.9626, 26.9119],\n",
      "        [25.3108, 30.1884],\n",
      "        [27.8960, 27.8623]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1162, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9792, 29.9582],\n",
      "        [31.9627, 26.9119],\n",
      "        [25.3109, 30.1884],\n",
      "        [27.8960, 27.8623]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9792, 29.9582],\n",
      "        [31.9626, 26.9119],\n",
      "        [25.3109, 30.1884],\n",
      "        [27.8960, 27.8623]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9792, 29.9582],\n",
      "        [31.9627, 26.9119],\n",
      "        [25.3109, 30.1884],\n",
      "        [27.8961, 27.8623]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9792, 29.9582],\n",
      "        [31.9627, 26.9120],\n",
      "        [25.3109, 30.1885],\n",
      "        [27.8960, 27.8624]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9792, 29.9582],\n",
      "        [31.9627, 26.9120],\n",
      "        [25.3110, 30.1885],\n",
      "        [27.8961, 27.8624]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9792, 29.9582],\n",
      "        [31.9627, 26.9120],\n",
      "        [25.3110, 30.1885],\n",
      "        [27.8961, 27.8624]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9792, 29.9582],\n",
      "        [31.9627, 26.9120],\n",
      "        [25.3110, 30.1885],\n",
      "        [27.8961, 27.8624]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9792, 29.9583],\n",
      "        [31.9627, 26.9120],\n",
      "        [25.3110, 30.1885],\n",
      "        [27.8961, 27.8624]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9792, 29.9583],\n",
      "        [31.9628, 26.9120],\n",
      "        [25.3111, 30.1885],\n",
      "        [27.8961, 27.8624]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9792, 29.9583],\n",
      "        [31.9627, 26.9121],\n",
      "        [25.3110, 30.1885],\n",
      "        [27.8961, 27.8624]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9792, 29.9583],\n",
      "        [31.9628, 26.9121],\n",
      "        [25.3111, 30.1885],\n",
      "        [27.8961, 27.8624]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9792, 29.9583],\n",
      "        [31.9628, 26.9121],\n",
      "        [25.3111, 30.1885],\n",
      "        [27.8961, 27.8624]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9792, 29.9583],\n",
      "        [31.9628, 26.9121],\n",
      "        [25.3112, 30.1885],\n",
      "        [27.8961, 27.8624]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9792, 29.9583],\n",
      "        [31.9628, 26.9122],\n",
      "        [25.3111, 30.1886],\n",
      "        [27.8961, 27.8625]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9793, 29.9583],\n",
      "        [31.9628, 26.9122],\n",
      "        [25.3112, 30.1886],\n",
      "        [27.8962, 27.8624]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9792, 29.9583],\n",
      "        [31.9628, 26.9122],\n",
      "        [25.3112, 30.1886],\n",
      "        [27.8961, 27.8625]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9793, 29.9583],\n",
      "        [31.9629, 26.9122],\n",
      "        [25.3112, 30.1886],\n",
      "        [27.8962, 27.8625]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9793, 29.9584],\n",
      "        [31.9628, 26.9123],\n",
      "        [25.3112, 30.1886],\n",
      "        [27.8962, 27.8625]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9873, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9793, 29.9584],\n",
      "        [31.9629, 26.9123],\n",
      "        [25.3113, 30.1886],\n",
      "        [27.8962, 27.8625]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9793, 29.9584],\n",
      "        [31.9628, 26.9123],\n",
      "        [25.3112, 30.1886],\n",
      "        [27.8962, 27.8625]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9793, 29.9584],\n",
      "        [31.9629, 26.9123],\n",
      "        [25.3113, 30.1886],\n",
      "        [27.8962, 27.8625]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9793, 29.9584],\n",
      "        [31.9629, 26.9123],\n",
      "        [25.3113, 30.1887],\n",
      "        [27.8962, 27.8625]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1163, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9793, 29.9584],\n",
      "        [31.9629, 26.9123],\n",
      "        [25.3114, 30.1886],\n",
      "        [27.8962, 27.8625]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9793, 29.9584],\n",
      "        [31.9629, 26.9124],\n",
      "        [25.3113, 30.1887],\n",
      "        [27.8962, 27.8625]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9793, 29.9584],\n",
      "        [31.9629, 26.9124],\n",
      "        [25.3114, 30.1887],\n",
      "        [27.8962, 27.8625]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9793, 29.9584],\n",
      "        [31.9629, 26.9124],\n",
      "        [25.3114, 30.1887],\n",
      "        [27.8962, 27.8625]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9793, 29.9584],\n",
      "        [31.9630, 26.9124],\n",
      "        [25.3114, 30.1887],\n",
      "        [27.8962, 27.8625]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9793, 29.9584],\n",
      "        [31.9629, 26.9125],\n",
      "        [25.3114, 30.1887],\n",
      "        [27.8962, 27.8626]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9793, 29.9584],\n",
      "        [31.9630, 26.9125],\n",
      "        [25.3115, 30.1887],\n",
      "        [27.8962, 27.8626]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9793, 29.9585],\n",
      "        [31.9629, 26.9125],\n",
      "        [25.3114, 30.1887],\n",
      "        [27.8962, 27.8626]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9793, 29.9585],\n",
      "        [31.9630, 26.9125],\n",
      "        [25.3115, 30.1887],\n",
      "        [27.8963, 27.8626]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9793, 29.9585],\n",
      "        [31.9630, 26.9125],\n",
      "        [25.3115, 30.1887],\n",
      "        [27.8963, 27.8626]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9793, 29.9585],\n",
      "        [31.9630, 26.9125],\n",
      "        [25.3116, 30.1887],\n",
      "        [27.8963, 27.8626]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9793, 29.9585],\n",
      "        [31.9630, 26.9126],\n",
      "        [25.3115, 30.1888],\n",
      "        [27.8963, 27.8626]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9794, 29.9585],\n",
      "        [31.9630, 26.9126],\n",
      "        [25.3116, 30.1887],\n",
      "        [27.8963, 27.8626]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9793, 29.9585],\n",
      "        [31.9630, 26.9126],\n",
      "        [25.3116, 30.1888],\n",
      "        [27.8963, 27.8626]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9794, 29.9585],\n",
      "        [31.9631, 26.9126],\n",
      "        [25.3116, 30.1888],\n",
      "        [27.8963, 27.8626]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9794, 29.9585],\n",
      "        [31.9630, 26.9127],\n",
      "        [25.3116, 30.1888],\n",
      "        [27.8963, 27.8627]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9794, 29.9585],\n",
      "        [31.9631, 26.9127],\n",
      "        [25.3117, 30.1888],\n",
      "        [27.8963, 27.8626]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9794, 29.9585],\n",
      "        [31.9630, 26.9127],\n",
      "        [25.3116, 30.1888],\n",
      "        [27.8963, 27.8627]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9794, 29.9585],\n",
      "        [31.9631, 26.9127],\n",
      "        [25.3117, 30.1888],\n",
      "        [27.8963, 27.8627]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9794, 29.9585],\n",
      "        [31.9631, 26.9127],\n",
      "        [25.3117, 30.1888],\n",
      "        [27.8963, 27.8627]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1164, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9794, 29.9585],\n",
      "        [31.9631, 26.9127],\n",
      "        [25.3117, 30.1888],\n",
      "        [27.8963, 27.8627]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9794, 29.9586],\n",
      "        [31.9631, 26.9128],\n",
      "        [25.3117, 30.1889],\n",
      "        [27.8963, 27.8627]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9794, 29.9586],\n",
      "        [31.9631, 26.9128],\n",
      "        [25.3118, 30.1888],\n",
      "        [27.8963, 27.8627]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9794, 29.9586],\n",
      "        [31.9631, 26.9128],\n",
      "        [25.3118, 30.1889],\n",
      "        [27.8963, 27.8627]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9794, 29.9586],\n",
      "        [31.9631, 26.9128],\n",
      "        [25.3118, 30.1889],\n",
      "        [27.8964, 27.8627]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9874, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9794, 29.9586],\n",
      "        [31.9631, 26.9129],\n",
      "        [25.3118, 30.1889],\n",
      "        [27.8963, 27.8627]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9874, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9794, 29.9586],\n",
      "        [31.9632, 26.9129],\n",
      "        [25.3119, 30.1889],\n",
      "        [27.8964, 27.8627]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9794, 29.9586],\n",
      "        [31.9631, 26.9129],\n",
      "        [25.3118, 30.1889],\n",
      "        [27.8964, 27.8627]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9794, 29.9586],\n",
      "        [31.9632, 26.9129],\n",
      "        [25.3119, 30.1889],\n",
      "        [27.8964, 27.8627]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9794, 29.9586],\n",
      "        [31.9632, 26.9130],\n",
      "        [25.3119, 30.1889],\n",
      "        [27.8964, 27.8628]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9794, 29.9586],\n",
      "        [31.9632, 26.9129],\n",
      "        [25.3119, 30.1889],\n",
      "        [27.8964, 27.8628]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9794, 29.9586],\n",
      "        [31.9632, 26.9130],\n",
      "        [25.3119, 30.1889],\n",
      "        [27.8964, 27.8628]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9794, 29.9586],\n",
      "        [31.9632, 26.9130],\n",
      "        [25.3120, 30.1889],\n",
      "        [27.8964, 27.8628]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9794, 29.9586],\n",
      "        [31.9632, 26.9130],\n",
      "        [25.3120, 30.1890],\n",
      "        [27.8964, 27.8628]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9795, 29.9586],\n",
      "        [31.9632, 26.9130],\n",
      "        [25.3120, 30.1890],\n",
      "        [27.8964, 27.8628]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9795, 29.9587],\n",
      "        [31.9632, 26.9131],\n",
      "        [25.3120, 30.1890],\n",
      "        [27.8964, 27.8628]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9795, 29.9587],\n",
      "        [31.9633, 26.9131],\n",
      "        [25.3121, 30.1890],\n",
      "        [27.8964, 27.8628]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9795, 29.9587],\n",
      "        [31.9632, 26.9131],\n",
      "        [25.3120, 30.1890],\n",
      "        [27.8964, 27.8628]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9795, 29.9587],\n",
      "        [31.9633, 26.9131],\n",
      "        [25.3121, 30.1890],\n",
      "        [27.8965, 27.8629]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9795, 29.9587],\n",
      "        [31.9633, 26.9132],\n",
      "        [25.3121, 30.1890],\n",
      "        [27.8964, 27.8629]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9795, 29.9587],\n",
      "        [31.9633, 26.9132],\n",
      "        [25.3121, 30.1890],\n",
      "        [27.8965, 27.8629]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9795, 29.9587],\n",
      "        [31.9633, 26.9132],\n",
      "        [25.3121, 30.1890],\n",
      "        [27.8965, 27.8629]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9875, 0.1165, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9795, 29.9587],\n",
      "        [31.9633, 26.9132],\n",
      "        [25.3122, 30.1890],\n",
      "        [27.8965, 27.8629]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9875, 0.1166, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 1 reward: tensor([[29.9795, 29.9587],\n",
      "        [31.9633, 26.9132],\n",
      "        [25.3122, 30.1891],\n",
      "        [27.8965, 27.8629]], grad_fn=<MmBackward0>)\n",
      "player 1 beliefs: tensor([0.9988, 0.9875, 0.1166, 0.9627], grad_fn=<SigmoidBackward0>)\n",
      "player 2 reward: tensor([[29.9795, 29.9587],\n",
      "        [31.9634, 26.9132],\n",
      "        [25.3122, 30.1891],\n",
      "        [27.8965, 27.8629]], grad_fn=<MmBackward0>)\n",
      "player 2 beliefs: tensor([0.9988, 0.9875, 0.1166, 0.9627], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGzCAYAAAAMr0ziAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcDUlEQVR4nO3de1wU9f4/8Nfuwl64LSA3URREE2+BoZJaWskvTA+Z1cnSCrEsUyujk2l57xh1KrJjltb5pp7So5Zaniw9RlpppqlYGt7voVwVluteP78/FlZXuS3Czi6+no/HPtid+czMewZjXs3OfD4yIYQAERERkQuTS10AERERUUMYWIiIiMjlMbAQERGRy2NgISIiIpfHwEJEREQuj4GFiIiIXB4DCxEREbk8BhYiIiJyeQwsRERE5PIYWIhagW3btkEmk2Hbtm1Sl9JqDRs2DOPHj5e6jBaTnZ0NDw8PHDx4UOpSiGrFwEJEksvOzsacOXNw+vTpJq9j5cqVWLBgQbPVdKUdO3bgf//7H15++WXbtJqQWFvN27Ztw/3334+wsDAolUqEhIQgOTkZ69ats7U5ffr0dYXMyMhIzJkz55rpeXl5+Nvf/oaYmBh4eXnB29sb8fHx+Pvf/47i4mJbuzvuuANjx461fe7evTuGDx+OWbNmNakeopbmIXUBRHT9Bg0ahMrKSiiVSqlLaZLs7GzMnTsXd9xxByIjI5u0jpUrV+LgwYOYMmVKs9YGAG+99RaGDBmCzp07N9h29uzZmDdvHrp06YKnn34aHTt2RFFREb755hs88MADWLFiBUaPHt3sNQLAr7/+imHDhqGsrAyPPvoo4uPjAQB79uzBG2+8gR9//BH/+9//6lx+woQJGDZsGE6cOIHo6OgWqZGoqRhYiJzIYrHAYDBArVY363rlcnmzr5Os8vPzsXHjRixevLjBtl988QXmzZuHBx98ECtXroSnp6dt3ksvvYTNmzfDaDS2SJ3FxcUYOXIkFAoFsrKyEBMTYzd//vz5+Pjjj+tdR2JiIgICArB8+XLMmzevReokaip+JUTkoDlz5kAmk+Hw4cN46KGH4OfnhzZt2uD5559HVVWVXVuZTIbJkydjxYoV6NGjB1QqFTZt2gQAyMnJwbhx4xAaGgqVSoUePXrgk08+sS2bl5cHDw8PzJ0795oajhw5AplMhvfffx9A3fewfP7554iPj4dGo0FQUBAeffRR5OTk2LW54447cMcdd1yzjbFjx15ztWPVqlWIj4+Hr68v/Pz80KtXL7z33nsNHrP6llu2bBn++te/AgDuvPNOyGQyu3356quvMHz4cISHh0OlUiE6OhqvvfYazGaz3T5s3LgRZ86csS1/Ze16vR6zZ89G586doVKpEBERgalTp0Kv1zdY+8aNG2EymZCYmNhg25kzZyIwMBCffPKJXVipkZSUhL/85S8NrqcplixZgpycHGRkZFwTVgAgNDQUM2bMqHcdnp6euOOOO/DVV1+1SI1E14NXWIia6KGHHkJkZCTS09Pxyy+/4J///CcuXbqEf//733btvv/+e6xZswaTJ09GUFAQIiMjkZeXh1tvvdUWaIKDg/Htt9/iiSeegE6nw5QpUxAaGorBgwdjzZo1mD17tt06V69eDYVCYTvR12bZsmVITU1F3759kZ6ejry8PLz33nvYsWMHsrKy4O/v79D+btmyBY888giGDBmCN998EwBw6NAh7NixA88//3yTlxs0aBCee+45/POf/8Qrr7yCbt26AYDt57Jly+Dj44O0tDT4+Pjg+++/x6xZs6DT6fDWW28BAF599VWUlJTgzz//xLvvvgsA8PHxAWC9qnXvvfdi+/bteOqpp9CtWzccOHAA7777Lo4ePYovv/yy3v3++eef0aZNG3Ts2LHedseOHcPhw4cxbtw4+Pr6NnA0m9+GDRug0Wjw4IMPXtd64uPj8dVXX0Gn08HPz6+ZqiNqBoKIHDJ79mwBQNx777120ydOnCgAiN9++802DYCQy+Xijz/+sGv7xBNPiLZt24rCwkK76Q8//LDQarWioqJCCCHEkiVLBABx4MABu3bdu3cXd911l+3z1q1bBQCxdetWIYQQBoNBhISEiJ49e4rKykpbu6+//loAELNmzbJNGzx4sBg8ePA1+5mSkiI6duxo+/z8888LPz8/YTKZ6jk612rMcp9//rld/VeqORZXevrpp4WXl5eoqqqyTRs+fLhdvTU+/fRTIZfLxU8//WQ3ffHixQKA2LFjR73133bbbSI+Pr7eNkII8dVXXwkA4t13322wbUsICAgQsbGx172elStXCgBi165d118UUTPiV0JETTRp0iS7z88++ywA4JtvvrGbPnjwYHTv3t32WQiBtWvXIjk5GUIIFBYW2l5JSUkoKSnBvn37AAD3338/PDw8sHr1atvyBw8eRHZ2NkaNGlVnbXv27EF+fj4mTpxod2/L8OHDERMTg40bNzq8v/7+/igvL8eWLVucslwNjUZje19aWorCwkLcfvvtqKiowOHDhxtc/vPPP0e3bt0QExNjd6zvuusuAMDWrVvrXb6oqAgBAQENbken0wGAJFdXarbfHNuu2dfCwsLrXhdRc2JgIWqiLl262H2Ojo6GXC6/5jHXqKgou88FBQUoLi7GRx99hODgYLtXamoqAOuNngAQFBSEIUOGYM2aNbblV69eDQ8PD9x///111nbmzBkAQNeuXa+ZFxMTY5vviIkTJ+Kmm27CPffcg/bt22PcuHG2+3FaYrkaf/zxB0aOHAmtVgs/Pz8EBwfj0UcfBQCUlJQ0uPyxY8fwxx9/XHOsb7rpJgCXj3V9hBANtqn5+qS0tLTBti3Bz8+vWbZds68ymey610XUnHgPC1EzqesP/JVXCADrPRUA8OijjyIlJaXWZW6++Wbb+4cffhipqanYv38/4uLisGbNGgwZMgRBQUHNVndtJ+Qrb2oFgJCQEOzfvx+bN2/Gt99+i2+//RZLly7F448/juXLl9e5/qYuB1iffBk8eDD8/Pwwb948REdHQ61WY9++fXj55Zdtx7I+FosFvXr1QkZGRq3zIyIi6l2+TZs2uHTpUoPbqbnR9cCBAw22bQkxMTHYv38/DAbDdT3eXrOvzfXvi6i5MLAQNdGxY8fsrp4cP34cFoulwX5EgoOD4evrC7PZ3KgnT+677z48/fTTtq+Fjh49iunTp9e7TM0NokeOHLF99VHjyJEjdjeQBgQE4OTJk9eso7arMEqlEsnJyUhOTobFYsHEiROxZMkSzJw5s94+Shparq6wt23bNhQVFWHdunUYNGiQbfqpU6euaVvXOqKjo/Hbb79hyJAhTbpqEBMTg7Vr1zbY7qabbkLXrl3x1Vdf4b333rPd9OssycnJ2LlzJ9auXYtHHnmkyes5deoU5HK57QoUkavgV0JETbRo0SK7zwsXLgQA3HPPPfUup1Ao8MADD2Dt2rW1doNeUFBg99nf3x9JSUlYs2YNVq1aBaVSifvuu6/ebfTp0wchISFYvHix3aO73377LQ4dOoThw4fbpkVHR+Pw4cN22/3tt9+wY8cOu3UWFRXZfZbL5bYrQfU9HtyY5by9vQHAridWwHqsAPuvZAwGAz744INrtuPt7V3rV0QPPfQQcnJyau2DpLKyEuXl5XXWDgD9+/fHpUuXag11V5s7dy6Kiorw5JNPwmQyXTP/f//7H77++usG19MUEyZMQNu2bfHiiy/i6NGj18zPz8/H3//+9wbXs3fvXvTo0QNarbYlyiRqMl5hIWqiU6dO4d5778XQoUOxc+dOfPbZZxg9ejRiY2MbXPaNN97A1q1bkZCQgPHjx6N79+64ePEi9u3bh++++w4XL160az9q1Cg8+uij+OCDD5CUlNTgI8menp548803kZqaisGDB+ORRx6xPdYcGRmJF154wdZ23LhxyMjIQFJSEp544gnk5+dj8eLF6NGjh+1GUgB48skncfHiRdx1111o3749zpw5g4ULFyIuLs72CHJtGrNcXFwcFAoF3nzzTZSUlEClUuGuu+7CgAEDEBAQgJSUFDz33HOQyWT49NNPa/0KKz4+HqtXr0ZaWhr69u0LHx8fJCcn47HHHsOaNWswYcIEbN26FQMHDoTZbMbhw4exZs0abN68GX369Kmz/uHDh8PDwwPfffcdnnrqqXqP+6hRo3DgwAHMnz8fWVlZeOSRR2w93W7atAmZmZlYuXJlncufPn0aUVFRSElJwbJly+rd1tUCAgKwfv16DBs2DHFxcXY93e7btw//+c9/0L9//3rXYTQa8cMPP2DixIkObZvIKSR8QonILdU81pydnS0efPBB4evrKwICAsTkyZPtHiEWwvpY86RJk2pdT15enpg0aZKIiIgQnp6eIiwsTAwZMkR89NFH17TV6XRCo9EIAOKzzz67Zv7VjzXXWL16tejdu7dQqVQiMDBQjBkzRvz555/XLP/ZZ5+JTp06CaVSKeLi4sTmzZuveaz5iy++EHfffbcICQkRSqVSdOjQQTz99NPiwoUL9R6vxi738ccfi06dOgmFQmG3Lzt27BC33nqr0Gg0Ijw8XEydOlVs3rz5mv0tKysTo0ePFv7+/gKAXe0Gg0G8+eabokePHkKlUomAgAARHx8v5s6dK0pKSuqtXwgh7r33XjFkyJAG29XIzMwUI0aMECEhIcLDw0MEBweL5ORk8dVXX9W73IEDBwQAMW3atEZv62rnz58XL7zwgrjpppuEWq0WXl5eIj4+XsyfP7/Bff32228FAHHs2LEmb5+opciEaMTt70RkM2fOHMydOxcFBQW8MfEG8dNPP+GOO+7A4cOHr3k6rDl98MEHmDp1Kk6cOIHQ0NAW205d7rvvPshkMqxfv97p2yZqCO9hISJqwO233467774b//jHP1p0O1u3bsVzzz0nSVg5dOgQvv76a7z22mtO3zZRY/AeFiKiRvj2229bfBuff/55i2+jLt26dav1RmEiV8ErLEREROTyeA8LERERuTxeYSEiIiKXx8BCRERELq/V3HRrsVhw/vx5+Pr6ctAuIiIiNyGEQGlpKcLDwyGX130dpdUElvPnzzc4iBkRERG5pnPnzqF9+/Z1zm81gcXX1xeAdYdrhnknIiIi16bT6RAREWE7j9el1QSWmq+B/Pz8GFiIiIjcTEO3c/CmWyIiInJ5DCxERETk8hhYiIiIyOUxsBAREZHLY2AhIiIil8fAQkRERC6PgYWIiIhcnsOB5ccff0RycjLCw8Mhk8nw5ZdfNrjMtm3bcMstt0ClUqFz585YtmzZNW0WLVqEyMhIqNVqJCQkYPfu3Y6WRkRERK2Uw4GlvLwcsbGxWLRoUaPanzp1CsOHD8edd96J/fv3Y8qUKXjyySexefNmW5vVq1cjLS0Ns2fPxr59+xAbG4ukpCTk5+c7Wh4RERG1QjIhhGjywjIZ1q9fj/vuu6/ONi+//DI2btyIgwcP2qY9/PDDKC4uxqZNmwAACQkJ6Nu3L95//30A1oEMIyIi8Oyzz2LatGmNqkWn00Gr1aKkpIQ93RIREbmJxp6/W/welp07dyIxMdFuWlJSEnbu3AkAMBgM2Lt3r10buVyOxMREW5va6PV66HQ6uxcRERG1Ti0eWHJzcxEaGmo3LTQ0FDqdDpWVlSgsLITZbK61TW5ubp3rTU9Ph1artb04UjMREVHr5baDH06fPh1paWm2zzWjPRIREV0PIQTMFgGLACxCQAjALIT1vcU6zfZZoLqt9b3limWFsP68Zr4QtnkWS81n67yaaZYrlrW1FeLyywK7dV6uVUCgZh3WacDlNuKKdrV+hv1+C2H/+W9JXeGjkiY6tPhWw8LCkJeXZzctLy8Pfn5+0Gg0UCgUUCgUtbYJCwurc70qlQoqlapFaiYicjdmi4DJYoHJLGCyCJjMFpgtAkaLgNksYLRYP5vM1hOq2XZitU6rOdGahYDFYl2Hpc521hO42WyB+YqTrtly+XXl+szmy+s11yxvscBsuXyCt72EaGB9NSdR63pq3l99ordUr8f+RF/P9CuWrZ2AHAIKWCCHBYrqV23v5TKLXVuZ3bICMlyeb51X/Vl2ua28eln5FZ9lV6yjZj3W7YmrtmG/TdkVy1y9TbnMAo8rP1+1TflV26sc8DF8VMHO/Kdt0+KBpX///vjmm2/spm3ZsgX9+/cHACiVSsTHxyMzM9N2867FYkFmZiYmT57c0uUR0Q3ObBEwmi3QmywwmqtfJgGD2QLDFdMufxa2abZlqqfXBAVTTXi4IiAYawKEWcBssdiCxJXt7ALHFe9rW96uncX6f7+OEfCAGQpYqn+a4QHL5Z8ys938y/Oqp8nqWRbmq+Zbf3pWz7/yxF5zsq85GdcXAuyn2YcH2zKyK6eJ2td1Zdvq9coVV7a7tha5rMnPp7QqZdBLtm2HA0tZWRmOHz9u+3zq1Cns378fgYGB6NChA6ZPn46cnBz8+9//BgBMmDAB77//PqZOnYpx48bh+++/x5o1a7Bx40bbOtLS0pCSkoI+ffqgX79+WLBgAcrLy5GamtoMu0hErsZUfbLXmyyoMpqr35tRZbRAX/358vRa2pjM0BsvBwb7YCFgMJltwaJmnqE6iNiHD0s9/0dtTw4LPGGCJ0zVJ1+T9QQsu/y+Zr51+hXvr2jvKTNBAzOUMMHjimmX12u2vVfK7Ld1TWCQWeChMEOhuBwUbCFBdjloWD/bt1HA0rK/5BuODJArAJmi+qe8+r28+r388jTbe9kVba9uI7v8udY28ibOl11VgyPzZfDx1Up2hB0OLHv27MGdd95p+1xzH0lKSgqWLVuGCxcu4OzZs7b5UVFR2LhxI1544QW89957aN++Pf71r38hKSnJ1mbUqFEoKCjArFmzkJubi7i4OGzatOmaG3GJqOWZzBZUGs2oNJhRUf26/NlkN6/SWD3NYEGl0WRrX2U0273XG82oMl0OI6Z6U4KAJ8xQwggVjFDCCKXMZHuvghEqmRFKmKCCofqnEd6yK9rDVN3m8jTVVetQykxQehrtQoYnTPCUVYcJ2eWgURMSbggyBSD3uOLVnJ8VV53UFfYny7rmNWm6/Kp5V3+ub3o9665znkzq31yrd139sLgS9sNCNzKj2YJyvQmlVSaUG0woqzKhVG/9Wa43oax6Xln1tLLqNrbP1W0qDWYYzFefmAVUMEINAzTQQyOz/lTDAHX1ew0M0Miqp8Fg91kDfXW7y+8vBwkT1LLLAUIFIzxhhBzu8GdJBiiU1S8P60+551Xva15K6wlbobR+vvK9wrO67dXruXLeFe9rDQVNCRJ1tOGJl5yssedvt31KiKi1MVsESquMKK4woqTSiOJK68+SSiNKKgzWaRVXTKt+FVcYUWk0oyZYeKMKXrIq+KAKXqiCj6wSXtBX/6xCG1QhQlYFb1S/ZJXwhh7eskpoFAaoFfZBRC0zSBsg5J6Ah8r6UqiueK8EPNRXzaueZptX87mOeQqVfXC4OljYBYarQ4dCumNCdANiYCFqIWaLQHGFAUXlBhSVGVBUrsfFcgMKywwoKrO+LyozoLBcj0tlVTBWlsIPFfCVVcAPFfCTlcMXlbafQbJyRKECfrb5FdbAIa+Et8oaPjxkLfy1hUIJeGgAz5qX1xXvr5jmob5qnhfgqb4878qgcU0Queq9nGO0EhEDC5HDzBaBonI98nV65OmqkKurQp5Oj3xdFfJKKqHTFcNYWgBZ5SVoUYoAlCJAVoYAWSkCUIYuslL0q56mlZXDFxXwRSXk6ma8iuHpDSi9AZWP9afSt57PNS/vWkLGFUHEQ2P9yoKISAL860N0lXK9CTnFlci5VIk/L1Ug51IZSgpzUXnpAkRpHpRVBWgjihEkK0GwrARRKEa8rLQ6kJRCKTNbV6R0fNtC7gmZWgvYXn6X36v8ALX/5WkqP0DlWx06rgggnl78uoKIWh0GFrrhCCGQq6vCqcJynMm7hIsXTkFfdA7Q5UBZfh7+xny0lV1EW9lF9JQVIxA6KK7sg6ER/9VYFCoITSDk3m0g8woENIGAVxvg6vdqf7tgIvNQ86ZHIqJaMLBQq1VSacTxvBJcOHcSZReOwlR4EsqSM/CrOoe2ogBdZIUYIKtl0Mxa/qsQkMGgagOLdzDkvqHw1IZB7hsK+IQC3iGAd5BdGJErvVp+B4mIbiAMLOT2qoxmnMzJQ96J31D+50Eoig7Dt+w0Qk0X0FOWj3iZ0X4BWfWrmlGmRIUmDCafcCj820PdpiPUbSIAbXtrIPEJhcyrDVS8f4OISDL8C0xupbzKgBNHfkfR0V0wXzgA75JjaG86g+6yAnS/unH1wyUmKFCsbItK345AYBQ0oV3gH94ZHgERgF97eHoFQsuvYYiIXBoDC7ksi9mCk8f/wPk/dsCck4WA4j8QbTqOm2WV9g2rs0axPAAXvTrBENgVmvBuCOrQDd5tu8DDrz2CeHWEiMit8a84uQyD0YRjB3/FxeytUOXsQmTFb+iMS+h8ZSMZoIcSf6qiURHYA6p2PREcFQv/yJvh7x0Ef4lqJyKilsXAQpL689QRnPv1v1Cd3oro8iz0kJXbzTcKBc6qOqM0sCeUEfEIjbkVbSJvRrTCU6KKiYhICgws5FQmowGHd22C7revEV64A5HiT7SvmSkDKqDCaU1PVLTth4CYweh48yBEq72lLJmIiFwAAwu1OINej0M7v4b+t3XocukH9ESpbZ5ZyHBM1Q0l4YMRHDcUkT0GoLtnE3pcIyKiVo2BhVqEsFhw8vftKNq+FF0LNyMWl7/quQRfHPe/HcpuSYhO+Ati/IMkrJSIiNwBAws1K11hLg5tXoLQE18g2nIW0dXTi6DF8TZ3wjvufsTceg/68ioKERE5gIGFmsW5w3uQ978F6Fm0CQnVHbVVCU8c9LsdnvGPoedt9yLBg//ciIioaXgGoaYTAkd3fwPj1rfRo2ofIgBABhxVdMbFrg+jW+JY9AkMlrpKIiJqBRhYqEmO7voGlu9fR4z+AADrzbNZ3rdDddsk9Lz1bsjkcokrJCKi1oSBhRxyLvsXlG14Gd2q9gMA9MIDe9rciw5/mYY+nbpKWxwREbVaDCzUKLrC8zi+ahriCjZALhPQCw/sbfMXdBwxEwM7dm54BURERNeBgYXqJSwW/L7hn+i0/03cggpABuzyvhNh97+BAdExUpdHREQ3CAYWqlPhn0dRsOJpxFbuAwAclUej/K75SLjtHokrIyKiGw0DC9Xq4DcfotPu2egGPSqFEruiJmHA6FehVHIMHyIicj4GFrJjrCpD9sdPIbZoIwDgoEcPqB74EHd0i5W4MiIiupExsJBN0bnDKFv2EGLNZ2AWMvzYbjwGpqZD6cl/JkREJC2eiQgAcPa3rfBd/zg6QocC+OP0He/hzjvvk7osIiIiAAwsBODwd8sR9dOLUMmMOCKPhlfKF+jbsZPUZREREdkwsNzgsr9ehJhfX4VcJvCr6lZ0nrAKAQEBUpdFRERkh4HlBnZww3vouW8WIAN+9EtGwuRPoFJyFGUiInI9DCw3qENfL7SGFQDb/B/AbZM/hoeHQuKqiIiIascR6m5Ax39ag5t+nQkA2BrwEMMKERG5PAaWG8yfv29Du8xJUMgEfvIZitsnLWZYISIil8fAcgPR5Z2Gz7rHoIEBe5R9ET9pGcMKERG5BQaWG4TFUInC/3sI/tDhqCwKURPWwEujkbosIiKiRmlSYFm0aBEiIyOhVquRkJCA3bt319nWaDRi3rx5iI6OhlqtRmxsLDZt2mTXxmw2Y+bMmYiKioJGo0F0dDRee+01CCGaUh7V4uD/PYNOhiO4JHwgHvoUbQIDpS6JiIio0RwOLKtXr0ZaWhpmz56Nffv2ITY2FklJScjPz6+1/YwZM7BkyRIsXLgQ2dnZmDBhAkaOHImsrCxbmzfffBMffvgh3n//fRw6dAhvvvkm/vGPf2DhwoVN3zOyOb7tM9yctx4WIcPBWzPQtVsvqUsiIiJyiEw4eBkjISEBffv2xfvvvw8AsFgsiIiIwLPPPotp06Zd0z48PByvvvoqJk2aZJv2wAMPQKPR4LPPPgMA/OUvf0FoaCj+7//+r842DdHpdNBqtSgpKYGfn58ju9SqlRf9CdPCBGhRhu+CHkPi5PelLomIiMimsedvh66wGAwG7N27F4mJiZdXIJcjMTERO3furHUZvV4PtVptN02j0WD79u22zwMGDEBmZiaOHj0KAPjtt9+wfft23HPPPXXWotfrodPp7F50FSFwbukT0KIMR2Sd0C/1TakrIiIiahKHOo4rLCyE2WxGaGio3fTQ0FAcPny41mWSkpKQkZGBQYMGITo6GpmZmVi3bh3MZrOtzbRp06DT6RATEwOFQgGz2Yz58+djzJgxddaSnp6OuXPnOlL+DefYlo8RU/YL9MITVfd+CD9vb6lLIiIiapIWf0rovffeQ5cuXRATEwOlUonJkycjNTUVcvnlTa9ZswYrVqzAypUrsW/fPixfvhxvv/02li9fXud6p0+fjpKSEtvr3LlzLb0rbsVQehFBO/8OAPgx/AnE3nKrxBURERE1nUNXWIKCgqBQKJCXl2c3PS8vD2FhYbUuExwcjC+//BJVVVUoKipCeHg4pk2bhk6dLo8G/NJLL2HatGl4+OGHAQC9evXCmTNnkJ6ejpSUlFrXq1KpoFKpHCn/hnLkP1PRS5TgJNqj35hZUpdDRER0XRy6wqJUKhEfH4/MzEzbNIvFgszMTPTv37/eZdVqNdq1aweTyYS1a9dixIgRtnkVFRV2V1wAQKFQwGKxOFIeVSs8tgc9cr4AAJwf8Bq0PvwqiIiI3JvDgx+mpaUhJSUFffr0Qb9+/bBgwQKUl5cjNTUVAPD444+jXbt2SE9PBwDs2rULOTk5iIuLQ05ODubMmQOLxYKpU6fa1pmcnIz58+ejQ4cO6NGjB7KyspCRkYFx48Y1027eWIo2vIIgmcAO1SAM/H8jpS6HiIjoujkcWEaNGoWCggLMmjULubm5iIuLw6ZNm2w34p49e9buaklVVRVmzJiBkydPwsfHB8OGDcOnn34Kf39/W5uFCxdi5syZmDhxIvLz8xEeHo6nn34as2bxqwxH5WT9D11Ld8EoFND+ZS5kMpnUJREREV03h/thcVXshwWAEDj5Rn900h/CVr97cWfap1JXREREVK8W6YeFXNvZ3V+hk/4QKoQKHUfOkbocIiKiZsPA0ooYtr0DAPg58D50ioqWuBoiIqLmw8DSSuQe/AGdK3+HXnggYtiLUpdDRETUrBhYWolL//sHAGCnz/9D1y5dJa6GiIioeTGwtAKlOUfQTbcdFiGDdgivrhARUevDwNIKnN5sHYF5j2c84nr3kbgaIiKi5sfA4uaEoQIdzq4HAJTf/Dj7XSEiolaJgcXNHd/2GbQoxXkRhL7/72GpyyEiImoRDCxuTr5vGQDgj7Yj4aPhYJBERNQ6MbC4sdILRxFd9QfMQob2dz0ldTlEREQthoHFjZ3ZuhwAkOURh5guXSSuhoiIqOUwsLgrIRB48ksAQHHn+3izLRERtWoMLG6q8OgvCDf9iUqhRMydo6Uuh4iIqEUxsLipC9utIzHv0/RH+7AQiashIiJqWQws7kgIhOVsAQBUdb1P2lqIiIicgIHFDV06tRfBlnxUCiW63TZC6nKIiIhaHAOLGzq/8wsAwH7lLQgPbiNxNURERC2PgcUN+Z75HwCgNHKoxJUQERE5BwOLm6nMP4kOhhMwCxk69r9f6nKIiIicgoHFzZz+5SsAwAF5N9wU1UHiaoiIiJyDgcXdnNgKACgIHcjO4oiI6IbBwOJOzCZElOwBAPh0/38SF0NEROQ8DCxupPDoTvigHMXCG93jB0tdDhERkdMwsLiR3KxvAQB/qHpD662WuBoiIiLnYWBxI17nfgAAlEcMkrgSIiIi52JgcRPCUI6IysMAgOCb75a4GiIiIudiYHETedk/wxMm5IkAdOvWS+pyiIiInIqBxU0UHrJ+HXRc3QtqpYfE1RARETkXA4ub8MzZBQAoD+sncSVERETOx8DiDixmtC87AADwu+k2iYshIiJyPgYWN1B8KgveqIROaND15lulLoeIiMjpGFjcwIUD1u74D3t0Q4CvRuJqiIiInI+BxQ2Yz1m74y9pEydtIURERBJhYHEDgSUHAQCeHfpIXAkREZE0mhRYFi1ahMjISKjVaiQkJGD37t11tjUajZg3bx6io6OhVqsRGxuLTZs2XdMuJycHjz76KNq0aQONRoNevXphz549TSmvVRFVJQgz5QAAQmN4/woREd2YHA4sq1evRlpaGmbPno19+/YhNjYWSUlJyM/Pr7X9jBkzsGTJEixcuBDZ2dmYMGECRo4ciaysLFubS5cuYeDAgfD09MS3336L7OxsvPPOOwgICGj6nrUSeUd/hRwCOSII0ZFRUpdDREQkCZkQQjiyQEJCAvr27Yv3338fAGCxWBAREYFnn30W06ZNu6Z9eHg4Xn31VUyaNMk27YEHHoBGo8Fnn30GAJg2bRp27NiBn376qck7otPpoNVqUVJSAj8/vyavx9X88cV89Dj4D/ysHIABr3wrdTlERETNqrHnb4eusBgMBuzduxeJiYmXVyCXIzExETt37qx1Gb1eD7XafmRhjUaD7du32z5v2LABffr0wV//+leEhISgd+/e+Pjjj+utRa/XQ6fT2b1aI9l565Wo0kB2x09ERDcuhwJLYWEhzGYzQkND7aaHhoYiNze31mWSkpKQkZGBY8eOwWKxYMuWLVi3bh0uXLhga3Py5El8+OGH6NKlCzZv3oxnnnkGzz33HJYvX15nLenp6dBqtbZXRESEI7viNgJL/gAAqDrcInElRERE0mnxp4Tee+89dOnSBTExMVAqlZg8eTJSU1Mhl1/etMViwS233ILXX38dvXv3xlNPPYXx48dj8eLFda53+vTpKCkpsb3OnTvX0rvidKLyEsLM5wEAYTH9Ja6GiIhIOg4FlqCgICgUCuTl5dlNz8vLQ1hYWK3LBAcH48svv0R5eTnOnDmDw4cPw8fHB506dbK1adu2Lbp37263XLdu3XD27Nk6a1GpVPDz87N7tTZ5x/YBAP4UQYju2DqvIBERETWGQ4FFqVQiPj4emZmZtmkWiwWZmZno37/+KwBqtRrt2rWDyWTC2rVrMWLECNu8gQMH4siRI3btjx49io4dOzpSXqtz6dR+AECOMgqeCnaZQ0RENy4PRxdIS0tDSkoK+vTpg379+mHBggUoLy9HamoqAODxxx9Hu3btkJ6eDgDYtWsXcnJyEBcXh5ycHMyZMwcWiwVTp061rfOFF17AgAED8Prrr+Ohhx7C7t278dFHH+Gjjz5qpt10T6Zc6/0rpX43SVwJERGRtBwOLKNGjUJBQQFmzZqF3NxcxMXFYdOmTbYbcc+ePWt3f0pVVRVmzJiBkydPwsfHB8OGDcOnn34Kf39/W5u+ffti/fr1mD59OubNm4eoqCgsWLAAY8aMuf49dGNexdVXnUK719+QiIiolXO4HxZX1er6YRECZXPbwQfl2D30v+h36yCpKyIiImp2LdIPCzmP4eI5+KAcRqFAuy6xUpdDREQkKQYWF5V/3PqE0Bm0RXhgK7hiREREdB0YWFyU7uzvAIBcdSfIZDKJqyEiIpIWA4uLEnnZAIAKfz4hRERExMDionx0xwEAijA+IURERMTA4oqEQLDBOtSAf0QPiYshIiKSHgOLCzKVXIAXqmAWMoRFxkhdDhERkeQYWFxQ4Vnr/Ss5CEbbQK3E1RAREUmPgcUFFZ87BADI82wPuZxPCBERETGwuCBj/lEAQKl3pLSFEBERuQgGFhfkUXwSAGDy7yRxJURERK6BgcUF+ZWfAQCoQtkHCxEREcDA4nosZoSYLgAA/Dt0k7gYIiIi18DA4mL0RafhCROqhCfCO3SRuhwiIiKXwMDiYgpP/wEAOIu2CPJVS1wNERGRa2BgcTG6nCMAgEJVOw56SEREVI2BxcWYLp4GAFR6t5e2ECIiIhfCwOJiFLo/AQAWbUeJKyEiInIdDCwuxrvCGlg82zCwEBER1WBgcTGBxlwAgHdotMSVEBERuQ4GFhciKovhK8oAAG3adZa4GiIiItfBwOJCSvOsXfIXCV+EhwRJXA0REZHrYGBxIZdyTgAA8uQhUHsqJK6GiIjIdTCwuJCKfGtguaRsK3ElREREroWBxYWYL1oHPaz0Yh8sREREV2JgcSEeunMAAIs2QuJKiIiIXAsDiwvxrswBAHgGRUpbCBERkYthYHEVQiDQYO2DxYd9sBAREdlhYHERoqoE3qgAALRpx8BCRER0JQYWF1FWYL1/pVh4o21QG4mrISIici0MLC6iJN/6hFCBLBAaJftgISIiuhIDi4soLzgLACj2CJa4EiIiItfDwOIijJesTwiVq0IkroSIiMj1MLC4CKGzBhajF3u5JSIiulqTAsuiRYsQGRkJtVqNhIQE7N69u862RqMR8+bNQ3R0NNRqNWJjY7Fp06Y627/xxhuQyWSYMmVKU0pzW57ledY3fgwsREREV3M4sKxevRppaWmYPXs29u3bh9jYWCQlJSE/P7/W9jNmzMCSJUuwcOFCZGdnY8KECRg5ciSysrKuafvrr79iyZIluPnmmx3fEzfnVWUNLB4B7JafiIjoag4HloyMDIwfPx6pqano3r07Fi9eDC8vL3zyySe1tv/000/xyiuvYNiwYejUqROeeeYZDBs2DO+8845du7KyMowZMwYff/wxAgICmrY3bkxrKgAAeAUxsBAREV3NocBiMBiwd+9eJCYmXl6BXI7ExETs3Lmz1mX0ej3UarXdNI1Gg+3bt9tNmzRpEoYPH2637vro9XrodDq7l9syVkErrPVrQyKlrYWIiMgFORRYCgsLYTabERoaajc9NDQUubm5tS6TlJSEjIwMHDt2DBaLBVu2bMG6detw4cIFW5tVq1Zh3759SE9Pb3Qt6enp0Gq1tldEhPsOGKgvtt5wWyU8ERISJnE1RERErqfFnxJ677330KVLF8TExECpVGLy5MlITU2FXG7d9Llz5/D8889jxYoV11yJqc/06dNRUlJie507d66ldqHFleSeBgDkog0CvJXSFkNEROSCHAosQUFBUCgUyMvLs5uel5eHsLDarwwEBwfjyy+/RHl5Oc6cOYPDhw/Dx8cHnTp1AgDs3bsX+fn5uOWWW+Dh4QEPDw/88MMP+Oc//wkPDw+YzeZa16tSqeDn52f3clc13fJfUrSBTCaTuBoiIiLX41BgUSqViI+PR2Zmpm2axWJBZmYm+vfvX++yarUa7dq1g8lkwtq1azFixAgAwJAhQ3DgwAHs37/f9urTpw/GjBmD/fv3Q6Fo/d3UVxVZA0upkp3GERER1cbD0QXS0tKQkpKCPn36oF+/fliwYAHKy8uRmpoKAHj88cfRrl072/0ou3btQk5ODuLi4pCTk4M5c+bAYrFg6tSpAABfX1/07NnTbhve3t5o06bNNdNbK4vuPABArwltoCUREdGNyeHAMmrUKBQUFGDWrFnIzc1FXFwcNm3aZLsR9+zZs7b7UwCgqqoKM2bMwMmTJ+Hj44Nhw4bh008/hb+/f7PthLuTl1lvWBY+vOGWiIioNjIhhJC6iOag0+mg1WpRUlLidvezHH/zdnSu/B2ZPd/EkAcnSF0OERGR0zT2/M2xhFyAl6EIAKDy5xUWIiKi2jCwuACt+RIAwCsgXOJKiIiIXBMDi9SMlfBGBQDAL5iBhYiIqDYMLBIzlFj7tNELTwQGBktcDRERkWtiYJGYrvBPAEAhtPD3Yi+3REREtWFgkVhZkXVMpUvyAMjl7OWWiIioNgwsEtNfsnYaV+YRKHElRERErouBRWJGnfUeliplG4krISIicl0MLBITZdbAYvTiDbdERER1YWCRmKKiEAAgGFiIiIjqxMAiMVVVAQBA7seBD4mIiOrCwCIxb+NFAOyWn4iIqD4MLBKr6ZbfO5C93BIREdWFgUVK+jJoUAUA8A1qJ3ExRERErouBRUI13fJXCBWCAtgPCxERUV0YWCSkK8oBYO2WX8tu+YmIiOrEwCKhsovWKyw6uZbd8hMREdWDgUVCVdVfCZV7+EtbCBERkYtjYJGQqdTaB4veM0DiSoiIiFwbA4uELOVFAACjmoGFiIioPgwsEpJVWDuNs6j5hBAREVF9GFgk5Km3BhaZd5DElRAREbk2BhYJqQzWXm4VvgwsRERE9WFgkZDGVAIAUPlypGYiIqL6MLBIyMdsDSwa/xCJKyEiInJtDCxSMRnggwoAgE9AqMTFEBERuTYGFomYqx9pNgk5tIG8h4WIiKg+DCwSKb+YCwC4BB8EeKslroaIiMi1MbBIpKzY2i1/icwPngr+GoiIiOrDM6VEKorzAQBlcq3ElRAREbk+BhaJGHTWcYQqPRlYiIiIGsLAIhFzWSEADnxIRETUGAwsEhEV1U8JcRwhIiKiBjGwSERRaR1HSHi1kbgSIiIi18fAIhGPmoEPGViIiIga1KTAsmjRIkRGRkKtViMhIQG7d++us63RaMS8efMQHR0NtVqN2NhYbNq0ya5Neno6+vbtC19fX4SEhOC+++7DkSNHmlKa21AbigEASo4jRERE1CCHA8vq1auRlpaG2bNnY9++fYiNjUVSUhLy8/NrbT9jxgwsWbIECxcuRHZ2NiZMmICRI0ciKyvL1uaHH37ApEmT8Msvv2DLli0wGo24++67UV5e3vQ9c3He5mIAgErLwEJERNQQmRBCOLJAQkIC+vbti/fffx8AYLFYEBERgWeffRbTpk27pn14eDheffVVTJo0yTbtgQcegEajwWeffVbrNgoKChASEoIffvgBgwYNqrWNXq+HXq+3fdbpdIiIiEBJSQn8/Pwc2SXnEwL6ucFQwYjfH/gJN/e6WeqKiIiIJKHT6aDVahs8fzt0hcVgMGDv3r1ITEy8vAK5HImJidi5c2ety+j1eqjV9l3PazQabN++vc7tlJRYRzEODKz7CZr09HRotVrbKyIiwpFdkZahHCoYAQDegRz4kIiIqCEOBZbCwkKYzWaEhtqfZENDQ5Gbm1vrMklJScjIyMCxY8dgsViwZcsWrFu3DhcuXKi1vcViwZQpUzBw4ED07NmzzlqmT5+OkpIS2+vcuXOO7IqkzBXWG271wgN+vuw4joiIqCEt/pTQe++9hy5duiAmJgZKpRKTJ09Gamoq5PLaNz1p0iQcPHgQq1atqne9KpUKfn5+di93UV5i7TROB29ovZQSV0NEROT6HAosQUFBUCgUyMvLs5uel5eHsLCwWpcJDg7Gl19+ifLycpw5cwaHDx+Gj48POnXqdE3byZMn4+uvv8bWrVvRvn17R0pzKxUl1k7jdPCG0oNPlhMRETXEobOlUqlEfHw8MjMzbdMsFgsyMzPRv3//epdVq9Vo164dTCYT1q5dixEjRtjmCSEwefJkrF+/Ht9//z2ioqIc3A33UqWzXmGpkPtKXAkREZF78HB0gbS0NKSkpKBPnz7o168fFixYgPLycqSmpgIAHn/8cbRr1w7p6ekAgF27diEnJwdxcXHIycnBnDlzYLFYMHXqVNs6J02ahJUrV+Krr76Cr6+v7X4YrVYLjUbTHPvpUgxl1ntYKhUMLERERI3hcGAZNWoUCgoKMGvWLOTm5iIuLg6bNm2y3Yh79uxZu/tTqqqqMGPGDJw8eRI+Pj4YNmwYPv30U/j7+9vafPjhhwCAO+64w25bS5cuxdixYx3fKxdnLL8EANB7MLAQERE1hsOBBbDeazJ58uRa523bts3u8+DBg5GdnV3v+hzsCsbtWSqsgcWg9Je2ECIiIjfBOz6lUFUMALCo+EgzERFRYzCwSEBRZe0YT6gZWIiIiBqDgUUCCoM1sMg0ARJXQkRE5B4YWCSgMloDi8KbgYWIiKgxGFgkoDKVAgA8GViIiIgahYFFAl6WMgCA2reNxJUQERG5BwYWZxMC3qI6sGiDJC6GiIjIPTCwOJu+FB6wAAB8tLzCQkRE1BgMLE5mKrd2y68XnvDzdZ8RpomIiKTEwOJk5dUjNZfAG34aT4mrISIicg8MLE5WUT1Scym84ang4SciImoMnjGdrEpnvcJSLufAh0RERI3FwOJkhjLrPSyVHKmZiIio0RhYnMx2060Hb7glIiJqLAYWJ7NUFAMAjEoGFiIiosZiYHG2qmIAgEXpL2kZRERE7oSBxcnkeuvAh9D4S1oHERGRO2FgcTJPfTEAQMbAQkRE1GgMLE6mrB6pWcGRmomIiBqNgcXJ1CYdAMDTO1DiSoiIiNwHA4uTeVmqR2r248CHREREjcXA4kwWC7xFOQBAw8BCRETUaAwszmQohQIWAICPNkjiYoiIiNwHA4sTGcsvAQCqhCf8fNk1PxERUWMxsDhRWXEBAKAE3vDTeEpcDRERkftgYHGiypJCAEApfKCQyySuhoiIyH0wsDhRVal14MMKhY/ElRAREbkXBhYnMpRZA0ulggMfEhEROYKBxYnMFdabbvUeDCxERESOYGBxIkt1YDEpGViIiIgcwcDiTJXFAACzyl/SMoiIiNwNA4sTKapHaoZGK2kdRERE7oaBxYk8DNaBD2UajtRMRETkCAYWJ1IarYFFwZGaiYiIHNKkwLJo0SJERkZCrVYjISEBu3fvrrOt0WjEvHnzEB0dDbVajdjYWGzatOm61umu1OZSAIDSh4GFiIjIEQ4HltWrVyMtLQ2zZ8/Gvn37EBsbi6SkJOTn59fafsaMGViyZAkWLlyI7OxsTJgwASNHjkRWVlaT1+muvC3WwKLyZWAhIiJyhEwIIRxZICEhAX379sX7778PALBYLIiIiMCzzz6LadOmXdM+PDwcr776KiZNmmSb9sADD0Cj0eCzzz5r0jpro9PpoNVqUVJSAj8/F3xs2GKBZV4g5BA4NHoPut3UReqKiIiIJNfY87dDV1gMBgP27t2LxMTEyyuQy5GYmIidO3fWuoxer4darbabptFosH379iavs2a9Op3O7uXS9DrIYc2G3v5BEhdDRETkXhwKLIWFhTCbzQgNDbWbHhoaitzc3FqXSUpKQkZGBo4dOwaLxYItW7Zg3bp1uHDhQpPXCQDp6enQarW2V0REhCO74nS2bvmFElofjiVERETkiBZ/Sui9995Dly5dEBMTA6VSicmTJyM1NRVy+fVtevr06SgpKbG9zp0710wVt4zy6pGaS+ANX7WHxNUQERG5F4dSQ1BQEBQKBfLy8uym5+XlISwsrNZlgoOD8eWXX6K8vBxnzpzB4cOH4ePjg06dOjV5nQCgUqng5+dn93JlFdWBpVTmA7lcJnE1RERE7sWhwKJUKhEfH4/MzEzbNIvFgszMTPTv37/eZdVqNdq1aweTyYS1a9dixIgR171Od1JVWgQAqJD7SlwJERGR+3H4u4m0tDSkpKSgT58+6NevHxYsWIDy8nKkpqYCAB5//HG0a9cO6enpAIBdu3YhJycHcXFxyMnJwZw5c2CxWDB16tRGr7M1MNbcw6JgYCEiInKUw4Fl1KhRKCgowKxZs5Cbm4u4uDhs2rTJdtPs2bNn7e5PqaqqwowZM3Dy5En4+Phg2LBh+PTTT+Hv79/odbYGpuqRmg2erv3VFRERkStyuB8WV+Xq/bAcWDYFvU4vxff+D+KuKf8ndTlEREQuoUX6YaHrUGm9wmJWcaRmIiIiRzGwOIlcX2J9o/GXtA4iIiJ3xMDiJJ7VIzXLNQESV0JEROR+GFicRFUdWBTeDCxERESOYmBxErXZOlKz0ocjNRMRETmKgcVJvKoDi9q3jcSVEBERuR8GFmewmOGNCgCAxo+BhYiIyFEMLM5QVQI5rN3d+PgHSVwMERGR+2FgcQJ9dbf8FUIFra+3xNUQERG5HwYWJygvto7UXAJv+CgdHg2BiIjohsfA4gSVOutIzaUyH8jlMomrISIicj8MLE5QVWoNLOVyjtRMRETUFAwsTmAotd7DovdwvUEZiYiI3AEDixOYK6oDiycHPiQiImoKBhYnsFRYR2o2KXmFhYiIqCkYWJxAXmUNLBa1v7SFEBERuSkGFieQ60sAADKNv7SFEBERuSkGFifwNFgDi9yLAx8SERE1BQOLE6hM1oEPPbwDJK6EiIjIPTGwOIGXWQcAUPlyHCEiIqKmYGBxAm9LGQCO1ExERNRUDCwtzWSABlUAAC+O1ExERNQkDCwtrKYPFouQwU/LKyxERERNwcDSwspLrCM16+AFPy+VxNUQERG5JwaWFlahqwks3lB7KiSuhoiIyD0xsLSwyuorLGUcqZmIiKjJGFhamL60CABQqWBgISIiaioGlhZmKq8eqdmDIzUTERE1FQNLCzOXW58SMnhypGYiIqKmYmBpadUjNZs5UjMREVGTMbC0MFmVdeBDMLAQERE1GQNLC/PQFwMAZBoOfEhERNRUDCwtTGm0Dnyo4EjNRERETcbA0sLUJmtgUfoESlwJERGR+2pSYFm0aBEiIyOhVquRkJCA3bt319t+wYIF6Nq1KzQaDSIiIvDCCy+gqqrKNt9sNmPmzJmIioqCRqNBdHQ0XnvtNQghmlKeS/GxWO9hUfoFS1wJERGR+/JwdIHVq1cjLS0NixcvRkJCAhYsWICkpCQcOXIEISEh17RfuXIlpk2bhk8++QQDBgzA0aNHMXbsWMhkMmRkZAAA3nzzTXz44YdYvnw5evTogT179iA1NRVarRbPPffc9e+lVCxm+IoyAICXf6jExRAREbkvh6+wZGRkYPz48UhNTUX37t2xePFieHl54ZNPPqm1/c8//4yBAwdi9OjRiIyMxN13341HHnnE7qrMzz//jBEjRmD48OGIjIzEgw8+iLvvvrvBKzeuTlReghzWq0TawGvDHBERETWOQ4HFYDBg7969SExMvLwCuRyJiYnYuXNnrcsMGDAAe/futYWPkydP4ptvvsGwYcPs2mRmZuLo0aMAgN9++w3bt2/HPffcU2cter0eOp3O7uVqyovzAQAlwguBft4SV0NEROS+HPpKqLCwEGazGaGh9l9vhIaG4vDhw7UuM3r0aBQWFuK2226DEAImkwkTJkzAK6+8Ymszbdo06HQ6xMTEQKFQwGw2Y/78+RgzZkydtaSnp2Pu3LmOlO90ZUW58AFQDD905EjNRERETdbiTwlt27YNr7/+Oj744APs27cP69atw8aNG/Haa6/Z2qxZswYrVqzAypUrsW/fPixfvhxvv/02li9fXud6p0+fjpKSEtvr3LlzLb0rDisvzgMA6OQcR4iIiOh6OHSFJSgoCAqFAnl5eXbT8/LyEBYWVusyM2fOxGOPPYYnn3wSANCrVy+Ul5fjqaeewquvvgq5XI6XXnoJ06ZNw8MPP2xrc+bMGaSnpyMlJaXW9apUKqhUKkfKdzqDrgAAUOHJwEJERHQ9HLrColQqER8fj8zMTNs0i8WCzMxM9O/fv9ZlKioqIJfbb0ahsH49UvPYcl1tLBaLI+W5HGNZIQBA78lO44iIiK6Hw481p6WlISUlBX369EG/fv2wYMEClJeXIzU1FQDw+OOPo127dkhPTwcAJCcnIyMjA71790ZCQgKOHz+OmTNnIjk52RZckpOTMX/+fHTo0AE9evRAVlYWMjIyMG7cuGbcVecT5UUAAJOKgYWIiOh6OBxYRo0ahYKCAsyaNQu5ubmIi4vDpk2bbDfinj171u5qyYwZMyCTyTBjxgzk5OQgODjYFlBqLFy4EDNnzsTEiRORn5+P8PBwPP3005g1a1Yz7KJ05BUXAQAWTRuJKyEiInJvMtEaupMFoNPpoNVqUVJSAj8/P6nLAQAcejsJ3cp+wfc3zcJdo1+UuhwiIiKX09jzN8cSakEqYzEAQOHLbvmJiIiuBwNLC/KqDiwqLQMLERHR9WBgaUG+1QMfevmzW34iIqLrwcDSUkx6eKMSAOAbwIEPiYiIrgcDSwsxllo7jTMJOfwDgiSuhoiIyL0xsLSQ0sLzAIBCaKH1cu0eeYmIiFwdA0sL0RXmAAAuyQIgl8skroaIiMi9MbC0kMpL1isspR6BEldCRETk/hhYWoipJBcAUKXi/StERETXi4GlhYgy64jWRg37YCEiIrpeDCwtRF5ufUpI+LAPFiIiouvFwNJCVFXWwKLwYx8sRERE14uBpYV4G60jNasDwiWuhIiIyP0xsLQQrdkaWLzbMLAQERFdLwaWFiD0ZbZu+f2D20tcDRERkftjYGkBFZesjzRXCBWCAtkPCxER0fViYGkBJXlnAACF8IeXylPiaoiIiNwfA0sLKCuwBpYiD/bBQkRE1BwYWFqAvtAaWMpUYRJXQkRE1DowsLQAUWId+NDozSeEiIiImgMDSwvwLLMGFmjbSVsIERFRK8HA0gK8qqxPCXkGdpC4EiIiotaBgaUFBBit3fL7hnSUuBIiIqLWwUPqAloboS+DH0oBAAFtO0lcDRHRjcFsNsNoNEpdBtXC09MTCoXiutfDwNLMdHlnoAWgExqEhnCkZiKiliSEQG5uLoqLi6Uuherh7++PsLAwyGSyJq+DgaWZXTp/AloABbIgRHtef6IkIqK61YSVkJAQeHl5XdcJkZqfEAIVFRXIz88HALRt27bJ62JgaWbleccAAIXKdoiWuBYiotbMbDbbwkqbNm2kLofqoNFoAAD5+fkICQlp8tdDvOm2mZkKTgAAKrz5hBARUUuquWfFy8tL4kqoITW/o+u5z4iBpZl5lpwGAFgCoqQthIjoBsGvgVxfc/yOGFiamV/lOQCAOrSLxJUQERG1HgwszcliRojpPAAgIKKrxMUQEZE7WrZsGfz9/aUuw+UwsDSjyqKzUMIEg1CgXYebpC6HiIhc0NixYyGTySCTyaBUKtG5c2fMmzcPJpNJ6tIa5aOPPsIdd9wBPz8/yGQypz1SzsDSjPJO/A4A+FMWBq2PWuJqiIjIVQ0dOhQXLlzAsWPH8OKLL2LOnDl46623pC7LTl03yFZUVGDo0KF45ZVXnFoPA0sz0p21BpZcNR9oJiKiuqlUKoSFhaFjx4545plnkJiYiA0bNtTa9sSJExgxYgRCQ0Ph4+ODvn374rvvvrPNnzdvHnr27HnNcnFxcZg5c6bt87/+9S9069YNarUaMTEx+OCDD2zzTp8+DZlMhtWrV2Pw4MFQq9VYsWJFrfVMmTIF06ZNw6233trU3W+SJgWWRYsWITIyEmq1GgkJCdi9e3e97RcsWICuXbtCo9EgIiICL7zwAqqqquza5OTk4NFHH0WbNm2g0WjQq1cv7NmzpynlSSc/GwBQ5c8bbomIpCCEQIXB5PSXEOK66tZoNDAYDLXOKysrw7Bhw5CZmYmsrCwMHToUycnJOHv2LABg3LhxOHToEH799VfbMllZWfj999+RmpoKAFixYgVmzZqF+fPn49ChQ3j99dcxc+ZMLF++3G5b06ZNw/PPP49Dhw4hKSnpuvapuTnccdzq1auRlpaGxYsXIyEhAQsWLEBSUhKOHDmCkFq6ol+5ciWmTZuGTz75BAMGDMDRo0dt399lZGQAAC5duoSBAwfizjvvxLfffovg4GAcO3YMAQEB17+HTuSrs3Ya59G2h8SVEBHdmCqNZnSftdnp282elwQvpeN9sQohkJmZic2bN+PZZ5+ttU1sbCxiY2Ntn1977TWsX78eGzZswOTJk9G+fXskJSVh6dKl6Nu3LwBg6dKlGDx4MDp1so5pN3v2bLzzzju4//77AQBRUVHIzs7GkiVLkJKSYlv3lClTbG1cjcNHNyMjA+PHj7eltsWLF2Pjxo345JNPMG3atGva//zzzxg4cCBGjx4NAIiMjMQjjzyCXbt22dq8+eabiIiIwNKlS23ToqLcrB8TiwVtDWcAAIFRsQ00JiKiG9nXX38NHx8fGI1GWCwWjB49GnPmzKm1bVlZGebMmYONGzfiwoULMJlMqKystF1hAYDx48dj3LhxyMjIgFwux8qVK/Huu+8CAMrLy3HixAk88cQTGD9+vG0Zk8kErVZrt60+ffo0/842E4cCi8FgwN69ezF9+nTbNLlcjsTEROzcubPWZQYMGIDPPvsMu3fvRr9+/XDy5El88803eOyxx2xtNmzYgKSkJPz1r3/FDz/8gHbt2mHixIl2B/Zqer0eer3e9lmn0zmyK82u+M9D8IcBlUKJjp2v/S6RiIhansZTgex5zv8qQ+Pg2HF33nknPvzwQyiVSoSHh8PDo+7T8d/+9jds2bIFb7/9Njp37gyNRoMHH3zQ7iuk5ORkqFQqrF+/HkqlEkajEQ8++CAAa+ABgI8//hgJCQl26766m3xvb2+H9sOZHAoshYWFMJvNCA0NtZseGhqKw4cP17rM6NGjUVhYiNtuuw1CCJhMJkyYMMHu7uKTJ0/iww8/RFpaGl555RX8+uuveO6556BUKu0uVV0pPT0dc+fOdaT8FnX+j+3wB3BM0Rk3e/EJISIiKchksiZ9NeNs3t7e6Ny5c6Pa7tixA2PHjsXIkSMBWAPI6dOn7dp4eHggJSUFS5cuhVKpxMMPP2wbwyc0NBTh4eE4efIkxowZ06z74Uwt/lvdtm0bXn/9dXzwwQdISEjA8ePH8fzzz+O1116z3b1ssVjQp08fvP766wCA3r174+DBg1i8eHGdgWX69OlIS0uzfdbpdIiIiGjp3amT4Yz1ZqeL/ry6QkREzadLly5Yt24dkpOTIZPJMHPmTFgslmvaPfnkk+jWrRsAa8i50ty5c/Hcc89Bq9Vi6NCh0Ov12LNnDy5dumR3Lm2M3Nxc5Obm4vjx4wCAAwcOwNfXFx06dEBgYGAT97JhDgWWoKAgKBQK5OXl2U3Py8tDWFhYrcvMnDkTjz32GJ588kkAQK9evVBeXo6nnnoKr776KuRyOdq2bYvu3bvbLdetWzesXbu2zlpUKhVUKpUj5bcov4vWR5rl7W+RuBIiImpNMjIyMG7cOAwYMABBQUF4+eWXa70NokuXLhgwYAAuXrx4zVc/Tz75JLy8vPDWW2/hpZdegre3N3r16oUpU6Y4XM/ixYvtvuEYNGgQAOuNvmPHjnV4fY3lUGBRKpWIj49HZmYm7rvvPgDWqyOZmZmYPHlyrctUVFRALrd/errmO7Oax8AGDhyII0eO2LU5evQoOnbs6Eh5krHoyxFhsCbNkJiBEldDRESubNmyZfXOHzt2rN2JPzIyEt9//71dm0mTJl2znBAC58+fx8SJE2td7+jRo20PwFwtMjKy0Y9mz5kzp84bhFuSw18JpaWlISUlBX369EG/fv2wYMEClJeX254aevzxx9GuXTukp6cDsN4IlJGRgd69e9u+Epo5cyaSk5NtweWFF17AgAED8Prrr+Ohhx7C7t278dFHH+Gjjz5qxl1tOWf3f49ImJEr2iD6Jj7STEREzlVQUIBVq1YhNzfXdj5ubRwOLKNGjUJBQQFmzZqF3NxcxMXFYdOmTbYbcc+ePWt3RWXGjBmQyWSYMWMGcnJyEBwcjOTkZMyfP9/Wpm/fvli/fj2mT5+OefPmISoqCgsWLHCbm4Mu/bEFkQBO+MYjzMOxO8WJiIiuV0hICIKCgvDRRx+5XR9mjSUT19s9n4vQ6XTQarUoKSmBn5+fU7d9cn4fdDIew489/o5Bf6294x8iImpeVVVVOHXqFKKioqBW8+lMV1bf76qx52+OJXSdKi/lIbL6/pX2t7hWN8ZEREStBQPLdTr+0yrIZQKHZZ0Q1YljCBEREbUEBpbr5HHYOrrmhXZJkMlkEldDRETUOjGwXIeK4jx0Kd8HAAi7dZTE1RAREbVeDCzX4eimJfCQWXBYHo2YHnFSl0NERNRqMbA0kbCYEXJ0JQAgr8tofh1ERETUghhYmujoT18g3HIBpUKDm4c+IXU5RETUSixbtgz+/v5Sl+FyGFiaQFgs8PzpHwCAfSH3t9pOeoiIqPmNHTsWMpkMMpkMSqUSnTt3xrx582AymaQurUEXL17Es88+i65du0Kj0aBDhw547rnnUFJS0uLbdv0xuF1Q9nfL0cN0HOVCha73vyJ1OURE5GaGDh2KpUuXQq/X45tvvsGkSZPg6emJ6dOnS12ajdFohKenp9208+fP4/z583j77bfRvXt3nDlzBhMmTMD58+fxxRdftGg9vMLioMrSSwjdaR2lcm/4owhr217iioiIyN2oVCqEhYWhY8eOeOaZZ5CYmIgNGzbU2vbEiRMYMWIEQkND4ePjg759++K7776zzZ83bx569ux5zXJxcXGYOXOm7fO//vUvdOvWDWq1GjExMfjggw9s806fPg2ZTIbVq1dj8ODBUKvVWLFixTXr7NmzJ9auXYvk5GRER0fjrrvuwvz58/Hf//63xa8Q8QqLgw4texa3iEs4J2uL+EfnSV0OERFdSQjAWOH87Xp6Adfx8IVGo0FRUVGt88rKyjBs2DDMnz8fKpUK//73v5GcnIwjR46gQ4cOGDduHObOnYtff/0Vffv2BQBkZWXh999/x7p16wAAK1aswKxZs/D++++jd+/eyMrKwvjx4+Ht7Y2UlBTbtqZNm4Z33nkHvXv3bvRwBzVd6nt4tGykYGBxwP6vF+OWov/CImQovPMfiPD2kbokIiK6krECeD3c+dt95Tyg9HZ4MSEEMjMzsXnzZjz7bO1j0cXGxiI2Ntb2+bXXXsP69euxYcMGTJ48Ge3bt0dSUhKWLl1qCyxLly7F4MGD0alTJwDA7Nmz8c477+D+++8HAERFRSE7OxtLliyxCyxTpkyxtWmMwsJCvPbaa3jqqacc3ndHMbA00qEdG9D911cBGfBz+ydw2+B7pS6JiIjc1Ndffw0fHx8YjUZYLBaMHj0ac+bMqbVtWVkZ5syZg40bN+LChQswmUyorKzE2bNnbW3Gjx+PcePGISMjA3K5HCtXrsS7774LACgvL8eJEyfwxBNPYPz48bZlTCYTtFqt3bb69OnT6H3Q6XQYPnw4unfvXmftzYmBpRGyd/wXHf83HkqZCXu9bsOtY9+QuiQiIqqNp5f1aocU23XAnXfeiQ8//BBKpRLh4eH1fp3yt7/9DVu2bMHbb7+Nzp07Q6PR4MEHH4TBYLC1SU5Ohkqlwvr166FUKmE0GvHggw8CsAYeAPj444+RkJBgt26FQmH32du7cVeJSktLMXToUPj6+mL9+vXX3JzbEhhYGrD3v4vRa88rUMrM+F3ZGz2e/RweTvjFEBFRE8hkTfpqxtm8vb3RuXPnRrXdsWMHxo4di5EjRwKwBpDTp0/btfHw8EBKSgqWLl0KpVKJhx9+GBqNBgAQGhqK8PBwnDx5EmPGjLnu2nU6HZKSkqBSqbBhw4ZG3+tyvRhY6pH35wn02vMqlDIz9voMRo9J/4Fa41iKJiIiuh5dunTBunXrkJycDJlMhpkzZ8JisVzT7sknn0S3bt0AWEPOlebOnYvnnnsOWq0WQ4cOhV6vx549e3Dp0iWkpaU1uhadToe7774bFRUV+Oyzz6DT6aDT6QAAwcHB11yxaU4MLPUIbR+NPX1eh+nPLPR7ahHkLfiLICIiqk1GRgbGjRuHAQMGICgoCC+//LItJFypS5cuGDBgAC5evHjNVz9PPvkkvLy88NZbb+Gll16Ct7c3evXqhSlTpjhUy759+7Br1y4AuOYK0alTpxAZGenQ+hwhE0KIFlu7E+l0Omi1WtvjVURE1LpVVVXh1KlTiIqKctrXEq5MCIEuXbpg4sSJDl01cYb6fleNPX/zCgsREZGbKygowKpVq5Cbm4vU1FSpy2kRDCxERERuLiQkBEFBQfjoo49a7fh2DCxERERurpXc3VEvjiVERERELo+BhYiIiFweAwsREbm12vokIdfSHL8j3sNCRERuSalUQi6X4/z58wgODoZSqYTsOkZMpuYnhIDBYEBBQQHkcjmUSmWT18XAQkREbkkulyMqKgoXLlzA+fMSjB9Ejebl5YUOHTpALm/6FzsMLERE5LaUSiU6dOgAk8kEs9ksdTlUC4VCAQ8Pj+u++sXAQkREbk0mk8HT09MpIwaTdHjTLREREbk8BhYiIiJyeQwsRERE5PJazT0sNd0S1zbkNhEREbmmmvN2Q8MLtJrAUlpaCgCIiIiQuBIiIiJyVGlpKbRabZ3zZaKVjJhksVhw/vx5+Pr6NmvHQTqdDhERETh37hz8/Pyabb1kj8fZeXisnYPH2Tl4nJ2jJY+zEAKlpaUIDw+vt5+WVnOFRS6Xo3379i22fj8/P/7H4AQ8zs7DY+0cPM7OwePsHC11nOu7slKDN90SERGRy2NgISIiIpfHwNIAlUqF2bNnQ6VSSV1Kq8bj7Dw81s7B4+wcPM7O4QrHudXcdEtEREStF6+wEBERkctjYCEiIiKXx8BCRERELo+BhYiIiFweAwsRERG5PAaWBixatAiRkZFQq9VISEjA7t27pS7JbcyZMwcymczuFRMTY5tfVVWFSZMmoU2bNvDx8cEDDzyAvLw8u3WcPXsWw4cPh5eXF0JCQvDSSy/BZDI5e1dczo8//ojk5GSEh4dDJpPhyy+/tJsvhMCsWbPQtm1baDQaJCYm4tixY3ZtLl68iDFjxsDPzw/+/v544oknUFZWZtfm999/x+233w61Wo2IiAj84x//aOldcykNHeexY8de82986NChdm14nBuWnp6Ovn37wtfXFyEhIbjvvvtw5MgRuzbN9fdi27ZtuOWWW6BSqdC5c2csW7aspXfPZTTmON9xxx3X/JueMGGCXRvJjrOgOq1atUoolUrxySefiD/++EOMHz9e+Pv7i7y8PKlLcwuzZ88WPXr0EBcuXLC9CgoKbPMnTJggIiIiRGZmptizZ4+49dZbxYABA2zzTSaT6Nmzp0hMTBRZWVnim2++EUFBQWL69OlS7I5L+eabb8Srr74q1q1bJwCI9evX281/4403hFarFV9++aX47bffxL333iuioqJEZWWlrc3QoUNFbGys+OWXX8RPP/0kOnfuLB555BHb/JKSEhEaGirGjBkjDh48KP7zn/8IjUYjlixZ4qzdlFxDxzklJUUMHTrU7t/4xYsX7drwODcsKSlJLF26VBw8eFDs379fDBs2THTo0EGUlZXZ2jTH34uTJ08KLy8vkZaWJrKzs8XChQuFQqEQmzZtcur+SqUxx3nw4MFi/Pjxdv+mS0pKbPOlPM4MLPXo16+fmDRpku2z2WwW4eHhIj09XcKq3Mfs2bNFbGxsrfOKi4uFp6en+Pzzz23TDh06JACInTt3CiGsJwu5XC5yc3NtbT788EPh5+cn9Hp9i9buTq4+kVosFhEWFibeeust27Ti4mKhUqnEf/7zHyGEENnZ2QKA+PXXX21tvv32WyGTyUROTo4QQogPPvhABAQE2B3rl19+WXTt2rWF98g11RVYRowYUecyPM5Nk5+fLwCIH374QQjRfH8vpk6dKnr06GG3rVGjRomkpKSW3iWXdPVxFsIaWJ5//vk6l5HyOPMroToYDAbs3bsXiYmJtmlyuRyJiYnYuXOnhJW5l2PHjiE8PBydOnXCmDFjcPbsWQDA3r17YTQa7Y5vTEwMOnToYDu+O3fuRK9evRAaGmprk5SUBJ1Ohz/++MO5O+JGTp06hdzcXLtjq9VqkZCQYHds/f390adPH1ubxMREyOVy7Nq1y9Zm0KBBUCqVtjZJSUk4cuQILl265KS9cX3btm1DSEgIunbtimeeeQZFRUW2eTzOTVNSUgIACAwMBNB8fy927txpt46aNjfq3/Srj3ONFStWICgoCD179sT06dNRUVFhmyflcW41ozU3t8LCQpjNZrtfCgCEhobi8OHDElXlXhISErBs2TJ07doVFy5cwNy5c3H77bfj4MGDyM3NhVKphL+/v90yoaGhyM3NBQDk5ubWevxr5lHtao5NbcfuymMbEhJiN9/DwwOBgYF2baKioq5ZR828gICAFqnfnQwdOhT3338/oqKicOLECbzyyiu45557sHPnTigUCh7nJrBYLJgyZQoGDhyInj17AkCz/b2oq41Op0NlZSU0Gk1L7JJLqu04A8Do0aPRsWNHhIeH4/fff8fLL7+MI0eOYN26dQCkPc4MLNRi7rnnHtv7m2++GQkJCejYsSPWrFlzQ/1hoNbr4Ycftr3v1asXbr75ZkRHR2Pbtm0YMmSIhJW5r0mTJuHgwYPYvn271KW0anUd56eeesr2vlevXmjbti2GDBmCEydOIDo62tll2uFXQnUICgqCQqG45i70vLw8hIWFSVSVe/P398dNN92E48ePIywsDAaDAcXFxXZtrjy+YWFhtR7/mnlUu5pjU9+/3bCwMOTn59vNN5lMuHjxIo//dejUqROCgoJw/PhxADzOjpo8eTK+/vprbN26Fe3bt7dNb66/F3W18fPzu6H+J6qu41ybhIQEALD7Ny3VcWZgqYNSqUR8fDwyMzNt0ywWCzIzM9G/f38JK3NfZWVlOHHiBNq2bYv4+Hh4enraHd8jR47g7NmztuPbv39/HDhwwO4P/pYtW+Dn54fu3bs7vX53ERUVhbCwMLtjq9PpsGvXLrtjW1xcjL1799rafP/997BYLLY/UP3798ePP/4Io9Foa7NlyxZ07dr1hvuaorH+/PNPFBUVoW3btgB4nBtLCIHJkydj/fr1+P7776/5iqy5/l7079/fbh01bW6Uv+kNHefa7N+/HwDs/k1Ldpyv65bdVm7VqlVCpVKJZcuWiezsbPHUU08Jf39/u7ujqW4vvvii2LZtmzh16pTYsWOHSExMFEFBQSI/P18IYX1MsUOHDuL7778Xe/bsEf379xf9+/e3LV/z+Nzdd98t9u/fLzZt2iSCg4P5WLMQorS0VGRlZYmsrCwBQGRkZIisrCxx5swZIYT1sWZ/f3/x1Vdfid9//12MGDGi1seae/fuLXbt2iW2b98uunTpYve4bXFxsQgNDRWPPfaYOHjwoFi1apXw8vK6oR63re84l5aWir/97W9i586d4tSpU+K7774Tt9xyi+jSpYuoqqqyrYPHuWHPPPOM0Gq1Ytu2bXaP01ZUVNjaNMffi5rHbV966SVx6NAhsWjRohvqseaGjvPx48fFvHnzxJ49e8SpU6fEV199JTp16iQGDRpkW4eUx5mBpQELFy4UHTp0EEqlUvTr10/88ssvUpfkNkaNGiXatm0rlEqlaNeunRg1apQ4fvy4bX5lZaWYOHGiCAgIEF5eXmLkyJHiwoULdus4ffq0uOeee4RGoxFBQUHixRdfFEaj0dm74nK2bt0qAFzzSklJEUJYH22eOXOmCA0NFSqVSgwZMkQcOXLEbh1FRUXikUceET4+PsLPz0+kpqaK0tJSuza//fabuO2224RKpRLt2rUTb7zxhrN20SXUd5wrKirE3XffLYKDg4Wnp6fo2LGjGD9+/DX/Q8Pj3LDajjEAsXTpUlub5vp7sXXrVhEXFyeUSqXo1KmT3TZau4aO89mzZ8WgQYNEYGCgUKlUonPnzuKll16y64dFCOmOs6x6J4iIiIhcFu9hISIiIpfHwEJEREQuj4GFiIiIXB4DCxEREbk8BhYiIiJyeQwsRERE5PIYWIiIiMjlMbAQERGRy2NgISIiIpfHwEJEREQuj4GFiIiIXN7/ByTWThaNu1DcAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from modules.Player import Player\n",
    "from modules.PlayerEnv import PlayerEnv\n",
    "from torch import optim\n",
    "\n",
    "pl1,pl2=Player(P1_beliefs,[r1,t1,p1,s1]),Player(P2_beliefs,[r2,p2,t2,s2])\n",
    "\n",
    "# Define optimizers for each player\n",
    "# Assuming that Player class has a method 'parameters()' that returns its parameters\n",
    "optimizer_p1 = optim.SGD(pl1.parameters(), lr=0.01)\n",
    "optimizer_p2 = optim.SGD(pl2.parameters(), lr=0.01)\n",
    "\n",
    "print(pl1.getBeliefs())\n",
    "\n",
    "env=PlayerEnv(pl1,pl2,gamma)\n",
    "\n",
    "print(\"grim trigger - expected cumulative rewards with cooperate,cooperate start\")\n",
    "print(f\"player 1: {env.play()[0, 0]}\")\n",
    "print(f\"player 2: {env.play()[0, 1]}\")\n",
    "\n",
    "print(\"grim trigger - expected cumulative rewards with cooperate,betray start\")\n",
    "print(f\"player 1: {env.play()[1, 0]}\")\n",
    "print(f\"player 2: {env.play()[1, 1]}\")\n",
    "\n",
    "print(\"grim trigger - expected cumulative rewards with betray,cooperate start\")\n",
    "print(f\"player 1: {env.play()[2, 0]}\")\n",
    "print(f\"player 2: {env.play()[2, 1]}\")\n",
    "\n",
    "print(\"grim trigger - expected cumulative rewards with betray,betray start\")\n",
    "print(f\"player 1: {env.play()[3, 0]}\")\n",
    "print(f\"player 2: {env.play()[3, 1]}\")\n",
    "\n",
    "print(env.play())\n",
    "\n",
    "print(\"done testing\")\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2500\n",
    "plot=[[],[]] #plotting\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    \"\"\"\n",
    "    The first agent adjusts its parameters attempting to maximize the objective\n",
    "    We fix player 2 while taking the gradient of player 1's reward, with respect to player 1's parameters\n",
    "    \"\"\"\n",
    "    reward = env.play()\n",
    "    plot[0].append(pl1.getBeliefs()) #plotting\n",
    "    optimizer_p1.zero_grad()\n",
    "    loss_p1 = -reward[1, 0]\n",
    "    loss_p1.backward()\n",
    "    print(f'player 1 reward: {reward}')\n",
    "    print(f'player 1 beliefs: {pl1.getBeliefs()}')\n",
    "    optimizer_p1.step()\n",
    "    \n",
    "    \"\"\"\n",
    "    The second agent adjusts its parameters attempting to maximize the objective\n",
    "    We fix player 1 while taking the gradient of player 2's reward, with respect to player 2's parameters\n",
    "    \"\"\"\n",
    "    reward = env.play()\n",
    "    plot[1].append(pl2.getBeliefs()) #plotting\n",
    "    optimizer_p2.zero_grad()\n",
    "    loss_p2 = -reward[1, 1]\n",
    "    loss_p2.backward()\n",
    "    print(f'player 2 reward: {reward}')\n",
    "    print(f'player 2 beliefs: {pl1.getBeliefs()}')\n",
    "    optimizer_p2.step()\n",
    "\n",
    "    # Logging\n",
    "    #if epoch % 10 == 0:\n",
    "    #    print(f\"Epoch {epoch}: pl1 reward = {rp1.sum().item()}, pl2 reward = {rp2.sum().item()}\")\n",
    "\n",
    "doplots(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 0, 1]\n",
      "[3, 0, 5, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/CGDs/gmres_torch.py:124: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1695454711129/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2198.)\n",
      "  y, _ = torch.triangular_solve(beta[0:j + 1].unsqueeze(-1), H[0:j + 1, 0:j + 1])  # j x j\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from CGDs import GACGD\n",
    "from modules.Player import Player\n",
    "from modules.PlayerEnv import PlayerEnv\n",
    "lr = 0.0001\n",
    "\n",
    "pl1=Player(P1_beliefs,[r1,t1,p1,s1])\n",
    "pl2=Player(P2_beliefs,[r2,p2,t2,s2])\n",
    "env=PlayerEnv(pl1,pl2,.2)\n",
    "optimizer = GACGD(x_params=pl1.parameters(), y_params=pl2.parameters(), lr_x=lr, lr_y=lr)\n",
    "\n",
    "# max_parems is maximizing the objective function while the min_params is trying to minimizing it. \n",
    "# BCGD(max_params=G.parameters(), min_params=D.parameters(), lr_max=lr, lr_min=lr, device=device)\n",
    "# ACGD: Adaptive CGD;\n",
    "plot=[[],[]] #plotting\n",
    "for epoch in range(10000):\n",
    "    \"\"\"\n",
    "    An aggregate is taken - the reward of the first player is added, the second player's is subtracted\n",
    "    First player tries to maximize this\n",
    "    Second player tries to minimize this\n",
    "    \"\"\"\n",
    "    reward=env.play()\n",
    "    plot[0].append(pl1.getBeliefs()) #plotting\n",
    "    plot[1].append(pl2.getBeliefs()) #plotting\n",
    "    pl1reward = reward[:, 0].sum()\n",
    "    pl2reward = reward[:, 1].sum()\n",
    "    optimizer.zero_grad()\n",
    "    optimizer.step(loss_x=-pl1reward,loss_y=-pl2reward)\n",
    "\n",
    "doplots(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pl1.ns(\"B\",\"B\"))\n",
    "print(pl1.ns(\"B\",\"C\"))\n",
    "print(pl1.ns(\"C\",\"B\"))\n",
    "print(pl1.ns(\"C\",\"C\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
